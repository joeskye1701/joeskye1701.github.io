{"pages":[{"title":"Joe","text":"时间就是金钱，效率就是生命。 联系方式 Email：joeskye1701@163.com 微信号：JavaUncle","link":"/about/index.html"},{"title":"归档","text":"","link":"/archives/index.html"},{"title":"分类","text":"","link":"/categories/index.html"},{"title":"标签","text":"","link":"/tags/index.html"}],"posts":[{"title":"++i和i++简单分析","text":"1 概念 2 示例 3 概念 3.1 3.2 1 概念如++i和i++如果用于自增这两个是没有区别的，都相当于i=i+1，但如果是通过这个来赋值如int a = i++;int b = ++j;那么a保存i原有值,b= j+1。 2 示例12345int i = 1; int j = 2; int a = i++; int b = ++j; 使用javap -c解开class后12345678910110: iconst_1 //从常量池取出1放入操作栈顶 1: istore_1 //把操作栈顶元素保存到本地变量i中 i=1 2: iconst_2 //从常量池取出2放入操作栈顶 3: istore_2 //把操作栈顶元素保存到本地变量j中 j=2 4: iload_1 //把本地变量i放入操作栈顶i=1 5: iinc 1, 1 //执行把本地变量i+1 ,操作栈顶不变 8: istore_3 //把操作栈顶元素保存到本地变量a中 9: iinc 2, 1 //执行把本地变量j+1 ,操作栈顶不变 12: iload_2 //把本来变量j放入栈顶 j=3 13: istore 4 //把栈顶j保存到本地变量，即b=3 15: return iconst：把int型数据放到操作栈顶。 istore：把栈顶int元素保存到本地变量，移除栈顶元素。 iload int：本地变量放入栈顶。 iinc：把int元素自动+1，如iinc 1,1第一位是本地变量index,第二位是+的数值。 iinc：不会改变栈顶元素的值，它只会改变本地变量的值。 后++ 的顺序是load ----iinc---store 先++ 的顺序是iinc ----load---store 先前说过iinc不会改变栈顶，会直接修改本地变量的值，所有后++会把先前load的值原封不动的保存进去，而先++会先改变本地变量值，然后把本地变量捞取出来，再保存。 3 概念3.1x=x+1，x+=1及x++的效率：x=x+1最低，因为它的执行如下： 读取右x的地址； x+1； 读取左x的地址； 将右值传给左边的x（编译器并不认为左右x的地址相同）。 x+=1其次，它的执行如下： 读取x的地址； x+1； 将得到的值传给x（因为x的地址已经读出）。 x++最高，它的执行如下： 读取右x的地址； x自增1。 3.2x=x+1和x+=1在什么情况下不成立而且x=x+1是错误的（类型隐式转换）123short x=1;x+=1;x=x+1; 因为x是short类型，当它+1会自动转变成int（低字节向高字节进行转换，强制类型转换），当是等于又是short类型，所以会报错。错误原因:x+=1，int和short转换，转换成int，执行到x=x+1时，x+1是int，高位不能转换成低位。","link":"/++iAndi++/"},{"title":"2进制,8进制,16进制相互转换","text":"1 概念 2 十六进制 2.1 Java例子 3 十进制 3.1 10转2 3.1.1 整数 例子1 例子2 3.1.2 负数 例子 3.1.3 小数 例子 3.2 10转8 3.2.1 整数 3.2.2 小数 例子 3.3 10转N 3.4 Java例子 4 八进制 4.1 Java例子 5 二进制 5.1 2转10 5.1.1 整数 例子1 例子2 5.1.2 负数 例子 5.2 2转8 例子 5.3 2转16(8421) Java例子 6 原码、反码、补码 6.1 原码 例子 6.2 反码 取反操作指 例子 6.3 补码 例子1 例子2 1 概念2进制，用两个阿拉伯数字：0、18进制，用八个阿拉伯数字：0、1、2、3、4、5、6、710进制，用十个阿拉伯数字：0、1、2、3、4、5、6、7、8、916进制，用十六个阿拉伯数字：0、1、2、3、4、5、6、7、8、9、A、B、C、D、E、F 2 十六进制2.1 Java例子使用JDK自带方法，16进制，先转换成10进制，再转换成2进制、8进制、16进制。 //十六进制转成十进制 System.out.println(\"十六进制转成十进制：\"+Integer.valueOf(\"e\",16).toString()); //十六进制转成二进制 System.out.println(\"十六进制转成二进制：\"+Integer.toBinaryString(Integer.valueOf(\"FFFF\",16))); //16进制先转换成10进制，再转换成2进制 //十六进制转成八进制 System.out.println(\"十六进制转成八进制：\"+Integer.toOctalString(Integer.valueOf(\"FFFF\",16))); //16进制先转换成10进制，再转换成8进制 十六进制转成十进制：14 十六进制转成二进制：1111111111111111 十六进制转成八进制：177777 3 十进制3.1 10转23.1.1 整数10进制数转换成二进制数，这是一个连续除2的过程：把要转换的数，除以2，得到商和余数，将商继续除以2，直到商为0。最后将所有余数倒序排列，得到数就是转换结果。整数除以2，商继续除以2，得到0为止，将余数逆序排列。 例子1转换6为二进制数三次计算依次得到余数分别是：0、1、1，将所有余数倒序排列，那就是：110。 例子2转换22为二进制数 22 /2 11 余 0 11 /2 5 余 1 5 /2 2 余 1 2 /2 1 余 0 1 /2 0 余 1 所以22的二进制是10110 3.1.2 负数将10进制负数转换为2进制：先得到该10进制负数的绝对值，然后转换为2进制，然后将该2进制取反，然后加1。 例子-85 得到绝对值：85 转换为二进制：01010101 取反：10101010 +1：10101011（补码） -85转换为二进制为10101011。 3.1.3 小数小数乘以2，取整，小数部分继续乘以2，取整，得到小数部分0为止，将整数顺序排列。 例子0.8125x2=1.625 取整1，小数部分是0.625 0.625x2=1.25 取整1，小数部分是0.25 0.25x2=0.5 取整0，小数部分是0.5 0.5x2=1.0 取整1，小数部分是0，结束 所以0.8125的二进制是0.1101（取整数部分）10进制22.8125等于2进制10110.1101 3.2 10转83.2.1 整数除数8，取整数。来看一个例子，如何将十进制数120转换成八进制数。120转换为8进制，结果为：170。 3.2.2 小数小数乘以8，取整，小数部分继续乘以8，取整，得到小数部分0为止，将整数顺序排列。 例子0.12*8=0.96， 取0 （整数部分得 0， 小数部分为0.96， 下次再用） 0.96*8=7.68， 取7 （整数部分得 7） 0.68*8=5.44， 取5 （整数部分得 5） 0.44*8=3.52， 取3 （整数部分得 3） 0.52*8=4.16， 取4 （整数部分得 4） 3.3 10转N10进制数转换成16进制的方法，和转换为2进制、八进制的方法类似，惟一变化：除数由2变成16。 3.4 Java例子使用JDK自带方法，10进制转换成2进制，8进制，16进制。 //十进制转成十六进制 System.out.println(\"十进制转成十六进制：\"+Integer.toHexString(14)); //十进制转成八进制 System.out.println(\"十进制转成八进制：\"+Integer.toOctalString(14)); //十进制转成二进制 System.out.println(\"十进制转成二进制：\"+Integer.toBinaryString(14)); 十进制转成十六进制：e 十进制转成八进制：16 十进制转成二进制：1110 4 八进制4.1 Java例子使用JDK自带方法，8进制，先转换成10进制，再转换成2进制、10进制、16进制。 //八进制转成二进制 System.out.println(\"八进制转成二进制：\"+Integer.toBinaryString(Integer.valueOf(\"23\",8))); //八进制转成十进制 System.out.println(\"八进制转成十进制：\"+Integer.valueOf(\"23\",8).toString());; //八进制转成十六进制 System.out.println(\"八进制转成十六进制：\"+Integer.toHexString(Integer.valueOf(\"23\",8))); 八进制转成二进制：10011 八进制转成十进制：19 八进制转成十六进制：13 5 二进制5.1 2转105.1.1 整数例子1110换成10进制2,1,0$(110)_2$ = $12^2+12^1+0*2^0$ = 6 例子27,6,5,4, 3,2,1,0$(1111 ，1011)2$=$(FB){16}$ 1111=8+4+2+1=15； 1011=8+2+1=11； 由于十六进制转换成二进制相当直接，所以，我们需要将一个十进制数转换成2进制数时，也可以先转换成16进制，然后再转换成2进制。 5.1.2 负数将2进制负数转换为10进制：先对该2进制数取反，然后加1，再转换为10进制，然后在前面加上负号。 例子10101011 最高位为1，所以为负数 取反： 01010100 +1 ： 01010101（补码） 转换为10进制：85 加上负号： -85 所以10101011 转换为十进制为 -85。 5.2 2转82换8进制时，从右到左，三位一组，不够补0。 例子111：2的2次方，2的1次方，2的0次方。 4 2 1 010 110 111 011 然后每组中的3个数分别对应4、2、1,然后再相加。 010 = 2 110 = 4+2 = 6 111 = 4+2+1 = 7 011 = 2+1 = 3 结果为：2673 5.3 2转16(8421)8.4.2.1 分别是4位二进数的位取值。 二进制 十六进制：8 4 2 1 ：1111=8+4+2+1，1001=8+0+0+1 二进制 八进制 ：4 2 1 ：101=4+0+1，110=4+2+0Java例子使用JDK自带方法，2进制，先转换成10进制，再转换成8进制、10进制、16进制。 //二进制转八进制 System.out.println(\"二进制转八进制：\"+Integer.toOctalString(Integer.parseInt(\"0101\", 2))); //二进制转十进制 System.out.println(\"二进制转十进制：\"+Integer.valueOf(\"0101\",2).toString()); //二进制转十六进制 System.out.println(\"二进制转十六进制：\"+Integer.toHexString(Integer.parseInt(\"0101\", 2))); 二进制转八进制：5 二进制转十进制：5 二进制转十六进制：5 6 原码、反码、补码在计算机中，负数以其正值的补码形式表达。比如，假设有一 int 类型的数，值为5，那么，我们知道它在计算机中表示为00000000 00000000 00000000 000001015转换成二制是101，不过int类型的数占用4字节（32位），所以前面填了一堆0（-5）。 6.1 原码一个整数，按照绝对值大小转换成的二进制数，称为原码。 例子00000000 00000000 00000000 00000101 是5的原码。 6.2 反码将二进制数按位取反，所得的新二进制数称为原二进制数的反码。 取反操作指原为1，得0；原为0，得1。（1变0; 0变1） 例子将00000000 00000000 00000000 00000101每一位取反，得11111111 11111111 11111111 11111010。11111111 11111111 11111111 11111010 是 00000000 00000000 00000000 00000101 的反码。反码是相互的，所以也可称11111111 11111111 11111111 11111010 和 00000000 00000000 00000000 00000101 互为反码。 6.3 补码反码加1称为补码。也就是说，要得到一个数的补码，先得到反码，然后将反码加上1，所得数称为补码。 例子100000000 00000000 00000000 00000101 的反码是11111111 11111111 11111111 11111010。那么，补码为11111111 11111111 11111111 11111010 + 1 = 11111111 11111111 11111111 11111011。所以，-5 在计算机中表达为 11111111 11111111 11111111 11111011。转换为十六进制0xFFFFFFFB。 例子2-1在计算机中如何表示。假设这也是一个int类型。 先取1的原码00000000 00000000 00000000 00000001 得反码 11111111 11111111 11111111 11111110 得补码 11111111 11111111 11111111 11111111 可见，－1在计算机里用二进制表达就是全1。16进制为0xFFFFFFFF。","link":"/248-Decimal/"},{"title":"(转载)01背包问题(动态规划算法)","text":"1 概述 解题思路 0/1背包问题的最优解的结构（状态） 定义最优解的值（状态转移方程） 3 程序代码 伪代码 C++ 4 背包问题示例 1 概述有n个物品，第i个物品价值为v，重量为w，其中v和w均为非负数，背包的容量是W。现需要考虑如何选择装入背包的物品，使装入背包的物品总价值最大。 物品编号 1 2 3 4 5 价值v 4 5 10 11 13 重量w 3 4 7 8 9 解题思路该问题以形式化描述如下目标函数:$$max\\sum_{i=0}^{n}v_ix_i$$约束条件:$$\\sum_{i=1}^{n}w_ix_i\\leq{W},x_i\\in{0,1}$$ 0/1背包问题的最优解的结构（状态）可以将背包问题的求解过程看作是进行一系列的决策过程，决定哪些物品应该放入背包，哪些物品不应该放入背包。放入背包物品有2种情况，如果一个问题的最优解包含物品n，那么其余的物品构成子问题，n-1在容量为W-wn时的最优解。如果这个最优解不包含物品n，其余问题肯定构成子问题，n-1在容量为W时的最优解。 定义最优解的值（状态转移方程）c[i,w]：背包容量为w，i个物品导致的最优解的总价值。123 i=0:c[i,w] = 0状态1 wi&gt;w:c[i,w] = c[i-1,w]状态2 i&gt;0且wi&lt;=w:max(c[c-1,w-wi]+vi，c[i-1,w]) 取范围内的最大值 3 程序代码伪代码n：数目W：最大重量时间复杂度：O(nW)1234567891011Knapsack-DP(n,W) for w &lt;- 0 to W do c[0,w] &lt;- 0 for i &lt;- 1 to n do c[i,0] &lt;- 0 for w &lt;- 1 to W do if w[i] &lt;= w //如果第 i 个背包不大于总承重，则最优解要么是包含第 i 个背包的最优解，要么是不包含第 i 个背包的最优解，取两者最大值 then if v[i] + c[i-1,w-w[i]] &gt;= c[c-1,w] then c[i,w] &lt;- v[i] + c[i-1,w-w[i]] else c[i,w] &lt;- c[i-1,w] else c[i,w] &lt;- c[i-1,w] //i物品的重量大于w，最优解存在i-1物品 C++12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788#include \"T.h\"#include &lt;iostream&gt;using namespace std;# define N 11 /*** c[i][w]表示背包容量为w时，i个物品导致的最优解的总价值，大小为(n+1)*(w+1) v[i]表示第i个物品的价值，大小为n w[i]表示第i个物品的重量，大小为n ***/ void DP(int n, int W, int c[][18], int *v, int *wei) { memset(*c, 0, (W+1)*sizeof(int)); //遍历n个物品 for (int i = 1; i &lt;= n; i++) { c[i][0] = 0; //遍历每个重量 for (int w = 1; w &lt;= W; w++) { //i物品的重量大于w，那最优解应该取i-1的物品 if (wei[i-1] &gt; w) { c[i][w] = c[i-1][w]; } else { //i物品的重量不大于w，最优解可能包含i物品，可能不包含i物品 int temp = c[i-1][w-wei[i-1]] + v[i-1]; //注意wei和v数组中的第i个应该为wei[i-1]和v[i-1] if (c[i-1][w] &gt; temp) { c[i][w] = c[i-1][w]; } else c[i][w] = temp; } } } } void findPath(int c[][18], int *x, int *wei, int n, int W) { int w = W; for (int i = n; i &gt;= 2; i--) { //i物品和i-1物品价值相等 if (c[i][w] == c[i-1][w]) { //标记0 x[i-1] = 0; } else { //标记1 x[i-1] = 1; //重量减少 w = w - wei[i-1]; } } if (c[1][w] == 0){//第1个物品判断是否存放背包里 x[0] = 0; }else{ x[0] = 1; }} int main() { //数目 int n = 5; //总重量 int W = 17; //重量数组 int w[] = {3, 4, 7, 8, 9}; //物品价值数组 int v[] = {4, 5, 10, 11, 13}; int c[6][18] = {0}; DP(n, W, c, v, w); cout&lt;&lt;c[5][17]&lt;&lt;endl; int x[5]; findPath(c, x, w, n, W); for (int i = 0; i &lt; n; i++){ cout&lt;&lt;x[i]&lt;&lt;\" \"; }} 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970#include&lt;stdio.h&gt;#include&lt;stdlib.h&gt;#include&lt;iostream&gt;#include&lt;queue&gt;#include&lt;climits&gt;#include&lt;cstring&gt;using namespace std;const int c = 10; //背包的容量const int w[] = {0,2,2,6,5,4};//物品的重量，其中0号位置不使用 。 const int v[] = {0,6,3,5,4,6};//物品对应的待加，0号位置置为空。const int n = sizeof(w)/sizeof(w[0]) - 1 ; //n为物品的个数 int x[n+1];void package0_1(int m[][11],const int w[],const int v[],const int n)//n代表物品的个数 { //采用从底到顶的顺序来设置m[i][j]的值 //首先放w[n] for(int j = 0; j &lt;= c; j++){ if(j &lt; w[n]) { m[n][j] = 0; //j小于w[n],所对应的值设为0，否则就为可以放置 }else{ m[n][j] = v[n]; } } //对剩下的n-1个物品进行放置。 int i; for(i = n-1; i &gt;= 1; i--) for(int j = 0; j &lt;= c; j++) if(j &lt; w[i]) { m[i][j] = m[i+1][j];//如果j &lt; w[i]则，当前位置就不能放置，它等于上一个位置的值。 }else{ m[i][j] = m[i+1][j] &gt; m[i+1][j-w[i]] + v[i]? m[i+1][j] : m[i+1][j-w[i]] + v[i]; //否则，就比较到底是放置之后的值大，还是不放置的值大，选择其中较大者。 }}void answer(int m[][11],const int n){ int j = c; int i; //遍历n-1个物品 for(i = 1; i &lt;= n-1; i++) { if(m[i][j] == m[i+1][j]){ x[i] = 0; }else{ x[i] = 1; j = j - w[i]; } } //判断n物品，是否放入背包 x[n] = m[i][j] ? 1 : 0; }int main(){ int m[6][11]={0}; package0_1(m,w,v,n); for(int i = 0; i &lt;= 5; i++) { for(int j = 0; j &lt;= 10; j++) printf(\"%2d \",m[i][j]); cout &lt;&lt; endl; } answer(m,n); cout &lt;&lt; \"The best answer is:\\n\"; for(int i = 1; i &lt;= 5; i++){ cout &lt;&lt; x[i] &lt;&lt; \" \"; } system(\"pause\"); return 0;} 123456789101112131415161718192021222324252627282930package demo1;public class Knapsack { /** 背包重量 */ private int weight; /** 背包物品价值 */ private int value; /*** * 构造器 */ public Knapsack(int weight, int value) { this.value = value; this.weight = weight; } public int getWeight() { return weight; } public int getValue() { return value; } public String toString() { return \"[weight: \" + weight + \" \" + \"value: \" + value + \"]\"; }} 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128package demo1;import java.util.ArrayList;/** * 求解背包问题： 给定 n 个背包，其重量分别为 w1,w2,……,wn, 价值分别为 v1,v2,……,vn 要放入总承重为 totalWeight * 的箱子中， 求可放入箱子的背包价值总和的最大值。 * * NOTE: 使用动态规划法求解 背包问题 设 前 n 个背包，总承重为 j 的最优值为 v[n,j], 最优解背包组成为 b[n]; 求解最优值： 1. * 若 j &lt; wn, 则 ： v[n,j] = v[n-1,j]; 2. 若 j &gt;= wn, 则：v[n,j] = max{v[n-1,j], vn + * v[n-1,j-wn]}。 * * 求解最优背包组成： 1. 若 v[n,j] &gt; v[n-1,j] 则 背包 n 被选择放入 b[n], 2. 接着求解前 n-1 个背包放入 j-wn * 的总承重中， 于是应当判断 v[n-1, j-wn] VS v[n-2,j-wn], 决定 背包 n-1 是否被选择。 3. 依次逆推，直至总承重为零。 * * 重点： 掌握使用动态规划法求解问题的分析方法和实现思想。 分析方法： 问题实例 P(n) 的最优解S(n) 蕴含 问题实例 P(n-1) * 的最优解S(n-1); 在S(n-1)的基础上构造 S(n) 实现思想： 自底向上的迭代求解 和 基于记忆功能的自顶向下递归 */public class KnapsackProblem { /** 指定背包 */ private Knapsack[] bags; /** 总承重 */ private int totalWeight; /** 给定背包数量 */ private int n; /** 前 n 个背包，总承重为 totalWeight 的最优值矩阵 */ private int[][] bestValues; /** 前 n 个背包，总承重为 totalWeight 的最优值 */ private int bestValue; /** 前 n 个背包，总承重为 totalWeight 的最优解的物品组成 */ private ArrayList&lt;Knapsack&gt; bestSolution; public KnapsackProblem(Knapsack[] bags, int totalWeight) { this.bags = bags; this.totalWeight = totalWeight; this.n = bags.length; if (bestValues == null) { bestValues = new int[n + 1][totalWeight + 1]; } } /** * 求解前 n 个背包、给定总承重为 totalWeight 下的背包问题 * */ public void solve() { System.out.println(\"给定背包：\"); for (Knapsack b : bags) { System.out.println(b); } System.out.println(\"给定总承重: \" + totalWeight); // 求解最优值 for (int j = 0; j &lt;= totalWeight; j++) { for (int i = 0; i &lt;= n; i++) { if (i == 0 || j == 0) { bestValues[i][j] = 0; } else { // 如果第 i 个背包重量大于总承重，则最优解存在于前 i-1 个背包中， // 注意：第 i 个背包是 bags[i-1] if (j &lt; bags[i - 1].getWeight()) { bestValues[i][j] = bestValues[i - 1][j]; } else { // 如果第 i 个背包不大于总承重，则最优解要么是包含第 i 个背包的最优解， // 要么是不包含第 i 个背包的最优解，取两者最大值，这里采用了分类讨论法 // 第 i 个背包的重量 iweight 和价值 ivalue int iweight = bags[i - 1].getWeight(); int ivalue = bags[i - 1].getValue(); bestValues[i][j] = Math.max(bestValues[i - 1][j], ivalue + bestValues[i - 1][j - iweight]); } // else } // else } // for } // for // 求解背包组成 if (bestSolution == null) { bestSolution = new ArrayList&lt;Knapsack&gt;(); } //总重量 int tempWeight = totalWeight; for (int i = n; i &gt;= 1; i--) { if (bestValues[i][tempWeight] &gt; bestValues[i - 1][tempWeight]) { // bags[i-1] 表示第 i 个背包 bestSolution.add(bags[i - 1]); tempWeight -= bags[i - 1].getWeight(); } if (tempWeight == 0) { break; } } //前n个背包的最优解(价值) bestValue = bestValues[n][totalWeight]; } /** * 获得前 n 个背包， 总承重为 totalWeight 的背包问题的最优解值 调用条件： 必须先调用 solve 方法 * */ public int getBestValue() { return bestValue; } /** * 获得前 n 个背包， 总承重为 totalWeight 的背包问题的最优解值矩阵 调用条件： 必须先调用 solve 方法 * */ public int[][] getBestValues() { return bestValues; } /** * 获得前 n 个背包， 总承重为 totalWeight 的背包问题的最优解值矩阵 调用条件： 必须先调用 solve 方法 * */ public ArrayList&lt;Knapsack&gt; getBestSolution() { return bestSolution; }} 123456789101112131415161718192021222324252627282930package demo1;public class KnapsackTest { public static void main(String[] args) { Knapsack[] bags = new Knapsack[] { new Knapsack(2,13), new Knapsack(1,10), new Knapsack(3,24), new Knapsack(2,15), new Knapsack(4,28), new Knapsack(5,33), new Knapsack(3,20), new Knapsack(1, 8) }; int totalWeight = 10; KnapsackProblem kp = new KnapsackProblem(bags, totalWeight); kp.solve(); System.out.println(\" -------- 该背包问题实例的解: --------- \"); System.out.println(\"最优值：\" + kp.getBestValue()); System.out.println(\"最优解【选取的背包】: \"); System.out.println(kp.getBestSolution()); System.out.println(\"最优决策矩阵表：\"); int[][] bestValues = kp.getBestValues(); for (int i=0; i &lt; bestValues.length; i++) { for (int j=0; j &lt; bestValues[i].length; j++) { System.out.printf(\"%-5d\", bestValues[i][j]); } System.out.println(); } } } 4 背包问题示例一切都要从一则故事说起。话说有一哥们去森林里玩发现了一堆宝石，他数了数，一共有n个。 但他身上能装宝石的就只有一个背包，背包的容量为C。这哥们把n个宝石排成一排并编上号：0,1,2,…,n-1。第i个宝石对应的体积和价值分别为V[i]和W[i]。排好后这哥们开始思考： 背包总共也就只能装下体积为C的东西，那我要装下哪些宝石才能让我获得最大的利益呢？OK，如果是你，你会怎么做？你斩钉截铁的说：动态规划啊！恭喜你，答对了。 那么让我们来看看，动态规划中最最最重要的两个概念： 状态和状态转移方程在这个问题中分别是什么。我们要怎样去定义状态呢？这个状态总不能是凭空想象或是从天上掉下来的吧。 为了方便说明，让我们先实例化上面的问题。一般遇到n，你就果断地给n赋予一个很小的数，比如n=3。然后设背包容量C=10，三个宝石的体积为5，4，3，对应的价值为20，10，12。 对于这个例子，我想智商大于0的人都知道正解应该是把体积为5和3的宝石装到背包里， 此时对应的价值是20+12=32。接下来，我们把第三个宝石拿走， 同时背包容量减去第三个宝石的体积（因为它是装入背包的宝石之一）， 于是问题的各参数变为：n=2,C=7，体积｛5，4｝，价值｛20，10｝。好了， 现在这个问题的解是什么？我想智商等于0的也解得出了：把体积为5的宝石放入背包 （然后剩下体积2，装不下第二个宝石，只能眼睁睁看着它溜走），此时价值为20。 这样一来，我们发现，n=3时，放入背包的是0号和2号宝石；当n=2时， 我们放入的是0号宝石。这并不是一个偶然，没错， 这就是传说中的“全局最优解包含局部最优解”（n=2是n=3情况的一个局部子问题）。 绕了那么大的圈子，你可能要问，这都哪跟哪啊？说好的状态呢？说好的状态转移方程呢？ 别急，它们已经呼之欲出了。我们再把上面的例子理一下。当n=2时，我们要求的是前2个宝石， 装到体积为7的背包里能达到的最大价值；当n=3时，我们要求的是前3个宝石， 装到体积为10的背包里能达到的最大价值。有没有发现它们其实是一个句式！OK， 让我们形式化地表示一下它们， 定义d(i,j)为前i个宝石装到剩余体积为j的背包里能达到的最大价值。 那么上面两句话即为：d(2, 7)和d(3, 10)。这样看着真是爽多了， 而这两个看着很爽的符号就是我们要找的状态了。 即状态d(i,j)表示前i个宝石装到剩余体积为j的背包里能达到的最大价值。上面那么多的文字，用一句话概括就是：根据子问题定义状态！你找到子问题， 状态也就浮出水面了。而我们最终要求解的最大价值即为d(n, C)：前n个宝石（0,1,2…,n-1）装入剩余容量为C的背包中的最大价值。状态好不容易找到了， 状态转移方程呢？顾名思义，状态转移方程就是描述状态是怎么转移的方程。 那么回到例子，d(2, 7)和d(3, 10)是怎么转移的？来，我们来说说2号宝石 （记住宝石编号是从0开始的）。从d(2, 7)到d(3, 10)就隔了这个2号宝石。 它有两种情况，装或者不装入背包。如果装入，在面对前2个宝石时， 背包就只剩下体积7来装它们，而相应的要加上2号宝石的价值12，d(3, 10)=d(2, 10-3)+12=d(2, 7)+12；如果不装入，体积仍为10，价值自然不变了，d(3, 10)=d(2, 10)。记住，d(3, 10)表示的是前3个宝石装入到剩余体积为10 的背包里能达到的最大价值，既然是最大价值，就有d(3, 10)=max{d(2, 10), d(2, 7)+12}。好了，这条方程描述了状态d(i, j)的一些关系， 没错，它就是状态转移方程了。把它形式化一下：d(i, j)=max{ d(i-1, j), d(i-1,j-V[i-1]) + W[i-1]}。注意讨论前i个宝石装入背包的时候， 其实是在考查第i-1个宝石装不装入背包（因为宝石是从0开始编号的）。至此， 状态和状态转移方程都已经有了。接下来，直接上代码。123456for(int i=0; i&lt;=n; ++i){ for(int j=0; j&lt;=C; ++j){ d[i][j] = i==0 ? 0 : d[i-1][j]; if(i&gt;0 &amp;&amp; j&gt;=V[i-1]) d[i][j] = d[i][j] &gt;d[i-1][j-V[i-1]]+W[i-1]?d[i][j] : d[i-1][j-V[i-1]]+W[i-1]; } } i=0时，d(i, j)为什么为0呢？因为前0个宝石装入背包就是没东西装入，所以最大价值为0。 if语句里，j&gt;=V[i-1]说明只有当背包剩余体积j大于等于i-1号宝石的体积时， 我才考虑把它装进来的情况，不然d[i][j]就直接等于d[i-1][j]。i&gt;0不用说了吧， 前0个宝石装入背包的情况是边界，直接等于0，只有i&gt;0才有必要讨论， 我是装呢还是不装呢。简单吧，核心算法就这么一丁点，接下来上完整代码。12345678910111213141516171819202122232425262728/**0-1 knapsack d(i, j)表示前i个物品装到剩余容量为j的背包中的最大重量**/#include&lt;cstdio&gt;using namespace std;#define MAXN 1000#define MAXC 100000int V[MAXN], W[MAXN];int d[MAXN][MAXC];int main(){ freopen(\"data.in\", \"r\", stdin);//重定向输入流 freopen(\"data.out\", \"w\", stdout);//重定向输出流 int n, C; while(scanf(\"%d %d\", &amp;n, &amp;C) != EOF){ for(int i=0; i&lt;n; ++i) scanf(\"%d %d\", &amp;V[i], &amp;W[i]); for(int i=0; i&lt;=n; ++i){ for(int j=0; j&lt;=C; ++j){ d[i][j] = i==0 ? 0 : d[i-1][j]; if(i&gt;0 &amp;&amp; j&gt;=V[i-1]) d[i][j] = d[i][j] &gt;d[i-1][j-V[i-1]]+W[i-1]?d[i][j] : d[i-1][j-V[i-1]]+W[i-1]; } } printf(\"%d\\n\", d[n][C]);//最终求解的最大价值 } fclose(stdin); fclose(stdout); return 0;} 好，至此我们解决了背包问题中最基本的0/1背包问题。等等，这时你可能要问， 我现在只知道背包能装入宝石的最大价值，但我还不知道要往背包里装入哪些宝石啊。嗯， 好问题！让我们先定义一个数组x，对于其中的元素为1时表示对应编号的宝石放入背包，为0则不放入。让我们回到上面的例子，对于体积为5，4，3，价值为20，10，12的3个宝石 ，如何求得其对应的数组x呢？（明显我们目测一下就知道x={1 0 1}， 但程序可目测不出来）OK，让我们还是从状态说起。如果我们把2号宝石放入了背包， 那么是不是也就意味着，前3个宝石放入背包的最大价值要比前2个宝石放入背包的价值大， 即：d(3, 10)&gt;d(2, 10)。再用字母代替具体的数字，当d(i, j)&gt;d(i-1, j)时，x(i-1)=1;OK， 上代码：12345678910111213141516171819202122232425262728293031323334353637383940/**0-1 knapsack d(i, j)表示前i个物品装到剩余容量为j的背包中的最大重量**/#include&lt;cstdio&gt;using namespace std;#define MAXN 1000#define MAXC 100000int V[MAXN], W[MAXN], x[MAXN];int d[MAXN][MAXC];int main(){ freopen(\"data.in\", \"r\", stdin); freopen(\"data.out\", \"w\", stdout); int n, C; while(scanf(\"%d %d\", &amp;n, &amp;C) != EOF){ for(int i=0; i&lt;n; ++i) scanf(\"%d %d\", &amp;V[i], &amp;W[i]); for(int i=0; i&lt;n; ++i) x[i] = 0; //初始化打印方案 for(int i=0; i&lt;=n; ++i){ for(int j=0; j&lt;=C; ++j){ d[i][j] = i==0 ? 0 : d[i-1][j]; if(i&gt;0 &amp;&amp; j&gt;=V[i-1]) d[i][j] &gt;?= d[i-1][j-V[i-1]]+W[i-1]; } } printf(\"%d\\n\", d[n][C]); //输出打印方案 int j = C; for(int i=n; i&gt;0; --i){ if(d[i][j] &gt; d[i-1][j]){ x[i-1] = 1; j = j - V[i-1]; } } for(int i=0; i&lt;n; ++i) printf(\"%d \", x[i]); printf(\"\\n\"); } fclose(stdin); fclose(stdout); return 0;} data.out输出结果变为：123456191 1 0 1 0401 0 1 0151 1 0 0 1 至此，好像该解决的问题都解决了。当一个问题找到一个放心可靠的解决方案后， 我们往往就要考虑一下是不是有优化方案了。为了保持代码的简洁， 我们暂且把宝石装包方案的求解去掉。该算法的时间复杂度是O(nC)， 即时间都花在两个for循环里了，这个应该是没办法再优化了。再看看空间复杂度， 数组d用来保存每个状态的值，空间复杂度为O(nC)； 数组V和W用来保存每个宝石的体积和价值，空间复杂度为O(n)。程序总的空间复杂度为O(nC)，这个是可以进一步优化的。首先，我们先把数组V和W去掉， 因为它们没有保存的必要，改为一边读入一边计算。好了，接下来让我们继续压榨空间复杂度。保存状态值我们开了一个二维数组d， 在看过把一维数组V和W变为一个变量后，我们是不是要思考一下，有没有办法将这个二维数组也压榨一下呢？换言之， 这个二维数组中的每个状态值我们真的有必要都保存么？ 让我们先来看一下以下的一张示意图（参照《算法竞赛入门经典》P169的图画的）由上面那一小段优化过后的代码可知，状态转移方程为：d(i, j)=max{ d(i-1, j), d(i-1, j-V)+W}，也就是在计算d(i, j)时我们用到d(i-1,j)和d(i-1, j-V)的值。 如果我们只用一个一维数组d(0)~d(C)来保存状态值可以么？将i方向的维数去掉，我们可以将原来二维数组表示为一维数据：d(i-1, j-V)变为d(j-V)，d(i-1, j)变为d(j)。当我们要计算d(i, j)时，只需要比较d(j)和d(j-V)+W的大小，用较大的数更新d(j)即可。等等，如果我要计算d(i, j+1)，而它恰好要用到d(i-1, j)的值， 那么问题就出来了，因为你刚刚才把它更新为d(i, j)了。那么，怎么办呢？ 按照j递减的顺序即可避免这种问题。比如，你计算完d(i, j)， 接下来要计算的是d(i,j-1)，而它的状态转移方程为d(i, j-1)=max{ d(i-1, j-1), d(i-1, j-1-V)+W }，它不会再用到d(i-1,j)的值！所以， 即使该位置的值被更新了也无所谓。好，上代码：123456789101112131415161718192021222324252627/**0-1 knapsack d(i, j)表示前i个物品装到剩余容量为j的背包中的最大重量**/#include&lt;cstdio&gt;#include&lt;cstdlib&gt;#include&lt;cstring&gt;using namespace std;int main(){ freopen(\"data.in\", \"r\", stdin); freopen(\"data.out\", \"w\", stdout); int n, C, V = 0, W = 0; while(scanf(\"%d %d\", &amp;n, &amp;C) != EOF){ int* d = (int*)malloc((C+1)*sizeof(int)); memset(d, 0, (C+1)*sizeof(int)); for(int i=0; i&lt;=n; ++i){ if(i&gt;0) scanf(\"%d %d\", &amp;V, &amp;W); for(int j=C; j&gt;=0; --j){ if(j&gt;=V &amp;&amp; i&gt;0) d[j] &gt;?= d[j-V]+W; } } printf(\"%d\\n\", d[C]); free(d); } fclose(stdin); fclose(stdout); return 0;}","link":"/01-package-Question/"},{"title":"(转载)2048-AI算法分析","text":"基础算法 Minimax 问题 基本思路 解题 Alpha-beta剪枝 针对2048游戏的实现 建模 格局评价 单调性 平滑性 空格数 孤立空格数 对对方选择的剪枝 搜索深度 算法的改进 参考文献 1针对目前火爆的2048游戏，有人实现了一个AI程序，可以以较大概率（高于90%）赢得游戏，并且作者在stackoverflow上简要介绍了AI的算法框架和实现思路。但是这个回答主要集中在启发函数的选取上 针对目前火爆的2048游戏，有人实现了一个AI程序，可以以较大概率（高于90%）赢得游戏，并且作者在stackoverflow上简要介绍了AI的算法框架和实现思路。但是这个回答主要集中在启发函数的选取上，对AI用到的核心算法并没有仔细说明。这篇文章将主要分为两个部分，第一部分介绍其中用到的基础算法，即Minimax和Alpha-beta剪枝；第二部分分析作者具体的实现。 基础算法12048本质上可以抽象成信息对称双人对弈模型（玩家向四个方向中的一个移动，然后计算机在某个空格中填入2或4）。这里“信息对称”是指在任一时刻对弈双方对格局的信息完全一致，移动策略仅依赖对接下来格局的推理。作者使用的核心算法为对弈模型中常用的带Alpha-beta剪枝的Minimax。这个算法也常被用于如国际象棋等信息对称对弈AI中。 Minimax下面先介绍不带剪枝的Minimax。首先本文将通过一个简单的例子说明Minimax算法的思路和决策方式。 问题现在考虑这样一个游戏：有三个盘子A、B和C，每个盘子分别放有三张纸币。A放的是1、20、50；B放的是5、10、100；C放的是1、5、20。单位均为“元”。有甲、乙两人，两人均对三个盘子和上面放置的纸币有可以任意查看。游戏分三步： 甲从三个盘子中选取一个。 乙从甲选取的盘子中拿出两张纸币交给甲。 甲从乙所给的两张纸币中选取一张，拿走。其中甲的目标是最后拿到的纸币面值尽量大，乙的目标是让甲最后拿到的纸币面值尽量小。下面用Minimax算法解决这个问题。基本思路一般解决博弈类问题的自然想法是将格局组织成一棵树，树的每一个节点表示一种格局，而父子关系表示由父格局经过一步可以到达子格局。Minimax也不例外，它通过对以当前格局为根的格局树搜索来确定下一步的选择。而一切格局树搜索算法的核心都是对每个格局价值的评价。Minimax算法基于以下朴素思想确定格局价值： Minimax是一种悲观算法，即假设对手每一步都会将我方引入从当前看理论上价值最小的格局方向，即对手具有完美决策能力。因此我方的策略应该是选择那些对方所能达到的让我方最差情况中最好的，也就是让对方在完美决策下所对我造成的损失最小。 Minimax不找理论最优解，因为理论最优解往往依赖于对手是否足够愚蠢，Minimax中我方完全掌握主动，如果对方每一步决策都是完美的，则我方可以达到预计的最小损失格局，如果对方没有走出完美决策，则我方可能达到比预计的最悲观情况更好的结局。总之我方就是要在最坏情况中选择最好的。上面的表述有些抽象，下面看具体示例。解题下图是上述示例问题的格局树：注意，由于示例问题格局数非常少，我们可以给出完整的格局树。这种情况下我可以找到Minimax算法的全局最优解。而真实情况中，格局树非常庞大，即使是计算机也不可能给出完整的树，因此我们往往只搜索一定深度，这时只能找到局部最优解。我们从甲的角度考虑。其中正方形节点表示轮到我方（甲），而三角形表示轮到对方（乙）。经过三轮对弈后（我方-对方-我方），将进入终局。黄色叶结点表示所有可能的结局。从甲方看，由于最终的收益可以通过纸币的面值评价，我们自然可以用结局中甲方拿到的纸币面值表示终格局的价值。下面考虑倒数第二层节点，在这些节点上，轮到我方选择，所以我们应该引入可选择的最大价值格局，因此每个节点的价值为其子节点的最大值：这些轮到我方的节点叫做max节点，max节点的值是其子节点最大值。倒数第三层轮到对方选择，假设对方会尽力将局势引入让我方价值最小的格局，因此这些节点的价值取决于子节点的最小值。这些轮到对方的节点叫做min节点。最后，根节点是max节点，因此价值取决于叶子节点的最大值。最终完整赋值的格局树如下：总结一下Minimax算法的步骤： 首先确定最大搜索深度D，D可能达到终局，也可能是一个中间格局。 在最大深度为D的格局树叶子节点上，使用预定义的价值评价函数对叶子节点价值进行评价。 自底向上为非叶子节点赋值。其中max节点取子节点最大值，min节点取子节点最小值。 每次轮到我方时（此时必处在格局树的某个max节点），选择价值等于此max节点价值的那个子节点路径。在上面的例子中，根节点的价值为20，表示如果对方每一步都完美决策，则我方按照上述算法可最终拿到20元，这是我方在Minimax算法下最好的决策。格局转换路径如下图红色路径所示：对于真实问题中的Minimax，再次强调几点： 真实问题一般无法构造出完整的格局树，所以需要确定一个最大深度D，每次最多从当前格局向下计算D层。 因为上述原因，Minimax一般是寻找一个局部最优解而不是全局最优解，搜索深度越大越可能找到更好的解，但计算耗时会呈指数级膨胀。 也是因为无法一次构造出完整的格局树，所以真实问题中Minimax一般是边对弈边计算局部格局树，而不是只计算一次，但已计算的中间结果可以缓存。 Alpha-beta剪枝简单的Minimax算法有一个很大的问题就是计算复杂性。由于所需搜索的节点数随最大深度呈指数膨胀，而算法的效果往往和深度相关，因此这极大限制了算法的效果。Alpha-beta剪枝是对Minimax的补充和改进。采用Alpha-beta剪枝后，我们可不必构造和搜索最大深度D内的所有节点，在构造过程中，如果发现当前格局再往下不能找到更好的解，我们就停止在这个格局及以下的搜索，也就是剪枝。Alpha-beta基于这样一种朴素的思想：时时刻刻记得当前已经知道的最好选择，如果从当前格局搜索下去，不可能找到比已知最优解更好的解，则停止这个格局分支的搜索（剪枝），回溯到父节点继续搜索。Alpha-beta算法可以看成变种的Minimax，基本方法是从根节点开始采用深度优先的方式构造格局树，在构造每个节点时，都会读取此节点的alpha和beta两个值，其中alpha表示搜索到当前节点时已知的最好选择的下界，而beta表示从这个节点往下搜索最坏结局的上界。由于我们假设对手会将局势引入最坏结局之一，因此当beta小于alpha时，表示从此处开始不论最终结局是哪一个，其上限价值也要低于已知的最优解，也就是说已经不可能此处向下找到更好的解，所以就会剪枝。下面同样以上述示例介绍Alpha-beta剪枝算法的工作原理。我们从根节点开始，详述使用Alpha-beta的每一个步骤： 根节点的alpha和beta分别被初始化为−∞，和+∞。 深度优先搜索第一个孩子，不是叶子节点，所以alpha和beta继承自父节点，分别为−∞，和+∞。 搜索第三层的第一个孩子，同上。 搜索第四层，到达叶子节点，采用评价函数得到此节点的评价值为1。 此叶节点的父节点为max节点，因此更新其alpha值为1，表示此节点取值的下界为1。 再看另外一个子节点，值为20，大于当前alpha值，因此将alpha值更新为20。 此时第三层最左节点所有子树搜索完毕，作为max节点，更新其真实值为当前alpha值：20。 由于其父节点（第二层最左节点）为min节点，因此更新其父节点beta值为20，表示这个节点取值最多为20。 搜索第二层最左节点的第二个孩子及其子树，按上述逻辑，得到值为50（注意第二层最左节点的beta值要传递给孩子）。由于50大于20，不更新min节点的beta值。 搜索第二层最左节点的第三个孩子。当看完第一个叶子节点后，发现第三个孩子的alpha=beta，此时表示这个节点下不会再有更好解，于是剪枝。 继续搜索B分支，当搜索完B分支的第一个孩子后，发现此时B分支的alpha为20，beta为10。这表示B分支节点的最大取值不会超过10，而我们已经在A分支取到20，此时满足alpha大于等于beta的剪枝条件，因此将B剪枝。并将B分支的节点值设为10，注意，这个10不一定是这个节点的真实值，而只是上线，B节点的真实值可能是5，可能是1，可能是任何小于10的值。但是已经无所谓了，反正我们知道这个分支不会好过A分支，因此可以放弃了。 在C分支搜索时遇到了与B分支相同的情况。因此讲C分支剪枝。此时搜索全部完毕，而我们也得到了这一步的策略：应该走A分支。可以看到相比普通Minimax要搜索18个叶子节点相比，这里只搜索了9个。采用Alpha-beta剪枝，可以在相同时间内加大Minimax的搜索深度，因此可以获得更好的效果。并且Alpha-beta的解和普通Minimax的解是一致的。针对2048游戏的实现下面看一下ov3y同学针对2048实现的AI。程序的github在这里，主要程序都在ai.js中。 建模上面说过Minimax和Alpha-beta都是针对信息对称的轮流对弈问题，这里作者是这样抽象游戏的： 我方：游戏玩家。每次可以选择上、下、左、右四个行棋策略中的一种（某些格局会少于四种，因为有些方向不可走）。行棋后方块按照既定逻辑移动及合并，格局转换完成。 对方：计算机。在当前任意空格子里放置一个方块，方块的数值可以是2或4。放置新方块后，格局转换完成。 胜利条件：出现某个方块的数值为“2048”。 失败条件：格子全满，且无法向四个方向中任何一个方向移动（均不能触发合并）。 如此2048游戏就被建模成一个信息对称的双人对弈问题。 格局评价作为算法的核心，如何评价当前格局的价值是重中之重。在2048中，除了终局外，中间格局并无非常明显的价值评价指标，因此需要用一些启发式的指标来评价格局。那些分数高的“好”格局是容易引向胜利的格局，而分低的“坏”格局是容易引向失败的格局。作者采用了如下几个启发式指标。 单调性单调性指方块从左到右、从上到下均遵从递增或递减。一般来说，越单调的格局越好。下面是一个具有良好单调格局的例子： 平滑性平滑性是指每个方块与其直接相邻方块数值的差，其中差越小越平滑。例如2旁边是4就比2旁边是128平滑。一般认为越平滑的格局越好。下面是一个具有极端平滑性的例子： 空格数这个很好理解，因为一般来说，空格子越少对玩家越不利。所以我们认为空格越多的格局越好。 孤立空格数这个指标评价空格被分开的程度，空格越分散则格局越差。具体来说，2048-AI在评价格局时，对这些启发指标采用了加权策略。具体代码如下：123456789101112131415161718// static evaluation function AI.prototype.eval = function() { var emptyCells = this.grid.availableCells().length; var smoothWeight = 0.1, //monoWeight = 0.0, //islandWeight = 0.0, mono2Weight = 1.0, emptyWeight = 2.7, maxWeight = 1.0; return this.grid.smoothness() * smoothWeight //+ this.grid.monotonicity() * monoWeight //- this.grid.islands() * islandWeight + this.grid.monotonicity2() * mono2Weight + Math.log(emptyCells) * emptyWeight + this.grid.maxValue() * maxWeight; }; 有兴趣的同学可以调整一下权重看看有什么效果。 对对方选择的剪枝在这个程序中，除了采用Alpha-beta剪枝外，在min节点还采用了另一种剪枝，即只考虑对方走出让格局最差的那一步（而实际2048中计算机的选择是随机的），而不是搜索全部对方可能的走法。这是因为对方所有可能的选择为“空格数×2”，如果全部搜索的话会严重限制搜索深度。相关剪枝代码如下：12345678910111213141516171819202122232425// try a 2 and 4 in each cell and measure how annoying it is // with metrics from eval var candidates = []; var cells = this.grid.availableCells(); var scores = { 2: [], 4: [] }; for (var value in scores) { for (var i in cells) { scores[value].push(null); var cell = cells[i]; var tile = new Tile(cell, parseInt(value, 10)); this.grid.insertTile(tile); scores[value][i] = -this.grid.smoothness() + this.grid.islands(); this.grid.removeTile(cell); } } // now just pick out the most annoying moves var maxScore = Math.max(Math.max.apply(null, scores[2]), Math.max.apply(null, scores[4])); for (var value in scores) { // 2 and 4 for (var i=0; i&lt;scores[value].length; i++) { if (scores[value][i] == maxScore) { candidates.push( { position: cells[i], value: parseInt(value, 10) } ); } } } 搜索深度在2048-AI的实现中，并没有限制搜索的最大深度，而是限制每次“思考”的时间。这里设定了一个超时时间，默认为100ms，在这个时间内，会从1开始，搜索到所能达到的深度。相关代码：12345678910111213141516171819202122232425// try a 2 and 4 in each cell and measure how annoying it is // with metrics from eval var candidates = []; var cells = this.grid.availableCells(); var scores = { 2: [], 4: [] }; for (var value in scores) { for (var i in cells) { scores[value].push(null); var cell = cells[i]; var tile = new Tile(cell, parseInt(value, 10)); this.grid.insertTile(tile); scores[value][i] = -this.grid.smoothness() + this.grid.islands(); this.grid.removeTile(cell); } } // now just pick out the most annoying moves var maxScore = Math.max(Math.max.apply(null, scores[2]), Math.max.apply(null, scores[4])); for (var value in scores) { // 2 and 4 for (var i=0; i&lt;scores[value].length; i++) { if (scores[value][i] == maxScore) { candidates.push( { position: cells[i], value: parseInt(value, 10) } ); } } } 因此这个算法实现的效果实际上依赖于执行javascript引擎机器的性能。当然可以通过增加超时时间来达到更好的效果，但此时每一步行走速度会相应变慢。 算法的改进目前这个实现作者声称成功合成2048的概率超过90%，但是合成4096甚至8192的概率并不高。作者在github项目的REAMDE中同时给出了一些优化建议，这些建议包括： 缓存结果。目前这个实现并没有对已搜索的树做缓存，每一步都要重新开始搜索。 多线程搜索。由于javascript引擎的单线程特性，这一点很难做到，但如果在其它平台上也许也可考虑并行技术。 更好的启发函数。也许可以总结出一些更好的启发函数来评价格局价值。参考文献2048-AI githubAn Exhaustive Explanation of Minimax, a Staple AI AlgorithmTic Tac Toe: Understanding the Minimax AlgorithmCS 161 Recitation Notes - Minimax with Alpha Beta Pruning","link":"/2048-AI/"},{"title":"(转载)A星+(最优路径算法)","text":"1 介绍 2 一只探路猫 3 简化搜索区域 4 Open和Closed列表 5 路径增量 6 关于G值 7 关于H值 8 A星算法 9 猫的路径 第一步 第二步 第三步 第四步 第五步 第六步 第七步 第八步 10 一只有远见的猫 object-c java 1 上下左右寻找，未做斜对角线寻找路径 2 上下左右，斜对角线寻找 10 改进 优化速度 排序查找算法 二叉树查找算法 总结 转帖：A*寻路算法介绍 1 介绍你是否在做一款游戏的时候想创造一些怪兽或者游戏主角，让它们移动到特定的位置，避开墙壁和障碍物呢？如果是的话，请看这篇教程，我们会展示如何使用A寻路算法来实现它！在网上已经有很多篇关于A寻路算法的文章，但是大部分都是提供给已经解基本原理的高级开发者的。本篇教程将从最基本的原理讲起。我们会一步步讲解A寻路算法，幷配有很多图解和例子。不管你使用的是什么编程语言或者操作平台，你会发现本篇教程很有帮助，因为它在非编程语言的层面上解释算法的原理。稍后，会有一篇教程，展示如何在Cocos2D iPhone 游戏中实现A算法。现在找下到达一杯咖啡因饮料和美味的零食的最短路径，开始吧！ 2 一只探路猫让我们想象一下，有一款游戏，游戏中一只猫想要找到获取骨头的路线。“为什么会有一只猫想要骨头？！”你可能会这么想。在本游戏中， 这是一只狡猾的猫，他想捡起骨头给狗，以防止被咬死！现在想像一下下图中的猫想找到到达骨头的最短路径。不幸的是，猫不能直接从它当前的位置走到骨头的位置，因为有面墙挡住去路，而且它在游戏中不是一只幽灵猫！游戏中的猫同样懒惰，它总是想找到最短路径，这样当他回家看望它的女朋友时不会太累。但是我们如何编写一个算法计算出猫要选择的那条路径呢？A*算法拯救我们！ 3 简化搜索区域寻路的第一步是简化成容易控制的搜索区域。怎么处理要根据游戏来决定。例如，我们可以将搜索区域划分成像素点，但是这样的划分粒度对于我们这款基于方块的游戏来说太高（没必要）。作为代替，我们使用方块（一个正方形）作为寻路算法的单元。其他的形状类型也是可能的（比如三角形或者六边形），但是正方形是最简单并且最适合我们需求的。像那样去划分，我们的搜索区域可以简单的用一个地图大小的二维数组去表示。所以如果是25*25方块大小的地图，我们的搜索区域将会是一个有625个正方形的数组。如果我们把地图划分成像素点，搜索区域就是一个有640，000个正方形的数组（一个方块是32*32像素）！现在让我们基于目前的区域，把区域划分成多个方块来代表搜索空间（在这个简单的例子中，7*6个方块 = 42 个方块）。 4 Open和Closed列表既然我们创建一个简单的搜索区域，我们来讨论下A*算法的工作原理吧。除了懒惰之外，我们的猫没有好的记忆力，所以它需要两个列表。 一个记录下所有被考虑来寻找最短路径的方块（称为open列表） 一个记录下不会再被考虑的方块（成为closed列表，称为：路径，也就是close列表存路径） 猫首先在closed列表中添加当前位置（我们把这个开始点称为点“A”）。然后，把所有与它当前位置相邻的可通行小方块添加到open列表中。下图是猫在某一位置时的情景（绿色代表open列表）。现在猫需要判断在这些选项中，哪项才是最短路径，但是它要如何去选择呢？在A*寻路算法中，通过给每一个方块一个和值，该值被称为路径增量。让我们看下它的工作原理！ 5 路径增量我们将会给每个方块一个G+H和值。 G是从开始点A到当前方块的移动量。所以从开始点A到相邻小方块的移动量为1，该值会随着离开始点越来越远而增大。 H是从当前方块到目标点（我们把它称为点B，代表骨头！）的移动量估算值。这个常被称为探视，因为我们不确定移动量是多少 – 仅仅是一个估算值。 你也许会对“移动量”感兴趣。在游戏中，这个概念很简单 – 仅仅是方块的数量。然而，在游戏中你可以对这个值做调整。例如。 如果你允许对角线移动，你可以针对对角线移动把移动量调得大一点。 如果你有不同的地形，你可以将相应的移动量调整得大一点 – 例如针对一块沼泽，水，或者猫女海报:-) 这就是大概的意思 – 现在让我们详细分析下如何计算出G和H值。 6 关于G值G是从开始点A到达当前方块的移动量（在本游戏中是指方块的数目）。为计算出G的值，我们需要从它的前继（上一个方块）获取，然后加1。所以，每个方块的G值代表从点A到该方块所形成路径的总移动量。例如，下图展示两条到达不同骨头的路径，每个方块都标有它的G值。 7 关于H值H值是从当前方块到终点的移动量估算值（在本游戏中是指方块的数目）。移动量估算值离真实值越接近，最终的路径会更加精确。如果估算值停止作用，很可能生成出来的路径不会是最短的（但是它可能是接近的）。这个题目相对复杂，所以我们不会再本教程中讲解，但是我在教程的末尾提供一个网络链接，对它做很好的解释。为让它更简单，我们将使用“曼哈顿距离方法”（也叫“曼哈顿长”或者“城市街区距离”），它只是计算出距离点B，剩下的水平和垂直的方块数量，略去障碍物或者不同陆地类型的数量。例如，下图展示使用“城市街区距离”，从不同的开始点到终点，去估算H的值（黑色字）。 8 A星算法既然你知道如何计算每个方块的和值（我们将它称为F，等于G+H), 我们来看下A*算法的原理。猫会重复以下步骤来找到最短路径。 将方块添加到open列表中，该列表有最小的和值。且将这个方块称为S吧。 将S从open列表移除，然后添加S到closed列表中。 对于与S相邻的每一块可通行的方块T： 如果T在closed列表中：不管它。 如果T不在open列表中：添加它然后计算出它的和值。 如果T已经在open列表中：当我们使用当前生成的路径到达那里时，检查F和值是否更小。如果是，更新它的和值和它的前继。 如果你对它的工作原理还有点疑惑，不用担心 – 我们会用例子一步步介绍它的原理！ 9 猫的路径让我们看下我们的懒猫到达骨头的行程例子。在下图中，我根据以下内容，列出了公式F = G + H中的每项值。 F（方块的和值）：左上角 G（从A点到方块的移动量）：左下角 H（从方块到B点的估算移动量）： 右下角 同时，箭头指示了到达相应方块的移动方向。最后，在每一步中，红色方块表示closed列表，绿色方块表示open列表。好的，我们开始吧！ 第一步第一步，猫会确定相对于开始位置（点A）的相邻方块，计算出他们的F和值，然后把他们添加到open列表中。你会看到每个方块都列出H值（有两个是6，一个是4）。我建议根据“城市街区距离”去计算方块的相关值，确保你理解它的原理。同时注意F值（在左上角）是G（左下角）值和H（右下脚）值的和。 第二步在第二步中，猫选择F和值最小的方块，把它添加到closed列表中，然后检索它的相邻方块的相关数值。现在你将看到拥有最小增量的是F值为5的方块。猫尝试添加所有相邻的方块到open列表中（然后计算他们的和值），除猫自身的方块不能添加以外（因为它已经被添加到closed列表中）或者它是墙壁方块（因为它不能通行）。注意被添加到open列表的两个新方块，他们的G值都增加1，因为他们现在离开始点有2个方块远。你也许需要再计算下“城市街区距离”以确保你理解每个新方块的H值。 第三步再次，我们选择有最小F和值（5）的方块，继续重复之前的步骤。现在，只有一个可能的方块被添加到open列表中，因为已经有一个相邻的方块在close列表中，其他两个是墙壁方块。 第四步现在我们遇到一个有趣的情况。正如你之前看到的，有4个方块的F和值都为7 – 我们要怎么做呢？！有几种解决方法可以使用，但是最简单（快速）的方法是一直跟着最近被添加到open列表中的方块。（F相同的时候，取最新的F值路径。因为之前的F值都相互比较过）现在继续沿着最近被添加的方块前进。这次有两个可通过的相邻方块，我们还是像之前那样计算他们的和值。 第五步接着我们选择最小和值（7）的方块，继续重复之前的步骤。我们越来越接近终点！ 第六步你现在训练有素！我打赌你能够猜出下一步是下面这样子。我们差不多到终点，但是这次你看到有两条到达骨头的最短路径提供给我们选择。在我们的例子中，有两条最短路径。 1-2-3-4-5-6 1-2-3-4-5-7 It doesn’t really matter which of these we choose, it comes down to the actual implementation in code.选择哪一条其实没关系，现在到真正用代码实现的时候。 第七步让我们从其中一块方块，再重复一遍步骤吧。骨头在open列表中！ 第八步现在目标方块在open列表中，算法会把它添加到closed列表中。然后，算法要做的所有事情就是返回，计算出最终的路径！ 10 一只有远见的猫在上面的例子中，我们看到当猫在寻找最短路径时，它经常选择更好的方块（那个在它的未来最短路径上的方块）- 好像它是一只有远见的猫！但是如果猫是盲目的，并且总是选择第一个添加到它的列表上的方块，会发生什么事情？下图展示所有在寻找过程中会被使用到的方块。你会看到猫在尝试更多的方块，但是它仍然找到最短路径（不是之前的那条，而是另一条等价的）。图中的红色方块不代表最短路径，它们只是代表在某个时候被选择为“S”的方块。我建议你看着上面的图，并且尝试过一遍步骤。这次无论你看到哪个相邻的方块，都选择“最坏”的方式去走。你会发现最后还是找到最短路径！所以你可以看到跟随一个“错误的”方块是没有问题的，你仍然会在多次重复尝试后找到最短路径。所以在我们的实现中，我们会按照以下的算法添加方块到open列表中。 相邻的方块会返回这些顺序: 上面/左边/下面/右边。 当所有的方块都有相同的和值后，方块会被添加到open列表中（所以第一个被添加的方块是第一个被猫挑选的）。 下面是从原路返回的示意图。最短的路径是从终点开始，一步步返回到起点构成的（例子：在终点我们可以看到箭头指向右边，所以该方块的前继在它的左边）。总的来说，我们可以用下面的伪代码，合成猫的寻找过程。这是Objective-C写的，但是你可以用任何的语言去实现它。 object-c123456789101112131415161718192021222324252627282930313233[openList add:originalSquare]; // start by adding the original position to the open listdo { currentSquare = [openList squareWithLowestFScore]; // Get the square with the lowest F score [closedList add:currentSquare]; // add the current square to the closed list [openList remove:currentSquare]; // remove it to the open list if ([closedList contains:destinationSquare]) { // if we added the destination to the closed list, we've found a path // PATH FOUND break; // break the loop } adjacentSquares = [currentSquare walkableAdjacentSquares]; // Retrieve all its walkable adjacent squares foreach (aSquare in adjacentSquares) { if ([closedList contains:aSquare]) { // if this adjacent square is already in the closed list ignore it continue; // Go to the next adjacent square } if (![openList contains:aSquare]) { // if its not in the open list // compute its score, set the parent [openList add:aSquare]; // and add it to the open list } else { // if its already in the open list // test if using the current G score make the aSquare F score lower, if yes update the parent because it means its a better path } } } while(![openList isEmpty]); // Continue until there is no more available square in the open list (which means there is no path) java1 上下左右寻找，未做斜对角线寻找路径Node.java节点类，存x，y，parent（原路返回的节点），计算F的值。123456789101112131415161718192021222324252627package demo1;/** * 节点 * */public class Node { //父节点，只是寻找回去的路径 public Node parent; public Node(int x, int y) { this.x = x; this.y = y; } public int x; public int y; public int F; public int G; public int H; public void calcF() { this.F = this.G + this.H; }} StarA.java寻最短路径核心算法。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264package demo1;import java.util.ArrayList;import java.util.List;public class StarA { public static final int[][] NODES = { { 0, 0, 0, 0, 0, 0, 0, 0, 0 }, { 0, 0, 0, 0, 0, 0, 0, 0, 0 }, { 0, 0, 0, 0, 0, 0, 0, 0, 0 }, { 0, 0, 0, 1, 0, 0, 0, 0, 0 }, { 0, 0, 0, 1, 0, 0, 0, 0, 0 }, { 0, 0, 0, 1, 0, 0, 0, 0, 0 }, { 0, 0, 0, 1, 0, 0, 0, 0, 0 }, { 0, 0, 0, 0, 0, 0, 0, 0, 0 }, { 0, 0, 0, 0, 0, 0, 0, 0, 0 }, }; /*{ 0, 0, 0, 0, 0, 0, 0, 0, 0 }, { 0, 0, 0, 0, 0, 0, 0, 0, 0 }, { 0, 0, 0, 0, 0, 0, 0, 0, 0 }, { 0, 0, 0, 1, 0, 0, 0, 0, 0 }, { 0, 0, 0, 1, 0, 0, 0, 0, 0 }, { 0, 2, 2, 1, 0, 2, 0, 0, 0 }, { 0, 0, 2, 1, 0, 2, 0, 0, 0 }, { 0, 0, 2, 2, 2, 2, 0, 0, 0 }, { 0, 0, 0, 0, 0, 0, 0, 0, 0 }, */ public static final int STEP = 10; private ArrayList&lt;Node&gt; openList = new ArrayList&lt;Node&gt;(); private ArrayList&lt;Node&gt; closeList = new ArrayList&lt;Node&gt;(); /** * 查最短F节点在OpenList中 * @return */ public Node findMinFNodeInOpneList() { //假设第一个点，F值最小 Node tempNode = openList.get(0); for (Node node : openList) { if (node.F &lt;= tempNode.F) { tempNode = node; } } return tempNode; } /** * 查相邻的节点 * @param currentNode 当前的节点 * @return */ public ArrayList&lt;Node&gt; findNeighborNodes(Node currentNode) { ArrayList&lt;Node&gt; arrayList = new ArrayList&lt;Node&gt;(); // 只考虑上下左右，不考虑斜对角 int topX = currentNode.x; int topY = currentNode.y - 1; //在面板范围内 if (canReach(topX, topY) &amp;&amp; !exists(closeList, topX, topY)) { arrayList.add(new Node(topX, topY)); } int bottomX = currentNode.x; int bottomY = currentNode.y + 1; if (canReach(bottomX, bottomY) &amp;&amp; !exists(closeList, bottomX, bottomY)) { arrayList.add(new Node(bottomX, bottomY)); } int leftX = currentNode.x - 1; int leftY = currentNode.y; if (canReach(leftX, leftY) &amp;&amp; !exists(closeList, leftX, leftY)) { arrayList.add(new Node(leftX, leftY)); } int rightX = currentNode.x + 1; int rightY = currentNode.y; if (canReach(rightX, rightY) &amp;&amp; !exists(closeList, rightX, rightY)) { arrayList.add(new Node(rightX, rightY)); } return arrayList; } /** * 是否能到达 * @param x * @param y * @return */ public boolean canReach(int x, int y) { if (x &gt;= 0 &amp;&amp; x &lt; NODES.length &amp;&amp; y &gt;= 0 &amp;&amp; y &lt; NODES[0].length) { return NODES[x][y] == 0; } return false; } /** * 查到路径 * @param startNode 开始位置 * @param endNode 结束位置 * @return */ public Node findPath(Node startNode, Node endNode) { // 把起点加入 open list openList.add(startNode); while (openList.size() &gt; 0) { // 遍历 open list ，查找 F值最小的节点，把它作为当前要处理的节点 Node currentNode = findMinFNodeInOpneList(); // 从open list中移除 openList.remove(currentNode); // 把这个节点移到 close list，路径节点 closeList.add(currentNode); //周围节点 ArrayList&lt;Node&gt; neighborNodes = findNeighborNodes(currentNode); for (Node node : neighborNodes) { //存在openlist中，是待考虑的路径 if (exists(openList, node)) { //重新计算g值，重新赋值 foundPoint(currentNode, node); } else {//openlist不存在，添加到openlist中 notFoundPoint(currentNode, endNode, node); } } //查询节点是否在待考虑的openlist中 if (find(openList, endNode) != null) { return find(openList, endNode); } } return find(openList, endNode); } /** * 查节点，计算g值，g值小的重新计算F值 * @param tempStart * @param node */ private void foundPoint(Node tempStart, Node node) { int G = calcG(tempStart, node); if (G &lt; node.G) { node.parent = tempStart; node.G = G; node.calcF(); } } /** * * @param tempStart 父节点 * @param end 最终位置节点 * @param node 当前位置的节点 */ private void notFoundPoint(Node tempStart, Node end, Node node) { node.parent = tempStart; node.G = calcG(tempStart, node); node.H = calcH(end, node); node.calcF(); openList.add(node); } /** * G是从开始点A到达当前方块的移动量 * 计算G * @param start * @param node * @return */ private int calcG(Node start, Node node) { int G = STEP; int parentG = node.parent != null ? node.parent.G : 0; return G + parentG; } /** * H值是从当前方块到终点的移动量估算值 * @param end 结束节点位置 * @param node 当前位置 * @return */ private int calcH(Node end, Node node) { int step = Math.abs(node.x - end.x) + Math.abs(node.y - end.y); return step * STEP; } /** * 查询节点在list中 * @param nodes * @param point * @return */ public static Node find(List&lt;Node&gt; nodes, Node point) { for (Node n : nodes) if ((n.x == point.x) &amp;&amp; (n.y == point.y)) { return n; } return null; } /** * 节点是否在list中 * @param nodes * @param node * @return */ public static boolean exists(List&lt;Node&gt; nodes, Node node) { for (Node n : nodes) { if ((n.x == node.x) &amp;&amp; (n.y == node.y)) { return true; } } return false; } /** * 节点是否在list中 * @param nodes * @param x * @param y * @return */ public static boolean exists(List&lt;Node&gt; nodes, int x, int y) { for (Node n : nodes) { if ((n.x == x) &amp;&amp; (n.y == y)) { return true; } } return false; } public static void main(String[] args) { Node startNode = new Node(5, 1); Node endNode = new Node(5, 5); Node parent = new StarA().findPath(startNode, endNode); for (int i = 0; i &lt; NODES.length; i++) { for (int j = 0; j &lt; NODES[0].length; j++) { System.out.print(NODES[i][j] + \", \"); } System.out.println(); } //添加所有的路径 ArrayList&lt;Node&gt; arrayList = new ArrayList&lt;Node&gt;(); while (parent != null) { // System.out.println(parent.x + \", \" + parent.y); arrayList.add(new Node(parent.x, parent.y)); parent = parent.parent; } System.out.println(\"\\n\"); for (int i = 0; i &lt; NODES.length; i++) { for (int j = 0; j &lt; NODES[0].length; j++) { if (exists(arrayList, i, j)) { System.out.print(\"2, \"); } else { System.out.print(NODES[i][j] + \", \"); } } System.out.println(); } }} 结果：123456789101112131415161718192021原地址0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 最短路径0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 2, 2, 1, 0, 2, 0, 0, 0, 0, 0, 2, 1, 0, 2, 0, 0, 0, 0, 0, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2 上下左右，斜对角线寻找Node2.java节点类，存x，y，parent（原路返回的节点），比较F的大小。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879package demo2;import java.util.Comparator;/** * 节点类 * */class Node2 { private int x;// X坐标 private int y;// Y坐标 private Node2 parentNode;// 父类节点 private int g;// 当前点到起点的移动耗费 private int h;// 当前点到终点的移动耗费，即曼哈顿距离|x1-x2|+|y1-y2|(忽略障碍物) private int f;// f=g+h public Node2(int x, int y, Node2 parentNode) { this.x = x; this.y = y; this.parentNode = parentNode; } public int getX() { return x; } public void setX(int x) { this.x = x; } public int getY() { return y; } public void setY(int y) { this.y = y; } public Node2 getParentNode() { return parentNode; } public void setParentNode(Node2 parentNode) { this.parentNode = parentNode; } public int getG() { return g; } public void setG(int g) { this.g = g; } public int getH() { return h; } public void setH(int h) { this.h = h; } public int getF() { return f; } public void setF(int f) { this.f = f; }}// 节点比较类class NodeFComparator implements Comparator&lt;Node2&gt; { @Override public int compare(Node2 o1, Node2 o2) { return o1.getF() - o2.getF(); }} StarA2.java：寻最短路径核心算法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255package demo2;import java.util.ArrayList;import java.util.Collections;import java.util.List;/** * * A星算法步骤： * 1.起点先添加到开启列表中 * 2.开启列表中有节点的话，取出第一个节点，即最小F值的节点 * 判断此节点是否是目标点，是则找到了，跳出 * 根据此节点取得八个方向的节点，求出G，H，F值 判断每个节点在地图中是否能通过，不能通过则加入关闭列表中，跳出 判断每个节点是否在关闭列表中，在则跳出 * 判断每个节点是否在开启列表中，在则更新G值，F值，还更新其父节点； * 不在则将其添加到开启列表中，计算G值，H值，F值，添加其节点 * 3.把此节点从开启列表中删除，再添加到关闭列表中 * 4.把开启列表中按照F值最小的节点进行排序，最小的F值在第一个 * 5.重复2，3，4步骤 * 直到目标点在开启列表中，即找到了；目标点不在开启列表中，开启列表为空，即没找到 * */public class StarA2 { private int[][] map;// 地图(1可通过 0不可通过) private List&lt;Node2&gt; openList;// 开启列表 private List&lt;Node2&gt; closeList;// 关闭列表 private final int COST_STRAIGHT = 10;// 垂直方向或水平方向移动的路径评分 private final int COST_DIAGONAL = 14;// 斜方向移动的路径评分 private int row;// 行 private int column;// 列 public StarA2(int[][] map, int row, int column) { this.map = map; this.row = row; this.column = column; openList = new ArrayList&lt;Node2&gt;(); closeList = new ArrayList&lt;Node2&gt;(); } /** * 查找坐标（-1：错误，0：没找到，1：找到） * * @param x1 起始位置X * @param y1 起始位置Y * @param x2 结束位置X * @param y2 结束位置Y * @return （-1：错误，0：没找到，1：找到） */ public int search(int x1, int y1, int x2, int y2) { if (x1 &lt; 0 || x1 &gt;= row || x2 &lt; 0 || x2 &gt;= row || y1 &lt; 0 || y1 &gt;= column || y2 &lt; 0 || y2 &gt;= column) { return -1; } if (map[x1][y1] == 0 || map[x2][y2] == 0) { return -1; } Node2 sNode = new Node2(x1, y1, null); Node2 eNode = new Node2(x2, y2, null); openList.add(sNode); List&lt;Node2&gt; resultList = search(sNode, eNode); // 没有找到 if (resultList.size() == 0) { return 0; } // 遍历结果，x，y赋值 for (Node2 node : resultList) { map[node.getX()][node.getY()] = -1; } // 找到 return 1; } /** * 查找核心算法 * * @param sNode * @param eNode 目标节点 * @return */ private List&lt;Node2&gt; search(Node2 sNode, Node2 eNode) { List&lt;Node2&gt; resultList = new ArrayList&lt;Node2&gt;(); boolean isFind = false; Node2 node = null; while (openList.size() &gt; 0) { // 取出开启列表中最低F值，即第一个存储的值的F为最低的 // 有可能是目标节点的上一个节点 node = openList.get(0); // 判断是否找到目标点 if (node.getX() == eNode.getX() &amp;&amp; node.getY() == eNode.getY()) { isFind = true; break; } // 上 if ((node.getY() - 1) &gt;= 0) { checkPath(node.getX(), node.getY() - 1, node, eNode, COST_STRAIGHT); } // 下 if ((node.getY() + 1) &lt; column) { checkPath(node.getX(), node.getY() + 1, node, eNode, COST_STRAIGHT); } // 左 if ((node.getX() - 1) &gt;= 0) { checkPath(node.getX() - 1, node.getY(), node, eNode, COST_STRAIGHT); } // 右 if ((node.getX() + 1) &lt; row) { checkPath(node.getX() + 1, node.getY(), node, eNode, COST_STRAIGHT); } // 左上 if ((node.getX() - 1) &gt;= 0 &amp;&amp; (node.getY() - 1) &gt;= 0) { checkPath(node.getX() - 1, node.getY() - 1, node, eNode, COST_DIAGONAL); } // 左下 if ((node.getX() - 1) &gt;= 0 &amp;&amp; (node.getY() + 1) &lt; column) { checkPath(node.getX() - 1, node.getY() + 1, node, eNode, COST_DIAGONAL); } // 右上 if ((node.getX() + 1) &lt; row &amp;&amp; (node.getY() - 1) &gt;= 0) { checkPath(node.getX() + 1, node.getY() - 1, node, eNode, COST_DIAGONAL); } // 右下 if ((node.getX() + 1) &lt; row &amp;&amp; (node.getY() + 1) &lt; column) { checkPath(node.getX() + 1, node.getY() + 1, node, eNode, COST_DIAGONAL); } // 从开启列表中删除 // 添加到关闭列表中 closeList.add(openList.remove(0)); // 开启列表中排序，把F值最低的放到最底端 Collections.sort(openList, new NodeFComparator()); } //是否结束 if (isFind) { getPath(resultList, node); } return resultList; } /** * 查询此路是否能走通（节点是否可以达到） * @param x * @param y * @param parentNode 父节点 * @param eNode 目标节点 * @param cost * @return */ private boolean checkPath(int x, int y, Node2 parentNode, Node2 eNode, int cost) { Node2 node = new Node2(x, y, parentNode); // 查找地图中是否能通过 //0：可以到达 if (map[x][y] == 0) { closeList.add(node); return false; } // 查找关闭列表中是否存在 //在closeList中，则不可达 if (isListContains(closeList, x, y) != -1) { return false; } // 查找开启列表中是否存在 int index = -1; //在openlist中存在 if ((index = isListContains(openList, x, y)) != -1) { // G值是否更小，即是否更新G，F值 // 重新设置节点G，F值 if ((parentNode.getG() + cost) &lt; openList.get(index).getG()) { node.setParentNode(parentNode); countG(node, eNode, cost); countF(node); openList.set(index, node); } } else {//节点不再openlist中 // 添加到开启列表中 node.setParentNode(parentNode); //计算G,H,F值 count(node, eNode, cost); openList.add(node); } return true; } /** * 集合中是否包含某个元素(-1：没有找到，否则返回所在的索引) * @param list * @param x * @param y * @return */ private int isListContains(List&lt;Node2&gt; list, int x, int y) { for (int i = 0; i &lt; list.size(); i++) { Node2 node = list.get(i); if (node.getX() == x &amp;&amp; node.getY() == y) { return i; } } return -1; } /** * 从终点往返回到起点（原路返回） * 递归 * @param resultList * @param node */ private void getPath(List&lt;Node2&gt; resultList, Node2 node) { if (node.getParentNode() != null) { getPath(resultList, node.getParentNode()); } resultList.add(node); } /** * 计算G,H,F值 * @param node * @param eNode * @param cost */ private void count(Node2 node, Node2 eNode, int cost) { countG(node, eNode, cost); countH(node, eNode); countF(eNode); } /** * 计算G值（从A点到方块的移动量） * @param node * @param eNode * @param cost */ private void countG(Node2 node, Node2 eNode, int cost) { //父节点是null，直接设置G值 if (node.getParentNode() == null) { node.setG(cost); } else { node.setG(node.getParentNode().getG() + cost); } } /** * 计算H值（从方块到B点的估算移动量） * @param node * @param eNode */ private void countH(Node2 node, Node2 eNode) { node.setF(Math.abs(node.getX() - eNode.getX()) + Math.abs(node.getY() - eNode.getY())); } /** * 计算F值 * @param node */ private void countF(Node2 node) { node.setF(node.getG() + node.getH()); }} 12345678910111213141516171819202122232425262728293031323334353637package demo2;public class TestStarA2 { static int[][] map=new int[][]{// 地图数组 {1,1,1,1,1,1,1,1,1,1}, {1,1,1,1,0,1,1,1,1,1}, {1,1,1,1,0,1,1,1,1,1}, {1,1,1,1,0,1,1,1,1,1}, {1,1,1,1,0,1,1,1,1,1}, {1,1,1,1,0,1,1,1,1,1} }; public static void main(String[] args) { StarA2 aStar = new StarA2(map, 6, 10); int flag = aStar.search(3, 0, 3, 8); if (flag == -1) { System.out.println(\"传输数据有误！\"); } else if (flag == 0) { System.out.println(\"没找到！\"); } else {// 找到 //遍历行 for (int x = 0; x &lt; 6; x++) { for (int y = 0; y &lt; 10; y++) { if (map[x][y] == 1) { System.out.print(\"0\"); } else if (map[x][y] == 0) { System.out.print(\"1\"); } else if (map[x][y] == -1) { System.out.print(\"2\"); } } System.out.println(); } } }} 结果：123456022220000020001200002000102000200010022000001000000000100000 10 改进优化速度排序查找算法顾名思义，这个算法就是，始终维持开启列表的排序，从小到大，或者从大到小，这样当我们查找最小值时，只需要把第一个节点取出来就行。提高openList 二叉树查找算法这个算法可以说是A*算法的黄金搭档，也是被称为苛求速度的binary heap的方法。就是根据二叉树原理，来维持开启列表的“排序”，这里说的排序只是遵循二叉树的原理的排序而已，即父节点永远比子节点小,就像下面这样。123456graph TD;1--&gt;5;1--&gt;9;5--&gt;7;9--&gt;12;9--&gt;10; 二叉树每个节点的父节点下标 = n / 2;(小数去掉)二叉树每个节点的左子节点下标 = n 2;右子节点下标 = n 2 +1注意，这里的下标和它的值是两个概念。我们看到，耗时15毫秒，速度是这三个方法里最快的，但是因为这个数字是不够准确的，实际上，用二叉树查找法，会让A*算法的速度提高几倍到10几倍，在一些足够复杂的地图里，这个速度是成指数成长的。 总结得出结论，用A*算法，就要配套的用它的黄金搭档，二叉树，它可以让你的游戏由完美走向更完美。","link":"/A+Star/"},{"title":"(转载)AOP知识","text":"1 基础知识 AOP的3个实现层面 AOP的3个实现层面 实现机制比较 AOP的基础 Joinpoint Pointcut Advice JoinPoint、Pointcut、Advice之间的关系 2 动态字节码生成 原理 3 字节码修改 4 字节码转换器 配置 执行结果 1 基础知识AOP的3个实现层面AOP就是面向切面编程，可以从3个层面来实现AOP 编译期：修改源代码。 字节码加载前：修改字节码。 字节码加载后：动态创建代理类的字节码。AOP的3个实现层面实现机制比较 AOP的基础Joinpoint拦截点，如某个业务方法。PointcutJoinpoint的表达式，表示拦截哪些方法。一个Pointcut对应多个Joinpoint。Advice要切入的逻辑。 Before Advice：在方法前切入。 After Advice：在方法后切入，抛出异常时也会切入。 After Returning Advice：在方法返回后切入，抛出异常则不会切入。 After Throwing Advice：在方法抛出异常时切入。 Around Advice：在方法执行前后切入，可以中断或忽略原有流程的执行。JoinPoint、Pointcut、Advice之间的关系织入器通过在切面中定义pointcut来搜索目标（被代理类）的JoinPoint(切入点)，然后把要切入的逻辑（Advice）织入到目标对象里，生成代理类。2 动态字节码生成原理运行期间目标字节码加载后，生成目标类的子类，将切面逻辑加入到子类中。所以使用Cglib实现AOP不需要基于接口，Cglib底层是实现ASM的。123456789101112131415161718192021222324252627282930313233343536373839public class CglibAopDemo { public static void main(String[] args) { byteCodeGe(); } public static void byteCodeGe() { // 创建一个织入器 Enhancer enhancer = new Enhancer(); // 设置父类 enhancer.setSuperclass(Business.class); // 设置需要织入的逻辑-InvocationHandler enhancer.setCallback(new LogIntercept()); // 创建子类对象 IBusiness2 newBusiness = (IBusiness2) enhancer.create(); newBusiness.doSomeThing2(); } /** * 记录日志 * * 类似InvocationHandler，织入新的逻辑 * */ public static class LogIntercept implements MethodInterceptor { @Override public Object intercept(Object target, Method method, Object[] args, MethodProxy proxy) throws Throwable { // 执行原有逻辑 Object rev = proxy.invokeSuper(target, args); // 执行织入的日志 if (method.getName().equals(\"doSomeThing2\")) { System.out.println(\"记录日志\"); } return rev; } }} 3 字节码修改在类加载到JVM之前直接修改某些类的方法，并将切入逻辑织入到这个方法里，然后将修改后的字节码文件交给虚拟机运行。Javassist是一个编辑字节码的框架，可以很简单地操作字节码。它可以在运行期定义或修改Class。使用Javassist实现AOP的原理是在字节码加载前直接修改需要切入的方法。这比使用Cglib实现AOP更加高效（不用生成代理类），并且没太多限制。12345678910111213public static void aop() throws NotFoundException, CannotCompileException, InstantiationException, IllegalAccessException { // 获取存放CtClass的容器ClassPool ClassPool cp = ClassPool.getDefault(); // 获取class CtClass cc = cp.get(\"model.Business\"); // 获得指定方法名的方法 CtMethod m = cc.getDeclaredMethod(\"doSomeThing\"); // 在方法执行前插入代码 m.insertBefore(\"{ System.out.println(\\\"记录日志\\\"); }\"); // 执行方法 ((Business) cc.toClass().newInstance()).doSomeThing();} 4 字节码转换器使用Instrumentation，它是Java 5提供的新特性，使用Instrumentation，可以构建一个字节码转换器，在字节码加载前进行转换。本节使用Instrumentation和Javassist来实现AOP。123456789101112131415161718192021222324252627282930313233343536373839404142/** * jdk自带的字节码转换器 */public class MyClassFileTransformer implements ClassFileTransformer { /** * 字节码加载到虚拟机前会进入这个方法 */ @Override public byte[] transform(ClassLoader loader, String className, Class&lt;?&gt; classBeingRedefined, ProtectionDomain protectionDomain, byte[] classfileBuffer) throws IllegalClassFormatException { System.out.println(className); // 如果加载Business类才拦截 if (!\"model/Business\".equals(className)) { return null; } // javassist的包名是用点分割的，需要转换下 if (className != null &amp;&amp; className.indexOf(\"/\") != -1) { className = className.replaceAll(\"/\", \".\"); } try { CtClass cc = ClassPool.getDefault().get(className); CtMethod m = cc.getDeclaredMethod(\"doSomeThing\"); m.insertBefore(\"{ System.out.println(\\\"记录日志\\\"); }\"); return cc.toBytecode(); } catch (NotFoundException e) { } catch (CannotCompileException e) { } catch (IOException e) { // 忽略异常处理 } return null; } /** * 注册转换器 */ public static void premain(String options, Instrumentation ins) { // 注册我自己的字节码转换器 ins.addTransformer(new MyClassFileTransformer()); }} 1234public static void main(String[] args) { new Business().doSomeThing(); new Business().doSomeThing2(); } 配置需要告诉JVM在启动main()之前，需要先执行premain()（注册转换器）。首先需要将premain()所在的类打成jar。并修改该jar里的META-INF\\MANIFEST.MF文件。12Manifest-Version: 1.0 Premain-Class: bci.MyClassFileTransformer 然后在JVM的启动参数里加上：1-javaagent:D:\\java\\projects\\opencometProject\\Aop\\lib\\aop.jar 执行结果12345678model/Businessmodel/IBusinessmodel/IBusiness2执行业务逻辑2记录日志执行业务逻辑1java/lang/Shutdownjava/lang/Shutdown$Lock","link":"/AOP/"},{"title":"活动选择问题(贪心算法)","text":"1 概述 2 解题思路 有2种解题方法 迭代方法 递归方法 3 程序代码 迭代方法 伪代码 C++版本 Java版本 递归方法 1 概述设有n个活动的集合E={1,2,…,n}，其中每个活动都要求使用同一资源，如演讲会场等，而在同一时间内只有一个活动能使用这一资源。每个活动i都有一个要求使用该资源的起始时间$s_i$和一个结束时间$f_i$，且$s_i$&lt;$f_i$。如果选择了活动i，则它在半开时间区间[$s_i$, $f_i$)内占用资源。若区间[$s_i$, $f_i$)与区间[$s_j$, $f_j$)不相交，则称活动i与活动j是相容的。也就是说，当$s_i$≥$f_j$或$s_j$≥$f_i$时，活动i与活动j相容。活动安排问题就是要在所给的活动集合中选出最大的相容活动子集合。 2 解题思路假定活动已按结束时间的单调递增顺序排序（小到大排序）：f1 ≤ f2 ≤ f3 ≤....≤ fn-1 ≤ fn用i代表第i个活动，s[i]代表第i个活动开始时间，f[i]代表第i个活动的结束时间。按照从小到大排序，挑选出结束时间尽量早的活动，并且满足后一个活动的起始时间晚于前一个活动的结束时间，全部找出这些活动就是最大的相容活动子集合。事实上系统一次检查活动i是否与当前已选择的所有活动相容。若相容活动i加入已选择活动的集合中，否则，不选择活动i，而继续i位置的下一个活动与集合A中活动比较相容性（集合A中的活动也就是上次比较的活动）。若活动i与之相容，则i成为最近加入集合A的活动，并取代活动j的位置（迭代方法）。 有2种解题方法迭代方法每次总是选择具有最早完成时间的相容活动加入集合A中（默认第1个加入集合A中）。直观上，按这种方法选择相容活动为未安排活动留下尽可能多的时间（因为添加到集合A中的时间最短，剩余的时间就长）。也就是说，该算法的贪心选择的意义是使剩余的可安排时间段极大化，以便安排尽可能多的相容活动。迭代方法的计算过程如下图所示。图中每行相应于算法的一次迭代。阴影长条表示的活动是已选入集合A的活动，而空白长条表示的活动是当前正在检查相容性的活动。若被检查的活动i的开始时间$s_i$小于最近选择的活动j的结束时间$f_i$，则不选择活动i，否则选择活动i加入集合A中。迭代方法的效率极高。当输入的活动已按结束时间的非减序排列，算法只需O(n)的时间安排n个活动，使最多的活动能相容地使用公共资源。如果所给出的活动未按非减序排列，可以用O(nlogn)的时间重排。 递归方法每次都是从相同位置开始，S和F开始比较是否兼容，如果F(i)&lt;S(M)，标记位M放入集合A中，下一次比较从M+1标记位开始。 3 程序代码迭代方法伪代码123456789GreedyActivitySelector(s,f) n &lt;- length(s) A &lt;- {a1} i &lt;- 1 for m &lt;- 2 to n do if Sm ≤ Fi then A &lt;- A U {am} i &lt;- m return A C++版本定义：s[]代表开始时间，f[]代表结束时间，n表示活动个数。准备工作：先对f[]进行排序，而且保持s[]与f[]一致。1234567891011121314public static int[] GreedyAc(int s[], int f[], int n){ int x[] = new int[n]; //默认标记第一个标记位i存入集合A中 x[0] = 1; int j = 0; //j用来表示f数组的下标值 for(int i = 1; i &lt; n; i++){ //判断下一个活动的开始时间是否比当前活动的结束时间晚 if(s[i] &gt;= f[j]){ x[i] = 1;//标记i位置存入集合A中 j = i;//i位置存入集合A中，那下次比较f的时候，就从i位置开始，i已经在集合活动中，下一个活动时间要比i来的晚 } } return x;} 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556//4d1 活动安排问题 贪心算法 #include \"stdafx.h\" #include &lt;iostream&gt; using namespace std; template&lt;class Type&gt; void GreedySelector(int n, Type s[], Type f[], bool A[]); const int N = 11; int main() { //下标从1开始,存储活动开始时间 int s[] = {0,1,3,0,5,3,5,6,8,8,2,12}; //下标从1开始,存储活动结束时间 int f[] = {0,4,5,6,7,8,9,10,11,12,13,14}; bool A[N+1]; cout&lt;&lt;\"各活动的开始时间,结束时间分别为：\"&lt;&lt;endl; for(int i=1;i&lt;=N;i++) { cout&lt;&lt;\"[\"&lt;&lt;i&lt;&lt;\"]:\"&lt;&lt;\"(\"&lt;&lt;s[i]&lt;&lt;\",\"&lt;&lt;f[i]&lt;&lt;\")\"&lt;&lt;endl; } GreedySelector(N,s,f,A); cout&lt;&lt;\"最大相容活动子集为：\"&lt;&lt;endl; for(int i=1;i&lt;=N;i++) { if(A[i]){ cout&lt;&lt;\"[\"&lt;&lt;i&lt;&lt;\"]:\"&lt;&lt;\"(\"&lt;&lt;s[i]&lt;&lt;\",\"&lt;&lt;f[i]&lt;&lt;\")\"&lt;&lt;endl; } } return 0; } template&lt;class Type&gt; void GreedySelector(int n, Type s[], Type f[], bool A[]) { A[1]=true; int j=1;//记录第1次加入A中的活动 for (int i=2;i&lt;=n;i++)//依次检查活动i是否与当前已选择的活动相容 { if (s[i]&gt;=f[j]) { A[i]=true; j=i; } else { A[i]=false; } } } 123456789101112131415161718192021222324252627282930313233343536373839#include&lt;stdio.h&gt;# define N 11void GreadyActivitySelector(int *s,int *f,int *A,int n);void RecursiveActivitySelector(int *s,int *f,int *A,int i,int n,int k);void main(){ int s[N]={1,3,0,5,3,5,6,8,8,2,12};//开始时间 int f[N]={4,5,6,7,8,9,10,11,12,13,14};//结束时间 int A[N]={0};//初始化 int n=N; GreadyActivitySelector(s,f,A,n);//迭代版本// RecursiveActivitySelector(s,f,A,0,n,0);//递归版本 for(int i=0;i&lt;n;i++) printf(\"%d \",A[i]);//被选择的活动 }/****************************************************\\函数功能：选择最佳的活动安排输入： 各个活动的起始时间和结束时间、待存储被选择活动的数组A、活动个数输出： 无\\****************************************************/void GreadyActivitySelector(int *s,int *f,int *A,int n)//迭代版本{ A[0]=1; int i=0; int j=1; for(int m=1;m&lt;n;m++) { if(s[m]&gt;=f[i])//开始时间大于上个活动的结束时间 { i=m; A[j]=m+1;//注意下标与第几位差一 j++; } }} Java版本1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556package demo2;/** * 活动安排问题（贪心算法） * * 迭代方法 * */public class ActionOrder { /** * 迭代方法 * * @param s 开始时间数组 * @param f 结束时间数组 * @param a 集合数组 * @return */ public int greedySelector(int[] s, int[] f, boolean[] a) { int n = s.length - 1; // 第一个活动被选中 a[1] = true; int j = 1; // 被选中活动的数量，默认第一个活动被选中 int count = 1; for (int i = 2; i &lt;= n; i++) { // 下一个活动开始时间大于大于等于上一个活动结束时间 if (s[i] &gt;= f[j]) { //当前时间是相互兼容的 a[i] = true; //当前时间开始的标记 赋值 时间结束的标记位，下次比较，下一个开始时间和当前结束时间进行比较 j = i; count++; } else {//i活动不兼容 a[i] = false; } } return count; } public static void main(String[] args) { // 默认下标从1开始（已非减序排好序），初始的-1无用 int s[] = { -1, 1, 3, 0, 5, 3, 5, 6, 8, 8, 2, 12 }; int f[] = { -1, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14 }; boolean[] a = new boolean[s.length]; ActionOrder ac = new ActionOrder(); int counts = ac.greedySelector(s, f, a); System.out.println(\"活动集合中最大相容活动数量为:\" + counts); for (int i = 1; i &lt;= s.length - 1; i++) { if (a[i]) { System.out.println(\"第\" + i + \"活动被选中，其开始时间为：\" + s[i] + \"，结束时间为：\" + f[i]); } } }} 结果：12345活动集合中最大相容活动数量为:4 第1活动被选中，其开始时间为：1，结束时间为：4 第4活动被选中，其开始时间为：5，结束时间为：7 第8活动被选中，其开始时间为：8，结束时间为：11 第11活动被选中，其开始时间为：12，结束时间为：14 递归方法 //s 开始时间集合//f 结束时间集合//A 符合条件的集合//i 结束集合的标记位//n 总数目//k A集合的标记位 12345678910111213141516171819/****************************************************\\\\****************************************************/void RecursiveActivitySelector(int *s,int *f,int *A,int i,int n,int k)//递归版本{ int j=k; int m=i; //找到结束时间大于上个活动开始时间的活动 while((m&lt;n)&amp;&amp;(s[m]&lt;f[i])&amp;&amp;(m!=0)){ m=m+1; } if(m&lt;n) { A[j]=m+1;//将被选择的活动存储起来 j++; RecursiveActivitySelector(s,f,A,m+1,n,j); }} 1234567891011121314public static void main(String[] args){ T *test=new T(); int s[N]={1,3,0,5,3,5,6,8,8,2,12};//开始时间 int f[N]={4,5,6,7,8,9,10,11,12,13,14};//结束时间 int A[N]={0};//初始化 int n=N; test-&gt;RecursiveActivitySelector(s,f,A,0,n,0);//递归版本 //被选择的活动 for(int i=0;i&lt;n;i++) { printf(\"%d \",A[i]); }} 第1次执行时：m没有变化，因为m=0第2次执行时：m=i=1，进入循环体m+1，i不变，m=2,i=1，f[1]和s[2]比较，2位置开始的时间大于等于1位置的结束时间，否则m+1，继续下一个位置和f[i]比较，直到m=5时，i=1时，s[m]=f[i]，开始的时间=结束的时间，m处于集合A中。第3次执行时：m=i=5，重复第2次执行的逻辑递归每次调用时候，s和f都是从同一个位置开始执行比较是否兼容。","link":"/Activity-Selection-Problem/"},{"title":"位运算","text":"1 基础知识 1.1 &amp;(与) 1.1.1 例子1 1.1.2 例子2 2.1 |(或) 2.1.1 例子1 2.1.2 例子2 3.1 ^(异或) 3.1.1 例子1 3.1.2 例子2 4.1 ~(非) 4.1.1 例子1 2 位置交换 1 基础知识1.1 &amp;(与)与运算符用符号&amp;表示，其使用规律如下：两个操作数中位都为1，结果才为1，否则结果为0。 1.1.1 例子1123int a=129;int b=128;System.out.println(\"a&amp;b的结果是：\"+(a&amp;b)); 1a&amp;b的结果是：128 “a”的值是129，转换成二进制就是：10000001。“b”的值是128，转换成二进制就是：10000000。根据与运算符的运算规律，只有两个位都是1，结果才是1，可以知道结果就是10000000，即128。 1.1.2 例子211&amp;2 10 “1”的二进制为：00000001。“2”的二进制为：00000010。结果为:00000000 = 0。 2.1 |(或)或运算符用符号|表示，其运算规律如下：两个位只要有一个为1，那么结果就是1，否则就为0。 2.1.1 例子1123int a=129;int b=128;System.out.println(\"a|b的结果是：\"+(a|b)); 1a|b的结果是：129 “a”的值是129，转换成二进制就是10000001。“b”的值是128，转换成二进制就是10000000。根据或运算符的运算规律，只有两个位有一个是1，结果才是1，可以知道结果就是10000001，即129。 2.1.2 例子215|6 console17 “5”的二进制为：00000101。“6”的二进制为：00000110。结果为：00000111 = 7 。 3.1 ^(异或)异或运算符是用符号^表示的，其运算规律是：两个操作数的位中，相同则结果为0，不同则结果为1。 3.1.1 例子1123int a=15;int b=2;System.out.println(\"a^b的结果是：\"+(a^b)); 1a^b的结果是：13 “a”的值是15，转换成二进制为1111。“b”的值是2，转换成二进制为0010。根据异或的运算规律，相同则结果为0，不同则结果为1，可以得出其结果为1101，即13。 3.1.2 例子2123 ^ 12 127 “23”转换为二进制为：00010111。“12”转换为二进制为：00001100。计算结果为：00011011 = 27。 4.1 ~(非)非运算符用符号~表示，其运算规律如下：如果位为0，结果是1，如果位为1，结果是0。 4.1.1 例子112int a=2;System.out.println(\"~a的结果是：\"+(~a)); 1~a的结果是：-3 “2”的二进制码为00000010， 它取反为11111101，可见取反后结果为负数。补码值：11111101（Java按照补码进行存取）非运算（~）：去反得到00000010然后+1得到00000011，得到的结果为3 ，然后在前面加上负号就可以了，所以结果为-3。 2 位置交换无需临时变量，替换两个变量的值，效率最高。12345678public static void main(String[] args) { int a = 1, b = 2; a = a ^ b; b = b ^ a; a = a ^ b; System.out.println(\"a=\" + a); System.out.println(\"b=\" + b);} 12a=2b=1","link":"/Bit-Operation/"},{"title":"回溯算法","text":"1 引言 2 概念 3 基本思想 4 步骤 1 引言寻找问题的解的一种可靠的方法是首先列出所有候选解，然后依次检查每一个，在检查完所有或部分候选解后，即可找到所需要的解。理论上，当候选解数量有限并且通过检查所有或部分候选解能够得到所需解时，上述方法是可行的。不过，在实际应用中，很少使用这种方法，因为候选解的数量通常都非常大（比如指数级，甚至是大数阶乘），即便采用最快的计算机也只能解决规模很小的问题。对候选解进行系统检查的方法有多种，其中回溯和分枝定界法是比较常用的两种方法。按照这两种方法对候选解进行系统检查通常会使问题的求解时间大大减少（无论对于最坏情形还是对于一般情形）。事实上，这些方法可以使我们避免对很大的候选解集合进行检查，同时能够保证算法运行结束时可以找到所需要的解。因此，这些方法通常能够用来求解规模很大的问题。 2 概念回溯算法也叫试探法，它是一种系统地搜索问题的解的方法（一种选优搜索法，按选优条件向前搜索，以达到目标）。当搜索到某一步时，发现原先选择并不优或达不到目标，就退回一步重新选择，这种走不通就退回再走的技术称为：回溯法，而满足回溯条件的某个状态的点称为：“回溯点”。回溯法实际是穷举算法，按问题某种变化趋势穷举下去，如某状态的变化用完还没有得到最优解，则返回上一种状态继续穷举。许多复杂的，规模较大的问题都可以使用回溯法，回溯算法有“通用解题方法”的美称，其采用了一种“走不通就掉头”思想作为其控制结构，用它可以求出问题的所有解和任意解。它的应用很广泛，很多算法都用到回溯法，例如，迷宫，八皇后问题，图的m着色总是等都用到回溯法，当然其中还使用了其他策略。 3 基本思想回溯算法的基本思想是：从一条路往前走，能进则进，不能进则退回来，换一条路再试。确定了解空间树的组织结构后，回溯法就从开始结点（根结点）出发，以深度优先的方式搜索整个解空间树。这个开始结点就成为一个活结点，同时也成为当前的扩展结点。在当前的扩展结点处，搜索向纵深方向移至一个新结点。这个新结点就成为一个新的活结点，并成为当前扩展结点。如果在当前的扩展结点处不能再向纵深方向移动，则当前扩展结点就成为死结点。此时，应往回移动（回溯）至最近的一个活结点处，并使这个活结点成为当前的扩展结点。回溯法即以这种工作方式递归地在解空间中搜索，直至找到所要求的解或解空间中已没有活结点时为止。 4 步骤用回溯算法解决问题的一般步骤为： 定义一个解空间树，它包含问题的解。解空间：至少包含问题的一个解。 利用适于搜索的方法组织解空间树。 利用深度优先法搜索解空间树。 利用限界函数避免移动到不可能产生解的子空间树。 问题的解空间树通常是在搜索问题的解的过程中动态产生的，这是回溯算法的一个重要特性。","link":"/Backtracking-Algorithm/"},{"title":"分支限界算法","text":"1 概念 回溯算法与分支限界法的不同之处 2 基本思想 2.1 队列式(FIFO)分支限界法 搜索策略 2.2 优先队列式分支限界法 搜索策略 3 示例 步骤 1 概念分支限界算法类似于回溯算法，也是一种在问题的解空间树T上搜索问题解的算法。但在一般情况下，分支限界法与回溯法的求解目标不同。 回溯算法与分支限界法的不同之处求解目标 回溯算法的求解目标：是找出T中满足约束条件的所有解。 分支限界算法的求解目标：是找出满足约束条件的一个解，或者是在满足约束条件的解中找出使某一目标函数值达到极大或者极小的解。（即：最优解） 搜索方式：由于求解目标不同，导致分支限界法和回溯法在解空间树T上的搜索方式也不相同。 回溯法：以深度优先的方式搜索解空间树T。 分支限界法：以广度优先的方式或者以最小耗费优先的方式搜索解空间树T。 2 基本思想在分支限界法中，每一个活结点只有一次机会成为扩展结点。活结点一旦成为扩展结点，就一次性产生其所有儿子结点。在这些儿子结点中，导致不可行解或导致非最优解的儿子结点被舍弃，其余儿子结点被加入活结点表中。此后，从活结点表中取下一结点成为当前扩展结点，并重复上述结点扩展过程。这个过程一直持续到找到所需的解或活结点表为空时为止。与回溯算法相似，限界函数的设计是分支限界法的一个核心问题。如何设计好限界函数来有效地减少搜索空间是应用分支限界法要考虑的问题。分支限界法首先确定一个合理的限界函数，并根据限界函数确定目标函数的界[down, up]；然后按照广度优先策略遍历问题的解空间树，在某一分支上，依次搜索该结点的所有孩子结点，分别估算这些孩子结点的目标函数的可能取值（对最小化问题，估算结点的down，对最大化问题，估算结点的up）。如果某孩子结点的目标函数值超出目标函数的界，则将其丢弃（从此结点生成的解不会比目前已得的更好），否则入待处理表（活动表）。根据从活动节点表中选择下一扩展节点的不同方式，可将分支限界法分为2种不同的类型： 2.1 队列式(FIFO)分支限界法按照队列先进先出（FIFO）原则选取下一个节点为扩展节点。 搜索策略一开始，根结点是唯一的活结点，根结点入队。从活结点队中取出根结点后，作为当前扩展结点。对当前扩展结点，先从左到右地产生它的所有儿子，用约束条件检查，把所有满足约束函数的儿子加入活结点队列中。再从活结点表中取出队首结点（队中最先进来的结点）为当前扩展结点，……，直到找到一个解或活结点队列为空为止。 2.2 优先队列式分支限界法按照优先队列中规定的优先级选取优先级最高的节点成为当前扩展节点。（通常在算法中用一个最大堆来实现最大优先级队列）。 搜索策略对每一活结点计算一个优先级（某些信息的函数值），并根据这些优先级；从当前活结点表中优先选择一个优先级最高（最有利）的结点作为扩展结点，使搜索朝着解空间树上有最优解的分支推进，以便尽快地找出一个最优解。再从活结点表中下一个优先级别最高的结点为当前扩展结点，……，直到找到一个解或活结点队列为空为止。 3 示例问题：0-1背包问题，当n=3时，w={16,15,15}, p={45,25,25}, c=30当n=3时候，解空间。1{{0，0，0}，{0，1，0}，{0，0，1}，{1，0，0}，{0，1，1}，{1，0，1}，{1，1，0}，{1，1，1}} 1：物品需要放到包里0：物品不需要放到包里 步骤 初始化时候活动点队列为空。 节点A是当前扩展节点，它的两个儿子节点B和C均为可行节点，将两个儿子节点按照从左到右的顺序加入活节点队列，并且舍弃当前扩展节点A。 按照先进先出的原则，下一个扩展节点是活节点队列的队首节点B。扩展节点B得到其儿子节点D和E。由于D是不可行节点，故被舍去。E是可行节点，被加入活节点队列。此时，活节点队列中的元素是C和E。 C成为当前扩展节点，它的两个儿子节点F和G均为可行节点。因此被加入活节点队列。此时活节点是E、F、G。 扩展下一个节点E，得到节点J和K。J是不可行节点，因而被舍去。K是一个可行的叶节点，表示所求问题的一个可行解，其价值为45。此时活动节点队列中的元素是F和G。 当前活节点队列的队首节点F成为下一个扩展节点。它的两个儿子节点L和M均为叶节点。L表示获得价值为50的可行解，M表示获得价值为25的可行解。 G释最后一个扩展节点。其儿子节点N和O均为可行叶节点。最后活节点队列为空。算法终止。 算法搜索得到最优解的值是50。对应的可行解为（0，1，1）。","link":"/Branch-And-Bound-Algorithm/"},{"title":"位图法排序(编程珠玑)","text":"1 问题 输入 输出 约束 2 解决思路 3 程序代码 1 问题输入一个最多包含n个正整数的文件，每个数都小于n，其中n=107。如果在输入文件中有任何正数重复出现就是致命错误。没有其他数据与该正数相关联。 输出按升序排列的输入正数的列表。 约束最多有1MB的内存空间可用，有充足的磁盘存储空间可用。运行时间最多几分钟，运行时间为10秒就不需要进一步优化。 2 解决思路应用位图或位向量表示集合。可用一个32位长的字符串来表示一个简单的非负整数，例如，可以用如下字符串表示集合{1,2,4,5,8}。101101100100 32位字符串位表示：0 1 1 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 032位字符串位下标：0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31数值的位都置为1，其他所有的位置为0。编程珠玑当中建议一个具有1000万个位的字符串来表示这个文件，那么这个文件的所占容量为10000000 bit= $10^7$bit，不到1MB的大小。分三个阶段来编写程序。 第一阶段：将所有的位都置为0，从而将集合初始化为空。 第二阶段：将每个对应的位置都置为1。 第三阶段：检验每一位，如果该为为1，就输出对应的整数，有此产生有序的输出文件。（通过&amp;运算来比较是否为1） int数组的存储位置：位置=数据/32(采用位运算即右移5位)int数组元素的位位置：位位置=数据%32(采用位运算即跟0X1F进行与操作)int数组如下所示，int大小：32位，从0开始。数组中每一个元素就是一个int，所以有长度是32位。 3 程序代码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556#include &lt;stdio.h&gt;//1000w位#define MAX 10000000 #define SHIFT 5//0x1F = 31//下标从0开始，所以是31#define MASK 0x1F #define DIGITS 32//初始化数组大小int a[1+MAX/DIGITS];//假设n=10//0000000000 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0//0123456789 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31void set(int n) //将逻辑位置为n的二进制位置为1 { //n&gt;&gt;SHIFT:在数组中的位置 //n&amp;MASK = n在字节{0，1}中的位置 a[n&gt;&gt;SHIFT] |=(1&lt;&lt;(n&amp;MASK)); //n&gt;&gt;SHIFT右移5位相当于除以32求算字节位置，n&amp;MASK相当于对32取余即求位位置，} //设置0，就是按位取反void clear(int n){ a[n&gt;&gt;SHIFT] &amp;=(~(1&lt;&lt;(n&amp;MASK))); //将逻辑位置为n的二进制位置为0}//对比int test(int n){ //&amp;，2个数字为1，则都为1 return a[n&gt;&gt;SHIFT] &amp; (1&lt;&lt;(n&amp;MASK)); //测试逻辑位置为n的二进制位是否为1 }int main(int argc, char *argv[]){ int i,n; //清空设置为0 for(i=1;i&lt;=MAX;i++) { clear(i); } set(10); for(i=1;i&lt;=MAX;i++) { if(test(i)){ printf(\"%d \",i); } } return 0;}","link":"/Bitmap-Order/"},{"title":"Centos命令行图形界面切换","text":"查看/etc/inittab如下 # systemd uses &apos;targets&apos; instead of runlevels. # by default, there are two main targets: # # multi-user.target: analogous to runlevel 3 # graphical.target: analogous to runlevel 5 # # To view current default target, run: # systemctl get-default # # To set a default target, run: # systemctl set-default TARGET.target 新版本的CentOS系统里使用targets取代了运行级别的概念。系统有两种默认的targets，多用户.target对应之前版本的3运行级别；而图形.target对应之前的5运行级别。 查看默认的targetsystemctl get-default 开机以命令模式启动systemctl set-default multi-user.target 开机以图形界面启动systemctl set-default graphical.target","link":"/Centos-Line/"},{"title":"分治算法","text":"1 基本思想 2 步骤 1 基本思想当我们求解某些问题时，由于这些问题要处理的数据相当多，或求解过程相当复杂，使得直接求解法在时间上相当长，或者根本无法直接求出。对于这类问题，我们往往先把它分解成几个子问题，找到求出这几个子问题的解法后，再找到合适的方法，把它们组合成求整个问题的解法。如果这些子问题还较大，难以解决，可以再把它们分成几个更小的子问题，以此类推，直至可以直接求出解为止。这就是分治策略的基本思想。分治算法的基本思想是将一个规模为N的问题分解为K个规模较小的子问题，这些子问题相互独立且与原问题性质相同。求出子问题的解，就可得到原问题的解。即一种分目标完成程序算法，简单问题可用二分法完成。Java有ForkJoin模式，MongoDB有MapReduce模式，这些都是分而治之的思想。 2 步骤分治法解题的一般步骤： 分解，将要解决的问题划分成若干规模较小的同类问题。 求解，当子问题划分得足够小时，用较简单的方法解决。 合并，按原问题的要求，将子问题的解逐层合并构成原问题的解。","link":"/Division-And-Treatment-Algorithm/"},{"title":"上下文切换和线程池","text":"1 上下文分类 1.1 让步式上下文切换 1.2 抢占式上下文切换 2 线程池 2.1 关键点 对于耗时短的任务 对于耗时长的任务 2.2 三种情况 高并发，低耗时 低并发，高耗时 高并发高耗时 1 上下文分类上下文切换是指CPU的控制权由运行任务转移到另外一个就绪任务时所发生的事件。 高并发，低耗时的情况，上下文切换本来就多，并且高并发就意味着CPU是处于繁忙状态的， 增加更多地线程也不会让线程得到执行时间片, 反而会增加线程切换的开销。 低并发，高耗时，保证有空闲线程或者增加线程数目，接收新任务，可以减少线程切换。 1.1 让步式上下文切换指执行线程主动释放CPU，与锁竞争严重程度成正比（锁竞争严重，释放多），可通过减少锁竞争来避免。1.2 抢占式上下文切换后者是指线程因分配的时间片用尽而被迫放弃CPU或者被其他优先级更高的线程所抢占，一般由于线程数大于CPU可用核心数引起，可通过调整线程数，适当减少线程数来避免。2 线程池2.1 关键点 尽量减少线程切换和管理的开支：要求线程数尽量少，这样可以减少线程切换和管理的开支。 最大化利用CPU：要求尽量多的线程，以保证CPU资源最大化的利用。 对于耗时短的任务要求线程尽量少，如果线程太多，有可能出现线程切换和管理的时间，大于任务执行的时间，那效率就低了。 对于耗时长的任务要分是CPU任务，还是io等类型的任务。如果是CPU类型的任务，线程数不宜太多；但是如果是io类型的任务，线程多一些更好，可以更充分利用cpu。2.2 三种情况高并发，低耗时建议少线程，只要满足并发即可（充分利用CPU）；例如并发100，线程池可能设置为10就可以。低并发，高耗时建议多线程，保证有空闲线程，接受新的任务；例如并发10，线程池可能就要设置为20。高并发高耗时 要分析任务类型（CPU型，io型，任务时间）。 增加排队。 加大线程数。","link":"/Context-Switch-And-Thread-Pool/"},{"title":"原子性,临界区,互斥量,信号量","text":"1 原子性 原子操作 2 临界区 2.1 临界区包含两个操作原语 2.2 程序调度法则 2.3 线程同步问题 2.4 其他问题 3 互斥量 3.1 互斥量包含的几个操作原语 4 信号量 4.1 P操作申请资源 4.2 V操作释放资源 4.3 信号量包含的几个操作原语 5 线程同步互斥的控制方法 5.1 临界区 5.2 互斥量 5.3 信号量 5.4 事件 6 总结 1 原子性原子性就是说一个操作不可以被中途CPU暂停然后调度，即不能被中断，要不就执行完，要不就不执行。 原子操作是不能被线程调度机制中断的操作，一旦操作开始，那么它一定可以在可能发生中断之前执行完毕。一个不正确的知识：“原子操作不需要进行同步控制”。原子性可以应用于基本数据类型（64位的long和double不是原子性），对于写入和读取，可以把它们当作原子操作来操作内存。但是，JVM可以将64（long和double）的读取和写入当作两个分离的32位操作来执行，这个就产生在读取和写入操作中间发生上下文切换问题，导致不同的任务可以看到不正确结果。 2 临界区每个进程中访问临界资源的那段代码称为临界区（Critical Section）（临界资源是一次仅允许一个进程使用的资源）。每次只准许一个进程进入临界区，进入后不允许其他进程进入。若能保证诸进程互斥地进入自己的临界区，便可实现诸进程对临界资源的互斥访问。不论是硬件临界资源，还是软件临界资源，多个进程必须互斥地对它进行访问。多个进程中涉及到同一个临界资源的临界区称为相关临界区。每个进程在进入临界区之前，应先对欲访问的临界资源进行检查，看它是否正被访问。如果此刻该临界资源未被访问，进程便可进入临界区对该资源进行访问，并设置它正被访问的标志；如果此刻该临界资源正被某进程访问，则本进程不能进入临界区。临界区内的数据一次只能同时被一个进程使用，当一个进程使用临界区内的数据时，其他需要使用临界区数据的进程进入等待状态。操作系统需要合理的分配临界区以达到多进程的同步和互斥关系，如果协调不好，就容易使系统处于不安全状态，甚至出现死锁现象。 2.1 临界区包含两个操作原语 EnterCriticalSection() 进入临界区 LeaveCriticalSection() 离开临界区 EnterCriticalSection()语句执行后代码将进入临界区以后无论发生什么，必须确保与之匹配的LeaveCriticalSection()都能够被执行到。否则临界区保护的共享资源将永远不会被释放。虽然临界区同步速度很快，但却只能用来同步本进程内的线程，而不可用来同步多个进程中的线程。 2.2 程序调度法则进程进入临界区的调度原则是 如果有若干进程要求进入空闲的临界区，一次仅允许一个进程进入。 任何时候，处于临界区内的进程不可多于一个。如已有进程进入自己的临界区，则其它所有试图进入临界区的进程必须等待。 进入临界区的进程要在有限时间内退出，以便其它进程能及时进入自己的临界区。 如果进程不能进入自己的临界区，则应让出CPU，避免进程出现“忙等”现象。2.3 线程同步问题如果有多个线程试图同时访问临界区，那么在有一个线程进入后，其他所有试图访问此临界区的线程将被挂起，并一直持续到进入临界区的线程离开。临界区在被释放后，其他线程可以继续抢占，并以此达到用原子方式操作共享资源的目的。2.4 其他问题在使用临界区时，一般不允许其运行时间过长，只要进入临界区的线程还没有离开，其他所有试图进入此临界区的线程都会被挂起而进入到等待状态，并会在一定程度上影响程序的运行性能。尤其需要注意的是不要将等待用户输入或是其他一些外界干预的操作包含到临界区。如果进入了临界区却一直没有释放，同样也会引起其他线程的长时间等待。3 互斥量互斥量跟临界区很相似，只有拥有互斥对象的线程才具有访问资源的权限，由于互斥对象只有一个，因此就决定了任何情况下此共享资源都不会同时被多个线程所访问。当前占据资源的线程在任务处理完后应将拥有的互斥对象交出，以便其他线程在获得后得以访问资源。互斥量比临界区复杂。因为使用互斥不仅仅能够在同一应用程序不同线程中实现资源的安全共享，而且可以在不同应用程序的线程之间实现对资源的安全共享。3.1 互斥量包含的几个操作原语 CreateMutex() 创建一个互斥量 OpenMutex() 打开一个互斥量 ReleaseMutex() 释放互斥量 WaitForMultipleObjects() 等待互斥量对象4 信号量信号量对象对线程的同步方式与前面几种方法不同，信号允许多个线程同时使用共享资源 ，这与操作系统中的PV操作相同。它指出了同时访问共享资源的线程最大数目。它允许多个线程在同一时刻访问同一资源，但是需要限制在同一时刻访问此资源的最大线程数目。在用CreateSemaphore()创建信号量时即要同时指出允许的最大资源计数和当前可用资源计数。一般是将当前可用资源计数设置为最大资源计数，每增加一个线程对共享资源的访问，当前可用资源计数就会减1，只要当前可用资源计数是大于0的，就可以发出信号量信号。但是当前可用计数减小到0时则说明当前占用资源的线程数已经达到了所允许的最大数目，不能在允许其他线程的进入，此时的信号量信号将无法发出。线程在处理完共享资源后，应在离开的同时通过ReleaseSemaphore()函数将当前可用资源计数加1。在任何时候当前可用资源计数决不可能大于最大资源计数。PV操作及信号量的概念都是由荷兰科学家E.W.Dijkstra提出的。信号量S是一个整数，S大于等于零时代表可供并发进程使用的资源实体数，但S小于零时则表示正在等待使用共享资源的进程数。 4.1 P操作申请资源 S减1。 若S减1后仍大于等于零，则进程继续执行。 若S减1后小于零，则该进程被阻塞后进入与该信号相对应的队列中，然后转入进程调度。 4.2 V操作释放资源 S加1。 若相加结果大于零，则进程继续执行。 若相加结果小于等于零，则从该信号的等待队列中唤醒一个等待进程，然后再返回原进程继续执行或转入进程调度。 4.3 信号量包含的几个操作原语 CreateSemaphore() 创建一个信号量 OpenSemaphore() 打开一个信号量 ReleaseSemaphore() 释放信号量 WaitForSingleObject() 等待信号量5 线程同步互斥的控制方法5.1 临界区通过对多线程的串行化来访问公共资源或一段代码，速度快，适合控制数据访问。5.2 互斥量为协调共同对一个共享资源的单独访问而设计的。5.3 信号量为控制一个具有有限数量用户资源而设计。5.4 事件用来通知线程有一些事件已发生，从而启动后继任务的开始。6 总结 互斥量与临界区的作用非常相似，但互斥量是可以命名的，也就是说它可以跨越进程使用。所以创建互斥量需要的资源更多，所以如果只为了在进程内部是用的话使用临界区会带来速度上的优势并能够减少资源占用量 。因为互斥量是跨进程的互斥量一旦被创建，就可以通过名字打开它。 互斥量（Mutex），信号灯（Semaphore），事件（Event）都可以被跨越进程使用来进行同步数据操作，而其他的对象与数据同步操作无关，但对于进程和线程来讲，如果进程和线程在运行状态则为无信号状态，在退出后为有信号状态。所以可以使用WaitForSingleObject来等待进程和线程退出。 通过互斥量可以指定资源被独占的方式使用，但如果有下面一种情况通过互斥量就无法处理，比如现在一位用户购买了一份三个并发访问许可的数据库系统，可以根据用户购买的访问许可数量来决定有多少个线程/进程能同时进行数据库操作，这时候如果利用互斥量就没有办法完成这个要求，信号灯对象可以说是一种资源计数器。","link":"/Atomic-Critical-Region-Mutex-Semaphore/"},{"title":"一致性哈希算法","text":"1 基本场景 2 hash算法和单调性 3 consistent hashing算法的原理 环形hash空间 把对象映射到hash空间 把cache映射到hash空间 把对象映射到cache 考察cache的变动 移除cache 添加 cache 4 虚拟节点 平衡性 5 总结 转帖：一致性哈希算法 Consistent Hashing算法早在1997年就在论文《Consistent hashing and random trees》 (https://dl.acm.org/citation.cfm?id=258660)中被提出，目前在cache系统中应用越来越广泛。 1 基本场景比如你有N个cache服务器（后面简称cache），那么如何将一个对象object映射到N个cache 上呢，你很可能会采用类似下面的通用方法计算object的hash值，然后均匀的映射到到N个cache；hash(object)%N一切都运行正常，再考虑如下的两种情况； 一个cache服务器m down掉了（在实际应用中必须要考虑这种情况），这样所有映射到cache m的对象都会失效，怎么办，需要把cache m从cache中移除，这时候cache是N-1台，映射公式变成了hash(object)%(N-1)。 由于访问加重，需要添加cache，这时候cache是N+1台，映射公式变成了hash(object)%(N+1) 意味着什么？这意味着突然之间几乎所有的cache都失效了。对于服务器而言，这是一场灾难，洪水般的访问都会直接冲向后台服务器；再来考虑第三个问题，由于硬件能力越来越强，你可能想让后面添加的节点多做点活，显然上面的 hash算法也做不到。有什么方法可以改变这个状况呢，这就是Consistent Hashing。 2 hash算法和单调性Hash算法的一个衡量指标是单调性（Monotonicity），定义如下：单调性是指如果已经有一些内容通过哈希分派到了相应的缓冲中，又有新的缓冲加入到系统中。哈希的结果应能够保证原有已分配的内容可以被映射到原有的缓存或者新的缓冲中去，而不会被映射到旧的缓冲集合中的其他缓冲区。（系统发生变化（新增，删除服务器）的时候，原来的对象可以映射到新的服务器）容易看到，上面的简单hash算法hash(object)%N难以满足单调性要求。 3 consistent hashing算法的原理Consistent Hashing是一种hash算法，简单的说，在移除/添加一个cache时，它能够尽可能小的改变已存在key映射关系，尽可能的满足单调性的要求。下面就来按照5个步骤简单讲讲consistent hashing算法的基本原理。 环形hash空间考虑通常的hash算法都是将value映射到一个32为的key值，也即是0~$2^{32-1}$次方的数值空间；我们可以将这个空间想象成一个首（0）尾（$2^{32-1}$）相接的圆环，如下面图1所示的那样。 把对象映射到hash空间接下来考虑4个对象object1~object4，通过hash函数计算出的hash值key在环上的分布如下图2所示。hash(object1) = key1;hash(object4) = key4; 把cache映射到hash空间Consistent Hashing的基本思想就是将对象和cache都映射到同一个hash数值空间中，并且使用相同的hash算法。假设当前有A,B和C共3台cache，那么其映射结果将下图3所示，他们在hash空间中，以对应的hash值排列。hash(cache A) = key A;hash(cache C) = key C;说到这里，顺便提一下cache的hash计算，一般的方法可以使用cache机器的IP地址或者机器名作为hash输入。 把对象映射到cache现在cache和对象都已经通过同一个hash算法映射到hash数值空间中，接下来要考虑的就是如何将对象映射到cache上面。在这个环形空间中，如果沿着顺时针方向从对象的key值出发，直到遇见一个cache，那么就将该对象存储在这个cache上，因为对象和cache的hash值是固定的，因此这个cache必然是唯一和确定的。这样不就找到对象和cache的映射方法了吗？依然继续上面的例子，那么根据上面的方法，对象object1将被存储到cache A上；object2和object3对应到cache C；object4对应到cache B； 考察cache的变动前面讲过，通过hash然后求余的方法带来的最大问题就在于不能满足单调性，当cache有所变动时，cache会失效，进而对后台服务器造成巨大的冲击，现在就来分析分析Consistent Hashing算法。 移除cache考虑假设cache B挂掉了，根据上面讲到的映射方法，这时受影响的将仅是那些沿cache B逆时针遍历直到下一个cache（cache C）之间的对象，也即是本来映射到cache B上的那些对象。因此这里仅需要变动对象object4，将其重新映射到cache C上即可；参见下图4。 添加 cache再考虑添加一台新的cache D的情况，假设在这个环形hash空间中，cache D被映射在对象object2和object3之间。这时受影响的将仅是那些沿cache D逆时针遍历直到下一个cache（cache B）之间的对象（它们是也本来映射到cache C上对象的一部分），将这些对象重新映射到cache D上即可。因此这里仅需要变动对象object2，将其重新映射到cache D上；参见下图5。 4 虚拟节点考量Hash算法的另一个指标是平衡性(Balance) ，定义如下： 平衡性平衡性是指哈希的结果能够尽可能分布到所有的缓冲中去，这样可以使得所有的缓冲空间都得到利用。hash算法并不是保证绝对的平衡，如果cache较少的话，对象并不能被均匀的映射到cache上，比如在上面的例子中，仅部署cache A和cache C的情况下，在4个对象中，cache A仅存储object1，而cache C则存储object2、object3和object4；分布是很不均衡的。为了解决这种情况，Consistent Hashing引入了“虚拟节点”的概念，它可以如下定义：“虚拟节点”（virtual node）是实际节点在hash空间的复制品（replica），一实际个节点对应了若干个“虚拟节点”，这个对应个数也成为“复制个数”，“虚拟节点”在hash空间中以hash值排列。仍以仅部署cache A和cache C的情况为例，在图4中我们已经看到，cache分布并不均匀。现在我们引入虚拟节点，并设置“复制个数”为2，这就意味着一共会存在4个“虚拟节点”，cache A1, cache A2代表cache A；cache C1, cache C2代表cache C；假设一种比较理想的情况，参见图6。此时，对象到“虚拟节点”的映射关系为：objec1-&gt;cache A2;objec2-&gt;cache A1;objec3-&gt;cache C1;objec4-&gt;cache C2;因此对象object1和object2都被映射到cache A上，而object3和object4映射到了cache C上；平衡性有了很大提高。引入“虚拟节点”后，映射关系就从{对象-&gt;节点}转换到了{对象-&gt;虚拟节点} 。查询物体所在cache时的映射关系如图7所示。“虚拟节点”的hash计算可以采用对应节点的IP地址加数字后缀的方式。例如假设 cache A的IP地址为202.168.14.241。引入“虚拟节点”前，计算cache A的hash值：Hash(“202.168.14.241”);引入“虚拟节点”后，计算“虚拟节”点cache A1和cache A2的hash值：Hash(“202.168.14.241#1”); // cache A1Hash(“202.168.14.241#2”); // cache A2 5 总结Consistent Hashing的基本原理就是这些，具体的分布性等理论分析应该是很复杂的，不过一般也用不到。http://weblogs.java.net/blog/2007/11/27/consistent-hashing 上面有一个java版本的例子，可以参考。http://blog.csdn.net/mayongzhan/archive/2009/06/25/4298834.aspx 转载了一个PHP版的实现代码。http://www.codeproject.com/KB/recipes/lib-conhash.aspx C语言版本一些参考资料地址：http://portal.acm.org/citation.cfm?id=258660http://en.wikipedia.org/wiki/Consistent_hashinghttp://www.spiteful.com/2008/03/17/programmers-toolbox-part-3-consistent-hashing/http://weblogs.java.net/blog/2007/11/27/consistent-hashinghttp://tech.idv2.com/2008/07/24/memcached-004/http://blog.csdn.net/mayongzhan/archive/2009/06/25/4298834.aspx","link":"/Consistent-Hash-1/"},{"title":"接口和抽象类的区别","text":"1 概述 抽象类 接口 2 理解抽象类（根据问题领域和设计意图） 3 从案例层面看Abstract和Interface 3.1 抽象类 3.2 接口 4 从语法定义层面看Abstract和Interface 5 从设计层面看Abstract和Interface（理解本质区别） 解决方案1 解决方案2 6 总结 抽象类 性质 接口 性质 1 概述Abstract和Interface是Java语言中对于抽象类定义进行支持的两种机制，正是由于这两种机制的存在，才赋予了Java强大的面向对象能力。Abstract和Interface之间在对于抽象类定义的支持方面具有很大的相似性，甚至可以相互替换，因此很多开发者在进行抽象类定义时对于Abstract和Interface的选择显得比较随意。其实，两者之间还是有很大的区别的，对于它们的选择甚至反映出对于问题领域本质的理解、对于设计意图的理解是否正确、合理。 抽象类把相同的东西提取出来, 就是为了重用。 接口程序里面固化的契约, 是为了降低偶合。 2 理解抽象类（根据问题领域和设计意图）Abstract和Interface在Java语言中都是用来进行抽象类（本文中的抽象类并非从abstract class翻译而来，它表示的是一个抽象体，而是abstract class为Java语言中用于定义抽象类的一种方法，请读者注意区分）定义的，那么什么是抽象类，使用抽象类能带来什么好处呢？在面向对象的概念中，知道所有的对象都是通过类来描绘的，但是反过来却不是这样。并不是所有的类都是用来描绘对象的，如果一个类中没有包含足够的信息来描绘一个具体的对象，这样的类就是抽象类。抽象类往往用来表征在对问题领域进行分析（继承还是实现，继承是is a关系，表示是它的一个种类；实现是like a，像它，相当于功能的扩展）、设计中得出的抽象概念，是对一系列看上去不同，但是本质上相同的具体概念的抽象。比如：进行一个图形编辑软件的开发，就会发现问题领域存在着圆、三角形这样一些具体概念，它们是不同的，但是它们又都属于形状这样一个概念，形状这个概念在问题领域是不存在的，它就是一个抽象概念。正是因为抽象的概念在问题领域没有对应的具体概念，所以用以表征抽象概念的抽象类是不能够实例化的，只能通过子类或者实现类去实例化。在面向对象领域，抽象类主要用来进行类型隐藏。可以构造出一个固定的一组行为的抽象描述(抽象类或者接口)，但是这组行为却能够有任意个可能的具体实现方式(子类继承或者实现)。这个抽象描述就是抽象类，而这一组任意个可能的具体实现则表现为所有可能的派生类。模块可以操作一个抽象体。由于模块依赖于一个固定的抽象体（模块是子类），因此它可以是不允许修改的；同时，通过从这个抽象体派生，也可扩展此模块的行为功能。熟悉OCP的读者一定知道，为了能够实现面向对象设计的一个最核心的原则OCP(Open-Closed Principle)，抽象类是其中的关键所在。 3 从案例层面看Abstract和Interface3.1 抽象类抽象类, 它的作用归根到底其实就是为了重用。这个重用包含几个层次的重用, 都知道的方法重用，几个类有共同的特质，就把公用的东西提取出来，搞了个父类，而这个父类有些方法不知道怎么实现,就搞成抽象的吧. 所以抽象类就诞生了。 3.2 接口接口，这是我想重点说的，因为我想让接口真正回归它本来的面目。接口就是契约，软件系统内部的契约。那电脑硬件打比方，内存条的卡口就规定好多长，卡位在哪。这样造主板的按这个契约留好口，造内存的外形也按这个造，都造好了，才能工作。任何一方不守规矩，直接导致造电脑失败。 这个造电脑，主板跟内存接口是什么？ 看到的主板上那个卡口吗？不是，接口是内存厂商跟主板厂商之间的契约，这份契约可能是一份双方签字的文档，也可能是一个电话达成的共识。而编程语言的接口Interface，就对应那分签字的文档或是一个电话的共识，只是它是程序化了的，相关双方都没有办法违约的；我告诉你了我要这个接口，你也答应实现，那你就必须实现，否则编译就过不了；所以它是一种固化的强制的契约。 4 从语法定义层面看Abstract和Interface在语法层面，Java语言对于Abstract和Interface给出了不同的定义方式，下面以定义一个名为Demo的抽象类为例来说明这种不同。使用Abstract的方式定义Demo抽象类的方式如下。12345abstract class Demo ｛ abstract void method1(); abstract void method2(); … ｝ 使用Interface的方式定义Demo抽象类的方式如下。12345interface Demo { void method1(); void method2(); … } 在Abstract方式中，Demo可以有自己的数据成员（常量或者属性），也可以有非abstarct的成员方法；而在interface方式的实现中，Demo只能够有静态的不能被修改的数据成员（也就是必须是static final的，不过在Interface中一般不定义数据成员），所有的成员方法都是Abstract的。从某种意义上说，Interface是一种特殊形式的Abstract(比抽象类更加抽象的类)。从编程的角度来看，Abstract和Interface都可以用来实现design by contract的思想。但是在具体的使用上面还是有一些区别的。首先，Abstract在Java语言中表示的是一种继承关系，一个类只能使用一次继承关系。(Java不允许多重继承，如：a继承b和c)，但是，一个类却可以实现多个Interface。也许，这是Java语言的设计者在考虑Java对于多重继承的支持方面的一种折中考虑吧。其次，在Abstract的定义中，可以赋予方法的默认行为（在抽象类中，方法可以自己实现）。但是在Interface的定义中，方法却不能拥有默认行为(方法只能声明，不能实现)，为了绕过这个限制，必须使用委托，但是这会增加一些复杂性，有时会造成很大的麻烦。在抽象类中不能定义默认行为还存在另一个比较严重的问题，那就是可能会造成维护上的麻烦。因为如果后来想修改类的界面以适应新的情况时，比如添加新的方法或者给已用的方法中添加新的参数，就会非常的麻烦，可能要花费很多的时间（对于派生类很多的情况）。但是如果界面是通过Abstract来实现的，那么可能就只需要修改定义在Abstract中的默认行为就可以了。同样，如果不能在抽象类中定义默认行为，就会导致同样的方法实现出现在该抽象类的每一个派生类中，违反了one rule,one place原则，造成代码重复，同样不利于以后的维护。因此，在Abstract和Interface间进行选择时要非常的小心。 5 从设计层面看Abstract和Interface（理解本质区别）上面主要从语法定义和编程的角度论述了Abstract和Interface的区别，这些层面的区别是比较低层次的、非本质的。本小节将从另一个层面：Abstract和Interface所反映出的设计理念，来分析一下二者的区别。Abstarct在Java语言中体现了一种继承关系，要想使得继承关系合理，父类和派生类之间必须存在is a关系，即父类和派生类在概念本质上应该是相同的。对于Interface来说则不然，并不要求Interface的实现者和Interface定义在概念本质上是一致的，仅仅是实现了Interface定义的契约而已。为了使论述便于理解，下面将通过一个简单的实例进行说明。(接口相对于，对实现类的功能的扩展，但是接口和实现类又没有本质上的一致。与实现类有本质上一致的是抽象类)考虑这样一个例子，假设在问题领域中有一个关于Door的抽象概念（门抽象概念），该Door具有执行两个动作open()和close()，此时可以通过Abstract或者Interface来定义一个表示该抽象概念的类型，定义方式分别如下所示。使用Abstract方式定义Door。1234abstract class Door { abstract void open(); abstract void close()； } 使用Interface方式定义Door。1234interface Door { void open(); void close(); } 其他具体的Door类型可以extends使用Abstract方式定义的Door或者implements使用Interface方式定义的Door。看起来好像使用Abstract和Interface没有大的区别。如果现在要求Door还要具有报警的功能（实际上属于动作的）。如何设计针对该例子的类结构呢？在本例中，主要是为了展示Abstract和Interface反映在设计理念上的区别，其他方面无关的问题都做了简化或者忽略。下面将罗列出可能的解决方案，并从设计理念层面对这些不同的方案进行分析。 解决方案1简单的在Door的定义中增加一个alarm方法，如下。12345abstract class Door { abstract void open(); abstract void close()； abstract void alarm(); } 或者12345interface Door { void open(); void close(); void alarm(); } 子类或者实现类，那么具有报警功能的AlarmDoor的定义方式，如下。12345class AlarmDoor extends Door { void open() { … } void close() { … } void alarm() { … } } 或者12345class AlarmDoor implements Door ｛ void open() { … } void close() { … } void alarm() { … } ｝ 这种方法违反了面向对象设计中的一个核心原则ISP（Interface Segregation Priciple），在Door的定义中把Door概念本身固有的行为方法和另外一个概念”报警器”的行为方法混在了一起。这样引起的一个问题是那些仅仅依赖于Door这个概念的模块会因为”报警器”这个概念的改变（比如：修改alarm方法的参数）而改变，反之依然。 解决方案2既然open、close和alarm属于两个不同的概念，根据ISP原则：应该把它们分别定义在代表这两个概念的抽象类中。定义方式有： 这两个概念都使用Abstract方式定义。 两个概念都使用Interface方式定义。 一个概念使用abstract方式定义，另一个概念使用Interface方式定义。 显然，由于Java语言不支持多重继承，所以两个概念都使用Abstract方式定义是不可行的。后面两种方式都是可行的，但是对于它们的选择却反映出，对于问题领域中的概念本质的理解、对于设计意图的反映是否正确、合理。 6 总结如果两个概念都使用Interface方式来定义，那么就反映出两个问题： 理解清楚问题领域，AlarmDoor在概念本质上到底是Door还是报警器？ 如果对于问题领域的理解没有问题，比如：通过对于问题领域的分析发现AlarmDoor在概念本质上和Door是一致的，那么在实现时就没有能够正确的揭示设计意图，因为在这两个概念的定义上（均使用Interface方式定义）反映不出上述含义。 如果对于问题领域的理解是：AlarmDoor在概念本质上是Door，同时它有具有报警的功能。该如何来设计、实现来明确的反映出问题的意思呢？前面已经说过，abstract class在Java语言中表示一种继承关系，而继承关系在本质上是”is a”关系。所以对于Door这个概念，应该使用abstarct class方式来定义。（AlarmDoor在概念本质上是Door，本质上就应该使用继承，则就是抽象类）另外，AlarmDoor又具有报警功能，说明它又能够完成报警概念中定义的行为(行为：功能的意思)，所以报警概念可以通过Interface方式定义。(具有xxx功能，则是like a的关系，用接口)如下所示。1234567891011121314abstract class Door { abstract void open(); abstract void close()； } interface Alarm { void alarm(); } //抽象类继承本质，接口实现功能class AlarmDoor extends Door implements Alarm { void open() { … } void close() { … } void alarm() { … } } 这种实现方式基本上能够明确的反映出对于问题领域的理解，正确的揭示设计意图。其实Abstract表示的是is a关系，interface表示的是like a关系，大家在选择时可以作为一个依据，当然这是建立在对问题领域的理解上的。比如：如果AlarmDoor在概念本质上是报警器，同时又具有Door的功能，那么上述的定义方式就要反过来了。 抽象类is a的关系，本质上一样的，用继承；则是使用抽象类。越顶层，越抽象。能够确定的通用动作比较多，抽象方法越多。 性质 可以有普通变量，普通方法，或者抽象方法。 子类只能继承一个抽象类。 子类选择性的覆写抽象方法，所以有了适配器模式。 抽象类可以定义构造函数，构造函数不是为了初始化操作，而是子类初始化的时候，会先初始化抽象类的构造函数（子类初始化之前，会调用父类的构造方法）。 抽象类可以定义静态方法。 一个抽象类可以实现多个接口。接口like a的关系，本质上不一定一样，用于对某一类的功能的扩展。性质 final，static全局的变量，只能是抽象方法。 子类可以实现多个接口，接口可以实现多个接口。 接口不能定义构造函数。 接口不能定义静态方法。 接口不允许继承抽象类。","link":"/Difference-Interface-Abstract/"},{"title":"Byte大小端模式","text":"1 什么是大小端 1.1 大端模式 1.2 小端模式 2 为什么有大小端之分 3 Java中的大小端 4 Byte转换工具 4.1 byte转换工具，用到大小端模式 1 什么是大小端1.1 大端模式高字节保存在内存的低地址中，而数据的低字节保存在内存的高地址中，这样的存储模式有点儿类似于把数据当作字符串顺序处理：地址由小向大增加，而数据从高位往低位放。 1.2 小端模式高字节保存在内存的高地址中，而数据的低字节保存在内存的低地址中，这种存储模式将地址的高低和数据位权有效地结合起来，高地址部分权值高，低地址部分权值低，和我们的逻辑方法一致。这两种模式，泥瓦匠记忆宫殿：“小端低低”。这样就知道小端的模式，反之大端的模式。比如，整形十进制数字305419896 ，转化为十六进制表示0x12345678。其中按着十六进制的话，每字符占8个位，1字节。 2 为什么有大小端之分在操作系统中，x86和一般的OS（如windows，FreeBSD，Linux）使用的是小端模式。但比如Mac OS是大端模式。在计算机系统中，是以字节为单位的，每个地址单元都对应着一个字节，一个字节为8bit。但是在C语言中除了8bit的char之外，还有16bit的short型，32bit的long型（要看具体的编译器）。另外，对于位数大于8位的处理器，例如16位或者32位的处理器，由于寄存器宽度大于一个字节，那么必然存在着一个如果将多个字节安排的问题。因此就导致了大端存储模式和小端存储模式。知道为什么有模式的存在，下面需要了解下具有有什么应用场景。 不同端模式的处理器进行数据传递时必须要考虑端模式的不同。 在网络上传输数据时，由于数据传输的两端对应不同的硬件平台，采用的存储字节顺序可能不一致。所以在TCP/IP协议规定了在网络上必须采用网络字节顺序，也就是大端模式。对于char型数据只占一个字节，无所谓大端和小端。而对于非char类型数据，必须在数据发送到网络上之前将其转换成大端模式。接收网络数据时按符合接受主机的环境接收。3 Java中的大小端存储量大于1字节，非char类型，如int，float等，要考虑字节的顺序问题了。Java由于虚拟机的关系，屏蔽了大小端问题，需要知道的话可用ByteOrder.nativeOrder()查询。在操作ByteBuffer中，也可以使用 ByteBuffer.order()进行设置。12345678910111213141516171819202122232425package memory;import java.nio.ByteBuffer;import java.nio.ByteOrder;import java.util.Arrays;public class Endians { public static void main(String[] args) { // 创建12个字节的字节缓冲区 ByteBuffer bb = ByteBuffer.wrap(new byte[12]); // 存入字符串 bb.asCharBuffer().put(\"abdcef\"); System.out.println(Arrays.toString(bb.array())); // 反转缓冲区 bb.rewind(); // 设置字节存储次序，大端模式 bb.order(ByteOrder.BIG_ENDIAN); bb.asCharBuffer().put(\"abcdef\"); System.out.println(Arrays.toString(bb.array())); // 反转缓冲区 bb.rewind(); // 设置字节存储次序，小端模式 bb.order(ByteOrder.LITTLE_ENDIAN); bb.asCharBuffer().put(\"abcdef\"); System.out.println(Arrays.toString(bb.array())); }} 123[0, 97, 0, 98, 0, 100, 0, 99, 0, 101, 0, 102][0, 97, 0, 98, 0, 99, 0, 100, 0, 101, 0, 102][97, 0, 98, 0, 99, 0, 100, 0, 101, 0, 102, 0] 前两句打印说明了，ByteBuffer存储字节次序默认为大端模式。最后一段设置了字节存储次序，然后会输出，可以看出存储次序为小端模式。 4 Byte转换工具4.1 byte转换工具，用到大小端模式123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408package com.mallcoo.util;import java.nio.ByteOrder;import org.apache.commons.logging.Log;import org.apache.commons.logging.LogFactory;/** * byte转换工具类 * * @Title: ByteUtil.java * @Package com.mallcoo.radius.util * @Description: * @author yujie@mallcoo.cn * @date 2013-10-1 下午4:43:13 * @version V1.0 * @jdk jdk1.6.0_45 */public class ByteUtil { public static final Log log = LogFactory.getLog(ByteUtil.class); /** * int转换成byte[4] * * @Title: intTobyte * @author : yujie@mallcoo.cn * @Description: int转换byte[4]，byte长度4的 * @param value * 整形 * @param order * 字节排序 big endian：(高位优先)将最重要的字节存放在地址最低的存储器单元 -&gt;0 big * littel_endian： (低位优先)则是将最重要的字节放在地址最高的存储器单元 0-&gt; * @return byte[] 长度=4 * */ public static byte[] intToByte(int value, ByteOrder order) { byte[] tmp = new byte[4]; if (order == ByteOrder.BIG_ENDIAN) { tmp[0] = (byte) (value &gt;&gt;&gt; 24); tmp[1] = (byte) (value &gt;&gt;&gt; 16); tmp[2] = (byte) (value &gt;&gt;&gt; 8); tmp[3] = (byte) value; /* * for (int i = 3; i &gt;= 0; i--) { b[i] = new * Integer(value).byteValue(); // 向右移8位 value = value &gt;&gt; 8; } * * for(int i=0; i&lt;4; i++){ b[i]=(byte)(value&gt;&gt;8*(3-i)); } */ } else { tmp[0] = (byte) value; tmp[1] = (byte) (value &gt;&gt;&gt; 8); tmp[2] = (byte) (value &gt;&gt;&gt; 16); tmp[3] = (byte) (value &gt;&gt;&gt; 24); /* * for (int i = 0; i &lt; 4; i++) { b[i] = new * Integer(value).byteValue(); // 向右移8位 value = value &gt;&gt; 8; } * * for(int i=3; i&gt;=0; i--){ b[i]=(byte)(value&gt;&gt;8 * i); } */ } return tmp; } /** * short转换成byte[2] * * @Title: shortTobyte * @author : yujie@mallcoo.cn * @Description: short转换byte[2]，byte长度2的 * @param value * 整形 * @param order * 字节排序 big endian：(高位优先)将最重要的字节存放在地址最低的存储器单元 big littel_endian： * (低位优先)则是将最重要的字节放在地址最高的存储器单元 * @return byte[] 长度=2 * */ public static byte[] shortToByte(short value, ByteOrder order) { byte[] tmp = new byte[2]; if (order == ByteOrder.BIG_ENDIAN) { tmp[0] = (byte) (value &gt;&gt;&gt; 8); tmp[1] = (byte) (value); /* * for (int i = 1; i &gt;= 0; i--) { b[i] = new * Integer(value).byteValue(); // 向右移8位 value = value &gt;&gt; 8; } * for(int i=0; i&lt;2; i++){ b[i]=(byte)(value&gt;&gt;8*(1-i)); } */ } else { tmp[0] = (byte) (value); tmp[1] = (byte) (value &gt;&gt;&gt; 8); /* * for (int i = 0; i &lt; 2; i++) { b[i] = new * Integer(value).byteValue(); // 向右移8位 value = value &gt;&gt; 8; } * * for(int i=1; i&gt;=0; i--){ b[i]=(byte)(value &gt;&gt; 8 * i); } */ } return tmp; } /** * long转byte[8] * * @Title: longTobyte * @author : yujie@mallcoo.cn * @Description: long转换byte[8]，byte长度8的 * @param value * 整形 * @param order * 字节排序 big endian：(高位优先)将最重要的字节存放在地址最低的存储器单元 big littel_endian： * (低位优先)则是将最重要的字节放在地址最高的存储器单元 * @return byte[] 长度=8 * */ public static byte[] longToByte(long value, ByteOrder order) { byte[] tmp = new byte[8]; if (order == ByteOrder.BIG_ENDIAN) { tmp[7] = (byte) value; tmp[6] = (byte) (value &gt;&gt;&gt; 8); tmp[5] = (byte) (value &gt;&gt;&gt; 16); tmp[4] = (byte) (value &gt;&gt;&gt; 24); tmp[3] = (byte) (value &gt;&gt;&gt; 32); tmp[2] = (byte) (value &gt;&gt;&gt; 40); tmp[1] = (byte) (value &gt;&gt;&gt; 48); tmp[0] = (byte) (value &gt;&gt;&gt; 56); /* * for (int i = 7; i &gt;= 0; i--) { b[i] = new * Integer(value).byteValue(); // 向右移8位 value = value &gt;&gt; 8; } * for(int i=0; i&lt;8; i++){ b[i]=(byte)(value&gt;&gt;8*(7-i)); } */ } else { tmp[0] = (byte) value; tmp[1] = (byte) (value &gt;&gt;&gt; 8); tmp[2] = (byte) (value &gt;&gt;&gt; 16); tmp[3] = (byte) (value &gt;&gt;&gt; 24); tmp[4] = (byte) (value &gt;&gt;&gt; 32); tmp[5] = (byte) (value &gt;&gt;&gt; 40); tmp[6] = (byte) (value &gt;&gt;&gt; 48); tmp[7] = (byte) (value &gt;&gt;&gt; 56); /* * for (int i = 0; i &lt; 8; i++) { b[i] = new * Integer(value).byteValue(); // 向右移8位 value = value &gt;&gt; 8; } * * for(int i=7; i&gt;=0; i--){ b[i]=(byte)(value&gt;&gt;8 * i); } */ } return tmp; } /*public byte[] floatToByte(float value, ByteOrder order) { } public byte[] byteToFloat(byte[] value, ByteOrder order) { }*/ /** * byte[4] 转换 int * * @Title: byteToInt * @author : yujie@mallcoo.cn * @Description: byte[4] 转换 int * @param value * 长度是4的字节 * @param order * 字节排序 big endian：(高位优先)将最重要的字节存放在地址最低的存储器单元 big * littel_endian：(低位优先)则是将最重要的字节放在地址最高的存储器单元 * @return int * @throws 数组越界 */ public static int byteToInt(byte[] value, ByteOrder order) throws IndexOutOfBoundsException { // 字节数组越界 if (value.length &gt; 4) { log.info(\"字节数组越界!\"); throw new IndexOutOfBoundsException(); } int tmp = 0; // big endian(高位优先)将最重要的字节存放在地址最低的存储器单元 if (order == ByteOrder.BIG_ENDIAN) { tmp += (value[0] &amp; 0xFF) &lt;&lt; 24; tmp += (value[1] &amp; 0xFF) &lt;&lt; 16; tmp += (value[2] &amp; 0xFF) &lt;&lt; 8; tmp += value[3] &amp; 0xFF; /* * * for(int i=0; i&lt;4; i++){ //高位都是1，所以需要&amp;255或者&amp;0xff，把高位的1去掉；然后在位移 * intValue +=(b[i] &amp; 0xFF)&lt;&lt;(8*(3-i)); } */ } else {// (低位优先)则是将最重要的字节放在地址最高的存储器单元 tmp += value[0] &amp; 0xFF; tmp += (value[1] &amp; 0xFF) &lt;&lt; 8; tmp += (value[2] &amp; 0xFF) &lt;&lt; 16; tmp += (value[3] &amp; 0xFF) &lt;&lt; 24; /* * * for(int i=3; i &gt;= 0; i--){ //高位都是1，所以需要&amp;255或者&amp;0xff，把高位的1去掉；然后在位移 * intValue +=(b[i] &amp; 0xFF)&lt;&lt;(8 * i); } */ } return tmp; } /** * byte[2] 转换 short * * @Title: byteToShort * @author : yujie@mallcoo.cn * @Description: byte[2] 转换 short * @param value * 长度是2的字节 * @param order * 字节排序 big endian：(高位优先)将最重要的字节存放在地址最低的存储器单元 big * littel_endian：(低位优先)则是将最重要的字节放在地址最高的存储器单元 * @return short * @throws IndexOutOfBoundsException * 数组越界 * */ public static short byteToShort(byte[] value, ByteOrder order) throws IndexOutOfBoundsException { if (value.length &gt; 2) { log.info(\"字节数组越界!\"); throw new IndexOutOfBoundsException(); } int tmp = 0; // big endian(高位优先)将最重要的字节存放在地址最低的存储器单元 if (order == ByteOrder.BIG_ENDIAN) { tmp += (value[0] &amp; 0xFF) &lt;&lt; 8; tmp += value[1] &amp; 0xFF; /* * * for(int i=0; i&lt;2; i++){ //高位都是1，所以需要&amp;255或者&amp;0xff，把高位的1去掉；然后在位移 * intValue +=(b[i] &amp; 0xFF)&lt;&lt;(8*(1-i)); } */ } else {// (低位优先)则是将最重要的字节放在地址最高的存储器单元 tmp += (value[1] &amp; 0xFF) &lt;&lt; 8; tmp += value[0] &amp; 0xFF; /* * * for(int i=1; i &gt;= 0; i--){ //高位都是1，所以需要&amp;255或者&amp;0xff，把高位的1去掉；然后在位移 * intValue +=(b[i] &amp; 0xFF)&lt;&lt;(8 * i); } */ } return (short) tmp; } /** * byte[8] 转换 long * * @Title: byteToLong * @author : yujie@mallcoo.cn * @Description: byte[8] 转换 long * @param value * 长度是8的字节 * @param order * 字节排序 big endian：(高位优先)将最重要的字节存放在地址最低的存储器单元 big littel_endian： * (低位优先)则是将最重要的字节放在地址最高的存储器单元 * @return long * @throws IndexOutOfBoundsException * 数组越界 * */ public static long byteToLong(byte[] value, ByteOrder order) throws IndexOutOfBoundsException { if (value.length &gt; 8) { log.info(\"字节数组越界!\"); throw new IndexOutOfBoundsException(); } long tmp = 0; // big endian(高位优先)将最重要的字节存放在地址最低的存储器单元 if (order == ByteOrder.BIG_ENDIAN) { tmp += (value[0] &amp; 0xFF) &lt;&lt; 56; tmp += (value[1] &amp; 0xFF) &lt;&lt; 48; tmp += (value[2] &amp; 0xFF) &lt;&lt; 40; tmp += (value[3] &amp; 0xFF) &lt;&lt; 32; tmp += (value[4] &amp; 0xFF) &lt;&lt; 24; tmp += (value[5] &amp; 0xFF) &lt;&lt; 16; tmp += (value[6] &amp; 0xFF) &lt;&lt; 8; tmp += (value[7] &amp; 0xFF); /* * * for(int i=0; i&lt;8; i++){ //高位都是1，所以需要&amp;255或者&amp;0xff，把高位的1去掉；然后在位移 * intValue +=(b[i] &amp; 0xFF)&lt;&lt;(8*(7-i)); } */ } else {// (低位优先)则是将最重要的字节放在地址最高的存储器单元 tmp += value[0] &amp; 0xFF; tmp += (value[1] &amp; 0xFF) &lt;&lt; 8; tmp += (value[2] &amp; 0xFF) &lt;&lt; 16; tmp += (value[3] &amp; 0xFF) &lt;&lt; 24; tmp += (value[4] &amp; 0xFF) &lt;&lt; 32; tmp += (value[5] &amp; 0xFF) &lt;&lt; 40; tmp += (value[6] &amp; 0xFF) &lt;&lt; 48; tmp += (value[7] &amp; 0xFF) &lt;&lt; 56; /* * * for(int i=7; i &gt;= 0; i--){ //高位都是1，所以需要&amp;255或者&amp;0xff，把高位的1去掉；然后在位移 * intValue +=(b[i] &amp; 0xFF)&lt;&lt;(8 * i); } */ } return tmp; } /** * 浮点转换为字节 * * @param f * @return */ public static byte[] floatToByte(float f) { // 把float转换为byte[] int fbit = Float.floatToIntBits(f); byte[] b = new byte[4]; for (int i = 0; i &lt; 4; i++) { b[i] = (byte) (fbit &gt;&gt; (24 - i * 8)); } // 翻转数组 int len = b.length; // 建立一个与源数组元素类型相同的数组 byte[] dest = new byte[len]; // 为了防止修改源数组，将源数组拷贝一份副本 System.arraycopy(b, 0, dest, 0, len); byte temp; // 将顺位第i个与倒数第i个交换 for (int i = 0; i &lt; len / 2; ++i) { temp = dest[i]; dest[i] = dest[len - i - 1]; dest[len - i - 1] = temp; } return dest; } /** * 字节转换为浮点 * * @param b 字节（至少4个字节） * @param index 开始位置 * @return */ public static float byteToFloat(byte[] b, int index) { int l; l = b[index + 0]; l &amp;= 0xff; l |= ((long) b[index + 1] &lt;&lt; 8); l &amp;= 0xffff; l |= ((long) b[index + 2] &lt;&lt; 16); l &amp;= 0xffffff; l |= ((long) b[index + 3] &lt;&lt; 24); return Float.intBitsToFloat(l); } /** * 将byte转换为一个长度为8的byte数组，数组每个值代表bit；&amp;操作，如果结果是0 那么这一位的2进制就是0，否则就是1 */ public static byte[] byteToArrayBit(byte b) { byte[] array = new byte[8]; for (int i = 7; i &gt;= 0; i--) { array[i] = (byte) (b &amp; 1); b = (byte) (b &gt;&gt; 1); // 下一位 } return array; } /** * 把byte转为字符串的bit；&amp;操作，如果结果是0 那么这一位的2进制就是0，否则就是1 */ public static String byteToBit(byte b) { return \"\" + (byte) ((b &gt;&gt; 7) &amp; 0x1) + (byte) ((b &gt;&gt; 6) &amp; 0x1) + (byte) ((b &gt;&gt; 5) &amp; 0x1) + (byte) ((b &gt;&gt; 4) &amp; 0x1) + (byte) ((b &gt;&gt; 3) &amp; 0x1) + (byte) ((b &gt;&gt; 2) &amp; 0x1) + (byte) ((b &gt;&gt; 1) &amp; 0x1) + (byte) ((b &gt;&gt; 0) &amp; 0x1); } /** * 二进制字符串转byte */ public static byte binaryToByte(String byteStr) { int b, len; if (null == byteStr) { return 0; } len = byteStr.length(); if (len != 4 &amp;&amp; len != 8) { return 0; } if (len == 8) {// 8 bit处理 if (byteStr.charAt(0) == '0') {// 正数 b = Integer.parseInt(byteStr, 2); } else {// 负数 b = Integer.parseInt(byteStr, 2) - 256; } } else {// 4 bit处理 b = Integer.parseInt(byteStr, 2); } return (byte) b; } public static void main(String[] args) { //高位-&gt;低位 /*byte[] aa={0,0,0,123}; System.out.println(ByteUtil.byteToInt(aa, ByteOrder.BIG_ENDIAN)); -------------------------------------------------------------------------*/ //测试float 转 byte byte[] v=ByteUtil.floatToByte(1.0f); for (int i = 0; i &lt; v.length; i++) { System.out.print(v[i]+\" \"); } System.out.println(); byte[] b = { 0, 0, -128, 63 }; System.out.println(ByteUtil.byteToFloat(b, 0)); }}","link":"/Byte-BigSmall/"},{"title":"ASM","text":"1 ASM JVM执行class的指令 ALOAD_0 Invokespecial GETSTATIC IDC Invokevirtual RETURN 2 ASM获取方法参数名字 ASM MethodParamNamesScanner 3 ASM增强代理类，并覆写方法 ASM工厂类 Class的适配器类（ClassAdapter ） 代理类 生成的class 1 ASMASM是一个Java字节码操控框架。它能被用来动态生成类或者增强既有类的功能。ASM可以直接产生二进制class文件，也可以在类被加载入Java虚拟机之前动态改变类行为。ASM实现可以是接口，也是可以类。Java class被存储在严格格式定义的.class文件里，这些类文件拥有足够的元数据来解析类中的所有元素：类名称、方法、属性以及Java字节码（指令）。ASM从类文件中读入信息后，能够改变类行为，分析类信息，甚至能够根据用户要求生成新类。 JVM执行class的指令在Java中每一个方法在执行的时候JVM都会为其分配一个”帧”，帧是用来存储方法中计算所需要的所有数据。其中第0个元素就是this，如果方法有参数传入会排在它的后面。 ALOAD_0这个指令是LOAD系列指令中的一个，它的意思表示装载当前第0个元素到堆栈中。代码上相当于”this”。而这个数据元素的类型是一个引用类型。这些指令包含ALOAD，ILOAD，LLOAD，FLOAD，DLOAD。区分它们的作用就是针对不用数据类型而准备的LOAD指令，此外还有专门负责处理数组的指令SALOAD。 Invokespecial这个指令是调用系列指令中的一个。其目的是调用对象类的方法。后面需要给上父类的方法完整签名。”#8”的意思是 .class文件常量表中第8个元素。值为java/lang/Object.&quot;&lt;init&gt;&quot;:()V。结合ALOAD_0。这两个指令可以翻译为super()。其含义是调用自己的父类构造方法。 GETSTATIC这个指令是GET系列指令中的一个其作用是获取静态字段内容到堆栈中。这一系列指令包括了：GETFIELD、GETSTATIC。它们分别用于获取动态字段和静态字段。 IDC这个指令的功能是从常量表中装载一个数据到堆栈中。 Invokevirtual是一种调用指令，这个指令区别与invokespecial的是它是根据引用调用对象类的方法。这里有一篇文章专门讲解这两个指令：”http://wensiqun.iteye.com/blog/1125503&quot;。 RETURN这也是一系列指令中的一个，其目的是方法调用完毕返回，可用的其他指令有：IRETURN，DRETURN，ARETURN等，用于表示不同类型参数的返回。 2 ASM获取方法参数名字ASM123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115package asm;import java.io.IOException;import java.lang.reflect.Method;import java.lang.reflect.Modifier;import org.objectweb.asm.ClassReader;import org.objectweb.asm.ClassVisitor;import org.objectweb.asm.ClassWriter;import org.objectweb.asm.Label;import org.objectweb.asm.MethodVisitor;import org.objectweb.asm.Opcodes;import org.objectweb.asm.Type;import com.me.WorkServiceImpl;/** * &lt;p&gt; * 基于asm的工具类 * &lt;/p&gt; */public final class ASM { private ASM() { } /** * * &lt;p&gt; * 比较参数类型是否一致 * &lt;/p&gt; * * @param types * asm的类型({@link Type}) * @param clazzes * java 类型({@link Class}) * @return */ private static boolean sameType(Type[] types, Class&lt;?&gt;[] clazzes) { // 个数不同 if (types.length != clazzes.length) { return false; } for (int i = 0; i &lt; types.length; i++) { if (!Type.getType(clazzes[i]).equals(types[i])) { return false; } } return true; } /** * * &lt;p&gt; * 获取方法的参数名 * &lt;/p&gt; * * @param m * @return */ public static String[] getMethodParamNames(final Method method) { //参数名字 final String[] paramNames = new String[method.getParameterTypes().length]; //方法名字 final String methodName = method.getDeclaringClass().getName(); //class写入 final ClassWriter classWriter = new ClassWriter(ClassWriter.COMPUTE_MAXS); ClassReader classReader = null; try { //写入方法 classReader = new ClassReader(methodName); } catch (IOException e) { e.printStackTrace(); } classReader.accept(new ClassVisitor(Opcodes.ASM4, classWriter) { @Override public MethodVisitor visitMethod(final int access, final String name, final String desc, final String signature, final String[] exceptions) { //参数类型 final Type[] args = Type.getArgumentTypes(desc); // 判断方法名字，方法参数 if (!name.equals(method.getName()) || !sameType(args, method.getParameterTypes())) { return super.visitMethod(access, name, desc, signature, exceptions); } //方法访问 MethodVisitor methodVisitor = cv.visitMethod(access, name, desc, signature, exceptions); return new MethodVisitor(Opcodes.ASM4, methodVisitor) { @Override public void visitLocalVariable(String name, String desc, String signature, Label start, Label end, int index) { int i = index - 1; // 如果是静态方法，则第一就是参数 // 如果不是静态方法，则第一个是\"this\"，然后才是方法的参数 if (Modifier.isStatic(method.getModifiers())) { i = index; } if (i &gt;= 0 &amp;&amp; i &lt; paramNames.length) { paramNames[i] = name; } super.visitLocalVariable(name, desc, signature, start, end, index); } }; } }, 0); return paramNames; } //ASM支持泛型 public static void main(String[] args) throws SecurityException, NoSuchMethodException { //获取方法参数，方法名字，方法参数 String[] s = getMethodParamNames(WorkServiceImpl.class.getMethod(\"work\", String.class,Object.class)); for (int i = 0; i &lt; s.length; i++) { System.out.println(s[i]); } }} MethodParamNamesScanner123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165package asm;import java.io.IOException;import java.io.InputStream;import java.lang.reflect.Constructor;import java.lang.reflect.Method;import java.util.ArrayList;import java.util.Arrays;import java.util.List;import org.objectweb.asm.ClassReader;import org.objectweb.asm.Type;import org.objectweb.asm.tree.ClassNode;import org.objectweb.asm.tree.LocalVariableNode;import org.objectweb.asm.tree.MethodNode;import com.me.WorkServiceImpl;/** * 获取方法参数名字 */public class MethodParamNamesScanner { /** * 获取方法参数名列表 * * @param clazz * @param m * @return * @throws IOException */ public static List&lt;String&gt; getMethodParamNames(Class&lt;?&gt; clazz, Method method) throws IOException { try (InputStream in = clazz.getResourceAsStream(\"/\" + clazz.getName().replace('.', '/') + \".class\")) { return getMethodParamNames(in, method); } } public static List&lt;String&gt; getMethodParamNames(InputStream in, Method method) throws IOException { try (InputStream ins = in) { return getParamNames(ins, new EnclosingMetadata(method.getName(), Type.getMethodDescriptor(method), method.getParameterTypes().length)); } } /** * 获取构造器参数名列表 * * @param clazz * @param constructor * @return */ public static List&lt;String&gt; getConstructorParamNames(Class&lt;?&gt; clazz, Constructor&lt;?&gt; constructor) { try (InputStream in = clazz.getResourceAsStream(\"/\" + clazz.getName().replace('.', '/') + \".class\")) { return getConstructorParamNames(in, constructor); } catch (IOException e) { e.printStackTrace(); } return new ArrayList&lt;String&gt;(); } public static List&lt;String&gt; getConstructorParamNames(InputStream ins, Constructor&lt;?&gt; constructor) { try (InputStream in = ins) { return getParamNames( in, new EnclosingMetadata(constructor.getName(), Type.getConstructorDescriptor(constructor), constructor .getParameterTypes().length)); } catch (IOException e1) { e1.printStackTrace(); } return new ArrayList&lt;String&gt;(); } /** * 获取参数名列表辅助方法 * * @param in * @param m * @return * @throws IOException */ private static List&lt;String&gt; getParamNames(InputStream in, EnclosingMetadata enclosingMetadata) throws IOException { ClassReader classReader = new ClassReader(in); ClassNode classNode = new ClassNode(); classReader.accept(classNode, ClassReader.EXPAND_FRAMES);// 建议EXPAND_FRAMES // ASM树接口形式访问 List&lt;MethodNode&gt; methods = classNode.methods; List&lt;String&gt; list = new ArrayList&lt;String&gt;(); for (int i = 0; i &lt; methods.size(); ++i) { List&lt;LocalVariable&gt; varNames = new ArrayList&lt;LocalVariable&gt;(); MethodNode methodNode = methods.get(i); // 验证方法签名 if (methodNode.desc.equals(enclosingMetadata.desc) &amp;&amp; methodNode.name.equals(enclosingMetadata.name)) { List&lt;LocalVariableNode&gt; local_variables = methodNode.localVariables; for (int k = 0; k &lt; local_variables.size(); k++) { String varName = local_variables.get(k).name; // index-记录了正确的方法本地变量索引。(方法本地变量顺序可能会被打乱。而index记录了原始的顺序) int index = local_variables.get(k).index; // 非静态方法,第一个参数是this if (!\"this\".equals(varName)) { varNames.add(new LocalVariable(index, varName)); } } LocalVariable[] tmpArr = varNames.toArray(new LocalVariable[varNames.size()]); // 根据index来重排序，以确保正确的顺序 Arrays.sort(tmpArr); for (int j = 0; j &lt; enclosingMetadata.size; j++) { list.add(tmpArr[j].name); } break; } } return list; } /** * 方法本地变量索引和参数名封装 * * @author xby Administrator */ static class LocalVariable implements Comparable&lt;LocalVariable&gt; { public int index; public String name; public LocalVariable(int index, String name) { this.index = index; this.name = name; } public int compareTo(LocalVariable o) { return this.index - o.index; } } /** * 封装方法描述和参数个数 * * @author xby Administrator */ static class EnclosingMetadata { // method name public String name; // method description public String desc; // params size public int size; public EnclosingMetadata(String name, String desc, int size) { this.name = name; this.desc = desc; this.size = size; } } public static void main(String[] args) throws IOException { for (Method m : WorkServiceImpl.class.getDeclaredMethods()) { List&lt;String&gt; list = getMethodParamNames(WorkServiceImpl.class, m); System.out.println(m.getName() + \":\"); for (String str : list) { System.out.println(str); } System.out.println(\"------------------------\"); } }} 3 ASM增强代理类，并覆写方法 生成被代理类的子类，并重写所有方法（除java.lang.Object类定义的方法），增加before和after拦截。 重新定义被代理类的所有属性（不包括属性的赋值）。 把生成的class文件保存到硬盘中。 从内存中加载新生成的class。ASM工厂类12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697package asm;import java.io.File;import java.io.FileNotFoundException;import java.io.FileOutputStream;import java.io.IOException;import org.objectweb.asm.ClassReader;import org.objectweb.asm.ClassVisitor;import org.objectweb.asm.ClassWriter;/** * * &lt;p&gt; * asm 代理工厂 * &lt;/p&gt; */public class AsmFactory { public static final String SUFIX = \"$EnhancedByCc\"; public static BytecodeLoader classLoader = new BytecodeLoader(); /** * * &lt;p&gt; * 根据字节码加载class * &lt;/p&gt; */ public static class BytecodeLoader extends ClassLoader { public Class&lt;?&gt; defineClass(String className, byte[] byteCodes) { return super.defineClass(className, byteCodes, 0, byteCodes.length); } } /** * * &lt;p&gt; * 返回代理类（增强类） * &lt;/p&gt; * * @param &lt;T&gt; * @param clazz * @return * @throws Exception */ @SuppressWarnings(\"unchecked\") protected static &lt;T&gt; Class&lt;T&gt; getEnhancedClass(Class&lt;T&gt; clazz) { String enhancedClassName = clazz.getName() + SUFIX; try { return (Class&lt;T&gt;) classLoader.loadClass(enhancedClassName); } catch (ClassNotFoundException classNotFoundException) {//class没有找到，重新加载class ClassReader reader = null; try { reader = new ClassReader(clazz.getName()); } catch (IOException ioexception) { throw new RuntimeException(ioexception); } ClassWriter writer = new ClassWriter(ClassWriter.COMPUTE_MAXS); //初始化classvisitor ClassVisitor visitor = new ClassAdapter(enhancedClassName, clazz, writer); reader.accept(visitor, 0); byte[] byteCodes = writer.toByteArray(); //写入class文件 writeClazz(enhancedClassName, byteCodes); Class&lt;T&gt; result = (Class&lt;T&gt;) classLoader.defineClass(enhancedClassName, byteCodes); return result; } } /** * * &lt;p&gt; * 把java字节码写入class文件 * &lt;/p&gt; * * @param &lt;T&gt; * @param name * @param data * @throws FileNotFoundException * @throws IOException */ public static &lt;T&gt; void writeClazz(String name, byte[] data) { try { File file = new File(\"C:/TEMP/\" + name + \".class\"); FileOutputStream fout = new FileOutputStream(file); fout.write(data); fout.close(); } catch (Exception e) { e.printStackTrace(); } } public static void main(String[] args) throws InstantiationException, IllegalAccessException { Class&lt;RoleService&gt; rsCls = getEnhancedClass(RoleService.class); rsCls.newInstance().executeOuter(1); }} Class的适配器类（ClassAdapter ）123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369package asm; import java.lang.reflect.Method;import java.lang.reflect.Modifier; import org.objectweb.asm.ClassVisitor;import org.objectweb.asm.ClassWriter;import org.objectweb.asm.FieldVisitor;import org.objectweb.asm.MethodVisitor;import org.objectweb.asm.Opcodes;import org.objectweb.asm.Type; /** * * &lt;p&gt;根据class A生成一个class B extends A&lt;/p&gt; * &lt;li&gt;重写A及A父类的所有方法，eg. public void xx() {super.xx();} * &lt;li&gt;copy A类定义的所有属性 * 1、生成被代理类的子类，并重写所有方法（除java.lang.Object类定义的方法），增加before和after拦截。 2、重新定义被代理类的所有属性（不包括属性的赋值）。 3、把生成的class文件保存到硬盘中。 4、从内存中加载新生成的class。 * */public class ClassAdapter extends ClassVisitor implements Opcodes{ public static final String INIT = \"&lt;init&gt;\"; private ClassWriter classWriter; //原始类名字 private String originalClassName; //增强类名字 private String enhancedClassName; //原始类 private Class&lt;?&gt; originalClass; /** * * &lt;p&gt;Title: &lt;/p&gt; * &lt;p&gt;Description: &lt;/p&gt; * @param enhancedClassName 增强类 * @param targetClass 目标类 * @param writer class写入 */ public ClassAdapter(String enhancedClassName, Class&lt;?&gt; targetClass, ClassWriter writer) { super(Opcodes.ASM4, writer); this.classWriter = writer; this.originalClassName = targetClass.getName(); this.enhancedClassName = enhancedClassName; this.originalClass = targetClass; } @Override public void visit(int version, int access, String name, String signature, String superName, String[] interfaces) { cv.visit(version, Opcodes.ACC_PUBLIC, toAsmCls(enhancedClassName), signature, name, interfaces); } /** * 访问属性 */ @Override public FieldVisitor visitField(int access, String name, String desc, String signature, Object value) { // 拷贝所有属性 可使用java反射给属性赋值（生成class后newInstance在赋值） return super.visitField(access, name, desc, signature, value); } @Override public MethodVisitor visitMethod(int access, String name, String desc, String signature, String[] exceptions) { // 删除所有方法 return null; } /** * 把类名中的.替换为/ * * @param className * @return */ private static String toAsmCls(String className) { return className.replace('.', '/'); } /** * * &lt;p&gt; * 前置方法 * &lt;/p&gt; * * @see TxHandler * @param mWriter */ private static void doBefore(MethodVisitor mWriter, String methodInfo) { mWriter.visitFieldInsn(GETSTATIC, \"java/lang/System\", \"out\", \"Ljava/io/PrintStream;\"); mWriter.visitLdcInsn(\"before method : \" + methodInfo); mWriter.visitMethodInsn(INVOKEVIRTUAL, \"java/io/PrintStream\", \"println\", \"(Ljava/lang/String;)V\"); // 或者直接调用静态方法 // mWriter.visitLdcInsn(methodInfo); // mWriter.visitMethodInsn(INVOKESTATIC,toAsmCls(TxHandler.class.getName()),\"before\",\"(Ljava/lang/String;)V\"); } /** * * &lt;p&gt; * 后置方法 * &lt;/p&gt; * * @see TxHandler * @param mWriter */ private static void doAfter(MethodVisitor mWriter, String methodInfo) { mWriter.visitFieldInsn(GETSTATIC, \"java/lang/System\", \"out\", \"Ljava/io/PrintStream;\"); mWriter.visitLdcInsn(\"after method : \" + methodInfo); mWriter.visitMethodInsn(INVOKEVIRTUAL, \"java/io/PrintStream\", \"println\", \"(Ljava/lang/String;)V\"); } /** * 判断方法是否可以重新覆写 * &lt;p&gt; * object类本身的方法不做重写 * &lt;/p&gt; * &lt;p&gt; * \"main\" 方法不做重写 * &lt;/p&gt; * * @param m * @return */ public static boolean needOverride(Method method) { // object类本身的方法不做重写 if (method.getDeclaringClass().getName().equals(Object.class.getName())) { return false; } // \"main\" 方法不做重写 if (Modifier.isPublic(method.getModifiers()) &amp;&amp; Modifier.isStatic(method.getModifiers()) &amp;&amp; method.getReturnType().getName().equals(\"void\") &amp;&amp; method.getName().equals(\"main\")) { return false; } return true; } @Override public void visitEnd() { // 如果originalClass定义了私有成员变量，那么直接在visitMethod中复制originalClass的&lt;init&gt;会报错。 // ALOAD 0 // INVOKESPECIAL cc/RoleService.&lt;init&gt;()V // RETURN // // 调用originalClassName的&lt;init&gt;方法，否则class不能实例化 MethodVisitor mvInit = classWriter.visitMethod(ACC_PUBLIC, INIT, \"()V\", null, null); mvInit.visitVarInsn(ALOAD, 0); mvInit.visitMethodInsn(INVOKESPECIAL, toAsmCls(originalClassName), INIT, \"()V\"); mvInit.visitInsn(RETURN); mvInit.visitMaxs(0, 0); mvInit.visitEnd(); // 获取所有方法，并重写(main方法 和 Object的方法除外) Method[] methods = originalClass.getMethods(); for (Method m : methods) { //不覆写main方法 if (!needOverride(m)) { continue; } //类型 Type mt = Type.getType(m); StringBuilder methodInfo = new StringBuilder(originalClassName); methodInfo.append(\".\").append(m.getName()); methodInfo.append(\"|\"); Class&lt;?&gt;[] paramTypes = m.getParameterTypes(); //类型名字 for (Class&lt;?&gt; t : paramTypes) { methodInfo.append(t.getName()).append(\",\"); } if (paramTypes.length &gt; 0) { //删除最后一个“,” methodInfo.deleteCharAt(methodInfo.length() - 1); } // 方法是被哪个类定义的 String declaringCls = toAsmCls(m.getDeclaringClass().getName()); // 方法 description MethodVisitor mWriter = classWriter.visitMethod(ACC_PUBLIC, m.getName(), mt.toString(), null, null); // insert code here (before) doBefore(mWriter, methodInfo.toString()); int i = 0; // 如果不是静态方法 load this对象 if (!Modifier.isStatic(m.getModifiers())) { mWriter.visitVarInsn(ALOAD, i++); } StringBuilder sb = new StringBuilder(m.getName()); // load 出方法的所有参数 for (Class&lt;?&gt; tCls : m.getParameterTypes()) { Type t = Type.getType(tCls); sb.append(loadCode(t)).append(\",\"); mWriter.visitVarInsn(loadCode(t), i++); if (t.getSort() == Type.LONG || t.getSort() == Type.DOUBLE) { i++; } } // super.xxx(); mWriter.visitMethodInsn(INVOKESPECIAL, declaringCls, m.getName(), mt.toString()); // 处理返回值类型 Type rt = Type.getReturnType(m); // 没有返回值 if (rt.toString().equals(\"V\")) { doAfter(mWriter, methodInfo.toString()); mWriter.visitInsn(RETURN); } // 把return xxx() 转变成 ： Object o = xxx(); return o; else { int storeCode = storeCode(rt); int loadCode = loadCode(rt); int returnCode = rtCode(rt); mWriter.visitVarInsn(storeCode, i); doAfter(mWriter, methodInfo.toString()); mWriter.visitVarInsn(loadCode, i); mWriter.visitInsn(returnCode); } // 已设置了自动计算，但还是要调用一下，不然会报错 mWriter.visitMaxs(i, ++i); mWriter.visitEnd(); } cv.visitEnd(); } /** * * &lt;p&gt; * get StoreCode(Opcodes#xStore) * &lt;/p&gt; * * * @param type * @return */ public static int storeCode(Type type) { //排序 int sort = type.getSort(); switch (sort) { case Type.ARRAY: sort = ASTORE; break; case Type.BOOLEAN: sort = ISTORE; break; case Type.BYTE: sort = ISTORE; break; case Type.CHAR: sort = ISTORE; break; case Type.DOUBLE: sort = DSTORE; break; case Type.FLOAT: sort = FSTORE; break; case Type.INT: sort = ISTORE; break; case Type.LONG: sort = LSTORE; break; case Type.OBJECT: sort = ASTORE; break; case Type.SHORT: sort = ISTORE; break; default: break; } return sort; } /** * * &lt;p&gt; * get StoreCode(Opcodes#xLOAD) * &lt;/p&gt; * * @param type * @return */ public static int loadCode(Type type) { int sort = type.getSort(); switch (sort) { case Type.ARRAY: sort = ALOAD; break; case Type.BOOLEAN: sort = ILOAD; break; case Type.BYTE: sort = ILOAD; break; case Type.CHAR: sort = ILOAD; break; case Type.DOUBLE: sort = DLOAD; break; case Type.FLOAT: sort = FLOAD; break; case Type.INT: sort = ILOAD; break; case Type.LONG: sort = LLOAD; break; case Type.OBJECT: sort = ALOAD; break; case Type.SHORT: sort = ILOAD; break; default: break; } return sort; } /** * * &lt;p&gt; * get StoreCode(Opcodes#xRETURN) * &lt;/p&gt; * * @param type * @return */ public static int rtCode(Type type) { int sort = type.getSort(); switch (sort) { case Type.ARRAY: sort = ARETURN; break; case Type.BOOLEAN: sort = IRETURN; break; case Type.BYTE: sort = IRETURN; break; case Type.CHAR: sort = IRETURN; break; case Type.DOUBLE: sort = DRETURN; break; case Type.FLOAT: sort = FRETURN; break; case Type.INT: sort = IRETURN; break; case Type.LONG: sort = LRETURN; break; case Type.OBJECT: sort = ARETURN; break; case Type.SHORT: sort = IRETURN; break; default: break; } return sort; }} 代理类1234567891011121314151617181920212223242526272829package asm;/** * &lt;p&gt;&lt;/p&gt; */public class RoleService extends Service{ private String field1 = \"\"; public String executeOuter(Integer name) { System.out.println(\"executeOuter call super.query()\"); return query(); } @Override public String query() { System.out.println(\"execute (RoleService): query\"); return \"query result (RoleService)\"; } public String getField1() { return field1; } public void setField1(String field1) { this.field1 = field1; } } 1234567891011121314151617181920/** * Service.java 11:59:38 AM Apr 27, 2012 * * Copyright(c) 2000-2012 HC360.COM, All Rights Reserved. */package asm;/** * &lt;p&gt;&lt;/p&gt; * */public class Service extends Dao{ @Override public void insert(Object o) { super.insert(o); } } 12345678910111213141516171819202122232425262728293031323334353637383940414243/** * Dao.java 11:58:24 AM Apr 27, 2012 * * Copyright(c) 2000-2012 HC360.COM, All Rights Reserved. */package asm;/** * &lt;p&gt;&lt;/p&gt; * */public class Dao { public void insert(Object o) { System.out.println(\"insert : \" + o); } public String query() { System.out.println(\"execute (Dao): query\"); return \"query result (Dao)\"; } public String query2() { System.out.println(\"execute (Dao): query2\"); return \"query2 result (Dao)\"; } public int test() { System.out.println(\"execute (Dao) : test\"); return 0; } protected void testProtected() { System.out.println(\"execute (Dao) : testProtected\"); testPrivate(); } private void testPrivate() { System.out.println(\"execute (Dao) : testPrivate\"); } public Dao[] testArray(String[] s,Object o) { System.out.println(\"execute (Dao) : testArray\"); return null; }} 生成的class12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970package asm;import java.io.PrintStream;public class RoleService$EnhancedByCc extends RoleService{ private String field1; public String executeOuter(Integer paramInteger) { System.out.println(\"before method : asm.RoleService.executeOuter|java.lang.Integer\"); String str = super.executeOuter(paramInteger); System.out.println(\"after method : asm.RoleService.executeOuter|java.lang.Integer\"); return str; } public String query() { System.out.println(\"before method : asm.RoleService.query|\"); String str = super.query(); System.out.println(\"after method : asm.RoleService.query|\"); return str; } public void setField1(String paramString) { System.out.println(\"before method : asm.RoleService.setField1|java.lang.String\"); super.setField1(paramString); System.out.println(\"after method : asm.RoleService.setField1|java.lang.String\"); } public String getField1() { System.out.println(\"before method : asm.RoleService.getField1|\"); String str = super.getField1(); System.out.println(\"after method : asm.RoleService.getField1|\"); return str; } public void insert(Object paramObject) { System.out.println(\"before method : asm.RoleService.insert|java.lang.Object\"); super.insert(paramObject); System.out.println(\"after method : asm.RoleService.insert|java.lang.Object\"); } public String query2() { System.out.println(\"before method : asm.RoleService.query2|\"); String str = super.query2(); System.out.println(\"after method : asm.RoleService.query2|\"); return str; } public int test() { System.out.println(\"before method : asm.RoleService.test|\"); int i = super.test(); System.out.println(\"after method : asm.RoleService.test|\"); return i; } public Dao[] testArray(String[] paramArrayOfString, Object paramObject) { System.out.println(\"before method : asm.RoleService.testArray|[Ljava.lang.String;,java.lang.Object\"); Dao[] arrayOfDao = super.testArray(paramArrayOfString, paramObject); System.out.println(\"after method : asm.RoleService.testArray|[Ljava.lang.String;,java.lang.Object\"); return arrayOfDao; }}","link":"/ASM/"},{"title":"(转载)Boyer-Moore(字符串匹配)","text":"1 引言 2 概念 Moore教授例子 特点 概念 坏字符 好后缀 3 代码 C++代码 Java代码1 Java代码2 Java代码3 5 代码解释 坏字符 好后缀 改进suff方法 suff数组 1 引言KMP它并不是效率最高的算法，实际采用并不多。各种文本编辑器的”查找”功能（Ctrl+F），大多采用Boyer-Moore算法。Boyer-Moore算法不仅效率高，而且构思巧妙，容易理解。1977年，德克萨斯大学的Robert S. Boyer教授和J Strother Moore教授发明了这种算法。在用于查找子字符串的算法当中，BM（Boyer-Moore）算法是目前被认为最高效的字符串搜索算法。 一般情况下，比KMP算法快3-5倍。该算法常用于文本编辑器中的搜索匹配功能，比如大家所熟知的GNU grep命令使用的就是该算法，这也是GNU grep比BSD grep快的一个重要原因。 2 概念Moore教授例子根据Moore教授自己的例子来解释这种算法。假定字符串（文本串）为”HERE IS A SIMPLE EXAMPLE”，搜索词（模式串）为”EXAMPLE”。首先，”字符串”与”搜索词”头部对齐，从尾部开始比较。这是一个很聪明的想法，因为如果尾部字符不匹配，那么只要一次比较，就可以知道前7个字符肯定不是要找的结果。我们看到，”S”与”E”不匹配。这时，”S”就被称为”坏字符”（bad character），即不匹配的字符。我们还发现，”S”不包含在搜索词”EXAMPLE”之中，这意味着可以把搜索词直接移到”S”的后一位。依然从尾部开始比较，发现”P”与”E”不匹配，所以”P”是”坏字符”。但是，”P”包含在搜索词”EXAMPLE”之中。所以，将搜索词后移两位，两个”P”对齐。我们由此总结出”坏字符规则”：1后移位数 = 坏字符的位置（在搜索串中的位置） - 搜索词中的上一次出现位置（最新比较的位置） 如果”坏字符”不包含在搜索词之中，则上一次出现位置为 -1。以”P”为例，它作为”坏字符”，出现在搜索词的第6位（从0开始编号），在搜索词中的上一次出现位置为4，所以后移6 - 4 = 2位。再以前面第二步的”S”为例，它出现在第6位，上一次出现位置是-1（即未出现），则整个搜索词后移6 - (-1) = 7位。依然从尾部开始比较，”E”与”E”匹配。比较前面一位，”LE”与”LE”匹配。比较前面一位，”PLE”与”PLE”匹配。比较前面一位，”MPLE”与”MPLE”匹配。我们把这种情况称为”好后缀”（good suffix），即所有尾部匹配的字符串。注意，”MPLE”、”PLE”、”LE”、”E”都是好后缀。比较前一位，发现”I”与”A”不匹配。所以，”I”是”坏字符”。根据”坏字符规则”，此时搜索词应该后移2 - （-1）= 3位。问题是，此时有没有更好的移法？我们知道，此时存在”好后缀”。所以，可以采用”好后缀规则”：1后移位数 = 好后缀的位置 - 搜索词中的上一次出现位置 计算时，位置的取值以”好后缀”的最后一个字符为准。如果”好后缀”在搜索词中没有重复出现，则它的上一次出现位置为-1。所有的”好后缀”（MPLE、PLE、LE、E）之中，只有”E”在”EXAMPLE”之中出现两次，所以后移6 - 0 = 6位。可以看到，”坏字符规则”只能移3位，”好后缀规则”可以移6位。所以，Boyer-Moore算法的基本思想是，每次后移这两个规则之中的较大值。更巧妙的是，这两个规则的移动位数，只与搜索词有关，与原字符串无关。因此，可以预先计算生成《坏字符规则表》和《好后缀规则表》。使用时，只要查表比较一下就可以了。继续从尾部开始比较，”P”与”E”不匹配，因此”P”是”坏字符”。根据”坏字符规则”，后移6 - 4 = 2位。从尾部开始逐位比较，发现全部匹配，于是搜索结束。如果还要继续查找（即找出全部匹配），则根据”好后缀规则”，后移6 - 0 = 6位，即头部的”E”移到尾部的”E”的位置。 特点Boyer-Moore 算法的主要特点有： 对模式字符的比较顺序时从右向左。 预处理需要O(m + σ)的时间和空间复杂度。 匹配阶段需要O(m × n)的时间复杂度。 匹配阶段在最坏情况下需要3n次字符比较。 最优复杂度O(n/m)。概念Boyer–Moore算法在对模式P字符串进行预处理时，将采用两种不同的启发式方法。这两种启发式的预处理方法称为： 坏字符（Bad Character Heuristic）：当文本 T 中的某个字符跟模式P的某个字符不匹配时，我们称文本T中的这个失配字符为坏字符。 好后缀（Good Suffix Heuristic）：当文本 T 中的某个字符跟模式P的某个字符不匹配时，我们称文本T中的已经匹配的字符串为好后缀。 Boyer–Moore算法在预处理时，将为两种不同的启发法结果创建不同的数组，分别称为 Bad-Character-Shift（or The Occurrence Shift）和Good-Suffix-Shift（or Matching Shift）。当进行字符匹配时，如果发现模式P中的字符与文本T中的字符不匹配时，将比较两种不同预处理方法，选择最大的一个值来对模式串（搜索词）P的位置进行滑动。 坏字符当出现一个坏字符时, BM算法向右移动模式串, 让模式串中最靠右的对应字符（对应的坏字符串）与坏字符相对，然后继续匹配。坏字符算法有两种情况。 模式串中有对应的坏字符时，让模式串中最靠右的对应字符（对应的坏字符串）与坏字符相对（PS：BM不可能走回头路，因为若是回头路，则移动距离就是负数了，肯定不是最大移动步数了），如下图。 模式串中不存在文本串的坏字符，直接右移模式串（未匹配的，示例：aba移动到c位置后）长度。为了用代码来描述上述的两种情况，设计一个数组bmBc['k']，表示坏字符‘k’在模式串中出现的位置距离模式串末尾的最大长度，那么当遇到坏字符的时候，模式串可以移动距离为：shift(坏字符) = bmBc[T[i]]-（m-1-i)。 好后缀有三种情况： 模式串中有子串匹配上好后缀，此时移动模式串，让该文本串和好后缀对齐即可，如果超过一个子串匹配上好后缀，则选择最靠左边的子串对齐。 模式串中没有文本串匹配上好后缀，此时需要寻找模式串的一个最长前缀，并让该前缀等于好后缀的后缀，寻找到该前缀后，让该前缀和好后缀对齐即可。 模式串中没有文本串匹配上好后缀，并且在模式串中找不到最长前缀，让该前缀等于好后缀的后缀。此时，直接移动模式串到好后缀（位置的取值以”好后缀”的最后一个字符为准）的下一个字符。 3 代码C++代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234#include &lt;stdio.h&gt;#include &lt;string.h&gt; #define MAX_CHAR 256#define SIZE 256#define MAX(x, y) (x) &gt; (y) ? (x) : (y) void BoyerMoore(char *pattern, int m, char *text, int n); int main(){ //char pattern[256] ={ 'b','a','b','c','d','e'}; //char text[256]={'a','b','c','d','e','f','g','b','c','d','e'}; char text[256] ={ 'I','a','m','h','a','p','p','y'},pattern[256]={'a','p',}; BoyerMoore(pattern, strlen(pattern), text, strlen(text)); /*char pattern[256]={'e','x','a','m','p','l','e',}; int suff[SIZE]; int i, j,m=strlen(pattern);*/ return 0;}//@pattern：搜索串//@m：搜索串长度//计算坏字符数组//一个数组bmBc['k']，表示坏字符‘k’在模式串中出现的位置距离模式串末尾的最大长度，那么当遇到坏字符的时候，模式串可以移动距离为： shift(坏字符) = bmBc[T[i]]-（m-1-i)void PreBmBc(char *pattern, int m, int bmBc[]){ int i; //条件2：坏字符没有出现在搜索串中，移动整个搜索串(初始化的时候默认移动) //初始化bmBc数据 for (i = 0; i &lt; MAX_CHAR; i++){ bmBc[i] = m; } //条件1 //bmBc存字符:似乎只需要bmBc[i] = m - 1 - i就行了，但这样是不对的，因为i位置处的字符可能在pattern中多处出现，而我们需要的是最右边的位置，这样就需要每次循环判断了， //非常麻烦，性能差。这里有个小技巧，就是使用字符作为下标而不是位置数字作为下标。这样只需要遍历一遍即可，这是空间换时间的做法. for (i = 0; i &lt; m - 1; i++){ //坏字符在搜索串中需要移动的距离 bmBc[pattern[i]] = m - 1 - i; } printf(\"bmBc[]:\"); for (i = 0; i &lt; m; i++) { printf(\"%d \",bmBc[pattern[i]]); } printf(\"\\n\");} //打印方法//array：字符数组指针//n长度//字符数组名字void print(int *array, int n, char *arrayName){ int i; printf(\"%s:\", arrayName); for (i = 0; i &lt; n; i++) { printf(\"%d \", array[i]); } printf(\"\\n\");}//计算好后缀数组//@pattern：模式串//@m：模式串长度//@suff：suffix[i] = s 表示以i为边界的字符后缀，与模式串后缀匹配的最大长度。（pattern中以i位置字符为后缀和以最后一个字符为后缀的公共后缀串的长度）void suffix_old(char *pattern, int m, int suff[]){ //i：从后往前比较的标记位,好后缀最后1个字符的位置 //j: 在搜索串中下标位置比较，表示好后缀在搜索词中上1次出现的位置 int i, j; //定义最后一个字符需要移动的距离：整个搜索串。例子：最后1个字符是好后缀，且没有在搜索串中出现，最后一个字符移动距离=(m-1)-(-1)=m //suffix[i] = s 表示以i为边界的字符后缀，与模式串后缀匹配的最大长度。 suff[m - 1] = m; //从最后一个串开始比较 for (i = m - 2; i &gt;= 0; i--) { j = i; //2个字符匹配，继续往前找字符 //j&lt;(m-1-i+j):相差1位 //如果j与j+1，不相同j=i=i--，m-1-i+j也就是最后1个字符，如果最后1个字符找相同的字符 while (j &gt;= 0 &amp;&amp; pattern[j] == pattern[m -1 - i + j]){ j--; } //获取匹配的最大长度 //i：好后缀最后1个字符的位置 //suff[i]：i位置需要移动的距离 //j:i位置的字符出现在搜索串中上1个的位置 //非好后缀，suff的值是0,不做移动 suff[i] = i - j; }}//改进计算suffix方法void suffix(char *pattern, int m, int suff[]) { int f, g, i; suff[m - 1] = m; //上一次进行成功匹配的失配位置 g = m - 1; //i开始匹配的位置 for (i = m - 2; i &gt;= 0; --i) { //f:上一个成功进行匹配的起始位置 if (i &gt; g &amp;&amp; suff[i + m - 1 - f] &lt; i - g){ //获取匹配的最大长度 suff[i] = suff[i + m - 1 - f]; } else { //g的最大值就是i if (i &lt; g){ g = i; } // f = i; //寻找上失配的位置 while (g &gt;= 0 &amp;&amp; pattern[g] == pattern[g + m - 1 - f]){ --g; } //最大的匹配长度 suff[i] = f - g; } } //print(suff, m, \"suff[]\");} //好后缀规则//@pattern：搜索串//@m：搜索串长度//@bmGs: bmGs[i] 表示遇到好后缀时，搜索串应该移动的距离，其中i表示好后缀前面一个字符的位置void PreBmGs(char *pattern, int m, int bmGs[]){ int i, j; int suff[SIZE]; // 计算后缀数组 suffix(pattern, m, suff); //suffix_old(pattern, m, suff); //条件3:模式串中没有子串匹配上好后缀 //以好后缀最后1个字符位置为标准，移动距离：(m-1)-(-1) for (i = 0; i &lt; m; i++){ bmGs[i] = m; } //条件2：模式串有前缀字符串匹配好后缀的后缀 //范围内的任意位置:模式串前缀匹配好后缀后1位置开始-好后缀的前一个字符串标记位 j = 0; //i:从尾部往前比较 //i：好后缀的前1个位置 for (i = m - 1; i &gt;= 0; i--) { //i等于其最大匹配长度,说明i位置的字符没有在模式串中重复出现 if (i + 1 == suff[i]) { //j从前往后比较 //模式串的前缀的位置开始-&gt;模式串后缀前1个位置 for (;j &lt; m - 1 - i; j++) { //如果j的最大移动位置不是m，说明j的位置字符串在模式串中重复存在，j的位置就是在好后缀范围内。根据公式：后移位数 = 好后缀的位置 - 搜索词中的上一次出现位置 //如果j的最大移动位置是m，说明j不在好后缀的范围内 if (m == bmGs[j]){ //j位置移动的最大距离.好后缀在模式串匹配的前缀+1位置开始移动 bmGs[j] = m - 1 - i; } } } } //条件1 for (i = 0; i &lt;= m - 2; i++){ int k=m - 1 - suff[i]; int p=m - 1 - i; //suff[i]：i位置的字符后缀与搜索串最后1个字符的后缀相同的最大长度，好后缀的最大长度 //在位置：m - 1 - suff[i]，需要移动的距离：m-1-i bmGs[k] = p; } print(bmGs, m , \"bmGs[]\");} //@pattern：搜索词字符串//@m：搜索词字符串长度//@text：文本字符串//@m：文本字符串长度void BoyerMoore(char *pattern, int m, char *text, int n){ int i, j, bmBc[MAX_CHAR], bmGs[SIZE]; //获取坏字符 PreBmBc(pattern, m, bmBc); //获取最好后缀 PreBmGs(pattern, m, bmGs); // Searching j = 0; while (j &lt;= n - m) { //文本串和模式串从尾部开始比较 for (i = m - 1; i &gt;= 0 &amp;&amp; pattern[i] == text[i + j]; i--){ printf(\"\\n\"); }; //找到第一个不匹配的位置，然后说明是最好后缀模式，输出模式串的移动距离 //i=0;i在搜索串第1个字符上,i--:在搜索字符串外的第1个位置 if (i &lt; 0) { printf(\"Find it, the position is %d\\n\", j); //在搜索字符串0这个位置需要移动的距离 j += bmGs[0]; return ; } else{ //坏字符规则:后移位数 = 坏字符的位置 - 搜索词中的上一次出现位置 //选择最大的一个值来对模式串（搜索词） 的位置进行滑动. //坏字符串移动的距离：bmBc[text[i + j]] - （m - 1 - i）,bmBc[text[i + j]]:坏字符在搜索字符串中出现的位置到搜索字符串末端的最大距离 //好后缀移动的距离：bmGs[i] //i在搜索串这个位置，搜索串需要移动的距离 j += MAX(bmBc[text[i + j]] - m + 1 + i, bmGs[i]); } } printf(\"No find.\\n\");} Java代码11234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768package demo1;public class BoyerMoore { /** * * right：存储搜索串中每个字符的位置，字符用ascii表示 * 这里字符的位置是最新比较的位置。每一个字符位置都会覆盖之前字符的位置 * 坏字符串：搜索词中的上一次出现位置，实际上就是最靠右的字符的位置，因为从后-&gt;前 * * @param pat * @param right */ public static void getRight(String pat, int[] right) { for (int i = 0; i &lt; 256; i++) { right[i] = -1; } for (int i = 0; i &lt; pat.length(); i++) { right[pat.charAt(i)] = i; } } /** * 只实现坏字符串，没有实现好后缀 * @param txt * @param pat * @param right * @return */ public static int BoyerMooreSearch(String txt, String pat, int[] right) { int M = txt.length(); int N = pat.length(); //跳跃标记（搜索串移动距离-后移的位置） //此代码指：文本串标记位的移动 int skip; //文本串从头开始比较 for (int i = 0; i &lt;= M - N; i += skip) { skip = 0; //搜索串从最后1个字符开始比较 for (int j = N - 1; j &gt;= 0; j--) { //比较最后1个字符，如果最后1个字符不匹配，就是不匹配。 //j：搜索串中最后1个位置，从后-&gt;前 //i+j：上1次不匹配移动距离+搜索串的长度 if (pat.charAt(j) != txt.charAt(i + j)) { //坏字符串：后移位数 = 坏字符的位置（在搜索串中的位置） - 搜索词中的上一次出现位置（最新比较的位置） //坏字符的位置：当前在搜索串不匹配的位置. //right[txt.charAt(i + j)]：坏字符串在搜索串的出现位置。未出现=-1 skip = j - right[txt.charAt(i + j)]; if (skip &lt; 1) { skip = 1; } break; } } if (skip == 0){ return i; } } return -1; } public static void main(String[] args) { String txt = \"BBC ABCDAB AACDABABCDABCDABDE\"; String pat = \"ABCDABD\"; int[] right = new int[256]; getRight(pat, right); System.out.println(BoyerMooreSearch(txt, pat, right)); }} Java代码2123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108package demo1;import java.util.HashMap;import java.util.Map;/** * 与C++版本类似。 * */public class BoyerMoore2 { public static void main(String[] args) { String text = \"aadqaqqcdqqasdadacbcdbccbcd\"; String pattern = \"adacbcd\"; BoyerMoore2 bm = new BoyerMoore2(); bm.boyerMoore(pattern, text); } public void boyerMoore(String pattern, String text) { int m = pattern.length(); int n = text.length(); Map&lt;String, Integer&gt; bmBc = new HashMap&lt;String, Integer&gt;(); int[] bmGs = new int[m]; // proprocessing preBmBc(pattern, m, bmBc); preBmGs(pattern, m, bmGs); // searching int j = 0; int i = 0; int count = 0; while (j &lt;= n - m) { for (i = m - 1; i &gt;= 0 &amp;&amp; pattern.charAt(i) == text.charAt(i + j); i--) { // 用于计数 count++; } if (i &lt; 0) { System.out.println(\"one position is:\" + j); j += bmGs[0]; } else { j += Math.max(bmGs[i], getBmBc(String.valueOf(text.charAt(i + j)), bmBc, m) - m + 1 + i); } } System.out.println(\"count:\" + count); } private void preBmBc(String pattern, int patLength, Map&lt;String, Integer&gt; bmBc) { System.out.println(\"bmbc start process...\"); { for (int i = patLength - 2; i &gt;= 0; i--) if (!bmBc.containsKey(String.valueOf(pattern.charAt(i)))) { bmBc.put(String.valueOf(pattern.charAt(i)), (Integer) (patLength - i - 1)); } } } private void preBmGs(String pattern, int patLength, int[] bmGs) { int i, j; int[] suffix = new int[patLength]; suffix(pattern, patLength, suffix); // 模式串中没有子串匹配上好后缀，也找不到一个最大前缀 for (i = 0; i &lt; patLength; i++) { bmGs[i] = patLength; } // 模式串中没有子串匹配上好后缀，但找到一个最大前缀 j = 0; for (i = patLength - 1; i &gt;= 0; i--) { if (suffix[i] == i + 1) { for (; j &lt; patLength - 1 - i; j++) { if (bmGs[j] == patLength) { bmGs[j] = patLength - 1 - i; } } } } // 模式串中有子串匹配上好后缀 //aacbcd for (i = 0; i &lt; patLength - 1; i++) { bmGs[patLength - 1 - suffix[i]] = patLength - 1 - i; } System.out.print(\"bmGs:\"); for (i = 0; i &lt; patLength; i++) { System.out.print(bmGs[i] + \",\"); } System.out.println(); } private void suffix(String pattern, int patLength, int[] suffix) { suffix[patLength - 1] = patLength; int q = 0; for (int i = patLength - 2; i &gt;= 0; i--) { q = i; while (q &gt;= 0 &amp;&amp; pattern.charAt(q) == pattern.charAt(patLength - 1 - i + q)) { q--; } suffix[i] = i - q; } System.out.println(); } private int getBmBc(String c, Map&lt;String, Integer&gt; bmBc, int m) { // 如果在规则中则返回相应的值，否则返回pattern的长度 if (bmBc.containsKey(c)) { return bmBc.get(c); } else { return m; } }} Java代码3123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199package demo1;/** * 好后缀方法没有看懂 * @author Administrator * */public class BoyerMoore3 { public static final int ALPHABET_SIZE = Character.MAX_VALUE + 1; //文本串 private String text; //搜索串 private String pattern; private int[] last; //搜索串-好后缀：每个字符移动的距离 private int[] match; private int[] suffix; public BoyerMoore3(String pattern, String text) { this.text = text; this.pattern = pattern; last = new int[ALPHABET_SIZE]; match = new int[pattern.length()]; suffix = new int[pattern.length()]; } /** * Searches the pattern in the text. Returns the position of the first * occurrence, if found and -1 otherwise. */ public int match() { // Preprocessing computeLast(); computeMatch(); // Searching int i = pattern.length() - 1; int j = pattern.length() - 1; while (i &lt; text.length()) { if (pattern.charAt(j) == text.charAt(i)) { if (j == 0) { // the left-most match is found return i; } j--; i--; } else { // a difference //i：文本串开始比较的位置 //Math.max(j - last[text.charAt(i)], match[j])：坏字符串，好后缀的最大值 //pattern.length()：从文本串+搜索串最后1个位置开始 i =i+ pattern.length() - j - 1 + Math.max(j - last[text.charAt(i)], match[j]); //搜索串不相同，从尾端重新开始 j = pattern.length() - 1; } } return -1; } /** * Computes the function * &lt;i&gt;last&lt;/i&gt; and stores its values in the array * &lt;code&gt;last&lt;/code&gt;. The function is defined as follows: * * &lt;pre&gt; * last(Char ch) = the index of the right-most occurrence of the character ch in the pattern; * -1 if ch does not occur in the pattern. * &lt;/pre&gt; * * The running time is O(pattern.length() + |Alphabet|). * * 存储搜索串中每个字符的位置，字符用ascii表示 * 这里字符的位置是最新比较的位置。每一个字符位置都会覆盖之前字符的位置 * 坏字符串：搜索词中的上一次出现位置，实际上就是最靠右的字符的位置，因为从后-&gt;前 * */ private void computeLast() { for (int k = 0; k &lt; last.length; k++) { last[k] = -1; } for (int j = pattern.length() - 1; j &gt;= 0; j--) { if (last[pattern.charAt(j)] &lt; 0) { last[pattern.charAt(j)] = j; } } } /** * Computes the function * &lt;i&gt;match&lt;/i&gt; and stores its values in the array * &lt;code&gt;match&lt;/code&gt;. The function is defined as follows: * * &lt;pre&gt; * match(j) = min{ s | 0 &lt; s &lt;= j &amp;&amp; p[j-s]!=p[j] * &amp;&amp; p[j-s+1]..p[m-s-1] is suffix of p[j+1]..p[m-1] }, * if such s exists, else * min{ s | j+1 &lt;= s &lt;= m * &amp;&amp; p[0]..p[m-s-1] is suffix of p[j+1]..p[m-1] }, * if such s exists, * m, otherwise, * where m is the pattern's length and p is the pattern. * &lt;/pre&gt; * * The running time is O(pattern.length()). */ private void computeMatch() { /* Phase 1 */ //条件3 for (int j = 0; j &lt; match.length; j++) { match[j] = match.length; } // O(m) computeSuffix(); // O(m) //条件1 /* Phase 2 */ // Uses an auxiliary array, backwards version of the KMP failure function. // suffix[i] = the smallest j &gt; i s.t. p[j..m-1] is a prefix of p[i..m-1], j&gt;i，好后缀在搜索串有重复的好后缀匹配 // if there is no such j, suffix[i] = m // Compute the smallest shift s, such that 0 &lt; s &lt;= j and // p[j-s]!=p[j] and p[j-s+1..m-s-1] is suffix of p[j+1..m-1] or j == m-1}, if such s exists, for (int i = 0; i &lt; match.length - 1; i++) { // suffix[i+1] &lt;= suffix[i] + 1 int j = suffix[i + 1] - 1; // therefore pattern[i] != pattern[j] if (suffix[i] &gt; j) { match[j] = j - i; } else { // j == suffix[i] match[j] = Math.min(j - i + match[i], match[j]); } } // End of Phase 2 //条件2 /* Phase 3 */ // Uses the suffix array to compute each shift s such that // p[0..m-s-1] is a suffix of p[j+1..m-1] with j &lt; s &lt; m //搜索串中的最大前缀和好后缀匹配 // and stores the minimum of this shift and the previously computed one. if (suffix[0] &lt; pattern.length()) { for (int j = suffix[0] - 1; j &gt;= 0; j--) { if (suffix[0] &lt; match[j]) { match[j] = suffix[0]; } } int j = suffix[0]; for (int k = suffix[j]; k &lt; pattern.length(); k = suffix[k]) { while (j &lt; k) { if (match[j] &gt; k){ match[j] = k; } j++; } } }// endif } /** * Computes the values of &lt;code&gt;suffix&lt;/code&gt;, * which is an auxiliary array, backwards version of the KMP failure function. &lt;br&gt; * suffix[i] = the smallest j &gt; i s.t. （j&gt;i的最小值，） * p[j..m-1] is a prefix of p[i..m-1]（后缀匹配）, if there is no such j, suffix[i] = m, i.e. &lt;br&gt; * p[suffix[i]..m-1] is the longest prefix of p[i..m-1]（）, if suffix[i] &lt; m. &lt;br&gt; * The running time for computing the &lt;code&gt;suffix&lt;/code&gt; is O(m). * * pattern中以i位置字符为后缀和以最后一个字符为后缀的公共后缀串的长度 */ private void computeSuffix() { //最后1个字符，在搜索串中的后缀匹配长度：m suffix[suffix.length - 1] = suffix.length; int j = suffix.length - 1; // suffix[i] = m - the length of the longest prefix of p[i..m-1] for (int i = suffix.length - 2; i &gt;= 0; i--) { //i：前1个字符 //j：后1个字符 //如果不匹配，说明找到最大好后缀 while (j &lt; suffix.length - 1 &amp;&amp; pattern.charAt(j) != pattern.charAt(i)) { // j = suffix[j + 1] - 1; } //如果字符匹配，继续前1个字符比较 if (pattern.charAt(j) == pattern.charAt(i)) { j--; } //i位置好后缀在搜索串中后缀匹配的最大长度 suffix[i] = j + 1; } } public static void main(String[] args) {// String text = \"here is a simple example sadasdw\";// String pattern = \"example\"; String text = \"aadqaqqcdqqasdaacbcdbccbcd\"; String pattern = \"aacbcd\"; System.out.println(new BoyerMoore3(pattern, text).match()); }} 5 代码解释坏字符定义一个bmBc数组：一个数组bmBc['k']，表示坏字符’k’在模式串中出现的位置距离模式串末尾的最大长度。这个计算应该很容易，似乎只需要bmBc[i] = m - 1 - i就行了，但这样是不对的，因为i位置处的字符可能在模式串中多处出现（如下图所示），而我们需要的是最右边的位置，这样就需要每次循环判断了，非常麻烦，性能差。这里有个小技巧，就是使用字符作为下标而不是位置数字作为下标。这样只需要遍历一遍即可，这是空间换时间的做法。条件1：字符在模式串中有出现，bmBc['v']表示字符v在模式串中最后一次出现的位置（期间有个循环），距离模式串串尾的长度，如上图所示。1234for (i = 0; i &lt; m - 1; i++){ bmBc[pattern[i]] = m - 1 - i; //bmBc['k']，表示坏字符‘k’在模式串中出现的位置距离模式串末尾的最大长度；pattern[i]:模式串单个字符； //表示:第i个字符，是坏字符，距离模式串末尾长度} 条件2：坏字符在模式串中没有出现，如模式串中没有字符v，则BmBc['v'] = strlen(pattern)。12for (i = 0; i &lt; MAX_CHAR; i++) bmBc[i] = m; //没有一个匹配，移动整个模式串 模式串实际要右移的距离就是：bmBc['v'] - m + 1 + i。 好后缀suffix的方法：定义一个suffix数组，该数组的意思是suffix[i] = s表示以i为边界的字符后缀，与模式串后缀匹配的最大长度。（pattern中以i位置字符为后缀和以最后一个字符为后缀的公共后缀串的长度）定义bmGs[]数组:bmGs[i]表示遇到好后缀时，模式串应该移动的距离，其中i表示好后缀前面一个字符的位置。条件1：模式串中有子串匹配上好后缀或者12345//条件1 for (i = 0; i &lt;= m - 2; i++){ //在位置：m - 1 - suff[i]，需要移动的距离：m-1-i bmGs[m - 1 - suff[i]] = m - 1 - i; //从前往后搜索匹配的模式串，i为好后缀边界的字符 } 条件2：模式串中没有子串匹配上好后缀，但找到一个最大前缀或者1234567891011121314151617181920 //条件2：模式串有前缀字符串匹配 //好后缀的前一个字符串标记位j = 0; //i:从尾部往前比较for (i = m - 1; i &gt;= 0; i--) { //i等于其最大匹配长度，说明：i是在模式串的匹配位置上 // if (i + 1 == suff[i]) { //j从前往后比较，从空白部分（如图）开始++ for (;j &lt; m - 1 - i; j++) { // if (m == bmGs[j]){ bmGs[j] = m - 1 - i;//假设j是在de后面的位置，也就是位置2，如果在位置2，de需要往后移动18，才能和de相匹配。所以则由：m-1-i } } } } 条件3：模式串中没有子串匹配上好后缀或者1234//条件3,每一个字符都是移动m的距离for (i = 0; i &lt; m; i++){ bmGs[i] = m; //每个字符的最好后缀都是移动整个模式串} 改进suff方法i：是当前正准备计算suff[]值的那个位置。（开始匹配的位置）f：是上一个成功进行匹配的起始位置。（不是每个位置都能进行成功匹配的， 实际上能够进行成功匹配的位置并不多）g：是上一次进行成功匹配的失配位置。如果i在g和f之间，那么一定有P[i]=P[m-1-f+i]（改进在此处）；并且如果suff[m-1-f+i] &lt; i-g, 则suff[i] = suff[m-1-f+i]，这不就利用了前面的suff了吗。PS：这里有些人可能觉得应该是suff[m-1-f+i] &lt;= i – g，因为若suff[m-1-f+i] = i – g，还是没超过suff[f]的范围，依然可以利用前面的suff[]，但这是错误的，比如一个极端的例子。12i ：0 1 2 3 4 5 6 7 8 9pattern：a a a a a b a a a a suff[4] = 4，这里f=4,g=0，当i=3是，这时suff[m-1=f+i]=suff[8]=3，而suff[3]=4，两者不相等，因为上一次的失配位置g可能会在这次得到匹配。suff[]与模式串后缀匹配的最大长度。g&lt;i&lt;f,P[i]=P[m-1-f+i]，这是相等的。比如：以最后一个字符开始，f=m-1。如果是以前半段那个字符开始。m-1-f截取中间一半，然后+i，则到下半部分，下半部分的i和上半部分的i是同一个字符。suff[m-1-f+i] &lt; i-g，相当于i在偏f方向。 suff数组在计算bmGc数组时，为提高效率，先计算辅助数组suff[]表示好后缀的长度。suff数组的定义：m是pattern的长度。123a. suffix[m-1] = m;b. suffix[i] = kfor [ pattern[i-k+1] ….,pattern[i]] == [pattern[m-1-k+1]，pattern[m-1]] 看上去有些晦涩难懂，实际上suff[i]就是求：pattern中以i位置字符为后缀和以最后一个字符为后缀的公共后缀串的长度。不知道这样说清楚了没有，还是举个例子吧。 i : 0 1 2 3 4 5 6 7 pattern: b c a b a b a b 当i=7时，按定义suff[7] = strlen(pattern) = 8。当i=6时，以pattern[6]为后缀的后缀串为bcababa，以最后一个字符b为后缀的后缀串为bcababab，两者没有公共后缀串，所以suff[6] = 0。当i=5时，以pattern[5]为后缀的后缀串为bcabab，以最后一个字符b为后缀的后缀串为bcababab，两者的公共后缀串为abab，所以suff[5] = 4。以此类推……当i=0时，以pattern[0]为后缀的后缀串为b，以最后一个字符b为后缀的后缀串为bcababab，两者的公共后缀串为b，所以suff[0] = 1。","link":"/Boyer-Moore/"},{"title":"动态规划算法","text":"1 引言 2 概念 多阶段决策问题 3 基本思想 4 特性 5 步骤 6 实现问题 1 引言在现实生活中，有一类活动的过程，由于它的特殊性，可将过程分成若干个互相联系的阶段，在它的每一阶段都需要作出决策，从而使整个过程达到最好的活动效果。当然，各个阶段决策的选取不是任意确定的，它依赖于当前面临的状态，又影响以后的发展，当各个阶段决策确定后，就组成一个决策序列，因而也就确定了整个过程的一条活动路线。这种把一个问题看作是一个前后关联具有链状结构的多阶段过程就称为多阶段决策过程，这种问题就称为多阶段决策问题。多阶段决策问题中，各个阶段采取的决策，一般来说是与时间有关的，决策依赖于当前状态，又随即引起状态的转移，一个决策序列就是在变化的状态中产生出来的，故有“动态”的含义，称这种解决多阶段决策最优化问题的方法为动态规划方法。 2 概念动态规划主要用于求解以时间划分阶段的动态过程的优化问题，但是一些与时间无关的静态规划(如线性规划、非线性规划)，只要人为地引进时间因素，把它视为多阶段决策过程，也可以用动态规划方法方便地求解。动态规划程序设计是对解最优化问题的一种途径、一种方法，而不是一种特殊算法。不像搜索或数值计算那样，具有一个标准的数学表达式和明确清晰的解题方法。动态规划程序设计往往是针对一种最优化问题，由于各种问题的性质不同，确定最优解的条件也互不相同，因而动态规划的设计方法对不同的问题，有各具特色的解题方法，而不存在一种万能的动态规划算法，可以解决各类最优化问题。因此在学习时，除了要对基本概念和方法正确理解外，必须具体问题具体分析处理，以丰富的想象力去建立模型，用创造性的技巧去求解。我们也可以通过对若干有代表性的问题的动态规划算法进行分析、讨论，逐渐学会并掌握这一设计方法。 多阶段决策问题如果一类活动过程可以分为若干个互相联系的阶段，在每一个阶段都需作出决策(采取措施)，一个阶段的决策确定以后，常常影响到下一个阶段的决策，从而就完全确定了一个过程的活动路线，则称它为多阶段决策问题。各个阶段的决策构成一个决策序列，称为一个策略。每一个阶段都有若干个决策可供选择，因而就有许多策略供我们选取，对应于一个策略可以确定活动的效果，这个效果可以用数量来确定。策略不同，效果也不同，多阶段决策问题，就是要在可以选择的那些策略中间，选取一个最优策略，使在预定的标准下达到最好的效果。 3 基本思想动态规划算法通常用于求解具有某种最优性质的问题。在这类问题中，可能会有许多可行解。每一个解都对应于一个值，我们希望找到具有最优值的解。最优值可能会有多个，动态规划算法能找到其中一个最优解。动态规划算法与分治法类似，其基本思想也是将待求解问题分解成若干个子问题，先求解子问题，然后从这些子问题的解得到原问题的解。与分治法不同的是，适合于用动态规划求解的问题，经分解得到子问题往往不是互相独立的。若用分治法来解这类问题，则分解得到的子问题数目太多，有些子问题被重复计算了很多次。如果我们能够保存已解决的子问题的答案，而在需要时再找出已求得的答案，这样就可以避免大量的重复计算，节省时间。我们可以用一个表来记录所有已解的子问题的答案。不管该子问题以后是否被用到，只要它被计算过，就将其结果填入表中。这就是动态规划法的基本思路。具体的动态规划算法多种多样，但它们具有相同的填表格式。 4 特性任何思想方法都有一定的局限性，超出了特定条件，它就失去了作用。同样，动态规划也并不是万能的。适用动态规划的问题必须满足最优化原理和无后效性。最优化原理（最优子结构性质） 最优化原理可这样阐述： 一个最优化策略具有这样的性质，不论过去状态和决策如何，对前面的决策所形成的状态而言，余下的诸决策必须构成最优策略。简而言之，一个最优化策略的子策略总是最优的（一个问题的最优解中包含其子问题的最优解）。一个问题满足最优化原理又称其具有最优子结构性质。当一个问题具有最优子结构的时候，动态规划法可能会适用，贪心算法也适用。无后效性： 将各阶段按照一定的次序排列好之后，对于某个给定的阶段状态，它以前各阶段的状态无法直接影响它未来的决策，而只能通过当前的这个状态。换句话说，每个状态都是过去历史的一个完整总结。这就是无后向性，又称为无后效性。子问题的重叠性： 动态规划将原来具有指数级时间复杂度的搜索算法改进成了具有多项式时间复杂度的算法。其中的关键在于解决冗余，这是动态规划算法的根本目的。用来解决原问题的递归算法可反复地解同样的子问题，而动态规划实质上是一种以空间换时间的技术，它在实现的过程中，不得不存储产生过程中的各种状态，所以它的空间复杂度要大于其它的算法。 5 步骤动态规划的基本模型如下： 确定问题的决策对象。 对决策过程划分阶段。 对各阶段确定状态变量。 根据状态变量确定目标函数。 建立各阶段状态变量的转移过程，确定状态转移方程。 动态规划算法通常基于一个递推公式及一个或多个初始状态。 当前子问题的解将由上一次子问题的解推出。我们要找到某个状态的最优解，然后在它的帮助下，找到下一个状态的最优解。动态规划里非常重要的两个概念：状态和状态转移方程状态：用来描述该问题的子问题的解。状态转移方程的一般形式：一般形式： U：状态； X：策略顺推： f[Uk]=opt{f[Uk-1]+L[Uk-1,Xk-1]} 其中， L[Uk-1,Xk-1]： 状态Uk-1通过策略Xk-1到达状态Uk 的费用初始f[U1]；结果：f[Un]。倒推： f[Uk]=opt{f[Uk+1]+L[Uk,Xk]}L[Uk,Xk]：状态Uk通过策略Xk到达状态Uk+1的费用初始f[Un]；结果：f(U1) 6 实现问题算法实现是比较好考虑的。但有时也会遇到一些问题，而使算法难以实现。动态规划思想设计的算法从整体上来看基本都是按照得出的递推关系式进行递推，这种递推相对于计算机来说，只要设计得当，效率往往是比较高的，这样在时间上溢出的可能性不大，而相反地，动态规划需要很大的空间以存储中间产生的结果，这样可以使包含同一个子问题的所有问题共用一个子问题解，从而体现动态规划的优越性，但这是以牺牲空间为代价的，为了有效地访问已有结果，数据也不易压缩存储，因而空间矛盾是比较突出的。另一方面，动态规划的高时效性往往要通过大的测试数据体现出来（以与搜索作比较），因而，对于大规模的问题如何在基本不影响运行速度的条件下，解决空间溢出的问题，是动态规划解决问题时一个普遍会遇到的问题。一个思考方向是尽可能少占用空间。如从结点的数据结构上考虑，仅仅存储必不可少的内容，以及数据存储范围上精打细算(按位存储、压缩存储等)。当然这要因问题而异，进行分析。另外，在实现动态规划时，一个我们经常采用的方法是用一个与结点数一样多的数组来存储每一步的决策，这对于倒推求得一种实现最优解的方法是十分方便的，而且处理速度也有一些提高。但是在内存空间紧张的情况下，我们就应该抓住问题的主要矛盾。省去这个存储决策的数组，而改成在从最优解逐级倒推时，再计算一次，选择某个可能达到这个值的上一阶段的状态，直到推出结果为止。这样做，在程序编写上比上一种做法稍微多花一点时间，运行的时效也可能会有一些(但往往很小)的下降，但却换来了很多的空间。因而这种思想在处理某些问题时，是很有意义的。但有时，即使采用这样的方法也会发现空间溢出的问题。这时就要分析，这些保留下来的数据是否有必要同时存在于内存之中。因为有很多问题，动态规划递推在处理后面的内容时，前面比较远处的内容实际上是用不着的。对于这类问题，在已经确信不会再被使用的数据上覆盖数据，从而使空间得以重复利用，如果能有效地使用这一手段，对于相当大规模的问题，空间也不至于溢出（为了求出最优方案，保留每一步的决策仍是必要的，这同样需要空间）。一般地说，这种方法可以通过两种思路来实现：一种是递推结果仅使用Data1和Data2这样两个数组，每次将Data1作为上一阶段，推得Data2数组，然后，将Data2通过复制覆盖到Data1之上，如此反复，即可推得最终结果。这种做法有一个局限性，就是对于递推与前面若干阶段相关的问题，这种做法就比较麻烦；而且，每递推一级，就需要复制很多的内容，与前面多个阶段相关的问题影响更大。另外一种实现方法是，对于一个可能与前N个阶段相关的问题，建立数组Data[0..N]，其中各项为前面N个阶段的保存数据。这样不采用这种内存节约方式时对于阶段k的访问只要对应成对数组Data中下标为k mod (N+1)的单元的访问就可以了。这种处理方法对于程序修改的代码很少，速度几乎不受影响，而且需要保留不同的阶段数也都能很容易实现。当采用以上方法仍无法解决内存问题时，也可以采用对内存的动态申请来使绝大多数情况能有效出解。而且，使用动态内存还有一点好处，就是在重复使用内存而进行交换时，可以只对指针进行交换，而不复制数据，这在实践中也是十分有效的。","link":"/Dynamic-Programming-Algorithm/"},{"title":"第57条-只针对异常的情况才使用异常","text":"第57条、只针对异常的情况才使用异常 总结 第58条、对可恢复的异常使用检测性异常，对编程错误使用运行时异常 受检异常 运行时异常 错误 总结 第59条、避免不必要地使用检测性异常 总结 第60条、优先使用标准的异常 总结 第61条、抛出与抽象相对应的异常 总结 第62条、每个方法抛出的异常都要有文档 第63条、在细节消息中包含能捕获失败的信息 总结 第64条、努力使失败保持原子性 总结 第65条、不要忽略异常 总结 第57条、只针对异常的情况才使用异常不知道你否则遇见过下面的代码。123456try { int i = 0;3 while (true) range[i++].climb();}catch (ArrayIndexOutOfBoundsException e) {} 这段代码的意图不是很明显，其本意就是遍历变量range[]中的每一个元素，并执行元素的climb()，当下标超出range[]的长度时，将会直接抛出ArrayIndexOutOfBoundsException异常，catch代码块将会捕获到该异常，但是未作任何处理，只是将该错误视为正常工作流程的一部分来看待。这样的写法确实给人一种匪夷所思的感觉，让我们再来看一下修改后的写法。123for (Mountain m : range) { m.climb(); } 和之前的写法相比其可读性不言而喻。那么为什么又有人会用第一种写法呢？显然他们是被误导了，他们企图避免for-each循环中JVM对每次数组访问都要进行的越界检查。这无疑是多余的，甚至适得其反，因为将代码放在try-catch块中反而阻止了JVM的某些特定优化，至于数组的边界检查，现在很多JVM实现都会将他们优化掉了。在实际的测试中，我们会发现采用异常的方式其运行效率要比正常的方式慢很多。除了刚刚提到的效率和代码可读性问题，第一种写法还会掩盖一些潜在的Bug，假设数组元素的climb()中也会访问某一数组，并且在访问的过程中出现了数组越界的问题，基于该错误，JVM将会抛出ArrayIndexOutOfBoundsException异常，不幸的是，该异常将会被climb()之外catch语句捕获，在未做任何处理之后，就按照正常流程继续执行了，这样Bug也就此被隐藏起来。这个例子的教训很简单：”异常应该只用于异常的情况下，它们永远不应该用于正常的控制流”。虽然有的时候有人会说这种怪异的写法可以带来性能上的提升，即便如此，随着平台实现的不断改进，这种异常模式的性能优势也不可能一直保持。然而，这种过度聪明的模式带来的微妙的Bug，以及维护的痛苦却依然存在。根据这条原则，我们在设计API的时候也是会有所启发的。设计良好的API不应该为了正常的控制流而使用异常。如Iterator，JDK在设计时充分考虑到这一点，客户端在执行next()之前，需要先调用hasNext()已确认是否还有可读的集合元素，见如下代码。123for (Iterator i = collection.iterator(); i.hasNext(); ) { Foo f = i.next();} 如果Iterator缺少hasNext()，改为下面的写法。123456try { Iterator i = collection.iterator(); while (true) Foo f = i.next(); }catch (NoSuchElementException e) { } 这应该非常类似于本条目开始时给出的遍历数组的例子。在实际的设计中，还有另外一种方式，即验证可识别的错误返回值，然而该方式并不适合于此例，因为对于next()，返回null可能是合法的。那么这两种设计方式在实际应用中有哪些区别呢？ 如果是缺少同步的并发访问，或者可被外界改变状态，使用可识别返回值的方法是非常必要的，因为在测试状态(hasNext())和对应的调用(next())之间存在一个时间窗口，在该窗口中，对象可能会发生状态的变化。因此，在该种情况下应选择返回可识别的错误返回值的方式。 如果状态测试方法(hasNext())和相应的调用方法(next())使用的是相同的代码，出于性能上的考虑，没有必要重复两次相同的工作，此时应该选择返回可识别的错误返回值的方式。 对于其他情形则应该尽可能考虑”状态测试”的设计方式，因为它可以带来更好的可读性。总结需要异常的地方才使用异常，不能使用异常去控制正常的业务流程。 第58条、对可恢复的异常使用检测性异常，对编程错误使用运行时异常Java中提供了三种可抛出结构：受检异常、运行时异常和错误。该条目针对这三种类型适用的场景给出了一般性原则。受检异常如果期望调用者能够适当地恢复，对于这种情况就应该使用受检异常，如某人打算网上购物，结果余额不足，此时可以抛出自定义的受检异常。通过抛出受检异常，调用者在catch子句中处理该异常，或继续向上传播。因此，在方法中声明受检异常，是对API用户的一种潜在提示。 运行时异常用运行时异常来表明编程错误。大多数的运行时异常都表示”前提违例”，即API的使用者没有遵守API设计者建立的使用约定。如数组访问越界等问题。不可修复的异常，由编程错误引起。 错误对于错误而言，通常是被JVM保留用于表示资源不足、约束失败，或者其他使程序无法继续执行的条件。针对自定义的受检异常，该条目还给出一个非常实用的技巧，当调用者捕获到该异常时，可以通过调用该自定义异常提供的接口方法，获取更为具体的错误信息，如当前余额等信息。 总结非检测性异常，错误使用try...catch捕获，会保证程序正常运行，但是数据会错误，所以try...catch意义不大。在web项目和thread项目可以使用throws上一层或者捕获未检测性异常来打印异常log信息。 第59条、避免不必要地使用检测性异常受检异常是Java提供的一个很好的特征。与返回值不同，它们使程序员必须处理异常的条件，从而大大增强了程序的可靠性。然而，如果过分使用受检异常则会使API在使用时非常不方便，毕竟我们还是需要用一些额外的代码来处理这些抛出的异常，倘若在一个函数中，它所调用的五个API都会抛出异常，那么编写这样的函数代码将会是一项令人沮丧的工作。如果正确的使用API不能阻止这种异常条件的产生，并且一旦产生异常，使用API的程序员可以立即采用有用的动作，这种负担就被认为是正当的。除非这两个条件都成立，否则更适合使用未受检异常，见如下测试。1234567891011121314(1) try { dosomething(); }catch (TheCheckedException e) { throw new AssertionError(); } (2) try { donsomething(); }catch (TheCheckedException e) { e.printStackTrace(); System.exit(1); } 当我们使用受检异常时，如果在catch子句中对异常的处理方式仅仅如以上两个示例，或者还不如它们的话，那么建议你考虑使用未受检异常。原因很简单，它们在catch子句中，没有做出任何用于恢复异常的动作。 总结检测性的异常，如果在catch中未有修复动作，可以考虑使用throws或者非检测性异常（运行时异常）。 第60条、优先使用标准的异常使用标准异常，不仅可以更好的复用已有的代码，同时也使你设计的API更加容易学习和使用，因为它和程序员已经熟悉的习惯用法更为一致。另外一个优势是，代码的可读性更好，程序员在阅读时不会出现更多的不熟悉的代码。该条目给出了一些非常常用且容易被复用的异常，见下表。 | 异常 | 应用场合-|—-|—– | IllegalArgumentException | 非null的参数值不正确。 | IllegalStateException | 对于方法调用而言，对象状态不合适。 | NullPointerException | 在禁止使用null的情况下参数值为null。 | IndexOutOfBoundsException | 下标参数值越界 | ConcurrentModificationException | 在禁止并发修改的情况下，检测到对象的并发修改。 | UnsupportedOperationException | 对象不支持用户请求的方法。当然在Java中还存在很多其他的异常，如ArithmeticException、NumberFormatException等，这些异常均有各自的应用场合，然而需要说明的是，这些异常的应用场合在有的时候界限不是非常分明，至于该选择哪个比较合适，则更多的需要依赖上下文环境去判断。最后需要强调的是，一定要确保抛出异常的条件和该异常文档中描述的条件保持一致。 总结优先使用类库的异常 第61条、抛出与抽象相对应的异常如果方法抛出的异常与它所执行的任务没有明显的关系，这种情形将会使人不知所措。特别是当异常从底层开始抛出时，如果在中间层没有做任何处理，这样底层的实现细节将会直接污染高层的API接口。为了解决这样的问题，我们通常会做出如下处理。12345try { doLowerLeverThings();} catch (LowerLevelException e) { throw new HigherLevelException(...);} 这种处理方式被称为异常转译。事实上，在Java中还提供了一种更为方便的转译形式–异常链。试想一下上面的示例代码，在调试阶段，如果高层应用逻辑可以获悉到底层实际产生异常的原因，那么对找到问题的根源将会是非常有帮助的，见如下代码。12345try { doLowerLevelThings();} catch (LowerLevelException cause) { throw new HigherLevelException(cause);} 底层异常作为参数传递给了高层异常，对于大多数标准异常都支持异常链的构造器，如果没有，可以利用Throwable#initCause()设置原因。异常链不仅让你可以通过接口函数getCause()访问原因，它还可以将原因的堆栈轨迹集成到更高层的异常中。通过这种异常链的方式，可以非常有效的将底层实现细节与高层应用逻辑彻底分离出来。 总结异常链是栈结构，先进后出。异常的构造方法里有保存当前异常的Throwable对象，new MyException(&quot;文件没有找到--02&quot;,e);如果没有此构造方法，可以使用initCause()保存异常信息。异常转义是把异常信息转义为用户或者其他人看得懂的异常。 第62条、每个方法抛出的异常都要有文档第63条、在细节消息中包含能捕获失败的信息当程序由于未被捕获的异常而失败的时候，系统会自动地打印出该异常的堆栈轨迹。在堆栈轨迹中包含该异常的字符串表示法，即toString()的返回结果。如果我们在此时为该异常提供了详细的出错信息，那么对于错误定位和追根溯源都是极其有意义的。比如，我们将抛出异常的函数的输入参数和函数所在类的域字段值等信息格式化后，再打包传递给待抛出的异常对象。假设我们的高层应用捕捉到IndexOutOfBoundsException异常，如果此时该异常对象能够携带数组的下界和上界，以及当前越界的下标值等信息，在看到这些信息后，我们就能很快做出正确的判断并修订该Bug。特别是对于受检异常，如果抛出的异常类型还能提供一些额外的接口方法用于获取导致错误的数据或信息，这对于捕获异常的调用函数进行错误恢复是非常重要的。 总结异常打印信息需要补全，包括业务信息，方便程序员进行Bug跟踪。 第64条、努力使失败保持原子性这是一个非常重要的建议，因为在实际开发中当你是接口的开发者时，经常会忽视他，认为不保证的话估计也没有问题。相反，如果你是接口的使用者，也同样会忽略他，会认为这个是接口实现者理所应当完成的事情。当对象抛出异常之后，通常我们期望这个对象仍然保持在一种定义良好的可用状态之中，即使失败是发生在执行某个操作的过程中间。对于受检异常而言，这尤为重要，因为调用者希望能从这种异常中进行恢复。一般而言，失败的方法调用应该使对象保持在被调用之前的状态。具有这种属性的方法被称为具有”失败原子性”。有以下几种途径可以保持这种原子性。 最简单的方法是设计不可变对象。因为失败的操作只会导致新对象的创建失败，而不会影响已有的对象。 对于可变对象，一般方法是在操作该对象之前先进行参数的有效性验证，这可以使对象在被修改之前，抛出更为有意义的异常。如果没有在操作之前验证size，elements的数组也会抛出异常，但是由于size的值已经发生了变化，之后再继续使用该对象时将永远无法恢复到正常状态了。 1234567public Object pop() { if (size == 0) throw new EmptyStackException(); Object result = elements[--size]; elements[size] = null; return result;} 预先写好恢复性代码，在出现错误时执行带段代码，由于此方法在代码编写和代码维护的过程中，均会带来很大的维护开销，再加之效率相对较低，因此很少会使用该方法。 为该对象创建一个临时的copy，一旦操作过程中出现异常，就用该复制对象重新初始化当前的对象的状态。 虽然在一般情况下都希望实现失败原子性，然而在有些情况下却是难以做到的，如两个线程同时修改一个可变对象，在没有很好同步的情况下，一旦抛出ConcurrentModificationException异常之后，就很难在恢复到原有状态了。 总结发生异常时，对象的状态需要恢复到之前的状态，以保证对象的一致性，可靠性，可以使用final。 第65条、不要忽略异常这是一个显而易见的常识，但是经常会被违反，因此该条目重新提出了它。1234try { dosomething();} catch (SomeException e) {} 可预见的、可以使用忽略异常的情形是在关闭FileInputStream的时候，因为此时数据已经读取完毕。即便如此，如果在捕获到该异常时输出一条提示信息，这对于挖出一些潜在的问题也是非常有帮助的。否则一些潜在的问题将会一直隐藏下去，直到某一时刻突然爆发，以致造成难以弥补的后果。该条目中的建议同样适用于受检异常和未受检的异常。 总结catch内容空，很容易忽略非检测性异常，不建议忽略catch内容，可以使用log打印信息。","link":"/Exception/"},{"title":"寻找数组中值最大的k个数","text":"1 题目描述 2 解法 解法1 解法2 解法3 解法4:如果N非常非常大 解法5 3 网络上其他文章 4 参考 1 题目描述有很多个无序的数，怎么选出其中最大的若干个数？即，从n个数中选出最大的K个数。 2 解法解法1先假设元素的数量不大，例如在几千个左右，在这种情况下，我们就排序吧。在这里，快速排序或堆排序都是不错的选择，他们的平均时间复杂度都是$O(n\\log_2n)$，然后取出前K个，O(K)。总的时间复杂度仍然是$O(n\\log_2n)$。可以注意到，即便是K=1的情况，上面的算法复杂度仍然是$O(n\\log_2n)$，而显然，我们可以通过n-1此的比较和交换得到结果，不需要对整个数组进行排序。要避免做后面n-K个数的排序，可以使用部分排序算法，选择排序和冒泡排序都是不错的选择。把n个数中的前K个数排序出来，复杂度是O(n*K)。哪一个更好呢？$O(n\\log_2n)$和O(n*K)？这取决于K的大小，在K&lt;$\\log_2n$的情况下，可以选择部分排序。 解法2回忆一下快速排序，快排中的每一步，都是将数据分为两组，其中一组的任何数都小于另一组中的任何数，不断地对数据进行分割直到不能再分即完成排序。假设n个数存储在数组S中，从S中找出一个元素X，它把数组分为比它大的和比它小的两部分，假设比它大的一部分数组是$S_{max}$，比它小的部分是$S_{min}$。这时有两种可能： $S_{max}$中元素不足K个，说明$S_{max}$中的所有数和$S_{min}$中最大的K-|$S_{max}$|个元素就是数组S中最大的K个数； $S_{max}$中元素的个数大于或等于K，则需要返回$S_{max}$中最大的K个元素。 这样递归下去，问题的规模不断地变小，平均时间复杂度O(n * $\\log_2K$)。 解法3寻找n个数中最大的K个数，本质上就是寻找这K个数中最小的那个，也就是第K大的数。可以使用二分搜索的策略。对于一个给定的数p，可以在O(n)的时间复杂度内找出所有不小于p的数。（此方法详述部分略）。 解法4:如果N非常非常大前面三个解法都需要对数据访问多次，如果n很大呢？100亿？这个时候数据不能全部装入内存，所以要求尽可能少地遍历所有数据。前K个数中最大的K个数是一个退化的情况，所有K个数就是最大的K个数，如果考虑第K+1个数，则它和前面K个数的最小值进行比较，比其大则替换它。如果用一个数组来存储最大的K个数，每加入一个数X，就扫描一遍数组，得到数组中最小的数Y。X和Y进行比较，替换它或者保持原数组不变。这种方法，所耗费的时间复杂度为O(n * K)。进一步，可以用容量为K的最小堆来存储最大的K个数。最小堆的堆顶元素就是最大K个数中最小的一个。每次新考虑一个数X，如果X小于堆顶则舍弃，如果X大于堆顶，那么用X替换堆顶，然后更新堆来维持堆的性质。（因为X可能并不是最小值，所以堆结构需要更新）。更新过程花费的时间复杂度为$O(\\log_2K)$。因此，算法的时间复杂度为$O(n * \\log_2K)$，这实际上是部分执行了堆排序的算法。 解法5如果所有n个数都是整数，且它们的取值范围不太大，可以考虑申请空间，记录每个整数出现的次数，然后再从大到小取最大的K个。比如用数组count，count[i]表示整数i出现的次数。极端情况下，如果n个整数各不相同，只需要一个bit来存储这个整数是否存在。实际情况下，并不一定能保证所有元素都是正整数，且取值范围不太大。但是这种方法仍然可以推广适用。比如把取值区间分成多块，然后统计各个小区间中元素的个数。可以知道第K大的元素在哪一个小区间，然后再对那个小区间继续进行分块处理。 3 网络上其他文章名称是：设计一组N个数，确定其中第k个最大值，这是一个选择问题，当然，解决这个问题的方法很多，本人在网上搜索了一番，查找到以下的方式，决定很好，推荐给大家。所谓“第（前）k大数问题”指的是在长度为n(n&gt;=k)的乱序数组中S找出从大到小顺序的第（前）k个数的问题。解法1：我们可以对这个乱序数组按照从大到小先行排序，然后取出前k大，总的时间复杂度为O(n*logn + k)。解法2：利用选择排序或交互排序，K次选择后即可得到第k大的数。总的时间复杂度为O(n*k)。解法3：利用快速排序的思想，从数组S中随机找出一个元素X，把数组分为两部分$S_a$和$S_b$。$S_a$中的元素大于等于X，$S_b$中元素小于X。这时有两种情况： $S_a$中元素的个数小于k，则Sb中的第k-|$S_a$|个元素即为第k大数。 $S_a$中元素的个数大于等于k，则返回$S_a$中的第k大数。时间复杂度近似为O(n)。 解法4： 二分[$S_{min}$,$S_{max}$]查找结果X，统计X在数组中出现，且整个数组中比X大的数目为k-1的数即为第k大数。时间复杂度平均情况为O(n*logn)。解法5：用O(4*n)的方法对原数组建最大堆，然后pop出k次即可。时间复杂度为O(4*n + k*logn)。解法6：维护一个k大小的最小堆，对于数组中的每一个元素判断与堆顶的大小，若堆顶较大，则不管，否则，弹出堆顶，将当前值插入到堆中。时间复杂度O(n*logk)。解法7：利用hash保存数组中元素$S_i$出现的次数，利用计数排序的思想，线性从大到小扫描过程中，前面有k-1个数则为第k大数，平均情况下时间复杂度O(n)。附注： STL中可以用nth_element求得类似的第n大的数（由谓词决定），使用的是解法3中的思想，还可以用partial_sort对区间进行部分排序，得到类似前k大的数（由谓词决定），它采用的是解法5的思想。 求中位数实际上是第k大数的特例。 《编程之美》2.5节课后习题： 如果需要找出N个数中最大的K个不同的浮点数呢？比如，含有10个浮点数的数组（1.5，1.5，2.5，3.5，3.5，5，0，- 1.5，3.5）中最大的3个不同的浮点数是（5，3.5，2.5）。 解答： 上面的解法均适用，需要注意的是浮点数比较时和整数不同，另外求hashkey的方法也会略有不同。 如果是找第k到第m（0&lt;k&lt;=m&lt;=n)大的数呢？ 解答： 如果把问题看做m-k+1个第k大问题，则前面解法均适用。但是对于类似前k大这样的问题，最好使用解法5或者解法7，总体复杂度较低。 在搜索引擎中，网络上的每个网页都有“权威性”权重，如page rank。如果我们需要寻找权重最大的K个网页，而网页的权重会不断地更新，那么算法要如何变动以达到快速更新（incremental update）并及时返回权重最大的K个网页？ 提示： 堆排序？当每一个网页权重更新的时候，更新堆。还有更好的方法吗？解答： 要达到快速的更新，我们可以解法5，使用映射二分堆，可以使更新的操作达到O(logn) 在实际应用中，还有一个“精确度”的问题。我们可能并不需要返回严格意义上的最大的K个元素，在边界位置允许出现一些误差。当用户输入一个query的时候，对于每一个文档d来说，它跟这个query之间都有一个相关性衡量权重f(query, d)。搜索引擎需要返回给用户的就是相关性权重最大的K个网页。如果每页10个网页，用户不会关心第1000页开外搜索结果的“精确度”，稍有误差是可以接受的。比如我们可以返回相关性第10001大的网页，而不是第9999大的。在这种情况下，算法该如何改进才能更快更有效率呢？网页的数目可能大到一台机器无法容纳得下，这时怎么办呢？ 提示： 归并排序？如果每台机器都返回最相关的K个文档，那么所有机器上最相关K个文档的并集肯定包含全集中最相关的K个文档。由于边界情况并不需要非常精确，如果每台机器返回最好的K个文档，那么K应该如何取值，以达到我们返回最相关的90%*K个文档是完全精确的，或者最终返回的最相关的K个文档精确度超过90%（最相关的K个文档中90%以上在全集中相关性的确排在前K），或者最终返回的最相关的K个文档最差的相关性排序没有超出110%*K。 解答： 正如提示中所说，可以让每台机器返回最相关的K个文档，然后利用归并排序的思想，得到所有文档中最相关的K个。 最好的情况是这K个文档在所有机器中平均分布，这时每台机器只要K = K / n（n为所有机器总数）；最坏情况，所有最相关的K个文档只出现在其中的某一台机器上，这时K需近似等于K了。我觉得比较好的做法可以在每台机器上维护一个堆，然后对堆顶元素实行归并排序。 如第4点所说，对于每个文档d，相对于不同的关键字q1, q2, …, qm，分别有相关性权重f(d, q1)，f(d, q2), …, f(d, qm)。如果用户输入关键字qi之后，我们已经获得了最相关的K个文档，而已知关键字qj跟关键字qi相似，文档跟这两个关键字的权重大小比较靠近，那么关键字qi的最相关的K个文档，对寻找qj最相关的K个文档有没有帮助呢？ 解答： 肯定是有帮助的。在搜索关键字qj最相关的K个文档时，可以在qj的“近义词”相关文档中搜索部分，然后在全局的所有文档中在搜索部分。 4 参考寻找最大的K个数","link":"/Find-The-K-Number-With-The-Largest-Value/"},{"title":"八皇后(回溯算法)","text":"1 概述 2 解题思路 解题思路 3 程序代码 代码1 代码2 代码3 代码4 代码5 代码6 1 概述八皇后问题，是一个古老而著名的问题，是回溯算法的典型案例。该问题是国际西洋棋棋手马克斯·贝瑟尔于1848年提出：在8×8格的国际象棋上摆放八个皇后，使其不能互相攻击，即任意两个皇后都不能处于同一行、同一列或同一斜线上（反斜线），问有多少种摆法。 高斯认为有76种方案。1854年在柏林的象棋杂志上不同的作者发表了40种不同的解，后来有人用图论的方法解出92种结果。计算机发明后，有多种计算机语言可以解决此问题。八皇后问题是一个以国际象棋为背景的问题：如何能够在 8×8 的国际象棋棋盘上放置八个皇后，使得任何一个皇后都无法直接吃掉其他的皇后？为了达到此目的，任两个皇后都不能处于同一条横行、纵行或斜线上。八皇后问题可以推广为更一般的n皇后摆放问题：这时棋盘的大小变为n × n，而皇后个数也变成n。当且仅当n = 1或n ≥ 4时问题有解。 2 解题思路可归纳问题的条件为，8皇后之间需满足： 不在同一行上 不在同一列上 不在同一斜线上 不在同一反斜线上解题思路 从第一行第一列开始逐行摆放棋子，找到符合条件的位置放置棋子。 接着就到下一行遍历下一个棋子的合适位置，遍历过程中有一个条件是绝对符合的——就是下一个棋子摆放位置与前面的棋子不在同一行。 在当前行，遍历列。判断当前位置是否符合棋子的条件，如果符合条件，则到下一行，继续寻找棋子合适的位置；如果不符合，则同行下一列继续判断，直到最后一列。 如果一个行的所有位置都不合适，就返回上一行，清除上一行的摆放记录，并且继续该行的其他位置遍历，尝试摆放下一位置的皇后（回溯算法的核心），当我们顺利遍历到最后一行，且有符合条件的位置时，就是一个可行的8皇后摆放方案，累加1次八皇后可行方案的个数。 然后继续遍历该行（因为递归函数，前面的行并没有改变，递归是从最后函数开始，所以前面行数据没有变化，最后一行重新遍历，寻找皇后的位置）其他位置是否有合适的，如果没有，则返回上一行，清除上一行的摆放记录，遍历该行其他位置，依此下去。 这样一个过程下来，我们就可以得出所有符合条件的8皇后摆放方案了。这是一个深度优先遍历的过程，同时也是经典的递归思路。3 程序代码程序代码分2类：代码1和代码2。 代码1使用：回溯算法，递归算法。时间：耗时【15豪秒】。截图：queen[]存：y行x列，皇后的位置。 1231 2 31 2 31 2 3 左下-&gt;右上：(1，1)，(2，2)，(3，3)左上-&gt;右下：(3，1)，(2，2)，(1，3)左下-&gt;右上：任意2点都满足i1-i2=j1-j2，演变i1-j1=i2-j2左上-&gt;右下：任意2点(i1，j1)和(i2，j2)都满足i1+j1=i2+j2 则定义对角线2个数组：rup = new int[(2 * 8) + 1]; i+j,这i属于(1-8),j属于(1-8),i+j范围(1-16)lup = new int[(2 * 8) + 1]; i-j,这为了避免出现负数，程序里在这里+8。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116package demo1;/** * 百度百科-八皇后 * 92个结果 * */public class Queen { // 同列是否有皇后，1表示有，0表示没有 private int[] column; //左下至右上是否有皇后，对角线 private int[] rup; //左上至右下是否有皇后，反对角线 private int[] lup; // queen[i]=j：i行j列 private int[] queen; // 解答编号 private int num; // 生成8*8队列，初始定义全部无皇后 public Queen() { column = new int[8 + 1]; /* 1 2 3 1 2 3 1 2 3 左下-&gt;右上：（1，1），（2，2），（3，3） 左上-&gt;右下：（3，1），（2，2），（1，3） 左下-&gt;右上：任意2点都满足i1-i2=j1-j2，演变i1-j1=i2-j2 左上-&gt;右下：任意2点（i1，j1）和（i2，j2）都满足i1+j1=i2+j2 则定义对角线2个数组：rup = new int[(2 * 8) + 1]; i+j,这i属于（1-8）,j属于（1-8）,i+j范围（1-16） lup = new int[(2 * 8) + 1]; i-j,这为了避免出现负数，程序里在这里+8. */ rup = new int[(2 * 8) + 1];//对角线上任意2点（i1，j1）和（i2，j2）都满足i1+j1=i2+j2，因为i+j可能的取值范围是从0到15，所以把这个数组的长度定义为16 lup = new int[(2 * 8) + 1];//反对角线上任意2点都满足i1-i2=j1-j2，演变i1-j1=i2-j2，i-j的范围是-8到8，为了避免出现负数，程序里在这里+8，所以把这个数组的长度定义为16 for (int i = 1; i &lt;= 8; i++) { column[i] = 0; } for (int i = 1; i &lt;= (2 * 8); i++) { rup[i] = lup[i] = 0; } queen = new int[8 + 1]; } /** * 回溯算法 * * @param i 行 */ public void backtrack(int i) { if (i &gt; 8) { // 打印日志 showAnswer(); } else { //遍历同行的列 for (int j = 1; j &lt;= 8; j++) { //同列不能有皇后；反对角线不能有皇后，对角线不能有皇后，符合条件进入循环体 //同列：column[j] //对角线：rup[i + j] =（1,1），（2,2），（3,3） //反对角线：lup[i - j + 8] = （1,3），（2,2），（3,1）；为了避免出现负数，程序里在这里+8。 if ((column[j] == 0) &amp;&amp; (rup[i + j] == 0) &amp;&amp; (lup[i - j + 8] == 0)) { //i行j列，放置一个皇后 queen[i] = j; //设置当前列、对角线，反对角线不能有皇后 column[j] = rup[i + j] = lup[i - j + 8] = 1; // 循环调用，获取当前行的下一行，继续进行判断是否在皇后路线上 backtrack(i + 1); //\"下一行\"不能放置皇后，回退到上一行，清空上一行遍历记录，然后再次遍历该行的其他列 column[j] = rup[i + j] = lup[i - j + 8] = 0;//清空遍历记录 } } } } /** * 打印日志 */ protected void showAnswer() { num++; System.out.print(\"\\n解答\" + num+\" = \"); for (int i = 0; i &lt; queen .length; i++) { System.out.print(queen[i]+\",\"); } System.out.println(); for (int y = 1; y &lt;= 8; y++) {//行 for (int x = 1; x &lt;= 8; x++) {//列 //y行x列，queen[y]的值是皇后所在列 if (queen[y] == x) { System.out.print(\"Q\"); } else { System.out.print(\"X\"); } } System.out.println(); } } public static void main(String[] args) { System.out.println(\"开始解决8皇后算法问题\"); long s1 = System.currentTimeMillis(); Queen queen = new Queen(); //从第1行第1列开始 queen.backtrack(1); long s2 = System.currentTimeMillis(); System.out.println(\"耗时【\"+(s2 - s1) +\"豪秒】【\" + ((s2 - s1) / 1000) + \"秒】.............................\"); }} 代码2时间：耗时【8豪秒】（这里时间比代码1小，可能是因为日志打印少的原因）注意：这方法代码很高效，在同一行X列，如果不符合皇后放置条件，不比清除当前行的皇后数据，直接遍历当前行的下一列。不同点： 代码1是先比较皇后是否符合条件，符合在放置皇后，标记皇后，遍历下一行；如果不符合条件，清空上一行皇后数据，重新遍历该行之后的列，再次寻找皇后的位置。 代码2是先放置皇后的位置，然后在比较该位置的皇后是否符合提交，如果符合条件继续遍历下一行；不符合条件，则遍历该行之后的列，这里节省一步骤：清空上一行皇后的数据。 1231 2 31 2 31 2 3 x[j] == x[k]：同一列。(Math.abs(k - j)) == (Math.abs(x[j] - x[k]):i1-i2=j1-j2 -&gt; i1-j1=i2-j2，对角线上。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899package demo2;/** * 92个结果 * * 很高效的方法。 * 省一步骤：清除当前行的皇后 * */public class Empress { private int n; // 皇后个数 private int[] x; // 当前解 private long sum; // 当前已找到的可行方案数 private static int h; // 记录遍历方案序数 public Empress() { this.sum = 0; // 初始化方案数为1，当回溯到最佳方案的时候，就自增1 this.n = 8; // 求n皇后问题，由自己定义 this.x = new int[n + 1]; // x[i]表示皇后i放在棋盘的第i行的第x[i]列，x[i]值是列 h = 1; // 这个是我额外定义的变量，用于遍历方案的个数，请看backTrace()中h变量的作用，这里将它定义为static静态变量 } /** * 验效 * * @param k 行 * @return */ public boolean place(int k) { //遍历列 for (int j = 1; j &lt; k; j++) { // 这个主要是刷选符合皇后条件的解，因为皇后可以攻击与之同一行同一列的或同一斜线上的棋子 //x[j] == x[k]：同一列 //(Math.abs(k - j)) == (Math.abs(x[j] - x[k])：i1-i2=j1-j2 -&gt; i1-j1=i2-j2，对角线上 if ((Math.abs(k - j)) == (Math.abs(x[j] - x[k])) || (x[j] == x[k])) { return false; // 如果是与之同一行同一列的或同一斜线上的棋子，返回false; } } return true;// 如果不是与之同一行同一列的或同一斜线上的棋子，返回true; } /** * * @param t * 行 */ public void backTrace(int t) { // 当t&gt;n时,算法搜索到叶节点，得到一个新的n皇后互不攻击放置方案，方案数加1 //达到皇后数目，结束1次方案 if (t &gt; n) { sum++; // 方案数自增1 System.out.println(\"\"); System.out.println(\"方案\" + (h++) + \"\"); //打印皇后 print(x); System.out.println(\"\");// 华丽的分割线 } else { // 当t&lt;=n时，当前扩展的结点Z是解空间中的内部结点，该节点有x[i]=1,2，…,n共n个子结点， // 对于当前扩展结点Z的每一个儿子结点，由place()方法检测其可行性， // 并以深度优先的方式递归地对可行子树搜索，或剪去不可行子数 //遍历列 for (int i = 1; i &lt;= n; i++) { //t行i列：在t行i列上放置皇后 x[t] = i; // 检查结点是否符合条件 // 不符合皇后规则，继续遍历当前行的下一列（注意：这里如果不符合条件，少一个清除当上一行皇后的数据） // 符合条件，则进入下一行 if (place(t)) { backTrace(t + 1); // 递归调用下一行 } } } } public void print(int[] a) { // 打印数组，没啥的 for (int i = 1; i &lt; a.length; i++) { System.out.print(\"皇后\" + i + \"在\" + i + \"行\" + a[i] + \"列、\"); } } public static void main(String[] args) { long s1 = System.currentTimeMillis(); Empress em = new Empress(); em.backTrace(1); // 从1开始回溯 System.out.println(\"\"); System.out.println(\"详细方案如上所示，\" + \"可行个数为:\" + em.sum); long s2 = System.currentTimeMillis(); System.out.println(\"耗时【\"+(s2 - s1) +\"豪秒】 .............................\"); }}/* * output:八皇后问题只有92种方案，这里只给出其中的三个方案 方案1 * 皇后1在1行1列、皇后2在2行5列、皇后3在3行8列、皇后4在4行6列、皇后5在5行3列、皇后6在6行7列、皇后7在7行2列、皇后8在8行4列、 * ---------------- 方案2 * 皇后1在1行1列、皇后2在2行6列、皇后3在3行8列、皇后4在4行3列、皇后5在5行7列、皇后6在6行4列、皇后7在7行2列、皇后8在8行5列、 * ---------------- . . . 方案92 * 皇后1在1行8列、皇后2在2行4列、皇后3在3行1列、皇后4在4行3列、皇后5在5行6列、皇后6在6行2列、皇后7在7行7列、皇后8在8行5列、 * ---------------- */// ~ 代码3时间：耗时【15豪秒】。详细：此代码和代码1类似，只是把每个方法拆分开。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123package demo3;/** * 92种方法 * 耗时【15豪秒】 * */public class Queen { private final int size = 8; // 棋盘的大小 private int[] location; // 皇后在棋盘上的每一行的列的位子，location[i]=j：i行j列 private int[] colsOccupied; // 皇后在棋盘上占据的列 private int[] cross1Occuptied; // 皇后在棋盘上占据的正对角线 private int[] cross2Occuptied; // 皇后在棋盘上占据的是反对角线 private static int count; // 解决的方法的个数 private static final int STATUS_OCCUPIED = 1; // 占据的状态 private static final int STATUS_OCCUPY_CANCELED = 0; // 没有占据的状态 //初始化数据 public Queen() { this.location = new int[this.size]; this.colsOccupied = new int[this.size]; this.cross1Occuptied = new int[2 * this.size]; this.cross2Occuptied = new int[2 * this.size]; } //打印棋盘皇后位置 public void printLocation() { System.out.println(); System.out.println(\"以下是皇后在棋盘上的第\" + count + \"种方式的摆放\"); /*for (int i = 0; i &lt; this.size; i++) { System.out.println(\"行：\" + i + \" 列：\" + this.location[i]); }*/ System.out.println(); for (int y = 0; y &lt;= 7; y++) {//行 for (int x = 0; x &lt;= 7; x++) {//列 //y行x列，queen[y]的值是皇后所在列 if (this.location[y] == x) { System.out.print(\"Q\"); } else { System.out.print(\"X\"); } } System.out.println(); } } // end 打印 /** * 判断位子（i,j）是否被占领了 * @param i 行 * @param j 列 * @return */ private boolean isOccupied(int i, int j) { //同一列 if (this.colsOccupied[j] == 1) { return true; } //对角线 if (this.cross1Occuptied[i - j + this.size - 1] == 1) { return true; } //反对角线 if (this.cross2Occuptied[i + j] == 1) { return true; } return false; } /** * 设置棋盘位置状态，如果flag为1，表示占领位子（i,j）; 如果flag为0，表示取消占领位子（i,j) ; */ private void setStatus(int i, int j, int flag) { this.colsOccupied[j] = flag; // 宣布占领或者是取消占领第j列 this.cross1Occuptied[i - j + this.size - 1] = flag; // 宣布占领或者取消占领正对角线 this.cross2Occuptied[i + j] = flag; // 宣布占领或取消占领反对角 } /** * 第一行开始摆放皇后 * @param i 行 */ public void place(int i) { // 在第i行尝试把皇后放在每一列 for (int j = 0; j &lt; this.size; j++) { // 判断该位子是不是已经被占领了的 if (!this.isOccupied(i, j)) { // 摆放皇后，在第i行把皇后放在第j列 this.location[i] = j; //设置状态，该点已经放置皇后 this.setStatus(i, j, this.STATUS_OCCUPIED); if (i &lt; this.size - 1) { //遍历下一行 this.place(i + 1); } else {//当前方案遍历完，打印该方案 this.count++; this.printLocation(); } // 设置状态，该点皇后位置被清空（回溯法） this.setStatus(i, j, STATUS_OCCUPY_CANCELED); } } } /** * 从第0行0列开始 */ public void start() { this.place(0); } public static void main(String[] args) { long s1 = System.currentTimeMillis(); Queen queen = new Queen(); queen.start(); long s2 = System.currentTimeMillis(); System.out.println(\"耗时【\" + (s2 - s1) + \"豪秒】 .............................\"); }} 代码4时间：耗时【15豪秒】。详细：此代码和代码1类似，只是把每个方法拆分开。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970package demo4;/** * 回溯法求解 N 皇后问题 * * 和demo1的方法一样 * */ public class N_Queens { // 皇后的个数 private int queensNum = 8; // column[i] = j 表示第 i 列的第 j 行放置一个皇后 private int[] queens = new int[queensNum + 1]; // rowExists[i] = true 表示第 i 行有皇后 private boolean[] rowExists = new boolean[queensNum + 1]; // a[i] = true 表示右高左低的第 i 条斜线有皇后 private boolean[] a = new boolean[queensNum * 2]; // b[i] = true 表示左高右低的第 i 条斜线有皇后 private boolean[] b = new boolean[queensNum * 2]; // 初始化变量 private void init() { for (int i = 0; i &lt; queensNum + 1; i++) { rowExists[i] = false; } for(int i = 0; i &lt; queensNum * 2; i++) { a[i] = b[i] = false; } } // 判断该位置是否已经存在一个皇后，存在则返回 true // 同列，对角线，反对角线 private boolean isExists(int row, int col) { return (rowExists[row] || a[row + col - 1] || b[queensNum + col - row]); } // 主方法：测试放置皇后 public void testing(int column) { // 遍历每一行 for (int row = 1; row &lt; queensNum + 1; row++) { // 如果第 row 行第 column 列可以放置皇后 if (!isExists(row, column)) { // 设置第 row 行第 column 列有皇后 queens[column] = row; // 设置以第 row 行第 column 列为交叉点的斜线不可放置皇后 rowExists[row] = a[row + column - 1] = b[queensNum + column - row] = true; // 全部尝试过，打印 if(column == queensNum) { for(int col = 1; col &lt;= queensNum; col++) { System.out.print(\"(\"+col + \",\" + queens[col] + \") \"); } System.out.println(); }else { // 放置下一列的皇后 testing(column + 1); } // 撤销上一步所放置的皇后，即回溯 rowExists[row] = a[row + column - 1] = b[queensNum + column - row] = false; } } } // 测试 public static void main(String[] args) { N_Queens queen = new N_Queens(); queen.init(); // 从第 1 列开始求解 queen.testing(1); } } 代码5时间：耗时【15豪秒】。详细：此代码和代码1类似，只是把每个方法拆分开。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364package demo5;/** * * 和demo1的方法一样 * */public class Queen { int num; // 记录方案数 int[] queenline = new int[8]; // 记录8个皇后所占用的列号 boolean[] col = new boolean[8]; // 列安全标志 boolean[] diagonal = new boolean[16]; // 对角线安全标志 boolean[] undiagonal = new boolean[16]; // 反对角线安全标志 void solve(int i) { for (int j = 0; j &lt; 8; j++) { // 表示第i行第j列是安全的可以放皇后 if (col[j] &amp;&amp; diagonal[i - j + 7] &amp;&amp; undiagonal[i + j]) { queenline[i - 1] = j + 1; // 修改安全标志 col[j] = false; diagonal[i - j + 7] = false; undiagonal[i + j] = false; // 判断是否放完8个皇后 if (i &lt; 8) { // 未放完8个皇后则继续放下一个 solve(i + 1); } else // 已经放完8个皇后 { num++; System.out.println(\"\\n皇后摆放第\" + num + \"种方案:\"); System.out.println(\"行分别为1 2 3 4 5 6 7 8 列分别为\"); for (int i1 = 0; i1 &lt; 8; i1++) { System.out.print(queenline[i1] + \" \"); } } // 修改安全标志，回溯 col[j] = true; diagonal[i - j + 7] = true; undiagonal[i + j] = true; } } } public static void main(String[] args) { Queen q = new Queen(); System.out.println(\"////////////////////////////八皇后问题////////////////////////////////\"); System.out.println(\"在8行8列的棋盘上放置8个皇后,皇后可吃掉与她处于同行或同列或同一对角线上的其他棋子,使任一个皇后都不能吃掉其他的7个皇后共有92种方法\"); // 方案初始化 q.num = 0; // 置所有列为安全 for (int i = 0; i &lt; 8; i++) { q.col[i] = true; } // 置所有对角线为安全 for (int i0 = 0; i0 &lt; 16; i0++) { q.diagonal[i0] = q.undiagonal[i0] = true; } //开始第1行第1列 q.solve(1); }} 代码6解析：代码有点绕，整体思路和代码1一样1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192package demo6;/** * 92种方法 * */public class Queen8 { public static int num = 0; // 累计方案总数 public static final int MAXQUEEN = 8;// 皇后个数，同时也是棋盘行列总数 public static int[] cols = new int[MAXQUEEN]; // 定义cols数组，表示8列棋子摆放情况 public Queen8() { // 第0行开始 getArrangement(0); System.out.print(\"\"); System.out.println(MAXQUEEN + \"皇后问题有\" + num + \"种摆放方法。\"); } /** * * @param n 行 */ public void getArrangement(int n) { // 遍历该列所有不合法的行，并用rows数组记录，不合法即rows[i]=true // 当前行的列数组 boolean[] rows = new boolean[MAXQUEEN]; //遍历行i，进行左边点判断是否符合皇后标准 for (int i = 0; i &lt; n; i++) { //当前行cols[i]列 不符合条件 //同列不能存皇后 rows[cols[i]] = true; //可以理解为：i1-i2=j1-j2=d int d = n - i; //cols[i]：i行x列，这x列就是皇后的位置，那么皇后可能在d（对角线）（cols[i]-j1+j2），皇后位置减去d位置=0，在对角线上 if (cols[i] - d &gt;= 0) { rows[cols[i] - d] = true; } //cols[i]：i行x列，这x列就是皇后的位置，那么皇后可能在d（反对角线）（cols[i]+j1-j2） if (cols[i] + d &lt;= MAXQUEEN - 1) { rows[cols[i] + d] = true; } } //遍历下一列 for (int i = 0; i &lt; MAXQUEEN; i++) { // 判断该行i列是否合法 // true：不符合皇后条件，遍历下一列 // false：符合皇后条件，放置皇后在当前位置 if (rows[i]) { continue; } // 设置当前列皇后所在行数 cols[n] = i; // 当前列不为最后一列时，遍历下一行 if (n &lt; MAXQUEEN - 1) { getArrangement(n + 1); } else { // 累计方案个数 num++; // 打印棋盘信息 printChessBoard(); } } } public void printChessBoard() { System.out.println(\"第\" + num + \"种走法 \"); //列 for (int i = 0; i &lt; MAXQUEEN; i++) { //行 for (int j = 0; j &lt; MAXQUEEN; j++) { //j行i列：cols[j]=i，值：列 if (i == cols[j]) { //皇后位置 System.out.print(\"0 \"); } else { System.out.print(\"+ \"); } } System.out.println(\" \"); } } public static void main(String args[]) { long s1 = System.currentTimeMillis(); Queen8 queen = new Queen8(); long s2 = System.currentTimeMillis(); System.out.println(\"耗时【\" + (s2 - s1) + \"豪秒】 .............................\"); }}","link":"/Eight-Queens/"},{"title":"Fork-Join模式","text":"1 什么是Fork-Join 2 work-stealing算法 3 Fork-Join框架 3.1 ForkJoinTask fork() join() 3.2 ForkJoinPool 3.3 注意 4 Fork-Join框架使用 4.1 extends RecursiveTask 4.2 例子 4.3 自定义forkjoin任务类 4.4 创建线程池 5 Fork-Join框架的异常处理 6 Fork-Join框架的性能测试 6.1 例1 1 什么是Fork-Join“分治”问题可以很容易地通过Callable线程的Executor接口来解决。通过为每个任务实例化一 个Callable实例，并在ExecutorService类中汇总计算结果来得出最终结果可以实现这一目的。那么自然而然想到的问题就是，如果这接口已经做得不错了，我们为什么还需要Java 7的其他框架？使用ExecutorService和Callable的主要问题是，Callable实例在本质上是阻塞的。一旦一个Callable实例开始执行，其他所有Callable都会被阻塞。由于队列后面的Callable实例在前一实例未执行完成的时候不会被执行，因此许多资源无法得到利用。Fork-Join框架被引入来解决这一并行问题，而Executor解决的是并发问题(译者注：并发和并行的区别就是一个处理器同时处理多个任务和多个处理器或者是多核的处理器同时处理多个不同的任务)。Fork-Join模式，分而治之，然后合并结果，这么一种编程模式。(注：Fork-Join是一个单机框架，类似的分布式的框架有Hadoop这类的，它们的计算模型是MapReduce，体现了和Fork-Join一样的思想-分而治之。)Fork-Join框架是一个”多核友好的、轻量级并行框架”，它支持并行编程风格，将问题递归拆分成多个更小片断，以并行和调配的方式解决。Fork-join融合了分而治之技术；获取问题后，递归地将它分成多个子问题，直到每个子问题都足够小，以至于可以高效地串行地解决它们。递归的过程将会把问题分成两个或者多个子问题，然后把这些问题放入队列中等待处理（fork步骤），接下来等待所有子问题的结果（join步骤），把多个结果合并到一起。Fork-Join模式有自己的适用范围。如果一个应用能被分解成多个子任务，并且组合多个子任务的结果就能够获得最终的答案，那么这个应用就适合用Fork-Join模式来解决。一个Fork-Join模式的示意图，位于图上部的Task依赖于位于其下的Task的执行，只有当所有的子任务都完成之后，调用者才能获得Task 0的返回结果。如下图。Fork-Join模式能够解决很多种类的并行问题。通过使用Doug Lea提供的Fork-Join框架，软件开发人员只需要关注任务的划分和中间结果的组合就能充分利用并行平台的优良性能。其他和并行相关的诸多难于处理的问题，例如负载平衡、同步等，都可以由框架采用统一的方式解决。这样，我们就能够轻松地获得并行的好处而避免了并行编程的困难且容易出错的缺点。 2 work-stealing算法工作窃取(work-stealing)算法是指某个线程从其他队列里窃取任务来执行。工作窃取的运行流程图如下。那么为什么需要使用工作窃取算法呢？假如我们需要做一个比较大的任务，我们可以把这个任务分割为若干互不依赖的子任务，为了减少线程间的竞争，于是把这些子任务分别放到不同的队列里，并为每个队列创建一个单独的线程来执行队列里的任务，线程和队列一一对应，比如A线程负责处理A队列里的任务。但是有的线程会先把自己队列里的任务干完，而其他线程对应的队列里还有任务等待处理。干完活的线程与其等着，不如去帮其他线程干活，于是它就去其他线程的队列里窃取一个任务来执行。而在这时它们会访问同一个队列，所以为了减少窃取任务线程和被窃取任务线程之间的竞争，通常会使用双端队列，被窃取任务线程永远从双端队列的头部拿任务执行，而窃取任务的线程永远从双端队列的尾部拿任务执行。工作窃取算法的优点是充分利用线程进行并行计算，并减少了线程间的竞争，其缺点是在某些情况下还是存在竞争，比如双端队列里只有一个任务时。并且消耗了更多的系统资源，比如创建多个线程和多个双端队列。Fork-join只有你在将一个任务拆分成小任务时才有用处。Fork-Join池是是一个work-stealing工作窃取线程池。每个工作线程维护本地任务队列。Fork-join池里的线程不是在等待新任务，而是主动分裂的现有任务到更小的，并帮助完成其他线程的大任务(切分以后)。如图所示。work-stealing所采用的基本调度策略。 每一个工作线程维护自己的调度队列中的可运行任务。 队列以双端队列的形式被维护(注：deques通常读作”decks”)，不仅支持后进先出——LIFO的push和pop操作，还支持先进先出——FIFO的take操作。 对于一个给定的工作线程来说，任务所产生的子任务将会被放入到工作者自己的双端队列中。 工作线程使用后进先出——LIFO的顺序，通过弹出任务来处理队列中的任务。 当一个工作线程的本地没有任务去运行的时候，它将使用先进先出——FIFO的规则尝试随机的从别的工作线程中拿(“偷窃”)一个任务去运行。 当一个工作线程触及了join操作，如果可能的话它将处理其他任务，直到目标任务被告知已经结束(通过isDone())。所有的任务都会无阻塞的完成。 当一个工作线程无法再从其他线程中获取任务和失败处理的时候，它就会退出（通过yields, sleeps, 和/或者优先级调整）并经过一段时间之后再度尝试直到所有的工作线程都被告知他们都处于空闲的状态。在这种情况下，他们都会阻塞直到其他的任务再度被上层调用。 使用后进先出——LIFO用来处理每个工作线程的自己任务，但是使用先进先出——FIFO规则用于获取别的任务，这是一种被广泛使用的进行递归Fork-Join设计的一种调优手段。 让偷取任务的线程从队列拥有者相反的方向进行操作会减少线程竞争。同样体现了递归分治算法的大任务优先策略。因此，更早期被偷取的任务有可能会提供一个更大的单元任务，从而使得偷取线程能够在将来进行递归分解。 3 Fork-Join框架我们已经很清楚Fork-Join框架的需求了，那么我们可以思考一下，如果让我们来设计一个Fork-Join框架，该如何设计？这个思考有助于你理解Fork-Join框架的设计。 分割任务。首先我们需要有一个fork类来把大任务分割成子任务，有可能子任务还是很大，所以还需要不停的分割，直到分割出的子任务足够小。 执行任务并合并结果。分割的子任务分别放在双端队列（线程，队列一一对应）里，然后几个启动线程分别从双端队列里获取任务执行。子任务执行完的结果都统一放在一个队列里，启动一个线程从队列里拿数据，然后合并这些数据。 Fork-Join使用两个类来完成以上两件事情。 3.1 ForkJoinTask我们要使用Fork-Join框架，必须首先创建一个Fork-Join任务。它提供在任务中执行fork()和join()操作的机制，通常情况下我们不需要直接继承ForkJoinTask类，而只需要继承它的子类，Fork-Join框架提供了以下两个子类。 RecursiveAction：用于没有返回结果的任务。 RecursiveTask：用于有返回结果的任务。 ForkJoinTask有两个主要的方法。 fork()这个方法决定了ForkJoinTask的异步执行，凭借这个方法可以创建新的任务。 join()该方法负责在计算完成侯返回结果，因此允许一个任务等待另一任务执行完成。 3.2 ForkJoinPoolForkJoinTask需要通过ForkJoinPool来执行，任务分割出的子任务会添加到当前工作线程所维护的双端队列中，进入队列的头部。当一个工作线程的队列里暂时没有任务时，它会随机从其他工作线程的队列的尾部获取一个任务（work-stealing）。ForkJoinPool会尝试在任何时候都维持与可用的处理器数目一样数目的活动线程数。 3.3 注意可用线程数和硬件支持。线程这东西，也是有开销的东西，绝对不是越多越好，尤其在硬件基础有限的情况下。任务分解的粒度。和前者有关系，就是分解的任务，“小”到什么程度是可以接受的，不可再分。切分到多少才合适呢？一般切分到一个阈值，再切分下去就没有意义的了。 4 Fork-Join框架使用4.1 extends RecursiveTask12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758package com.forkjoin2;import java.util.concurrent.ForkJoinPool;import java.util.concurrent.Future;import java.util.concurrent.RecursiveTask;public class CountTask extends RecursiveTask&lt;Object&gt; { private static final long serialVersionUID = 1L; private static final int THRESHOLD = 2; private int start; private int end; public CountTask(int start, int end) { this.start = start; this.end = end; } @Override protected Integer compute() { int sum = 0; boolean canCompute = (end - start) &lt;= THRESHOLD; if (canCompute) { for (int i = start; i &lt;= end; i++) { sum += i; } } else { // 如果任务大于阀值，就分裂成两个子任务计算 int mid = (start + end) / 2; CountTask leftTask = new CountTask(start, mid); CountTask rightTask = new CountTask(mid + 1, end); //异步的执行子任务 leftTask.fork(); rightTask.fork(); // 等待子任务执行完，并得到结果 int rightResult = (int) rightTask.join(); int leftResult = (int) leftTask.join(); sum = leftResult + rightResult; } return sum; } public static void main(String[] args) { ForkJoinPool forkJoinPool = new ForkJoinPool(); // 生成一个计算资格，负责计算1+2+3+4 CountTask task = new CountTask(1, 4); @SuppressWarnings({ \"rawtypes\" }) Future result = forkJoinPool.submit(task); try { System.out.println(result.get()); } catch (Exception e) { e.printStackTrace(); } }} 在Fork-Join框架中，提交任务的时候，有同步和异步两种方式。以前使用的invokeAll()是同步的，也就是任务提交后，这个方法不会返回直到所有的任务都处理完了。而还有另一种方式，就是使用fork()，这个是异步的。也就是你提交任务后，fork()立即返回，可以继续下面的任务。这个线程也会继续运行。下面我们以一个查询磁盘的以log结尾的文件的程序例子来说明异步的用法。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115package com.forkjoin5;import java.io.File;import java.util.ArrayList;import java.util.List;import java.util.concurrent.ForkJoinPool;import java.util.concurrent.RecursiveTask;import java.util.concurrent.TimeUnit;/* * */public class FolderProcessor extends RecursiveTask&lt;List&lt;String&gt;&gt; { private static final long serialVersionUID = 1L; private String path;// 路径 private String extension;// 文件后缀名 public FolderProcessor(String path, String extension) { super(); this.path = path; this.extension = extension; } // 任务执行 @Override protected List&lt;String&gt; compute() { // 符合文件搜索条件的list，添加文件的名字 List&lt;String&gt; list = new ArrayList&lt;String&gt;(); // 任务列表 List&lt;FolderProcessor&gt; taskList = new ArrayList&lt;FolderProcessor&gt;(); File file = new File(path); // 子文件列表 File[] content = file.listFiles(); if (content != null) { for (int i = 0; i &lt; content.length; i++) { //如果是目录的情况，继续搜索子文件 if (content[i].isDirectory()) { //子文件任务 FolderProcessor task = new FolderProcessor(content[i].getAbsolutePath(),extension); // 异步方式提交任务 task.fork(); taskList.add(task); } else { //非目录 if (checkFile(content[i].getName())) { list.add(content[i].getAbsolutePath()); } } } } if (taskList.size() &gt; 50) { System.out.printf(\"%s: %d tasks ran.\\n\", file.getAbsolutePath(), taskList.size()); } addResultsFromTasks(list, taskList); return list; } //添加文件的名字 private void addResultsFromTasks(List&lt;String&gt; list, List&lt;FolderProcessor&gt; taskList) { for (FolderProcessor item : taskList) { list.addAll(item.join()); } } //检测文件 private boolean checkFile(String name) { return name.endsWith(extension); } // 实现 showLog() 方法。它接收 ForkJoinPool 对象作为参数和写关于线程和任务的执行的状态的信息。 private static void showLog(ForkJoinPool pool) { System.out.printf(\"**********************\\n\"); System.out.printf(\"Main: Fork/Join Pool log\\n\"); //此方法返回池的并行的级别。 System.out.printf(\"Main: Fork/Join Pool: Parallelism:%d\\n\", pool.getParallelism()); //此方法返回 int 值，它是ForkJoinPool内部线程池的worker线程们的数量。 System.out.printf(\"Main: Fork/Join Pool: Pool Size:%d\\n\", pool.getPoolSize()); //此方法返回当前执行任务的线程的数量。 System.out.printf(\"Main: Fork/Join Pool: Active Thread Count:%d\\n\", pool.getActiveThreadCount()); //此方法返回没有被任何同步机制阻塞的正在工作的线程。 System.out.printf(\"Main: Fork/Join Pool: Running Thread Count:%d\\n\", pool.getRunningThreadCount()); //此方法返回已经提交给池还没有开始他们的执行的任务数。 System.out.printf(\"Main: Fork/Join Pool: Queued Submission:%d\\n\", pool.getQueuedSubmissionCount()); //此方法返回已经提交给池已经开始他们的执行的任务数。 System.out.printf(\"Main: Fork/Join Pool: Queued Tasks:%d\\n\", pool.getQueuedTaskCount()); //此方法返回 Boolean 值，表明这个池是否有queued任务还没有开始他们的执行。 System.out.printf(\"Main: Fork/Join Pool: Queued Submissions:%s\\n\", pool.hasQueuedSubmissions()); //此方法返回 long 值，worker 线程已经从另一个线程偷取到的任务数。 System.out.printf(\"Main: Fork/Join Pool: Steal Count:%d\\n\", pool.getStealCount()); //此方法返回 Boolean 值，表明 fork/join 池是否已经完成执行。 System.out.printf(\"Main: Fork/Join Pool: Terminated :%s\\n\", pool.isTerminated()); System.out.printf(\"**********************\\n\"); } public static void main(String[] args) throws InterruptedException { ForkJoinPool pool = new ForkJoinPool(); FolderProcessor system = new FolderProcessor(\"F:\\\\Workspace\", \"java\"); FolderProcessor apps = new FolderProcessor(\"F:\\\\Workspace\", \"jsp\"); pool.execute(system); pool.execute(apps); while (!apps.isDone() || !apps.isDone()) { showLog(pool); TimeUnit.SECONDS.sleep(5000); } pool.shutdown(); List&lt;String&gt; results = system.join(); System.out.printf(\"System: %d files found.\\n\", results.size()); results = apps.join(); System.out.printf(\"Apps: %d files found.\\n\", results.size()); }} 4.2 例子12345678910111213141516171819202122232425262728293031package com.forkjoin7;import java.util.concurrent.RecursiveTask;//递归的例子class Fibonacci extends RecursiveTask&lt;Integer&gt; { private static final long serialVersionUID = 1L; final int n; Fibonacci(int n) { this.n = n; } private int compute(int small) { final int[] results = { 1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89 }; return results[small]; } public Integer compute() { if (n &lt;= 10) { return compute(n); } Fibonacci f1 = new Fibonacci(n - 1); Fibonacci f2 = new Fibonacci(n - 2); f1.fork(); //子任务异步执行 f2.fork(); //join : 阻塞等待结果完成 return f1.join() + f2.join(); }} 123456public static void main(String[] args) throws InterruptedException, ExecutionException { ForkJoinTask&lt;Integer&gt; fjt = new Fibonacci(45); ForkJoinPool fjpool = new ForkJoinPool(); Future&lt;Integer&gt; result = fjpool.submit(fjt); System.out.println(\"Foke/Join = \" + result.get());} 4.3 自定义forkjoin任务类MyWorkerTask123456789101112131415161718192021222324252627282930313233343536373839404142434445464748package com.forkjoin8;import java.util.Date;import java.util.concurrent.ForkJoinTask; public abstract class MyWorkerTask extends ForkJoinTask&lt;Void&gt; { private static final long serialVersionUID = -1153949034138340822L; private String name; public MyWorkerTask() { } public MyWorkerTask(String name) { this.name = name; } // 1 @Override public Void getRawResult() { return null; } // 2 @Override protected void setRawResult(Void value) { } // 3 @Override protected boolean exec() { Date startDate = new Date(); compute(); Date finishDate = new Date(); long diff = finishDate.getTime() - startDate.getTime(); System.out.printf(\"MyWorkerTask: %s : %d Milliseconds to complete.\\n\", name, diff); return true; } // 4 public String getName() { return name; } // 5 protected abstract void compute();} Task123456789101112131415161718192021222324252627282930313233343536package com.forkjoin8;public class Task extends MyWorkerTask { private static final long serialVersionUID = -1773159586852826490L; private int array[]; private int start; private int end; public Task(String name, int array[], int start, int end) { super(name); this.array = array; this.start = start; this.end = end; } // 6 protected void compute() { if (end - start &gt; 100) { int mid = (end + start) / 2; Task task1 = new Task(this.getName() + \"1\", array, start, mid); Task task2 = new Task(this.getName() + \"2\", array, mid, end); invokeAll(task1, task2); } else {//7 for (int i = start; i &lt; end; i++) { array[i]++; } //最后，让正在执行任务的线程进入休眠50毫秒。 try { Thread.sleep(50); } catch (InterruptedException e) { e.printStackTrace(); } } }} MainTest212345678910111213141516package com.forkjoin8;import java.util.concurrent.ForkJoinPool;//如何为 Fork/Join 框架实现你自己的任务，实现一个任务扩展ForkJoinTask类。//你将要实现的任务是计量运行时间并写入操控台，这样你可以控制它的进展（evolution）public class MainTest2 { public static void main(String[] args) throws Exception { int array[] = new int[10000]; ForkJoinPool pool = new ForkJoinPool(); Task task = new Task(\"Task\", array, 0, array.length); pool.invoke(task); pool.shutdown(); System.out.printf(\"Main: End of the program.\\n\"); }} 实现getRawResult()。这是ForkJoinTask类的抽象方法之一。由于任务不会返回任何结果，此方法返回的一定是null值。 实现setRawResult()。这是ForkJoinTask类的另一个抽象方法。由于任务不会返回任何结果，方法留白即可。 实现exec()抽象方法。这是任务的主要方法。在这个例子，把任务的算法委托给compute()。计算方法的运行时间并写入操控台。 实现getName()来返回任务的名字。 声明抽象方法compute()。像我们之前提到的，此方法实现任务的算法，必须是由MyWorkerTask类的子类实现。 实现compute()。此方法通过start和end。属性来决定增加array的元素块。如果元素块的元素超过100个，把它分成2部分，并创建2个Task对象来处理各个部分。再使用invokeAll()把这些任务发送给池。 如果元素块的元素少于100，使用for循环增加全部的元素。 4.4 创建线程池 创建MyWorkerThreadFactory实现ForkJoinWorkerThreadFactory工厂类。 创建自定义工作者线程MyWorkerThread，继承ForkJoinWorkerThread。 创建工作者任务类MyRecursiveTask。 MyWorkerThreadFactory12345678910111213package com.forkjoin9;import java.util.concurrent.ForkJoinPool;import java.util.concurrent.ForkJoinWorkerThread;import java.util.concurrent.ForkJoinPool.ForkJoinWorkerThreadFactory;public class MyWorkerThreadFactory implements ForkJoinWorkerThreadFactory{ @Override public ForkJoinWorkerThread newThread(ForkJoinPool pool) { return new MyWorkerThread(pool); }} MyWorkerThread1234567891011121314151617181920212223242526272829303132333435package com.forkjoin9;import java.util.concurrent.ForkJoinPool;import java.util.concurrent.ForkJoinWorkerThread;public class MyWorkerThread extends ForkJoinWorkerThread { // 每个线程都有自己的任务计数器 private static ThreadLocal&lt;Integer&gt; taskCounter = new ThreadLocal&lt;Integer&gt;(); protected MyWorkerThread(ForkJoinPool pool) { super(pool); } @Override protected void onStart() { super.onStart(); System.out.printf(\"MyWorkerThread %d: Initializing taskcounter.\\n\", getId()); taskCounter.set(0); } // 中断 @Override protected void onTermination(Throwable exception) { System.out.printf(\"MyWorkerThread %d:%d\\n\", getId(), taskCounter.get()); super.onTermination(exception); } public void addTask() { int counter = taskCounter.get().intValue(); counter++; taskCounter.set(counter); }} MyRecursiveTask12345678910111213141516171819202122232425262728293031323334353637383940package com.forkjoin9;import java.util.concurrent.ExecutionException;import java.util.concurrent.RecursiveTask;import java.util.concurrent.TimeUnit;public class MyRecursiveTask extends RecursiveTask&lt;Integer&gt; { private static final long serialVersionUID = -6615653526171656238L; private int array[]; private int start, end; public MyRecursiveTask(int array[], int start, int end) { this.array = array; this.start = start; this.end = end; } @Override protected Integer compute() { Integer ret = 0; MyWorkerThread thread = (MyWorkerThread) Thread.currentThread(); thread.addTask(); if (end - start &gt; 100) { int mid = (start + end) / 2; MyRecursiveTask task1 = new MyRecursiveTask(array, start, mid); MyRecursiveTask task2 = new MyRecursiveTask(array, mid, end); task1.fork(); task2.fork(); int a1 = task1.join(); int a2 = task2.join(); ret = a1 + a2; } else { for (int i = start; i &lt; end; i++) { ret += array[i]; } } return ret; }} MainTest123456789101112131415161718//如何实现一个在ForkJoinPool类中使用的自定义的工作者线程，及如何使用一个工厂来使用它。public class MainTest { public static void main(String[] args) throws Exception { MyWorkerThreadFactory factory = new MyWorkerThreadFactory(); ForkJoinPool pool = new ForkJoinPool(4, factory, null, false); int array[] = new int[100000]; for (int i = 0; i &lt; array.length; i++) { array[i] = 1; } MyRecursiveTask task = new MyRecursiveTask(array, 0, array.length); pool.execute(task); task.join(); pool.shutdown(); pool.awaitTermination(1, TimeUnit.DAYS); System.out.printf(\"Main: Result: %d\\n\", task.get()); System.out.printf(\"Main: End of the program\\n\"); }} 5 Fork-Join框架的异常处理ForkJoinTask在执行的时候可能会抛出异常，但是我们没办法在主线程里直接捕获异常，所以ForkJoinTask提供了isCompletedAbnormally()来检查任务是否已经抛出异常或已经被取消了，并且可以通过ForkJoinTask的getException()获取异常。1234567891011121314151617181920212223242526272829303132333435363738394041package com.forkjoin2;import java.util.concurrent.ExecutionException;import java.util.concurrent.ForkJoinPool;import java.util.concurrent.Future;import java.util.concurrent.RecursiveTask;public class TaskForException extends RecursiveTask { private static final long serialVersionUID = 1L; @Override protected Integer compute() { try { System.out.println(1 / 0); } catch (Exception e) { System.out.println(\"异常：\"); //e.printStackTrace(); } return 0; } @SuppressWarnings(\"unchecked\") public static void main(String[] args) { ForkJoinPool forkJoinPool = new ForkJoinPool(); TaskForException task = new TaskForException(); Future result = forkJoinPool.submit(task); try { System.out.println(result.get()); } catch (InterruptedException e) { e.printStackTrace(); } catch (ExecutionException e) { e.printStackTrace(); } boolean f=task.isCompletedAbnormally(); //处理过的异常，不会报错，同样不会进入if分支。。。 if (task.isCompletedAbnormally()) { System.out.println(\"进入if\"); System.out.println(task.getException()); } }} 6 Fork-Join框架的性能测试6.1 例1测试Fork-Join框架性能，使用线程池，for循环与Fork-Join框架作比较。Task12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152package com.fokejoin1.model;import java.util.List;/** * 任务类 */public class Task { /** * 操作列表 */ private final List&lt;Operation&gt; operations; /** * Type of task 任务类型 */ private final TaskType taskType; public Task(List&lt;Operation&gt; operations, TaskType taskType) { this.operations = operations; this.taskType = taskType; } @Override public String toString() { return taskType.name() + \" (\" + operations.size() + \")\"; } public List&lt;Operation&gt; getOperations() { return operations; } public TaskType getTaskType() { return taskType; } /** * 任务的类型 * 任务数目大小 */ public static enum TaskType { XS(10), S(100), M(1000), L(10000), XL(100000), XXL(1000000); private final int range; TaskType(int range) { this.range = range; } public int getRange() { return range; } }} Operation1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677package com.fokejoin1.model;/** * Models an operation 操作模式 * */public abstract class Operation { // 操作类型 public enum OperationType { Q, // Query U // Update } private OperationType operationType; public Operation(OperationType intervalType) { this.operationType = intervalType; } public OperationType getIntervalType() { return operationType; } /** * Query an interval 查询操作 */ public static class QueryIntervalOperation extends Operation { private int left; private int right; public QueryIntervalOperation(int left, int right) { super(OperationType.Q); this.left = left; this.right = right; } @Override public String toString() { return \"\" + super.operationType.name() + \"[\" + left + \", \" + right + \"]\"; } public int getLeft() { return left; } public int getRight() { return right; } } /** * Update at an index 更新操作 */ public static class UpdateIntervalOperation extends Operation { private int index; private int val; public UpdateIntervalOperation(int index, int val) { super(OperationType.U); this.index = index; this.val = val; } public int getVal() { return val; } @Override public String toString() { return \"\" + super.operationType.name() + \"[@\" + this.index + \", \" + this.val + \"]\"; } public int getIndex() { return index; } }} TaskProducer创建任务信息的类，创建测试任务的数目，基本信息。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384package com.fokejoin1.producer;import java.io.File;import java.io.FileNotFoundException;import java.util.ArrayList;import java.util.List;import java.util.Random;import java.util.Scanner;import com.fokejoin1.model.Operation;import com.fokejoin1.model.Task;/** * 创建任务（任务生产者）：顺序数字的任务，随机数字的任务 */public class TaskProducer { /** * 随机任务数=100 */ private static final int RAND_SEED = 100; private static Random randomGenerator = new Random(RAND_SEED); /** * 任务的文件 */ private static final String TASK_FILENAME = \"task.txt\"; /** * 从左至右边缘的间隔最大跨度 */ private static final int MAX_INTERVAL_LENGTH = 10000; private static final int MAX_INTERVAL_INDEX_VALUE = 10000000; private final Scanner scanner; /** * 构造函数：读取任务文件 * * @throws FileNotFoundException */ public TaskProducer() throws FileNotFoundException { scanner = new Scanner(new File(TASK_FILENAME)); scanner.useDelimiter(\",\"); } /** * 从任务文件中获取任务 */ public Task getNext() { if (scanner == null) { return null; } if (scanner.hasNext()) { // 任务 String taskAsString = scanner.next(); return produceQueryTask(Task.TaskType.valueOf(taskAsString)); } return null; } /** * 创建查询任务 * * @param taskType * 任务类型 * @return 任务对象 */ private Task produceQueryTask(Task.TaskType taskType) { // 操作列表 List&lt;Operation&gt; operations = new ArrayList&lt;Operation&gt;(); for (int i = 0; i &lt; taskType.getRange(); ++i) { operations.add(getRandomQueryInterval()); } // 构造任务 return new Task(operations, taskType); } /** * 随机创建查询左右对象 */ private Operation.QueryIntervalOperation getRandomQueryInterval() { int left = randomGenerator.nextInt(MAX_INTERVAL_INDEX_VALUE - MAX_INTERVAL_LENGTH); int right = left + randomGenerator.nextInt(MAX_INTERVAL_LENGTH); return new Operation.QueryIntervalOperation(left, right); }} TaskResultHandler绑定任务执行结果类，countDownLatch计数任务。123456789101112131415161718192021222324252627282930package com.fokejoin1.result;import java.util.concurrent.CountDownLatch;import com.fokejoin1.model.Task;/** * 任务结果绑定对象 */public class TaskResultHandler { private CountDownLatch allTasksDoneLatch; public TaskResultHandler(CountDownLatch allTasksDoneLatch) { this.allTasksDoneLatch = allTasksDoneLatch; } public void reportQueryResult(Task task, int index, int val) { } public void reportUpdateResult(Task task, int index) { } /** * 任务完成，计数-1 */ public void taskDone(Task task) { allTasksDoneLatch.countDown(); }} TaskSolver123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107package com.fokejoin1.solver;import com.fokejoin1.model.Operation;import com.fokejoin1.model.Task;import com.fokejoin1.result.TaskResultHandler;import com.fokejoin1.rmq.RMQSegmentTree;/** * 任务解决类 */public class TaskSolver { /** * 用户查询，更新的对象 */ private RMQSegmentTree segmentTree; /** * 任务结果绑定对象 */ private TaskResultHandler taskResultHandler; /** * 构造函数，初始化对象 * * @param segmentTree * @param taskResultHandler */ public TaskSolver(RMQSegmentTree segmentTree, TaskResultHandler taskResultHandler) { this.segmentTree = segmentTree; this.taskResultHandler = taskResultHandler; } /** * 解决任务 */ public void solve(Task t) { solve(t, 0, t.getOperations().size()); } /** * * @param t * 任务对象 * @param from * 开始位置 * @param to * 结束位置 */ public void solve(Task t, int from, int to) { for (int k = from; k &lt; to; ++k) { solve(t, k); } } /** * 任务的解决 * * @param t * @param k */ private void solve(Task t, int k) { // 获取操作对象 Operation operation = t.getOperations().get(k); switch (operation.getIntervalType()) { case Q: solveQuery(t, k, operation); case U: solveUpdate(t, k, operation); } } /** * 查询任务解决方法 * * @param t * 任务 * @param k * 操作索引 * @param operation * 查询操作 */ private void solveQuery(Task t, int k, Operation operation) { // 操作类的内部类：查询操作 Operation.QueryIntervalOperation intervalQ = (Operation.QueryIntervalOperation) operation; int result = segmentTree.query(intervalQ.getLeft(), intervalQ.getRight()); // 任务结束，结果绑定 taskResultHandler.reportQueryResult(t, k, result); } /** * 更新操作 * * @param t * @param k * @param operation */ private void solveUpdate(Task t, int k, Operation operation) { } /** * @return The task result handler */ public TaskResultHandler getTaskResultHandler() { return taskResultHandler; }} RMQSegmentTree123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156package com.fokejoin1.rmq;/** * 线段树 * * Init : O(N) Query : O(log N) Update : O(log N) */public class RMQSegmentTree { /** * tree[k] Holds the index of the smallest element from values[k_start] .. * values[k_end] where [k_start, k_end] are the range values of node 'k'. * Node 1 is defined as having [0 .. N] as range values Node 2 is defined as * having [0 .. N/2] as range values Node 3 is defined as having [N/2+1 .. * N] as range values ... Node k defined recursively using above logic * * tree存的是values的索引 tree的索引是node */ public int[] tree; /** * 查询或者更新的数组 */ public int[] values; /** * 构造函数，初始化二叉树 * * @param values */ public RMQSegmentTree(int[] values) { int log2n = (int) (Math.log(values.length) / Math.log(2)); this.values = values; // 在区间内的二叉树 tree = new int[1 &lt;&lt; (log2n + 2)]; init(1, 0, values.length - 1); } /** * 计算tree的节点值 */ public void init(int node, int left, int right) { // root节点 if (left == right) { tree[node] = left; } else { int mid = (left + right) / 2; init(2 * node, left, mid);// 左节点 init(2 * node + 1, mid + 1, right);// 右节点 int minIndexHalf1 = tree[2 * node];// 左节点 int minIndexHalf2 = tree[2 * node + 1];// 右节点 // 存最小值 tree[node] = (values[minIndexHalf1] &lt;= values[minIndexHalf2]) ? minIndexHalf1 : minIndexHalf2; } } /** * 查询i，j之间的最小值 * * @param node * Id of the node * @param left * 左边的区间上限 * @param right * 右边的区间下限 * @param i * 左边的索引 * @param j * 右边的索引 * */ private int query(int node, int left, int right, int i, int j) { // 返回当前节点 if (i &lt;= left &amp;&amp; right &lt;= j) { return tree[node]; } else { int mid = (left + right) / 2; // 初始化左右索引的默认值，tree中的默认值 int minIndexHalf1 = -1, minIndexHalf2 = -1; // 左边索引 if (i &lt;= mid) { minIndexHalf1 = query(2 * node, left, mid, i, j); } // 右边索引 if (j &gt; mid) { minIndexHalf2 = query(2 * node + 1, mid + 1, right, i, j); } // 返回右边的索引 if (minIndexHalf1 == -1) { return minIndexHalf2; } // 返回左边的索引 if (minIndexHalf2 == -1) { return minIndexHalf1; } // 返回最小的值 if (values[minIndexHalf1] &lt;= values[minIndexHalf2]) { return minIndexHalf1; } return minIndexHalf2; } } /** * 更新值 * * @param node * Id of the node * @param left * Current considered interval left index * @param right * Current considered interval right index * @param i * values的索引值 * @param val * Value to which to update the index */ private void update(int node, int left, int right, int i, int val) { if (left == right &amp;&amp; left == i) { tree[node] = i; values[i] = val; } else { // 中间值 int mijl = (left + right) / 2; // 更新左边 if (i &lt;= mijl) { update(2 * node, left, mijl, i, val); } else {// 更新右边 update(2 * node + 1, mijl + 1, right, i, val); } // node的值是values中最小值 tree[node] = (values[tree[2 * node]] &lt; values[tree[2 * node + 1]]) ? tree[2 * node] : tree[2 * node + 1]; } } /** * 指定索引范围内数组中的最小值的索引 * * @param i * @param j * @return */ public int query(int i, int j) { return query(1, 0, values.length - 1, i, j); } /** * 更新值 */ public void update(int i, int val) { update(1, 0, values.length - 1, i, val); }} AbstractTaskProcessor123456789101112131415161718192021222324252627282930package com.fokejoin1.processor;import com.fokejoin1.model.Task;import com.fokejoin1.solver.TaskSolver;/** * 任务进程抽象类 * */public abstract class AbstractTaskProcessor { protected TaskSolver taskSolver; public AbstractTaskProcessor(TaskSolver taskSolver) { this.taskSolver = taskSolver; } /** * 任务执行 * * @param task */ public abstract void process(Task task); /** * 任务的关闭 */ public void shutdown() { }} TaskProcessorFJ1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071package com.fokejoin1.processor;import java.util.concurrent.ForkJoinPool;import java.util.concurrent.RecursiveAction;import com.fokejoin1.model.Task;import com.fokejoin1.solver.TaskSolver;/** * This is a Fork-Join processor for tasks, using a ForkJoinPool */public class TaskProcessorFJ extends AbstractTaskProcessor { private ForkJoinPool forkJoinPool; public TaskProcessorFJ(TaskSolver taskSolver) { super(taskSolver); forkJoinPool = new ForkJoinPool(); } @Override public void process(Task task) { forkJoinPool.invoke(new Subtask(task, 0, task.getOperations().size(), true)); } /** * 包装任务类 * */ private class Subtask extends RecursiveAction { private static final long serialVersionUID = 1L; /** * 需要解决的任务 */ final Task task; final int from; final int to; /** * Is this subtask == the initial task */ final boolean rootTask; public Subtask(Task task, int from, int to, boolean rootTask) { this.task = task; this.from = from; this.to = to; this.rootTask = rootTask; } @Override protected void compute() { // 如果是XS, S, M，则解决它 if (to - from &lt; Task.TaskType.L.getRange()) { taskSolver.solve(task, from, to); } else {// 如果是L, XL, XXL，拆分任务 int mid = (from + to) / 2; invokeAll(new Subtask(this.task, from, mid, false), new Subtask(this.task, mid + 1, to, false)); } //如果是XS,S,M者进入if，计数器-1 //L,XL,XXL，分支任务计数器不执行-1 //总任务计数器才-1 if (rootTask) { taskSolver.getTaskResultHandler().taskDone(task); } } }} TaskProcessorPool123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051package com.fokejoin1.processor;import java.util.concurrent.ExecutorService;import java.util.concurrent.Executors;import com.fokejoin1.model.Task;import com.fokejoin1.solver.TaskSolver;/** * This is a thread pool processor for tasks, using a fixed thread pool ExecutorService * * We spawn a pool of threads, and as soon as we have a job we submit it to the executor to process it * This should run 4 threads solving tasks in parallel. This is not as efficient as a workstealing thread pool, * because we might have one thread busy with a large task, while the others have nothing to do * */public class TaskProcessorPool extends AbstractTaskProcessor { public final int POOL_SIZE = 4; private ExecutorService threadPool; public TaskProcessorPool(TaskSolver taskSolver) { super(taskSolver); threadPool = Executors.newFixedThreadPool(POOL_SIZE); } @Override public void process(Task task) { threadPool.submit(new TaskRunnable(task)); } @Override public void shutdown() { threadPool.shutdown(); } class TaskRunnable implements Runnable { private Task task; public TaskRunnable(Task task) { this.task = task; } @Override public void run() { taskSolver.solve(task); taskSolver.getTaskResultHandler().taskDone(task); } }} TaskProcessorSimple12345678910111213141516171819202122package com.fokejoin1.processor;import com.fokejoin1.model.Task;import com.fokejoin1.solver.TaskSolver;/** * Naive implementation of a processor. * We just solve the task in the same thread, sequentially */public class TaskProcessorSimple extends AbstractTaskProcessor { public TaskProcessorSimple(TaskSolver taskSolver) { super(taskSolver); } @Override public void process(Task task) { taskSolver.solve(task); taskSolver.getTaskResultHandler().taskDone(task); }}","link":"/Fork-Join-Mode/"},{"title":"散列表","text":"1 直接寻址 2 散列表 链接法 开放寻址法 3 散列函数的设计 散列函数的需求 常见的散列函数 除法散列函数 乘法散列函数 转帖:散列表 1 直接寻址使用散列的目的是能够快速取得某个元素，那么如果能够保证每个元素都存在一个“槽”的话（类似于数组），就能够完成在O(1)的时间内完成取元素的工作。如果一个集合的元素都是取自全域U={1, 2, ... m}，那么通过使用数组T[1,...m]来保证每个元素都存在与之对应的”槽“。 2 散列表散列方式下，关键字k是放在h(k)中，显然散列表方法中最主要的是如何设计散列函数，尽可能的减少散列之间的冲突。但是散列中的冲突是无法避免的，那么常见的两种解决方法是：链接法和开放寻址法。 链接法链接法的核心思想就是冲突的元素（具有相同的h(k)）存放在链表中。 开放寻址法开放寻址法的核心思想如下：设具有关键字k的元素，通过散列函数h(x)，映射到h(k)，如果h(k)已经被占用的话，那么尝试去试探h(k)+ i，依次，直到找到一个合适位置去存放该元素。插入算法如下。查找的算法也是比较简单，先查找位置h(k)，如果不再该位置的话，通过开放寻址探查函数查找下一个位置，知道找到该元素，或者是没有找到。需要指出的是删除元素的情况，如果仅仅是简单讲该位置设为null的话，那么查找将遇到问题。如下图，如果查找5的话，首先查找到1，然后查找到3的时候，null表明已经结束，函数将返回“未找到”。解决方法就是删除时将3的位置设为特殊的标记IsDelete，然后查找时如果遇到IsDelete，那么继续向下查找。 3 散列函数的设计散列函数的需求显然如果要保证散列的高效性的话，需要将待散列的元素均匀的分布到各个槽中。 常见的散列函数除法散列函数h(k) = k mod m 乘法散列函数h(k) = [m(kA mod 1)] (0&lt;A&lt;1)","link":"/Hash-Table/"},{"title":"贪心算法","text":"1 引言 2 概念 3 基本思想 重要特性 存在问题 最大特点 4 步骤 1 引言平时购物找钱时，为了使找回零钱的硬币数最少，从最大面值的币种开始，按递减的顺序考虑币种，先尽量用大面值的币种，当不足大面值币种的金额时才去考虑下一种较小面值的币种。这就贪心算法。这种方法在这里总是最优的，是因为银行对其发行的硬币种类和硬币面值的巧妙安排。如果面值分别为1,5,11单位的硬币，而希望找回总额为15单位的硬币，按贪心算法，应该找1个11单位的硬币和4个1单位的硬币，总共找回5个硬币。但最优的解答是3个5单位面值硬币。贪心算法并不是一个具体的算法，而是一种算法的思想，或者说是解决问题一种思路。永远没有最好的算法，只有最适合的算法，我们选用贪心算法的原因就是因为它能够满足当前的需要并且比其他算法更加简单。 2 概念贪心算法并不是整体最优考虑，它所做出的选择只是在某种意义上的局部最优（总是做出在当前看来是最好的选择）。这种局部最优选择并不能保证总能获得全局最优解，但它通常可以获得较好的近似最优解。贪心算法在解决问题的策略上是仅根据当前已有的信息做出选择，而且一旦做出选择，不管将来有什么结果，这个选择不会改变。贪心算法一般在开始策略选择前会进行排序，排好序后就进行最优化选择。 3 基本思想重要特性 最优子结构：当一个问题的最优解包含其子问题的最优解时，称此问题具有最优子结构。问题具有最优子结构是该问题可以采用动态规划法或者贪心法求解的关键性质。 贪心选择性质：指问题的整体最优解可以通过一系列局部最优的选择。贪心算法则通常以自顶向下的方式进行，以迭代的方式作出相继的贪心选择，每作一次贪心选择就将所求问题简化为规模更小的子问题。通过每一步贪心选择，可得到问题的一个最优解，虽然每一步上都要保证能获得局部最优解，但由此产生的全局解有时不一定是最优的。既贪心选择来得到。这是贪心算法和动态规划法的主要区别。证明一个问题具有贪心选择性质也是贪心法的一个难点。（关键是贪心策略的选择，选择的贪心策略必须具备无后效性，即某个状态以前的过程不会影响以后的状态，只与当前状态有关。所以对所采用的贪心策略一定要仔细分析其是否满足无后效性。）贪心算法没有固定的算法框架，算法设计的关键是贪心策略的选择。存在问题 不能保证求得的最后解是最佳的。 不能用来求最大或最小解问题。 只能求满足某些约束条件的可行解的范围。最大特点就是在每一步中取最优化的解，不会回溯处理。这样的策略，自然在执行速度上更快，但是因为这种方法的短视。会导致得的解并不是真正的全局最优解，但是贪心算法得到的依然是一个近似最优解。 4 步骤 建立数学模型来描述问题。 把求解的问题分成若干个子问题。 对每一子问题求解，得到子问题的局部最优解。 把子问题的解局部最优解合成原来解问题的一个解。并且不做回溯处理。","link":"/Greedy-Algorithm/"},{"title":"华为机实题","text":"1 题目 2 解题 1 题目要求将输入的大写字母转成对应小写的后5个，如A转换后为f；如果转换后大于z则从a重新计，即多出1就转成a，多出2就转成b以此类推。 2 解题解题思路：假设输入'Z':'Z'-'A' = 25;25 + 5 = 30('E');30 % 26 = 4 (&gt;字母总数26，要从头计数); 'a' + 4 = 'e'； %26:26个英文字母，计算：与26取余多少。1234567891011121314151617public class Test1 { public static void main(String[] args) { System.out.println(t('B')); } /** * 假设输入'Z': 'Z' - 'A' = 25; 25 + 5 = 30; 30 % 26 = 4 (&gt;字母总数26，要从头计数); 'a' + 4 = 'e'; %26：26个英文字母，计算+5之后是多少。 * @param sour * @return */ public static char t(char sour) { if ('A' &gt; sour || 'Z' &lt; sour) { } return (char) ((sour - 'A' + 5) % 26 + 'a'); }}","link":"/Huawei-Interview/"},{"title":"GC输出日志分析","text":"1 verbose命令 2 JVM启动参数启用verbose GC JVM启动参数配置 log解析 年轻代空间分析 年老代空间分析 方法区空间分析 Java堆分解分析 基于JDK7 1 verbose命令Java -verbose:gc中参数-verbose:gc表示输出虚拟机中GC的详细情况。使用后输出如下：[Full GC 168K-&gt;97K(1984K)，0.0253873 secs]解读如下：箭头前后的数据168K和97K分别表示垃圾收集GC前后所有存活对象使用的内存容量，说明有168K-97K=71K的对象容量被回收，括号内的数据1984K为堆内存的总容量，收集所需要的时间是0.0253873秒（这个时间在每次执行的时候会有所不同）。 2 JVM启动参数启用verbose GC通过JVM启动参数设置来启用verbose gc，并指定了名字和gc日志文件存储路径。 JVM启动参数配置1234-XX:+PrintGCDetails -XX:+PrintGCTimeStamps(GC发生的时间) -XX:+PrintGCApplicationStoppedTime(GC消耗了多少时间) -XX:+PrintGCApplicationConcurrentTime(GC之间运行了多少时间) 1-server -Xms1024m -Xmx1024m -verbose:gc -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -Xloggc:D:/gc.log 运行程序，控制台打印JVM版本1Java 7 HotSpot Verbose GC Test Program v1.0 log文件分析：GC输出分成了3个主要部分。 5个Minor收集(年轻代收集)被标记为PSYoungGen。 2个Major收集(由System.gc()触发)被标记为Full GC。 每个内存区域的Java堆分解分析。 1234567891011121314151617181920212223Java HotSpot(TM) 64-Bit Server VM (24.76-b04) for windows-amd64 JRE (1.7.0_76-b13), built on Dec 18 2014 16:31:25 by \"java_re\" with unknown MS VC++:1600Memory: 4k page, physical 8286452k(3023144k free), swap 22905152k(11317276k free)CommandLine flags: -XX:InitialHeapSize=1073741824 -XX:MaxHeapSize=1073741824 -XX:+PrintGC -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+UseCompressedOops -XX:-UseLargePagesIndividualAllocation -XX:+UseParallelGC 0.413: [GC [PSYoungGen: 262656K-&gt;43496K(306176K)] 262656K-&gt;137856K(1005568K), 0.1518709 secs] [Times: user=0.45 sys=0.06, real=0.15 secs] 0.787: [GC [PSYoungGen: 306152K-&gt;43496K(306176K)] 400512K-&gt;277096K(1005568K), 0.2234163 secs] [Times: user=0.59 sys=0.06, real=0.22 secs] 1.143: [GC [PSYoungGen: 219344K-&gt;43496K(306176K)] 452944K-&gt;369728K(1005568K), 0.1305207 secs] [Times: user=0.39 sys=0.03, real=0.13 secs] 1.274: [Full GC [PSYoungGen: 43496K-&gt;0K(306176K)] [ParOldGen: 326232K-&gt;368338K(699392K)] 369728K-&gt;368338K(1005568K) [PSPermGen: 2576K-&gt;2575K(21504K)], 2.7245170 secs] [Times: user=6.93 sys=0.00, real=2.72 secs] 4.309: [GC [PSYoungGen: 262656K-&gt;32K(306176K)] 630994K-&gt;368370K(1005568K), 0.0343405 secs] [Times: user=0.09 sys=0.00, real=0.03 secs] 4.453: [GC [PSYoungGen: 113899K-&gt;0K(306176K)] 482237K-&gt;368338K(1005568K), 0.0239018 secs] [Times: user=0.09 sys=0.00, real=0.02 secs] 4.477: [Full GC [PSYoungGen: 0K-&gt;0K(306176K)] [ParOldGen: 368338K-&gt;134041K(699392K)] 368338K-&gt;134041K(1005568K) [PSPermGen: 2576K-&gt;2576K(21504K)], 0.3736071 secs] [Times: user=1.01 sys=0.00, real=0.37 secs] Heap PSYoungGen total 306176K, used 5253K [0x00000000eaa80000, 0x0000000100000000, 0x0000000100000000) eden space 262656K, 2% used [0x00000000eaa80000,0x00000000eafa1540,0x00000000fab00000) from space 43520K, 0% used [0x00000000fab00000,0x00000000fab00000,0x00000000fd580000) to space 43520K, 0% used [0x00000000fd580000,0x00000000fd580000,0x0000000100000000) ParOldGen total 699392K, used 134041K [0x00000000bff80000, 0x00000000eaa80000, 0x00000000eaa80000) object space 699392K, 19% used [0x00000000bff80000,0x00000000c82665f0,0x00000000eaa80000) PSPermGen total 21504K, used 2583K [0x00000000bad80000, 0x00000000bc280000, 0x00000000bff80000) object space 21504K, 12% used [0x00000000bad80000,0x00000000bb005f20,0x00000000bc280000) 从verbose GC的第1次Full GC输出你可以看到，ParOldGen（老年代）空间在初始加载了320万字符串实例到HashMap后达到了360M。在移除了200万字符串实例后下降到了134M。说明ParOldGen（老年代）在执行GC操作。 log解析10.413（0）：[GC（1） [PSYoungGen（2）: 262656K（3）-&gt;43496K(306176K)（4）] 262656K（5）-&gt;137856K(1005568K)（6）, 0.1518709（7） secs] [Times: user=0.45（8） sys=0.06（9）, real=0.15 secs（10）] （Allocation Failure）：引起垃圾回收的原因。本次GC是因为年轻代中没有任何合适的区域能够存放需要分配的数据结构而触发的。 GC时间的开始时间，相对于JVM的启动时间，单位是秒(Measured in seconds)。 用来区分(distinguish)是Minor GC还是Full GC的标志Flag。这里的GC表明本次发生的是Minor GC。 使用的垃圾收集器的名字。这里采用并行垃圾收集器（Throughput Collector）。 年轻代垃圾收集前占用内存。 年轻代垃圾收集后占用内存。 年轻代的总大小。 堆内存垃圾收集前占用内存。 堆内存垃圾收集后占用内存。 此次垃圾回收, 垃圾收集线程消耗的所有CPU时间(Total CPU time)。 操作系统调用(OS call) 以及等待系统事件的时间(waiting for system event)。 应用程序暂停的时间(Clock time)，由于串行垃圾收集器(Serial Garbage Collector)只会使用单个线程，所以Rreal Time等于user以及System Time的总和。年轻代空间分析10.413: [GC [PSYoungGen: 262656K-&gt;43496K(306176K)] 262656K-&gt;137856K(1005568K), 0.1518709 secs] [Times: user=0.45 sys=0.06, real=0.15 secs] 0.413：收集时间 PSYoungGen：收集类型 262656K：垃圾收集GC前存活对象使用的内存容量 43496K：垃圾收集GC后存活对象使用的内存容量 306176K：年轻代堆内存的总容量 年老代空间分析11.274: [Full GC [PSYoungGen: 43496K-&gt;0K(306176K)] [ParOldGen: 326232K-&gt;368338K(699392K)] 369728K-&gt;368338K(1005568K) [PSPermGen: 2576K-&gt;2575K(21504K)], 2.7245170 secs] [Times: user=6.93 sys=0.00, real=2.72 secs] 1.274：收集时间 ParOldGen：收集类型 326232K：垃圾收集GC前存活对象使用的内存容量 368338K：垃圾收集GC后存活对象使用的内存容量 699392K：老年代堆内存的总容量 方法区空间分析11.274: [Full GC [PSYoungGen: 43496K-&gt;0K(306176K)] [ParOldGen: 326232K-&gt;368338K(699392K)] 369728K-&gt;368338K(1005568K) [PSPermGen: 2576K-&gt;2575K(21504K)], 2.7245170 secs] [Times: user=6.93 sys=0.00, real=2.72 secs] 1.274：收集时间 PSPermGen：收集类型 2576K：垃圾收集GC前存活对象使用的内存容量 2575K：垃圾收集GC后存活对象使用的内存容量 21504K：方法区堆内存的总容量Java堆分解分析123456789Heap PSYoungGen total 306176K, used 5253K [0x00000000eaa80000, 0x0000000100000000, 0x0000000100000000) eden space 262656K, 2% used [0x00000000eaa80000,0x00000000eafa1540,0x00000000fab00000) from space 43520K, 0% used [0x00000000fab00000,0x00000000fab00000,0x00000000fd580000) to space 43520K, 0% used [0x00000000fd580000,0x00000000fd580000,0x0000000100000000) ParOldGen total 699392K, used 134041K [0x00000000bff80000, 0x00000000eaa80000, 0x00000000eaa80000) object space 699392K, 19% used [0x00000000bff80000,0x00000000c82665f0,0x00000000eaa80000) PSPermGen total 21504K, used 2583K [0x00000000bad80000, 0x00000000bc280000, 0x00000000bff80000) object space 21504K, 12% used [0x00000000bad80000,0x00000000bb005f20,0x00000000bc280000) 年轻代：eden，survive0，survive1老年代方法区","link":"/GC-LOG/"},{"title":"日语学习计划","text":"1 学习常识 50音图。 随教材 最好跟班学，自学的话也要跟视频讲座学。 与此同时，背单词啊，看动漫 听听力啊 这些实践的。 有点实力了，就去一些日本的网站啊，看看明星博客啊，体育新闻，政经新闻啥的，锻炼锻炼。 2 自学步骤供参考 买一套自学教材。 备齐工具书（如词典、语法书等）。 先学每课单词，大声朗读。 再看每课后的语法、句型讲解并熟记、掌握。 大声朗读课文，注意新单词、语法在课文中的运用。 做一下每课配套练习。 遇到不明白问题上日语论坛提问。 坚持记单词、多读课文，多看看日剧或动漫影视。有兴趣的话找一位一同学日语的朋友，互相用日语简单会。 3 制定学习计划 语音部分（五十音图）一个星期搞定。平均每天学时8小时（注：那时我是脱产学习的，根据你的实际情况，可以适当调整好学习时间）。 正文学习部分。平均1.5天/1课学习。步骤： 先把单词部分看一遍，在根据后面的注音大声朗读一遍。再抄写一遍（注：日语的单词后面有个音标符号，这个符号决定你今后的日语发音是否正确是否好听！）。 课文部分听一遍磁带并跟着念（最好是复读机）。 独立朗读一两遍课文。 把后面的练习部分做完（这一步很重要！！！因为这里可以学到很多课文中学不到的）。 看着课文把中文译文一字不漏的把日语部分写出来，反过来再同样操作一遍。 这样，一课就能算是过了。 同时还建议你多听一些日语广播或看一些日语情景剧，虽然不一定懂意思，但是对培养你的语感是很有帮助的（我当时就这样）。 日语广播频率：中波AM——华南——630KHZ调频FM——广州——106.6MHZ 4 学习方法如何入门、如何打下扎实的基础至关重要。那么，如何才能很快的入进日语的门，尽快打开你的耳朵、眼睛、嘴巴、和大脑呢？下面提出五点建议，希望能对日语初级者有一些帮助。 建议一：一定要多听。这个多听指的是一种最泛泛的听，不惯是洗漱、吃饭、坐公交车任何时间都可以，初期听五十音图，也可以听课本，听不懂说的是什么也没关系，要的就是让日语的声音一直围绕在你的身边往耳朵里钻，慢慢的你就可以培养起日语的语感了，为下面进入日语学习做好准备工作。相关：初学者学好日语五十音图方法总结。 建议二：一定要多读。日语的发音和中文发音口型不同，面部肌肉的运动也不尽相同，多读可以让你尽快的适应日语发音的感觉。（小编经验，在刚接触日语发音时，如果练习的时间足够长，你会发现两遍的腮会很痛） 建议三：听读结合反复练。读和听是两个不能分割的部分，在反复读时，你要认真的听自己的发音对不对，准不准。反复听，才能把你错误的发音纠正过来。 建议四：重点记忆日语单词。学习的初期，语法知识并不多，关键是记忆单词。记忆日语单词讲究的是在不经意间反复记忆。按照人类的记忆曲线，反复记忆单词。相关：艾宾浩斯遗忘曲线日语单词记忆法。 建议五：抄写、阅读日本原作的文章。这是个一举多得的练习方法。一边抄写还要一边朗读，不仅可以培养你的语感，有助于记忆单词，还可以提高你的日语口语能力。很多通过日语能力一级的同学总结自己合格经验之一就是多看日语原文的文章，不管是小说、新闻还是网上资源，长久以往日语的能力便会无形中有所提高。 5 学日语的口诀 学习日语不能急，慢慢悠悠出才子， 一天三词一个句，一年就是一千词， 三年学会九百句，胜过大专没问题。 学习日语不能听，开口才能练真功， 一词读上一百遍，一分钟内可搞完， 听力凭的是机器，无法练成铁嘴皮。 日语敬语特别难，日本人也很为难， 何况我们异国人，抛在脑后先别问， 抓住简体练半年，再练敬语也不完。 语句子有特点，就像农民垒砖墙， 句子主干是单词，助词粘单词的泥， 初学不要讲顺序，能粘一起就表意。 动词简单有规律，变变词尾就可以， 自动他动分两类，他动及物宾语追， 自动无宾也无悔，“方向”“对象”配成对。 五十音图八卦阵，既可表意又表音， 十行五段要记心，当心邻居什么人， 顺序方位都要记，动词变化全在里。 最后再次强调读，耳熟能详全靠读， 为何1加1熟练，不是简单是熟练， 不管单词有多难，读上百遍自熟练。","link":"/Japanese-Language-Study-Plan/"},{"title":"中缀表达式转换为后缀表达式","text":"1 算法 2 Java 1 算法中缀表达式转后缀表达式的方法： 遇到操作数：直接输出（添加到后缀表达式中） 栈为空时，遇到运算符，直接入栈 遇到左括号：将其入栈 遇到右括号：执行出栈操作，并将出栈的元素输出，直到弹出栈的是左括号，左括号不输出。 遇到其他运算符：加减乘除：弹出所有优先级大于或者等于该运算符的栈顶元素【栈内的栈顶运算符&gt;=遇到的运算符，就弹出】，然后将该运算符入栈 最终将栈中的元素依次出栈，输出。 实现中缀表达式转换为后缀表达式主要包含三个类，一个主函数，一个自定义栈的类，还有一个就是核心类，实现其转换。 2 Java输入的表达式为：A(B+C)-D/(E+F)执行的结果如下：请输入算术表达式：A(B+C)-D/(E+F)for A Stack (bottom–&gt;top):for Stack (bottom–&gt;top):for ( Stack (bottom–&gt;top): for B Stack (bottom–&gt;top): (for + Stack (bottom–&gt;top): (for C Stack (bottom–&gt;top): ( +for ) Stack (bottom–&gt;top): ( +for - Stack (bottom–&gt;top): for D Stack (bottom–&gt;top): -for / Stack (bottom–&gt;top): -for ( Stack (bottom–&gt;top): - /for E Stack (bottom–&gt;top): - / (for + Stack (bottom–&gt;top): - / (for F Stack (bottom–&gt;top): - / ( +for ) Stack (bottom–&gt;top): - / ( +While Stack (bottom–&gt;top): - /While Stack (bottom–&gt;top): -end while!! Stack (bottom–&gt;top):Profix is ABC+DEF+/- 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public class MyStack { private int maxSize;//栈的最大容量 private char[] ch; //栈的数据 private int top; //栈头标记 public MyStack(int s) { maxSize = s; ch = new char[s]; top = -1; } public void push(char c) {//入栈 ch[++top] = c; } public char pop() {//出栈 return ch[top--]; } public char peek() { return ch[top]; } public boolean isEmpty() { return top == -1; } public boolean isFull() { return top == (maxSize - 1); } public int size() { return top + 1; } public char get(int index) { return ch[index]; } public void display(String str) { System.out.print(str); System.out.print(\" Stack (bottom--&gt;top): \"); for (int i = 0; i &lt; size(); i++) { System.out.print(get(i)+\" \"); } System.out.println(); } } 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687public class InToPost { private MyStack ms;//自定义栈 private String input;//输入中缀表达式 private String output=\"\";//输出的后缀表达式 public InToPost(String input) { this.input = input; int size = input.length(); ms = new MyStack(size); } public String doTrans() {//转换为后缀表达式方法 for (int i = 0; i &lt; input.length(); i++) { char ch = input.charAt(i); ms.display(\"for \" + ch + \" \"); switch (ch) { case '+': case '-': getOper(ch, 1); break; case '*': case '/': getOper(ch, 2); break; case '(': ms.push(ch); break; case ')': getParent(ch); break; default: output = output + ch; break; }//end switch }//end for while(!ms.isEmpty()){ ms.display(\"While \"); output=output+ms.pop(); } ms.display(\"end while!!\"); return output; } /** * @param ch * 获得上一级字符串 */ public void getParent(char ch) { while(!ms.isEmpty()){ char chx=ms.pop(); if(chx=='('){ break; }else{ output=output+chx; } } } /** * @param ch 操作符 * @param prec1 操作符的优先级 * 根据操作符的优先级判断是否入栈，及入栈的顺序 */ public void getOper(char ch, int prec1) { while (!ms.isEmpty()) {//判断栈是否为空 char operTop = ms.pop(); if (operTop == '(') { ms.push(operTop); break; } else { int prec2; if (operTop == '+' || operTop == '-') { prec2 = 1; } else { prec2 = 2; } if (prec2 &lt;prec1) { ms.push(operTop); break; } else { output = output + operTop; } } }// end while ms.push(ch); } } 1234567891011121314151617181920212223242526public class InfixMain { public static void main(String[] args) { String input, output; while (true) { input = getString(); if (\"\".equals(input) || input == null) { break; } InToPost itp = new InToPost(input); output = itp.doTrans(); System.out.println(\"Profix is \" + output + \"\\n\"); } } public static String getString() { String output = \"\"; BufferedReader br = new BufferedReader(new InputStreamReader(System.in)); try { System.out.println(\"请输入算术表达式：\"); output = br.readLine(); } catch (IOException e) { e.printStackTrace(); } return output; } }","link":"/Infix-Expression-Is-Converted-To-A-Postfix-Expression/"},{"title":"Java Copy-On-Write并发优化策略","text":"1 基础知识 1.1 CopyOnWrite容器 2 实现原理 CopyOnWriteArrayList源码 CopyOnWriteArrayList#add() CopyOnWriteArrayList#get() 实现简单的CopyOnWriteMap 3 应用场景 3.1 需要注意两件事情 4 缺点 内存占用问题 数据一致性问题 1 基础知识Copy-On-Write简称COW，是一种用于程序设计中的优化策略。开始都在共享同一个内容，当想要修改这个内容的时候，才会真正把内容Copy出去形成一个新的内容然后再改，这是一种延时懒惰策略。 1.1 CopyOnWrite容器CopyOnWrite容器即写时复制的容器。通俗的理解：往一个容器添加元素的时候，不直接往当前容器添加，而是先将当前容器进行Copy，复制出一个新的容器，然后新的容器里添加元素，添加完元素之后，再将原容器的引用指向新的容器。这样做的好处是可以对CopyOnWrite容器进行并发的读，而不需要加锁，因为当前容器不会添加任何元素。（但是读取的数据会有延迟）所以CopyOnWrite容器也是一种读写分离的思想，读和写不同的容器。目的是为了提高并发能力。 2 实现原理CopyOnWriteArrayList源码CopyOnWriteArrayList#add()向ArrayList里添加元素，可以发现在添加的时候是需要加锁的，否则多线程写的时候会Copy出N个副本出来。123456789101112131415161718192021public boolean add(T e) { final ReentrantLock lock = this.lock; lock.lock(); try { Object[] elements = getArray(); int len = elements.length; // 复制出新数组 Object[] newElements = Arrays.copyOf(elements, len + 1); // 把新元素添加到新数组里 newElements[len] = e; // 把原数组引用指向新数组 setArray(newElements); return true; } finally { lock.unlock(); }} final void setArray(Object[] a) { array = a;} CopyOnWriteArrayList#get()读的时候不需要加锁，如果读的时候有多个线程正在向ArrayList添加数据，读还是会读到旧的数据，因为写的时候不会锁住旧的ArrayList。（懒或者延迟加载机制）123public E get(int index) { return get(getArray(), index);} 实现简单的CopyOnWriteMap根据Copy-On-Write策略，实现一个简单的CopyOnWriteMap。1234567891011121314151617181920212223242526272829303132import java.util.Collection;import java.util.Map;import java.util.Set;public class CopyOnWriteMap&lt;K, V&gt; implements Map&lt;K, V&gt;, Cloneable { private volatile Map&lt;K, V&gt; internalMap; public CopyOnWriteMap() { internalMap = new HashMap&lt;K, V&gt;(); } public V put(K key, V value) { synchronized (this) { Map&lt;K, V&gt; newMap = new HashMap&lt;K, V&gt;(internalMap); V val = newMap.put(key, value); internalMap = newMap; return val; } } public V get(Object key) { return internalMap.get(key); } public void putAll(Map&lt;? extends K, ? extends V&gt; newData) { synchronized (this) { Map&lt;K, V&gt; newMap = new HashMap&lt;K, V&gt;(internalMap); newMap.putAll(newData); internalMap = newMap; } }} 3 应用场景CopyOnWrite并发容器用于读多写少的并发场景。比如：白名单，黑名单，商品类目的访问和更新场景，假如我们有一个搜索网站，用户在这个网站的搜索框中，输入关键字搜索内容，但是某些关键字不允许被搜索。这些不能被搜索的关键字会被放在一个黑名单当中，黑名单每天晚上更新一次。当用户搜索时，会检查当前关键字在不在黑名单当中，如果在，则提示不能搜索。 3.1 需要注意两件事情 减少扩容开销。 使用批量添加。因为每次添加，容器每次都会进行复制，所以减少添加次数，可以减少容器的复制次数。4 缺点CopyOnWrite容器有很多优点，但是同时也存在两个问题，即内存占用问题和数据一致性问题。 内存占用问题因为CopyOnWrite的写时复制机制，所以在进行写操作的时候，内存里会同时驻扎两个对象的内存，旧的对象和新写入的对象（注意:在复制的时候只是复制容器里的引用，只是在写的时候会创建新对象添加到新容器里，而旧容器的对象还在使用，所以有两份对象内存）。如果这些对象占用的内存比较大，比如说200M左右，那么再写入100M数据进去，内存就会占用300M，那么这个时候很有可能造成频繁的Yong GC和Full GC。针对内存占用问题，可以通过压缩容器中的元素的方法来减少大对象的内存消耗，比如，如果元素全是10进制的数字，可以考虑把它压缩成36进制或64进制。或者不使用CopyOnWrite容器，而使用其他的并发容器，如ConcurrentHashMap。数据一致性问题CopyOnWrite容器只能保证数据的最终一致性，不能保证数据的实时一致性。（写入的时候是copy一份出来，读取是读老的数据）所以如果希望写入的的数据，马上能读到，请不要使用CopyOnWrite容器。","link":"/Java-Copy-On-Write/"},{"title":"完全背包问题(贪心算法)","text":"1 概述 2 解题思路 2.1 选择价值最大的物品，放入背包。 2.2 选择重量最轻的物品，放入背包。 2.3 单位重量价值最大的物品，放入背包。 3 程序代码 伪代码 Java代码 C++代码 1 概述给定N个物品和一个容量为C的背包，物品i的重量是Wi，其价值为Vi，背包问题是如何选择入背包的物品，使得装入背包的物品的总价值最大，但不能超过总容量。在背包问题中可以将物品的一部分装入背包（物品可以拆分的装入背包），但不能重复装入。 2 解题思路用贪心法求解背包问题的关键是如何选定贪心策略，使得按照一定的顺序选择每个物品，并尽可能的装入背包，直到背包装满。至少有三种看似合适的贪心策略。 2.1 选择价值最大的物品，放入背包。因为这可以尽可能快的增加背包的总价值，但是，虽然每一步选择获得了背包价值的极大增长，但背包容量却可能消耗的太快，使得装入背包的物品个数减少，从而不能保证目标函数达到最大。 2.2 选择重量最轻的物品，放入背包。因为这可以装入尽可能多的物品，从而增加背包的总价值。但是，虽然每一步选择使背包的容量消耗的慢了，但背包的价值却没能保证迅速的增长，从而不能保证目标函数达到最大。 2.3 单位重量价值最大的物品，放入背包。最大价值和最大重量两种贪心策略或者只考虑背包价值的增长，或者只考虑背包容量的消耗，而为了求得背包问题的最优解，需要在背包价值增长和背包容量消耗二者之间寻找平衡。正确的贪心策略是选择单位重量价值最大的物品。例如：有三个物品，其重量分别为{20,30,10}，价值分别为{60,120,50}，背包的容量为50，应用三种贪心策略装入背包的物品和获得的价值如下图所示： 3 程序代码程序思想：首先计算每种物品单位重量的价值Vi/Wi，然后，依贪心选择策略，将尽可能多的单位重量价值最高的物品装入背包。若将这种物品全部装入背包后，背包内的物品总重量未超过C，则选择单位重量价值次高的物品并尽可能多地装入背包。依此策略一直地进行下去，直到背包装满为止。 伪代码1234567891011Knapsack(v,w,W,x,n) x &lt;- 0 c &lt;- W for i &lt;- 1 to n do if w[i] ≤ c then x[i] &lt;- 1 c &lt;- c - w[i] if i ≤ n then x[i] &lt;- c/w[i]return x 对N个物品按其单位重量价值从大到小进行排序，排序的时间复杂度为O(nlog2n)，整个算法最耗时的也是这个排序。 Java代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134package demo1;/** * 按照单位价值最高来计算 * 贪心算法解决 背包问题 非0/1背包 * @author Administrator * */public class Knapsack { private float m; // 背包容量 private float[] v; // 三个物品的价值 private float[] w; // 三个物品的质量 private float[] x; // 物品在背包中占的比例 private int n; // 物品个数 double[] p_w_v; // 每个物品的单位重量价值 public static void main(String[] args) throws Exception { Knapsack ksp = new Knapsack(); /*ksp.sort(ksp.n, ksp.v, ksp.w); System.out.println(\"w：\"); for (int i = 0; i &lt; ksp.w.length; i++) { System.out.print(ksp.w[i] + \" \"); } System.out.println(); System.out.println(\"v：\"); for (int i = 0; i &lt; ksp.v.length; i++) { System.out.print(ksp.v[i] + \" \"); }*/ ksp.knapsack(); } public Knapsack() { this.m = 50.0f; // 背包容量为50 this.v = new float[] { 60.0f, 120.0f, 50.0f }; // 三个物品的价值分别为60,120,100 this.w = new float[] { 10.0f, 30.0f, 20.0f }; // 三个物品的质量分别是10,30,20 this.x = new float[3]; // 往背包装东西的比例 this.n = 3; // 三个物品 this.p_w_v = new double[n]; // 每个物品的单位重量价值 } // 对物品的单位重量价值进行排序 public void sort(int n, float[] v, float[] w) throws Exception { //计算物品重量平均价值 for (int i = 0; i &lt; n; i++) { p_w_v[i] = v[i] / w[i]; } System.out.println(\"单位重量价值：\"); print(p_w_v); System.out.println(\"\"); insertSort(p_w_v, w, v); print(p_w_v); } // 打印输出数组 public void print(double a[]) { int len = a.length; for (int i = 0; i &lt; len; i++) { System.out.print(a[i] + \" \"); } } // 打印输出数组 public void print(String str) { System.out.println(str); } /** * 从大到小排序：根据单位重量的价值，把质量和价值从大到小排序 * * @param a 每个物品的单位重量价值 * @param b 三个物品的质量分别是10,30,20 * @param c 三个物品的价值分别为60,120,100 */ public void insertSort(double[] a, float[] b, float[] c) {// 排序静态函数，实现排序功能 int len = a.length;// 获得数组长度 double temp;// 临时变量，用于交换值 float w_temp; float v_temp; // 从大到小排序 for (int i = 0; i &lt; len - 1; i++) { for (int j = 0; j &lt; len - 1 - i; j++) { if (a[j + 1] &gt; a[j]) { // 如果后一下值比前一个值大，则交换两个值的大小， temp = a[j + 1]; w_temp = w[j + 1]; v_temp = v[j + 1]; a[j + 1] = a[j]; w[j + 1] = w[j]; v[j + 1] = v[j]; w[j] = w_temp; v[j] = v_temp; a[j] = temp; } } } } // 贪心算法核心思想 public void knapsack() throws Exception { sort(n, v, w); int i; for (i = 0; i &lt; n; i++) { x[i] = 0; } //重量 float c = m; //遍历物品数目 for (i = 0; i &lt; n; i++) { //大于剩余重量，退出循环 if (w[i] &gt; c) { break; } //i物品，100%放入背包里 x[i] = 1; //剩余的重量 c -= w[i]; } //计算超重的那个物品，占比例 if (i &lt; n) { x[i] = c / w[i]; } System.out.println(); print(\"物品一可以装入的比例: \" + x[0]); print(\"物品二可以装入的比例: \" + x[1]); print(\"物品三可以装入的比例: \" + x[2]); print(\"可以装入的最大价值为: \" + (x[0] * v[0] + x[1] * v[1] + x[2] * v[2])); print(\"可以装入的最大重量为\" + (x[0] * w[0] + x[1] * w[1] + x[2] * w[2])); }} C++代码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162//4d2 贪心算法 背包问题#include \"stdafx.h\"#include &lt;iostream&gt; using namespace std; const int N = 3;void Knapsack(int n,float M,float v[],float w[],float x[]);int main(){ float M = 50;//背包所能容纳的重量 //这里给定的物品按单位价值减序排序 float w[] = {0,10,20,30};//下标从1开始 float v[] = {0,60,100,120}; float x[N+1]; cout&lt;&lt;\"背包所能容纳的重量为：\"&lt;&lt;M&lt;&lt;endl; cout&lt;&lt;\"待装物品的重量和价值分别为：\"&lt;&lt;endl; for(int i=1; i&lt;=N; i++) { cout&lt;&lt;\"[\"&lt;&lt;i&lt;&lt;\"]:(\"&lt;&lt;w[i]&lt;&lt;\",\"&lt;&lt;v[i]&lt;&lt;\")\"&lt;&lt;endl; } Knapsack(N,M,v,w,x); cout&lt;&lt;\"选择装下的物品比例如下：\"&lt;&lt;endl; for(int i=1; i&lt;=N; i++) { cout&lt;&lt;\"[\"&lt;&lt;i&lt;&lt;\"]:\"&lt;&lt;x[i]&lt;&lt;endl; } return 0;}void Knapsack(int n,float M,float v[],float w[],float x[]){ //Sort(n,v,w);//这里假定w[],v[]已按要求排好序 int i; for (i=1;i&lt;=n;i++) { x[i]=0;//初始化数组x[] } float c=M; for (i=1;i&lt;=n;i++)//物品整件被装下,x[i]=1 { if (w[i]&gt;c) { break; } x[i]=1; c-=w[i]; } //物品i只有部分被装下 if (i&lt;=n) { x[i]=c/w[i]; }}","link":"/Full-Backpack-Problem/"},{"title":"倒排索引(反向索引)","text":"1 文档矩阵 2 倒排索引基本概念 2.1 文档(Document) 2.2 文档集合(Document Collection) 2.3 文档编号(Document ID) 2.4 单词编号(Word ID) 2.5 倒排索引(Inverted Index) 2.6 单词词典(Lexicon) 2.7 倒排列表(PostingList) 2.8 倒排文件(Inverted File) 3 倒排索引 4 倒排列表 5 倒排索引简单实例 6 单词词典 哈希加链表 树形结构 7 索引更新 7.1 完全重建策略 7.2 再合并策略 7.3 原地更新策略 7.4 混合策略 1 文档矩阵单词-文档矩阵是表达两者之间所具有的一种包含关系的概念模型。图的每列代表一个文档，每行代表一个单词，打对勾的位置代表包含关系。从纵向即文档这个维度来看，每列代表文档包含了哪些单词，比如文档1包含了词汇1和词汇4，而不包含其它单词。从横向即单词这个维度来看，每行代表了哪些文档包含了某个单词。比如对于词汇1来说，文档1和文档4中出现过单词1，而其它文档不包含词汇1。矩阵中其它的行列也可作此种解读。搜索引擎的索引其实就是实现“单词-文档矩阵”的具体数据结构。可以有不同的方式来实现上述概念模型，比如“倒排索引”、“签名文件”、“后缀树”等方式。但是各项实验数据表明，“倒排索引”是实现单词到文档映射关系的最佳实现方式。 2 倒排索引基本概念2.1 文档(Document)一般搜索引擎的处理对象是互联网网页，而文档这个概念要更宽泛些，代表以文本形式存在的存储对象，相比网页来说，涵盖更多种形式，比如Word，PDF，html，XML等不同格式的文件都可以称之为文档。再比如一封邮件，一条短信，一条微博也可以称之为文档。在本书后续内容，很多情况下会使用文档来表征文本信息。 2.2 文档集合(Document Collection)由若干文档构成的集合称之为文档集合。比如海量的互联网网页或者说大量的电子邮件都是文档集合的具体例子。 2.3 文档编号(Document ID)在搜索引擎内部，会将文档集合内每个文档赋予一个唯一的内部编号，以此编号来作为这个文档的唯一标识，这样方便内部处理，每个文档的内部编号即称之为“文档编号”，后文有时会用DocID来便捷地代表文档编号。 2.4 单词编号(Word ID)与文档编号类似，搜索引擎内部以唯一的编号来表征某个单词，单词编号可以作为某个单词的唯一表征。 2.5 倒排索引(Inverted Index)倒排索引是实现“单词-文档矩阵”的一种具体存储形式，通过倒排索引，可以根据单词快速获取包含这个单词的文档列表。倒排索引主要由两个部分组成：“单词词典”和“倒排文件”。 2.6 单词词典(Lexicon)搜索引擎的通常索引单位：单词。单词词典是由文档集合中出现过的所有单词构成的字符串集合，单词词典内每条索引项记载单词本身的一些信息以及指向“倒排列表”的指针。 2.7 倒排列表(PostingList)倒排列表记载了出现过某个单词的所有文档的文档列表及单词在该文档中出现的位置信息，每条记录称为一个倒排项(Posting)。根据倒排列表，即可获知哪些文档包含某个单词。 2.8 倒排文件(Inverted File)所有单词的倒排列表往往顺序地存储在磁盘的某个文件里，这个文件即被称之为倒排文件，倒排文件是存储倒排索引的物理文件。 3 倒排索引倒排索引有两种不同的反向索引形式： 一条记录的水平反向索引（或者反向档案索引）包含每个引用单词的文档的列表。 一个单词的水平反向索引（或者完全反向索引）又包含每个单词在一个文档中的位置。 后者的形式提供了更多的兼容性（比如短语搜索），但是需要更多的时间和空间来创建。现代搜索引起的索引都是基于倒排索引。相比“签名文件”、“后缀树”等索引结构，“倒排索引”是实现单词到文档映射关系的最佳实现方式和最有效的索引结构。 4 倒排列表倒排列表用来记录有哪些文档包含了某个单词。一般在文档集合里会有很多文档包含某个单词，每个文档会记录文档编号（DocID），单词在这个文档中出现的次数（TF）及单词在文档中哪些位置出现过等信息，这样与一个文档相关的信息被称做倒排索引项（Posting），包含这个单词的一系列倒排索引项形成了列表结构，这就是某个单词对应的倒排列表。下图是倒排列表的示意图，在文档集合中出现过的所有单词及其对应的倒排列表组成了倒排索引。在实际的搜索引擎系统中，并不存储倒排索引项中的实际文档编号，而是代之以文档编号差值（D-Gap）。文档编号差值是倒排列表中相邻的两个倒排索引项文档编号的差值，一般在索引构建过程中，可以保证倒排列表中后面出现的文档编号大于之前出现的文档编号，所以文档编号差值总是大于0的整数。如下图所示的例子中，原始的 3个文档编号分别是187、196和199，通过编号差值计算，在实际存储的时候就转化成了：187、9、3。之所以要对文档编号进行差值计算，主要原因是为了更好地对数据进行压缩，原始文档编号一般都是大数值，通过差值计算，就有效地将大数值转换为了小数值，而这有助于增加数据的压缩率。 5 倒排索引简单实例倒排索引从逻辑结构和基本思路上来讲非常简单。假设文档集合包含五个文档，每个文档内容如图，在图中最左端一栏是每个文档对应的文档编号。我们的任务就是对这个文档集合建立倒排索引。中文和英文等语言不同，单词之间没有明确分隔符号，所以首先要用分词系统将文档自动切分成单词序列。这样每个文档就转换为由单词序列构成的数据流，为了系统后续处理方便，需要对每个不同的单词赋予唯一的单词编号，同时记录下哪些文档包含这个单词，在如此处理结束后，我们可以得到最简单的倒排索引（如图）。在图中，“单词ID”一栏记录了每个单词的单词编号，第二栏是对应的单词，第三栏即每个单词对应的倒排列表。比如单词“谷歌”，其单词编号为1，倒排列表为{1,2,3,4,5}，说明文档集合中每个文档都包含了这个单词。上图所示倒排索引是最简单的，是因为这个索引系统只记载了哪些文档包含某个单词，而事实上，索引系统还可以记录除此之外的更多信息。下图是一个相对复杂些的倒排索引，与上图的基本索引系统比，在单词对应的倒排列表中不仅记录了文档编号，还记载了单词频率信息（TF），即这个单词在某个文档中的出现次数，之所以要记录这个信息，是因为词频信息在搜索结果排序时，计算查询和文档相似度是很重要的一个计算因子，所以将其记录在倒排列表中，以方便后续排序时进行分值计算。在下图的例子里，单词“创始人”的单词编号为7，对应的倒排列表内容为：（3:1），其中的3代表文档编号为3的文档包含这个单词，数字1代表词频信息，即这个单词在3号文档中只出现过1次，其它单词对应的倒排列表所代表含义与此相同。实用的倒排索引还可以记载更多的信息，索引系统除了记录文档编号和单词频率信息外，额外记载了两类信息，即每个单词对应的“文档频率信息”以及在倒排列表中记录单词在某个文档出现的位置信息。“文档频率信息”代表了在文档集合中有多少个文档包含某个单词，之所以要记录这个信息，其原因与单词频率信息一样，这个信息在搜索结果排序计算中是非常重要的一个因子。而单词在某个文档中出现的位置信息并非索引系统一定要记录的，在实际的索引系统里可以包含，也可以选择不包含这个信息，之所以如此，因为这个信息对于搜索系统来说并非必需的，位置信息只有在支持“短语查询”的时候才能够派上用场。以单词“拉斯”为例，其单词编号为8，文档频率为2，代表整个文档集合中有两个文档包含这个单词，对应的倒排列表为：{(3;1;&lt;4&gt;)，(5;1;&lt;4&gt;)},其含义为在文档3和文档5出现过这个单词，单词频率都为1，单词“拉斯”在两个文档中的出现位置都是4，即文档中第四个单词是“拉斯”。实际搜索系统的索引结构基本如此，区别无非是采取哪些具体的数据结构来实现上述逻辑结构。有了这个索引系统，搜索引擎可以很方便地响应用户的查询，比如用户输入查询词“Facebook”，搜索系统查找倒排索引，从中可以读出包含这个单词的文档，这些文档就是提供给用户的搜索结果，而利用单词频率信息、文档频率信息即可以对这些候选搜索结果进行排序，计算文档和查询的相似性，按照相似性得分由高到低排序输出，此即为搜索系统的部分内部流程。 6 单词词典单词词典是倒排索引中非常重要的组成部分，它用来维护文档集合中出现过的所有单词的相关信息，同时用来记载某个单词对应的倒排列表在倒排文件中的位置信息。在支持搜索时，根据用户的查询词，去单词词典里查询，就能够获得相应的倒排列表，并以此作为后续排序的基础。对于一个规模很大的文档集合来说，可能包含几十万甚至上百万的不同单词，能否快速定位某个单词，这直接影响搜索时的响应速度，所以需要高效的数据结构来对单词词典进行构建和查找，常用的数据结构包括哈希加链表结构和树形词典结构。 哈希加链表主体部分是哈希表，每个哈希表项保存一个指针，指针指向冲突链表，在冲突链表里，相同哈希值的单词形成链表结构。之所以会有冲突链表，是因为两个不同单词获得相同的哈希值，如果是这样，在哈希方法里被称做是一次冲突，可以将相同哈希值的单词存储在链表里，以供后续查找。在建立索引的过程中，词典结构也会相应地被构建出来。比如在解析一个新文档的时候，对于某个在文档中出现的单词T，首先利用哈希函数获得其哈希值，之后根据哈希值对应的哈希表项读取其中保存的指针，就找到了对应的冲突链表。如果冲突链表里已经存在这个单词，说明单词在之前解析的文档里已经出现过。如果在冲突链表里没有发现这个单词，说明该单词是首次碰到，则将其加入冲突链表里。通过这种方式，当文档集合内所有文档解析完毕时，相应的词典结构也就建立起来了。在响应用户查询请求时，其过程与建立词典类似，不同点在于即使词典里没出现过某个单词，也不会添加到词典内。以下图为例，假设用户输入的查询请求为单词3，对这个单词进行哈希，定位到哈希表内的2号槽，从其保留的指针可以获得冲突链表，依次将单词3和冲突链表内的单词比较，发现单词3在冲突链表内，于是找到这个单词，之后可以读出这个单词对应的倒排列表来进行后续的工作，如果没有找到这个单词，说明文档集合内没有任何文档包含单词，则搜索结果为空。 树形结构B树（或者B+树）是另外一种高效查找结构，下图是一个B树结构示意图。B树与哈希方式查找不同，需要字典项能够按照大小排序（数字或者字符序），而哈希方式则无须数据满足此项要求。B树形成了层级查找结构，中间节点用于指出一定顺序范围的词典项目存储在哪个子树中，起到根据词典项比较大小进行导航的作用，最底层的叶子节点存储单词的地址信息，根据这个地址就可以提取出单词字符串。 7 索引更新更新策略有四种：完全重建、再合并策略、原地更新策略以及混合策略。 7.1 完全重建策略当新增文档到达一定数量，将新增文档和原先的老文档整合，然后利用静态索引创建方法对所有文档重建索引，新索引建立完成后老索引会被遗弃。此法代价高，但是目前主流商业搜索引擎一般是采用此方式来维护索引的更新。 7.2 再合并策略当新增文档进入系统，解析文档，之后更新内存中维护的临时索引，文档中出现的每个单词，在其倒排表列表末尾追加倒排表列表项；一旦临时索引将指定内存消耗光，即进行一次索引合并，这里需要倒排文件里的倒排列表存放顺序已经按照索引单词字典顺序由低到高排序，这样直接顺序扫描合并即可。其缺点是：因为要生成新的倒排索引文件，所以对老索引中的很多单词，尽管其在倒排列表并未发生任何变化，也需要将其从老索引中取出来并写入新索引中，这样对磁盘消耗是没必要的。 7.3 原地更新策略试图改进再合并策略，在原地合并倒排表，这需要提前分配一定的空间给未来插入，如果提前分配的空间不够了需要迁移。实际显示，其索引更新的效率比再合并策略要低。 7.4 混合策略出发点是能够结合不同索引更新策略的长处，将不同索引更新策略混合，以形成更高效的方法。","link":"/Inverted-Index/"},{"title":"int，byte之间转换","text":"1 基础知识 1.1 整形(int) 1.2 字节(byte) 1.3 位移 左移 右移 1.4 补码反码 正数 负数 1.5 int在byte[] byte[]图解 2 int-&gt;byte 2.1 例子1 2.2 例子2 2.3 例子3 3 byte-&gt;int 3.1 0xFF 3.2 例子1 3.3 例子2 &amp;255(0x000000ff) 1 基础知识1.1 整形(int)4个字节，占32位，1111，1111，1111，1111，1111，1111，1111，1111。整型int 其实不能说是去掉3个字节，只能说在读取数据的时候只读取了最低的一个字节里的数据而已，那另外的3个字节还在 ，只是没有读取里面的内容而已，因为高位都是0，可以不显示。int转换成4个byte的时候，byte[4] b=b[0][1][2][3]需要移位，从1个字节开始移位。 1.2 字节(byte)1个字节，占8位，1111，1111。byte的数据范围：-128-127，255+符号位=256长度。 byte转换成int，需要左移(数据范围低-&gt;数据范围大，发生自动类型转换)。 int转换成byte，需要右移。1.3 位移左移&lt;&lt;低位补0，相当于×2的n次方。右移&gt;&gt;高位补0，相当于/2的n次方1.4 补码反码Java的2进制采用的是补码形式。包括：2进制转10进制，10进制转2进制。第1位表示符号位，符号位是负数情况，按补码进行存取。负数都是按照补码形式表示。补码=反码+1。反码=原码除了符号位之外，进行按位取反。 正数原码，反码，补码都相同负数原码=源码，反码=除了第一个符号位为1，其他全部按位取反，补码=反码+11.5 int在byte[]byte[]图解“一”表示一个字节，即 8位：一，一，一，一。 下标0：从32位右移24位，&gt;&gt;24，在下标3的位置，需要把高位清空为0，用&amp;，即&amp;0x0000ff；以此类推。 下标1：&gt;&gt;16，0x00ff，0xff=f表示4位二进制数，f=1111。 下标2：&gt;&gt;8，0xff。 下标3：不移动，也不需要清空0。123[0] [1] [2] [3] 表示 index一， 一， 一， 一[0] [1] [2] [3] 1个int用byte表示[0][1][2][3]，1个byte占8位，一个int占32位，一个int[]代表一个byte大小。1234value%256 b[3]value/256%256 b[2] //表示，除以256是b[3]的256，%是获取b[2]的值value/65536%256 b[1]value/16777216%256 b[0]----》256*256*256 int有正负数，所以要消除符号位（&amp;256），负数的符号位补码影响。256=$2^8$ = 1111,1111，每位都可以表示：0，1；所以1111，1111 = $2^8$。123456789value%256 b[3] //取余是b[3]的值value/256%256 b[2] //除以256是b[3]的256,是获取b[3]的值，%是获取b[2]的值value/65536%256 b[1] //256*256，这里的256是，b[3],b[2]的2个256，扣除b[3],b[2]的2个256，b[1]的值是取余的获得value/16777216%256 b[0] //256*256*256==[3],[2],[1]的256 或 value&amp;255 b[3] //&amp;255表示清除值是负数，高位是1，java2进制按照补码取值.0&amp;1=0；低位8个11，高位24个0.（value&amp;255）&gt;&gt;8 b[2]（value&amp;255）&gt;&gt;16 b[1]（value&amp;255）&gt;&gt;24 b[0] b[0][1][2][3]多维素组12345b[0][1][2][3] b[0]：256的3次方 11111111，11111111，11111111，11111111b[1]：256的2次方 //[1],[2],[3]b[2]：256的1次方 //[2],[3]b[3]：256的0次方 //[3] 2 int-&gt;byte2.1 例子1转换成 byte[] b1int a=270 因为byte占256长度，超出256长度，则溢出，向高位进1，a = 270 = b[1][14]b每1维占256长度，超过进1位。123456789public static void main(String[] args) { int a = 2; byte[] b = new byte[4]; b[0] = (byte) (a &gt;&gt; 24); //第一个字节 b[1] = (byte) (a &gt;&gt; 16); //第二个字节 b[2] = (byte) (a &gt;&gt; 8); //第三个字节 b[3] = (byte) (a); //第四个字节 System.out.println(b[0] + \"\" + b[1] + \"\" + b[2] + \"\" + b[3]); } 10002 2.2 例子2(int类型)156转byte是-100。156=10011100最高位为符号位，而11100=28 故为-28，结果为10011100（此时，第一位符号位为1，为负），由于负数按补码存储，所以转换为byte之后的真值为反码=11100101，补码=11100100（进1位），然后加上-1（符号位是-1），即-100。 2.3 例子31234567public static void main(String[] args) { // 95+46=141 int c1 = 46; int c2 = 95; byte c3 = (byte) (c1 + c2); System.out.println(\"c3=\" + c3);} 95+46=141 (00000000 00000000 00000000)10001101 负数，按补码的方式存10001101的补码11110010 64 +32+ 16 +2=(-)114 //补码的方式进行，负号还是要保留 符号位占一位，-114-1 = -115 3 byte-&gt;int3.1 0xFF将byte[]转化十六进制的字符串，注意这里b[i] &amp; 0xFF将一个byte和0xFF进行了与运算，然后使用Integer.toHexString取得了十六进制字符串，可以看出b[i] &amp; 0xFF运算后得出的仍然是个int，那么为何要和0xFF进行与运算呢？直接Integer.toHexString(b[i])；将byte强转为int不行吗？答案是不行的。 byte的大小为8bits，int的大小为32bits Java的二进制采用的是补码形式（正数：源码，反码，补码相同。负数：源码。反码除了符号位，其余相反。补码是反码+1） 0xFF = 1111，1111；因为前3个字节不读取，只是读取最后一个字节，所以可以看成1111，1111；但是实际上还是 00000000，00000000，00000000，1111，1111。这样就可以消除因为负数符号位，补码的时候按位取反，高位是1的情况，&amp;实际上是为了消除1。1234567891011public static String bytes2HexString(byte[] b) { String ret = \"\"; for (int i = 0; i &lt; b.length; i++) { String hex = Integer.toHexString(b[i] &amp; 0xFF); if (hex.length() == 1) { hex = '0' + hex; } ret += hex.toUpperCase(); } return ret;} 3.2 例子1没有&amp;255123456public static void main(String[] args) { byte b=-1; int a=b; String c=Integer.toBinaryString(a); System.out.println(c);} 111111111，11111111，11111111，1111，1111 有&amp;255123456public static void main(String[] args) { byte b = -1; int a = b &amp; 255; //1 String c = Integer.toBinaryString(a); System.out.println(c); } 11111，1111 代码标注 255=0xff=1111,1111=0000,0000,0000,0000,1111,1111；通过&amp;运算进行，前24位被清1。 Java中的一个byte，其范围是-128~127的，而Integer.toHexString的参数本来是int，如果不进行&amp;0xff，那么当一个byte会转换成int时，对于负数，会做位扩展(因为负数是取补码，按位取反，&amp;0xff是为了负数)，举例来说，一个byte的-1（即0xff），会被转换成int的-1（即0xffffffff），那么转化出的结果就不是正确。而0xff默认是整形，所以，一个byte跟0xff相与会先将那个byte转化成整形运算(32位)，这样，结果中的高的24个byte就总会被清1。 3.3 例子21234567891011public static void main(String[] args) { int a = 2; byte[] b = new byte[4]; b[0] = (byte) (a &gt;&gt; 24); // 第一个字节 b[1] = (byte) (a &gt;&gt; 16); // 第二个字节 b[2] = (byte) (a &gt;&gt; 8); // 第三个字节 b[3] = (byte) (a); // 第四个字节 System.out.println(b[0] + \"\" + b[1] + \"\" + b[2] + \"\" + b[3]); //byte-&gt;int System.out.println(((b[0] &amp; 0x000000ff) &lt;&lt; 24) | ((b[1] &amp; 0x000000ff) &lt;&lt; 16) | ((b[2] &amp; 0x000000ff) &lt;&lt; 8) | (b[3] &amp; 0x000000ff));} 1200022 &amp;255(0x000000ff)消除符号位，比如负数的情况，要按照补码取值，补码是反码+1。这里有可能b是负数，高位按照补码进行存取会是1111，1111...，所以要消除1。","link":"/int-byte-convert/"},{"title":"Java Class文件的结构(实践篇)","text":"1 实例 魔数 主次版本号 常量池的数量 常量池 class_index name_and_type_index u2 access_flags u2 this_class u2 super_class interfaces_count 、 interfaces[interfaces_count] fields_count、field_info access_flags name_index descriptor_index attributes_count attribute_info TestClass字段(fields_count)的数量 fields_info access_flags name_index descriptor_index attributes_count attributes[attributes_count] attribute_name_index attribute_length constantValue_index int staticVar = 0 methods_count、method_info name_index descriptor_index attributes_count attributes TestClass第1个方法 access_flag name_index descriptor_index attributes_count attribute_name_index attribute_length max_stack max_locals code_length exception_table_length\\exception_table attributes_count attribute_info attribute_length max_stack max_locals code_length code exception_table_length attribute_count attribute_info LineNumberTable attribute_name_index attribute_length line_number_table_length start_pc line_number attribute_name_index attribute_length line_number_table_length start_pc line_number TestClass第2个方法 access_flags name_index descriptor_index attribute_name_index attribute_length max_stack max_locals code_length code exception_table_length\\exception_table attributes_count attribute_info数组 attribute_name_index attribute_length line_number_table_length start_pc line_number Class文件的属性 attribute_length sourcefile_index attribute_length soucefile_index 1 实例首先有一个TestClass类，代码如下。1234567891011121314package com.ejushang.TestClass;public class TestClass implements Super { private static final int staticVar = 0; private int instanceVar = 0; public int instanceMethod(int param) { return param + 1; }}interface Super {} 通过jdk1.6.0_37的javac编译后的TestClass.java对应的TestClass.class的二进制结构如下。TestClass.class用WinHex工具查看字节码。 魔数从Class的文件结构我们知道，刚开始的4个字节是魔数，上图中从地址00000000h-00000003h的内容就是魔数，从上图可知Class的文件的魔数是0xCAFEBABE。 主次版本号接下来的4个字节是主次版本号，由上图可知从00000004h-00000005h对应的是0x0000,因此Class的minor_version为0x0000,从00000006h-00000007h对应的内容为0x0032,因此Class文件的major_version版本为0x0032,这正好就是jdk1.6.0不带target参数编译后的Class对应的主次版本。 常量池的数量接下来的2个字节从00000008h-00000009h表示常量池的数量，由上图可以知道其值为0x0018，十进制为24个,但是对于常量池的数量需要明确一点，常量池的数量是constant_pool_count-1，为什么减一，是因为索引0表示class中的数据项不引用任何常量池中的常量。 常量池我们上面说了常量池中有不同类型的常量，下面就来看看TestClass.class的第一个常量，我们知道每个常量都有一个u1类型的tag标识来表示常量的类型，上图中0000000ah处的内容为0x0A，转换成二级制是10，由上面的关于常量类型的描述可知tag为10的常量是Constant_Methodref_info，而Constant_Methodref_info的结够如下图(常量池结构)。 class_index指向常量池中类型为CONSTANT_Class_info的常量，从TestClass的二进制文件结构中可以看出class_index的值为0x0004（地址为0000000bh-0000000ch)，也就是说指向第四个常量。 name_and_type_index指向常量池中类型为CONSTANT_NameAndType_info常量。从上图可以看出name_and_type_index的值为0x0013，表示指向常量池中的第19个常量.接下来又可以通过同样的方法来找到常量池中的所有常量。不过JDK提供了一个方便的工具可以让我们查看常量池中所包含的常量。通过javap -verbose TestClass即可得到所有常量池中的常量，截图如下。TestClass中常量池有24个常量，不要忘记了第0个常量，因为第0个常量被用来表示Class中的数据项不引用任何常量池中的常量。从上面的分析中我们得知TestClass的第一个常量表示方法，其中class_index指向的第四个常量为java/lang/Object，name_and_type_index指向的第19个常量值为:()V，从这里可以看出第一个表示方法的常量表示的是Java编译器生成的实例构造器方法。通过同样的方法可以分析常量池的其它常量。12345678910111213141516171819202122230A 0004 001309 0003 0014 int instanceVar 07 0015 utf-807 0016 utf-807 0017 utf-8 01 0009 737461746 963566172 01 0001 49 01 000D 436F6E7374616 E7456 616C7 565 03 0000000001 000B 696E7 37461 6E636 556617201 0006 3C696E 69743E 01 0003 28295601 0004 436F646501 000F 4C696E654E 756D626572 5461626C6501 000E 696E737461 6E63654D65 74686F6401 0004 2849294901 000A 536F757263 6546696C6501 000E 5465737443 6C6173732E 6A6176610C 000B 000C0C 000A 000701 0020 636F6D2F65 6A75736861 6E672F5465 7374436C61 73732F5465 7374436C61 737301 0010 6A6176612F 6C616E672F 4F626A6563 74 01 001C 636F6D2F65 6A75736861 6E672F5465 7374436C61 73732F5375 706572 注：utf-8（string）= 1个英文字符占1个byte，1个中文字符占2个byte，长度=byte长度。 u2 access_flags表示类或者接口方面的访问信息，比如Class表示的是类还是接口，是否为public，static，final等。具体访问标示的含义之前已经说过了，下面我们就来看看TestClass的访问标示。Class的访问标示是从00000100d-0000010e，其值为0x0021，根据前面说的各种访问标示的标志位，我们可以知道0x0021=0x0001|0x0020，也即ACC_PUBLIC和ACC_SUPER为真，其中ACC_PUBLIC大家好理解，ACC_SUPER是jdk1.2之后编译的类都会带有的标志。 u2 this_class表示类的索引值，用来表示类的全限定名称，类的索引值如下图。类索引值为0x0003，对应常量池的第三个常量，通过javap的结果，我们知道第三个常量为CONSTANT_Class_info类型的常量，通过它可以知道类的全限定名称为com/ejushang/TestClass/TestClass。 u2 super_class表示当前类的父类的索引值，索引值指向常量池中类型为CONSTANT_Class_info的常量，父类的索引值如下图所示，其值为0x0004,查看常量池的第四个常量，可知TestClass的父类的全限定名称为java/lang/Object。 interfaces_count 、 interfaces[interfaces_count]表示接口数量以及具体的每一个接口，TestClass的接口数量以及接口如下图所示，其中0x0001表示接口数量为1，而0x0005表示接口在常量池的索引值，找到常量池的第五个常量，其类型为CONSTANT_Class_info，其值为com/ejushang/TestClass/Supe。 fields_count、field_infofields_count表示类中field_info表的数量，而field_info表示类的实例变量和类变量，这里需要注意的是field_info不包含从父类继承过来的字段，field_info的结构如下图。 access_flags表示字段的访问标识，比如public，private，protected，static。final等，access_flags的取值如下图。 name_index常量池的索引值，表示字段的名称。 descriptor_index常量池的索引值，表示字段的描述符。其实在JVM规范中，对于字段的描述符规定如下图。关注上图最后一行，它表示的是对一维数组的描述符，对于数组类型，每一维度将使用一个前置的[字符来描述，String[][]的描述符将是[[Ljava/lang/String，而对于int[][]的描述符为[[I。用描述符来描述方法时，按照先参数列表，后返回值的顺序描述。参数列表按照严格的顺序放在一组小括号()内。如方法void inc()的描述符为()V，方法java.lang.String.toString()的描述符为()Ljava/lang/String;，方法int indexOf(char[] source，int offset，int count，char[] target，int tOffset，int tCount，int fromIndex的描述符为([CII[CIII)I。 attributes_count表示属性表的数量。 attribute_info表示属性表的属性表。 TestClass字段(fields_count)的数量fields_count = 2，TestClass有两个字段，查看TestClass的源代码可知，确实也只有两个字段，接下来我们看看第一个字段，我们知道第一个字段应该为private int staticVar，它在Class文件中的二进制表示如下图。 fields_info access_flags0x001A表示访问标示，通过查看access_flags表可知，其为ACC_PRIVATE，ACC_STATIC，ACC_FINAL。 name_index0x0006表示常量池中第6常量，通过查看常量池可知，其值为staticVar，其中staticVar为字段名称。 descriptor_index0x0007表示常量第7个常量，通过查看常量池可知，其值为I，而I为字段的描述符，通过上面对描述符的解释，I所描述的是int类型的变量。 attributes_count0x0001表示staticVar这个字段表中的属性表的数量，从上图可以staticVar字段对应的属性表有1个。 attributes[attributes_count]0x0008表示属性表集合，常量池中的第8个常量，查看常量池可以得知此属性为ConstantValue属性。ConstantValue属性的格式如下图。 attribute_name_index0x0008表述属性名的常量池索引，本例中为ConstantValue。 attribute_length0x00000002固定长度为2。 constantValue_index表示常量池中的引用，本例中，其中为0x0009，查看第9个常量可以知道，它表示一个类型为CONSTANT_Integer_info的常量，其值为0。 int staticVar = 0private static final int staticVar = 0instanceVar的二进制表示如下图。其中0x0002表示访问标示为ACC_PRIVATE，0x000A表示字段的名称，它指向常量池中的第10个常量，查看常量池可以知道字段名称为instanceVar，而0x0007表示字段的描述符，它指向常量池中的第7个常量，查看常量池可以知道第7个常量为I，表示类型为instanceVar的类型为I，最后0x0000表示属性表的数量为0。 methods_count、method_info方法表和字段表field_info虽然都有属性数量和属性表，但是它们里面所包含的属性是不同。methods_count表示方法的数量，而method_info表示的方法表，其中方法表的结构如下图。可以看出method_info和field_info的结构是很类似的，由于ACC_VOLATILE标志和ACC_TRANSIENT标志不能修饰方法，所以access_flags中不包含这两项，同时增加ACC_SYNCHRONIZED标志、ACC_NATIVE标志、ACC_STRICTFP标志和ACC_ABSTRACT标志 ，方法表的access_flag的所有标志位以及取值如下图。标志名称 | 标志值 | 含义—–|—–|—ACC_PUBLIC | 0x0001 | 字段是否为publicACC_PRIVATE | 0x0002 | 字段是否为privateACC_PROTECTED | 0x0004 | 字段是否为protectedACC_STATIC | 0x0008 | 字段是否为staticACC_FINAL | 0x0010 | 字段是否为finalACC_SYNCHRONIZED | 0x0020 | 字段是否为synchronizedACC_BRIDGE | 0x0040 | 方法是否是由编译器产生的桥接方法ACC_VARARGS | 0x0080 | 方法是否接受不定参数ACC_NATIVE | 0x0100 | 字段是否为nativeACC_ABSTRACT | 0x0400 | 字段是否为abstractACC_STRICTFP | 0x0800 | 字段是否为strictfpACC_SYNTHETIC | 0x1000 | 字段是否为编译器自动产生 name_index表示的是方法的名称，指向常量池的索引。 descriptor_index表示的是方法的描述符，指向常量池的索引。方法的描述符的结构为（参数列表）返回值，比如public int instanceMethod(int param)的描述符为(I)I，表示带有一个int类型参数且返回值也为int类型的方法。 attributes_count属性数量。 attributes属性表。方法表的二进制。 TestClass第1个方法方法表的数量为0x0002表示有两个方法，分析第1个方法，首先来看一下TestClass的第1个方法的access_flag，name_index，descriptor_index。 access_flag0x0001表示访问标示，通过查看access_flags表可知，其为ACC_PUBLIC。 name_index0x000B表示方法的名字，查看常量池中的第11个常量。 descriptor_index0x000C表示descriptor_index表示常量池中的第12常量，其值为()V，表示方法没有参数和返回值，其实这是编译器自动生成的实例构造器方法。 attributes_count0x0001表示方法的方法表有1个属性。属性表图。0x000D对应的常量池中的常量为Code，表示的方法的Code属性，所以到这里大家应该明白：方法的那些代码是存储在Class文件方法表中的属性表中的Code属性中。接下来我们在分析一下Code属性，Code属性的结构如下图。 attribute_name_index指向常量池中值为Code的常量。 attribute_length的长度表示Code属性表的长度（这里需要注意的时候长度不包括attribute_name_index和attribute_length的6个字节的长度）。 max_stack表示最大栈深度，虚拟机在运行时根据这个值来分配栈帧中操作数的深度。 max_locals代表了局部变量表的存储空间，它的单位为slot，slot是虚拟机为局部变量分配内存的最小单元，在运行时，对于不超过32位类型的数据类型，比如byte，char，int等占用1个slot，而double和Long这种64位的数据类型则需要分配2个slot，另外max_locals的值并不是所有局部变量所需要的内存数量之和，因为slot是可以重用的，当局部变量超过了它的作用域以后，局部变量所占用的slot就会被重用。 code_length代表了字节码指令的数量，而code表示的时候字节码指令，从上图可以知道code的类型为u1，一个u1类型的取值为0x00-0xFF,对应的十进制为0-255，目前虚拟机规范已经定义了200多条指令。 exception_table_length\\exception_table分别代表方法对应的异常信息。 attributes_count表示Code属性中的属性数量。 attribute_info表示Code属性中的属性表，从这里可以看出Class的文件结构中，属性表是很灵活的，它可以存在于Class文件，方法表，字段表以及Code属性中。继续以上面的图来分析，从上面init()的Code属性开始。 attribute_length属性表的长度为0x00000026。 max_stack0x0002。 max_locals0x0001。 code_length0x0000000A。 code00000149h-00000152h为字节码的值；字节码的长度是以code_length值为准。 exception_table_length0x0000。 attribute_count0x0001。 attribute_info00000157h-00000158h的值为0x000E，它表示常量池中属性的名称，查看常量池得知第14个常量的值为LineNumberTable，LineNumberTable用于描述Java源代码的行号和字节码行号的对应关系，它不是运行时必需的属性。 LineNumberTable 如果通过-g:none的编译器参数来取消生成LineNumberTable的话，最大的影响就是异常发生的时候，堆栈中不能显示出出错的行号，调试的时候也不能按照源代码来设置断点。 attribute_name_index表示常量池的索引。 attribute_length表示属性长度。 line_number_table_length表示行号属性数目。 start_pc表示字节码的行号。 line_number表示源代码的行号。LineNumberTable属性的字节流如下图。 attribute_name_index0x000E，表示属性集的名字。 attribute_length0x0000A，表示属性的长度（行号长度+start_pc+line_number的长度）。 line_number_table_length0x0002，行号的长度=2。 start_pc0x0000，0x0004，2次行号。 line_number0x0003，0x0005。 TestClass第2个方法 access_flags0x0001。 name_index0x000F。 descriptor_index0x0010，通过查看常量池可以知道此方法为public int instanceMethod(int param)。通过和上面类似的方法，instanceMethod的Code属性为下图。 attribute_name_index0x000D attribute_length0X0000001C max_stack0x0002 max_locals0x0002 code_length0x00000004 code0x1B0460AC exception_table_length\\exception_table0x0000 attributes_count0x0001 attribute_info数组attribute_name_index0x000E，表示属性集的名字 attribute_length0x000006，表示属性的长度（行号长度+start_pc+line_number的长度） line_number_table_length0x0001 start_pc0x0000 line_number0x0008 Class文件的属性Class文件的属性，从00000191h-00000199h为Class文件中的属性表，其中0x0011表示属性的名称，查看常量池可以知道属性名称为SourceFile，我们再来看看SourceFile的结构如下图。 attribute_length属性的长度。 sourcefile_index指向常量池中值为源代码文件名称的常量，在本例中SourceFile属性截图。0x0001表示sourceFile以指向常量池中CONSTANT_Utf8_info类型常量的索引，utf8-info是0x01。 attribute_length0x00000002表示长度为2个字节。 soucefile_index值为0x0012，查看常量池的第18个常量可以知道源代码文件的名称为TestClass.java。","link":"/Java-Class-structure-practice/"},{"title":"Java CAS(Compare And Swap)","text":"基础知识 2 原子操作 2.1 原子性 2.2 处理器实现原子性 处理器自动保证基本内存操作的原子性 2.3 总线保证原子性 2.4 缓存锁保证原子性 2.5 Java保证原子性 CAS的3个问题 ABA问题 循环时间长开销大 只能保证一个共享变量的原子操作 3 CAS的ABA问题解决方式 3 CAS的Uncafe学习 例子 4 参考 基础知识CAS(Compare And Swap)比较和替换是设计并发算法时用到的一种技术。简单来说，比较和替换是使用一个期望值和一个变量的当前值进行比较，如果当前变量的值与期望的值相等，就使用一个新值替换当前变量的值。在程序和算法中一个经常出现的模式就是Check And Act模式。先检查后操作模式发生在代码中首先检查一个变量的值，然后再基于这个值做一些操作。简单的示例12345678910class MyLock { private boolean locked = false; public boolean lock() { if(!locked) { locked = true; return true; } return false; }} 如果同个线程访问同一个MyLock实例，上面的lock()将不能保证正常工作。如果一个线程A检查locked的值，然后将其设置为false，与此同时，一个线程B也在检查locked的值。因此，线程A和线程B可能都看到locked的值为false，然后两者都基于这个信息做一些操作。(会有线程安全问题)为了在一个多线程程序中良好的工作，Check Then Act操作必须是原子的。原子就是说Check操作和Act被当做一个原子代码块执行。(放在临界区中执行，不存在并发问题，只允许一个线程执行)。把之前的lock()用synchronized关键字重构成一个原子块。12345678910class MyLock { private boolean locked = false; public synchronized boolean lock() { if(!locked) { locked = true; return true; } return false; }} 现在lock()是同步的。所以，在某一时刻只能有一个线程在同一个MyLock实例上执行它。原子的lock()实际上是一个Compare And Swap的例子。 2 原子操作2.1 原子性原子(atom)本意是”不能被进一步分割的最小粒子”，而原子操作(Atomic Operation)意为”不可被中断的一个或一系列操作”。在多处理器上实现原子操作就变得有点复杂。使用AtomicBoolean类实现lock()的例子。123456public static class MyLock { private AtomicBoolean locked = new AtomicBoolean(false); public boolean lock() { return locked.compareAndSet(false, true); }} locked变量不再是boolean类型而是AtomicBoolean。这个类中有一个compareAndSet()方法，它使用一个期望值和AtomicBoolean实例的值比较，和两者相等，则使用一个新值替换原来的值。在这个例子中，它比较locked的值和false，如果locked的值为false，则把修改为true。如果值被替换了，compareAndSet()返回true，否则，返回false。 2.2 处理器实现原子性32位IA-32处理器使用基于对缓存加锁或总线加锁的方式来实现多处理器之间的原子操作。 处理器自动保证基本内存操作的原子性首先处理器会自动保证基本的内存操作的原子性。处理器保证从系统内存当中读取或者写入一个字节是原子的，意思是当一个处理器读取一个字节时，其他处理器不能访问这个字节的内存地址。奔腾6和最新的处理器能自动保证单处理器对同一个缓存行里进行16/32/64位的操作是原子的，但是复杂的内存操作处理器不能自动保证其原子性，比如跨总线宽度，跨多个缓存行，跨页表的访问。但是处理器提供总线锁定和缓存锁定两个机制来保证复杂内存操作的原子性。 2.3 总线保证原子性通过总线锁保证原子性。如果多个处理器同时对共享变量进行读改写（i++就是经典的读改写操作）操作，那么共享变量就会被多个处理器同时进行操作，这样读改写操作就不是原子的，操作完之后共享变量的值会和期望的不一致。例子：如果i=1，进行两次i++操作，期望的结果是3，但是有可能结果是2。如下图。有可能多个处理器同时从各自的缓存中读取变量i，分别进行加一操作，然后分别写入系统内存当中。那么想要保证读改写共享变量的操作是原子的，就必须保证CPU1读改写共享变量的时候，CPU2不能操作缓存了该共享变量内存地址的缓存。处理器使用总线锁就是来解决这个问题的。所谓总线锁就是使用处理器提供的一个LOCK＃信号，当一个处理器在总线上输出此信号时，其他处理器的请求将被阻塞住，那么该处理器可以独占使用共享内存。 2.4 缓存锁保证原子性通过缓存锁定保证原子性。在同一时刻我们只需保证对某个内存地址的操作是原子性即可，但总线锁定把CPU和内存之间通信锁住了，这使得锁定期间，其他处理器不能操作其他内存地址的数据，所以总线锁定的开销比较大，最近的处理器在某些场合下使用缓存锁定代替总线锁定来进行优化。频繁使用的内存会缓存在处理器的L1，L2和L3高速缓存里，那么原子操作就可以直接在处理器内部缓存中进行，并不需要声明总线锁，在奔腾6和最近的处理器中可以使用“缓存锁定”的方式来实现复杂的原子性。所谓“缓存锁定”就是如果缓存在处理器缓存行中内存区域在LOCK操作期间被锁定，当它执行锁操作回写内存时，处理器不在总线上声明LOCK＃信号，而是修改内部的内存地址，并允许它的缓存一致性机制来保证操作的原子性，因为缓存一致性机制会阻止同时修改被两个以上处理器缓存的内存区域数据，当其他处理器回写已被锁定的缓存行的数据时会起缓存行无效（另一个线程不能缓存这个数据），在上图中，当CPU1修改缓存行中的i时使用缓存锁定，那么CPU2就不能同时缓存了i的缓存行。但是有两种情况下处理器不会使用缓存锁定。 当操作的数据不能被缓存在处理器内部，或操作的数据跨多个缓存行(cache line(缓存的最小操作单位))，则处理器会调用总线锁定。 有些处理器不支持缓存锁定。对于Inter486和奔腾处理器，就算锁定的内存区域在处理器的缓存行中也会调用总线锁定。 以上两个机制可以通过Inter处理器提供了很多LOCK前缀的指令来实现。比如位测试和修改指令BTS，BTR，BTC，交换指令XADD，CMPXCHG和其他一些操作数和逻辑指令，比如ADD(加)，OR(或)等，被这些指令操作的内存区域就会加锁，导致其他处理器不能同时访问它。 2.5 Java保证原子性在Java中可以通过锁和循环CAS的方式来实现原子操作。JVM中的CAS操作正是利用了上面提到的处理器提供的CMPXCHG指令实现的。自旋CAS实现的基本思路就是循环进行CAS操作直到成功为止，以下代码实现了一个基于CAS线程安全的计数器方法safeCount和一个非线程安全的计数器count。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152private AtomicInteger atomicI = new AtomicInteger(0); private int i = 0; public static void main(String[] args) { final Counter cas = new Counter(); List&lt;Thread&gt; ts = new ArrayList&lt;Thread&gt;(600); long start = System.currentTimeMillis(); for (int j = 0; j &lt; 100; j++) { Thread t = new Thread(new Runnable() { @Override public void run() { for (int i = 0; i &lt; 10000; i++) { cas.count(); cas.safeCount(); } } }); ts.add(t); } for (Thread t : ts) { t.start(); } // 等待所有线程执行完成 for (Thread t : ts) { try { t.join(); } catch (InterruptedException e) { e.printStackTrace(); } } System.out.println(cas.i); System.out.println(cas.atomicI.get()); System.out.println(System.currentTimeMillis() - start); } /** * 使用CAS实现线程安全计数器 */ private void safeCount() { for (;;) { int i = atomicI.get(); boolean suc = atomicI.compareAndSet(i, ++i); if (suc) { break; } } } /** * 非线程安全计数器 */ private void count() { i++; }} 在Java并发包中有一些并发框架也使用了自旋CAS的方式来实现原子操作，比如LinkedTransferQueue类的Xfer()。 CAS的3个问题CAS虽然很高效的解决原子操作，但是CAS仍然存在三大问题。 ABA问题。 循环时间长开销大。 只能保证一个共享变量的原子操作。ABA问题因为CAS需要在操作值的时候检查下值有没有发生变化，如果没有发生变化则更新，但是如果1个值原来是A，变成了B，又变成了A，那么使用CAS进行检查时会发现它的值没有发生变化，但是实际上却变化了。ABA问题的解决思路就是使用版本号。在变量前面追加上版本号，每次变量更新的时候把版本号加1，那么A－B－A就会变成1A-2B－3A。从Java1.5开始JDK的atomic包里提供了1个类AtomicStampedReference来解决ABA问题。这个类的compareAndSet()作用是首先检查当前引用是否等于预期引用，并且当前标志的值是否等于预期标志的值，如果全部相等，则以原子方式将该引用和该标志的值设置为给定的更新值。123456public boolean compareAndSet( V expectedReference,//预期引用 V newReference,//更新后的引用 int expectedStamp, //预期标志 int newStamp //更新后的标志) 循环时间长开销大自旋CAS如果长时间不成功，会给CPU带来非常大的执行开销。如果JVM能支持处理器提供的pause指令那么效率会有一定的提升，pause指令有两个作用，第一它可以延迟流水线执行指令(de-pipeline)，使CPU不会消耗过多的执行资源，延迟的时间取决于具体实现的版本，在一些处理器上延迟时间是零。第二它可以避免在退出循环的时候因内存顺序冲突(memory order violation)而引起CPU流水线被清空(CPU pipeline flush)，从而提高CPU的执行效率。 只能保证一个共享变量的原子操作当对一个共享变量执行操作时，可以使用循环CAS的方式来保证原子操作，但是对多个共享变量操作时，循环CAS就无法保证操作的原子性，这个时候就可以用锁，或者有一个取巧的办法，就是把多个共享变量合并成一个共享变量来操作。比如有两个共享变量i＝2，j=a，合并一下ij=2a，然后用CAS来操作ij。从Java1.5开始JDK提供了AtomicReference类来保证引用对象之间的原子性，可以把多个变量放在一个对象里来进行CAS操作。 3 CAS的ABA问题解决方式线程1准备用CAS将变量的值由A替换为B，在此之前，线程2将变量的值由A替换为C，又由C替换为A，然后线程1执行CAS时发现变量的值仍然为A，所以CAS成功。但实际上这时的现场已经和最初不同了(引用地址变)，尽管CAS成功，但可能存在潜藏的问题。现有一个用单向链表实现的堆栈，栈顶为A，这时线程T1已经知道A.next为B，然后希望用CAS将栈顶替换为B。head.compareAndSet(A,B);在T1执行上面这条指令之前，线程T2介入，将A、B出栈，再push D、C、A，此时堆栈结构如下图，而对象B此时处于游离状态。(B已经不在栈内)此时轮到线程T1执行CAS操作，检测发现栈顶仍为A，所以CAS成功，栈顶变为B，但实际上B.next为null，所以此时的情况变为。其中堆栈中只有B一个元素，C和D组成的链表不再存在于堆栈中，平白无故就把C、D丢掉了(B的栈内，不存在C,D)。例如下面的代码分别用AtomicInteger和AtomicStampedReference来对初始值为100的原子整型变量进行更新，AtomicInteger会成功执行CAS操作，而加上版本戳的AtomicStampedReference对于ABA问题会执行CAS失败。以上就是由于ABA问题带来的隐患，各种乐观锁的实现中通常都会用版本戳version来对记录或对象标记，避免并发操作带来的问题，在Java中，AtomicStampedReference&lt;E&gt;也实现了这个作用，它通过包装[E,Integer]的元组来对对象标记版本戳stamp，从而避免ABA问题。12345678910111213141516/** * Atomically sets the value of both the reference and stamp * to the given update values if the * current reference is {@code ==} to the expected reference * and the current stamp is equal to the expected stamp. * * @param expectedReference the expected value of the reference * @param newReference the new value for the reference * @param expectedStamp the expected value of the stamp * @param newStamp the new value for the stamp * @return true if successful */ public boolean compareAndSet(V expectedReference,//预期引用 V newReference,//更新引用 int expectedStamp,//以前的版本 int newStamp)//更新版本 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273import java.util.concurrent.TimeUnit;import java.util.concurrent.atomic.AtomicInteger;import java.util.concurrent.atomic.AtomicStampedReference;public class ABA { private static AtomicInteger atomicInt = new AtomicInteger(100); @SuppressWarnings({ \"unchecked\", \"rawtypes\" }) private static AtomicStampedReference atomicStampedRef = new AtomicStampedReference(100, 0); public static void main(String[] args) throws InterruptedException { Thread intT1 = new Thread(new Runnable() { @Override public void run() { //1 atomicInt.compareAndSet(100, 101); //2 atomicInt.compareAndSet(101, 100); } }); //3 Thread intT2 = new Thread(new Runnable() { @Override public void run() { try { TimeUnit.SECONDS.sleep(1); } catch (InterruptedException e) { } //4 boolean c3 = atomicInt.compareAndSet(100, 101); System.out.println(\"[AtomicInteger]ABA问题：\" + c3); // 交换成功true } }); intT1.start(); intT2.start(); intT1.join(); intT2.join(); //5 Thread refT1 = new Thread(new Runnable() { @SuppressWarnings(\"unchecked\") @Override public void run() { try { TimeUnit.SECONDS.sleep(1); } catch (InterruptedException e) { } //6 boolean c = atomicStampedRef.compareAndSet(100, 101, atomicStampedRef.getStamp(), atomicStampedRef.getStamp() + 1); System.out.println(\"线程1,第1次交换后101版本：\" + atomicStampedRef.getStamp()); //7 boolean c1 = atomicStampedRef.compareAndSet(101, 100, atomicStampedRef.getStamp(), atomicStampedRef.getStamp() + 1); System.out.println(\"线程1,第2次交换100版本：\" + (atomicStampedRef.getStamp())); System.out.println(\"线程1,第1次交换：\" + c); System.out.println(\"线程1,第2次交换：\" + c1); } }); Thread refT2 = new Thread(new Runnable() { @Override public void run() { int stamp = atomicStampedRef.getStamp(); try { TimeUnit.SECONDS.sleep(2); } catch (InterruptedException e) { } //8 @SuppressWarnings(\"unchecked\") boolean c3 = atomicStampedRef.compareAndSet(100, 101, stamp, stamp + 1); System.out.println(\"线程2,第1次交换：\" + c3);// false } }); refT1.start(); refT2.start(); }} 标注代码分析 以前A是100，B是101，交换A=101，B=100。 A=101，101=101，则交换A=100。 intT1值是100，交换过后还是100。 A原来的值是100，100=100，进行交换。 intT1，intT2线程执行完毕之后，再执行下面代码。版本号只在当前线程内有效。 初始化100版本=0；101版本=1。第一次交换，设置101值，版本=1。 101和版本都预期的值相同，更新值=100，版本=2。 初始化=100:0,101:1。因为100值，版本=2，当前值和预期的值，不相同。交换失败。3 CAS的Uncafe学习Unsafe的源码：http://www.docjar.com/html/api/sun/misc/Unsafe.java.htmlUnsafe源码中的描述如下 A collection of methods for performing low-level, unsafe operations. Although the class and all methods are public, use of this class is limited because only trusted code can obtain instances of it. 这个类是用于执行低级别、不安全操作的方法集合。尽管这个类和所有的方法都是公开的(public)，但是这个类的使用仍然受限，无法在自己的Java程序中直接使用该类，因为只有授信的代码才能获得该类的实例。从上面的描述，可以了解到该类是用来执行较低级别的操作的，比如获取某个属性在内存中的位置，不过一般人很少会有这样的需求。在AtomicInteger的源码中相关的代码如下12// setup to use Unsafe.compareAndSwapInt for updates private static final Unsafe unsafe = Unsafe.getUnsafe(); 上面这行代码是获取Unsafe实例的。一般情况下，是拿不到该类的实例的，jdk库里面是可以随意使用的。12345static { try { valueOffset = unsafe.objectFieldOffset(AtomicInteger.class.getDeclaredField(\"value\")); } catch (Exception ex) { throw new Error(ex); } } 上面这几行代码，是用来获取AtomicInteger实例中的value属性在内存中的位置。这里使用了Unsafe的objectFieldOffset()。这个方法是一个本地方法， 该方法用来获取一个给定的静态属性的内存中位置。（内存中的偏移量，内存地址偏移量，这个值对于给定的filed是唯一的且是固定不变的）1public native long objectFieldOffset(Field f); 通过查看AtomicInteger源码发现，在这样几个地方使用到了这个valueOffset（偏移量）值。1234567891011public final void lazySet(int newValue) { unsafe.putOrderedInt(this, valueOffset, newValue); }public final boolean compareAndSet(int expect, int update) { return unsafe.compareAndSwapInt(this, valueOffset, expect, update); }public final boolean weakCompareAndSet(int expect, int update) { return unsafe.compareAndSwapInt(this, valueOffset, expect, update); } 查找资料后，发现lazySet方法大多用在并发的数据结构中，用于低级别的优化。compareAndSet这个方法多见于并发控制中，简称CAS(Compare And Swap)，意思是如果valueOffset位置包含的值与expect值（预期位置值）相同，则更新valueOffset位置的值为update，并返回true，否则不更新，返回false。 例子通过反射获取Unsafe实例，计算对象在内存中的偏移量。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051import java.lang.reflect.Field;import sun.misc.Unsafe;/** * Unsafe代码测试 * * @author Administrator * */public class UnsafeTest { private static Unsafe unsafe; static { try { // 通过反射获取rt.jar下的Unsafe类 Field field = Unsafe.class.getDeclaredField(\"theUnsafe\"); field.setAccessible(true); // 实例化对象 unsafe = (Unsafe) field.get(null); } catch (Exception e) { System.out.println(\"Get Unsafe instance occur error\" + e); } } public static void main(String[] args) throws Exception { @SuppressWarnings(\"rawtypes\") Class clazz = Target.class; Field[] fields = clazz.getDeclaredFields(); System.out.println(\"属性的偏移量fieldName:fieldOffset\"); for (Field f : fields) { // 获取属性偏移量，可以通过这个偏移量给属性设置 System.out.println(\"属性名字：\" + f.getName() + \"，类型：\" + f.getType() + \"，偏移量:\" + unsafe.objectFieldOffset(f)); } Target target = new Target(); Field intFiled = clazz.getDeclaredField(\"intParam\"); int a = (Integer) intFiled.get(target); System.out.println(\"intParam初始化值是:\" + a); // intParam的字段偏移是12, 初始化值3, 我们要改为10 System.out.println(\"改变成偏移量10：\"+unsafe.compareAndSwapInt(target, 12, 3, 10)); int b = (Integer) intFiled.get(target); System.out.println(\"intParam改变之后的值是:\" + b); // 这个时候已经改为10了,所以会返回false System.out.println(\"这个时候已经改为10,不是12；所以交换失败，intParam:\" + unsafe.compareAndSwapInt(target, 12, 3, 10)); System.out.println(\"偏移量24,值是null:\" + unsafe.compareAndSwapObject(target, 24, null, \"5\")); //int c = (Integer) intFiled.get(target); //System.out.println(\"偏移量24,值是null,改变之后的值\" + c); }}class Target { int intParam = 3; long longParam; String strParam; String strParam2;} 4 参考百度百科聊聊并发（五）原子操作的实现原理","link":"/Java-CAS/"},{"title":"Java异常机制","text":"1、基本定义 2、异常体系 Error Exception Runtime Exception 3、异常使用 系统异常 实例1 实例2 实例3 自定义异常 异常处理步骤 4、异常链 实例 5、异常的使用误区 减小try代码块 保证所有资源都被正确释放，充分运用finally关键词 catch语句应当尽量指定具体的异常类型，而不应该指定涵盖范围太广的Exception类 既然捕获异常，就要对它进行适当的处理 异常处理方法 对代码层次结构的污染 将异常包含在循环语句块中 6、总结 Think in java Effective java 1、基本定义异常的处理机制可以确保程序的健壮性，提高系统可用率。在OO中提供的异常处理机制是提供代码健壮的强有力的方式。使用异常机制它能够降低错误处理代码的复杂度，如果不使用异常，那么就必须检查特定的错误，并在程序中的许多地方去处理它，而如果使用异常，那就不必在方法调用处进行检查，因为异常机制将保证能够捕获这个错误，并且，只需在一个地方处理错误，即所谓的异常处理程序中。这种方式不仅节约代码，而且把“概述在正常执行过程中做什么事”的代码和“出问题怎么办”的代码相分离。总之，与以前的错误处理方法相比，异常机制使代码的阅读、编写和调试工作更加井井有条。（摘自《Think in java 》）。在《Think in java》中是这样定义异常的：异常情形是指阻止当前方法或者作用域继续执行的问题。在这里一定要明确一点,异常代码某种程度的错误，尽管Java有异常处理机制，但是我们不能以“正常”的眼光来看待异常，异常处理机制的原因就是告诉你：这里可能会或者已经产生错误，您的程序出现不正常的情况，可能会导致程序失败！那么什么时候才会出现异常呢？只有在你当前的环境下程序无法正常运行下去，也就是说程序已经无法来正确解决问题，这时它所就会从当前环境中跳出，并抛出异常。抛出异常后，它首先会做几件事。首先，它会使用new创建一个异常对象，然后在产生异常的位置终止程序，并且从当前环境中弹出对异常对象的引用。这时，异常处理机制就会接管程序，并开始寻找一个恰当的地方来继续执行程序，这个恰当的地方就是异常处理程序，它的任务就是将程序从错误状态恢复，以使程序要么换一种方法执行，要么继续执行下去。总的来说异常处理机制就是当程序发生异常时，它强制终止程序运行，记录异常信息并将这些信息反馈给我们，由我们来确定是否处理异常。 2、异常体系Java提供非常完美的异常处理机制，从下面这幅图可以看出，Throwable是Java语言中所有错误和异常的超类。它有两个子类：Error、Exception。 ErrorError为错误，是程序无法处理的（表示仅靠程序本身无法恢复的严重错误），如OutOfMemoryError、ThreadDeath等，交由JVM来处理，不过JVM在大多数情况下会选择终止线程。（程序本身无法修复这些错误。一般不去扩展Error类来创建用户自定义的错误类。也不用去try..catch这类异常）Error是Unchecked Exception，编译器不会检查Error是否被处理，在程序中不用捕获Error类型的异常。 ExceptionException是程序可以处理的异常。它又分为两种Checked Exception（受检查异常），一种是Unchecked Exception（不受检异常）。 Check Exception：发生在编译阶段，必须要使用try…catch（或者throws）否则编译不通过。发现错误的最佳时期是编译期间（检测性异常），然而编译期间并不能找出所有数据，余下的问题必须在运行期间解决。 Unchecked Exception：发生在运行期，具有不确定性，主要是由于程序的逻辑问题所引起的，难以排查。发生异常，尽量处理异常，即使产生异常，也能尽量保证程序朝着有利方向发展。 所以,对于可恢复的条件使用被检查的异常（Checked Exception）进行try...catch捕获，对于程序错误（言外之意不可恢复，大错已经酿成，程序自己的错误）使用运行时异常（RuntimeException）不使用try..catch捕获，由JVM处理，一般终止进程。另一方面，我们直接将异常分为非运行时异常（Check Exception）和运行时异常（Unchecked Exception）。异常的捕获就要做一些有意义的处理，比如受检查的异常，在catch中就可以恢复程序。 Runtime ExceptionRuntimeException是那些可能在Java虚拟机正常运行期间抛出的异常的超类(空指针，越界)。Java编译器不去检查它，也就是说，当程序中可能出现这类异常时，即使没有用try...catch语句捕获它，也没有用throws字句声明抛出它，还是会编译通过，这种异常可以通过改进代码实现来避免。（这类异常程序中可以选择捕获处理，也可以不处理，这类异常一般是由于代码逻辑错误。尽量去避免这种异常，一旦发现该异常，正确的做法就会改进程序设计的代码和实现方式，修改程序中的错误。）RuntimeException发生的时候，表示程序中出现编程错误，所以应该找出错误修改程序，而不是去捕获RuntimeException。因此在做异常体系设计时要根据错误的性质合理选择自定义异常的继承关系。 3、异常使用系统异常在异常中try快包含着可能出现异常的代码块，catch块捕获异常后对异常进行处理。 实例1123456789101112131415161718public class ExceptionTest { public static void main(String[] args) { String file = \"D:\\\\exceptionTest.txt\"; FileReader reader; try { reader = new FileReader(file); Scanner in = new Scanner(reader); String string = in.next(); System.out.println(string + \"不知道我有幸能够执行到不.....\"); } catch (FileNotFoundException e) { e.printStackTrace(); System.out.println(\"对不起,你执行不到...\"); } finally{ System.out.println(\"finally 在执行...\"); } }} 12345678java.io.FileNotFoundException: D:\\exceptionTest.txt (系统找不到指定的文件。) at java.io.FileInputStream.open(Native Method) at java.io.FileInputStream.&lt;init&gt;(FileInputStream.java:106) at java.io.FileInputStream.&lt;init&gt;(FileInputStream.java:66) at java.io.FileReader.&lt;init&gt;(FileReader.java:41) at com.test9.ExceptionTest.main(ExceptionTest.java:19)对不起,你执行不到...finally 在执行... 从这个结果可以看出这些 当程序遇到异常时会终止程序的运行（即后面的代码不在执行），控制权交由异常处理机制处理。 catch捕捉异常后，执行里面的函数。实例21234567public class ExceptionTest { public staticvoid main(String[] args) { int[] a = {1,2,3,4}; System.out.println(a[4]); System.out.println(\"我执行了吗???\"); }} 运行程序结果如下12Exception in thread \"main\" java.lang.ArrayIndexOutOfBoundsException: 4 at com.test9.ExceptionTest.main(ExceptionTest.java:14) 实例1和实例2的异常放在一起看12java.io.FileNotFoundException: D:\\exceptionTest.txt (系统找不到指定的文件。) //实例1Exception in thread \"main\"java.lang.ArrayIndexOutOfBoundsException: 4 //实例2 区别：第二个异常信息多一条Exception in thread &quot;main&quot;（这里异常是由JVM进行处理），这显示出现异常信息的位置。在这里可以得到如下结论,若程序中显示的声明某个异常，则抛出异常时不会显示出处，若程序中没有显示的声明某个异常，当抛出异常时，系统会显示异常的出处，但是最终会有异常栈信息打印出来at com.test9.ExceptionTest.main(ExceptionTest.java:19)。 实例3123456789101112131415161718192021222324252627282930313233343536package demo1;import java.io.FileNotFoundException;import java.io.FileReader;import java.util.Scanner;/** * 异常链 * */public class Test { public void f() throws Exception { System.out.println(1/0); System.out.println(\"---------------f---------\"); } public void g() throws MyException { try { f(); } catch (Exception e) { System.out.println(\"进入g的异常...........\"); // e 保存异常信息 throw new MyException(\"文件没有找到--02\",e); } System.out.println(\"---------------g---------\"); } public static void main(String[] args) { Test t = new Test(); try { t.g(); } catch (MyException e) { e.printStackTrace(); } }} 12345678进入g的异常...........demo1.MyException: 文件没有找到--02 at demo1.Test.g(Test.java:23) at demo1.Test.main(Test.java:31)Caused by: java.lang.ArithmeticException: / by zero at demo1.Test.f(Test.java:13) at demo1.Test.g(Test.java:19) ... 1 more 结论：A()体内调用另一个T()，这个T()`throw抛出异常或者不处理，A()捕获T()，A()中捕获T()中的异常，那么A()中的catch就会处理异常，但是T()`异常出现位置的后续程序都不会执行。（有异常，程序中断，后续程序不会执行） 自定义异常Java自定义异常的使用要经历如下四个步骤： 定义一个类继承Throwable或其子类（RuntimeException，即Unchecked Exception）。 添加构造方法(当然也可以不用添加，使用默认构造方法)。 在某个方法类抛出该异常。 捕捉该异常。异常处理步骤 调用异常的对象的printStackTrace()，打印方法调用栈的异常信息。 如果出现异常的线程为主线程，则整个程序运行终止；如果非主线程，则终止该线程，其他线程继续运行。 finally语句在任何情况下都必须执行的代码，这样可以保证一些在任何情况下都必须执行代码的可靠性。比如，在数据库查询异常的时候，应该释放JDBC连接等等。 通过分析思考可以看出，越早处理异常消耗的资源和时间越小，产生影响的范围也越小。因此，不要把自己能处理的异常也抛给调用者。finally语句先于return语句执行，而不论其先后位置，也不管是否try块出现异常。finally语句唯一不被执行的情况是方法执行System.exit(0)。System.exit(0)的作用是终止当前正在运行的Java虚拟机。（终止线程）finally语句块中不能通过给变量赋新值来改变return的返回值，也建议不要在finally块中使用return语句，没有意义还容易导致错误。（finally中有return，程序会返回此return，因为finally优先于try的return执行，so，程序是返回finally的return！实际上就是finally的return会覆盖try的return） 4、异常链在设计模式中有一个叫做责任链模式，该模式是将多个对象链接成一条链，客户端的请求沿着这条链传递直到被接收、处理。同样Java异常机制也提供这样一条链：异常链。有两种方式处理异常，一是throws抛出交给上级处理，二是try…catch做具体处理。try…catch的catch块可以不需要做任何处理，仅仅只用throw这个关键字将封装异常信息主动抛出来。然后在通过关键字throws继续抛出该方法异常。 它的上层也可以做这样的处理，以此类推就会产生一条由异常构成的异常链。通过使用异常链，我们可以提高代码的可理解性、系统的可维护性和友好性。同理，有时候在捕获一个异常后抛出另一个异常信息（异常转移），并且希望将原始的异常信息也保持起来，这个时候也需要使用异常链。在异常链的使用中，throw抛出的是一个新的异常信息，这样势必会导致原有的异常信息丢失，如何保持？在Throwable及其子类中的构造器中都可以接受一个cause参数，该参数保存原有的异常信息，通过getCause()就可以获取该原始异常信息。 实例123456789101112131415161718192021222324252627282930public class Test { public void f() throws MyException{ try { FileReader reader = new FileReader(\"G:\\\\myfile\\\\struts.txt\"); Scanner in = new Scanner(reader); System.out.println(in.next()); } catch (FileNotFoundException e) { //e 保存异常信息 throw new MyException(\"文件没有找到--01\",e); } } public void g() throws MyException{ try { f(); } catch (MyException e) { //e 保存异常信息 throw new MyException(\"文件没有找到--02\",e); } } public static void main(String[] args) { Test t = new Test(); try { t.g(); } catch (MyException e) { e.printStackTrace(); } }} 运行结果：优先打印出try..catch的异常或者由JVM处理的异常信息，栈是先进后出。这里先进入是main()，然后g()，最后f()。12345678910111213com.test9.MyException: 文件没有找到--02 at com.test9.Test.g(Test.java:31) at com.test9.Test.main(Test.java:38)Caused by: com.test9.MyException: 文件没有找到--01 这里才是异常链 at com.test9.Test.f(Test.java:22) at com.test9.Test.g(Test.java:28) ... 1 moreCaused by: java.io.FileNotFoundException: G:\\myfile\\struts.txt (系统找不到指定的路径。)JVM处理的异常信息 at java.io.FileInputStream.open(Native Method) at java.io.FileInputStream.&lt;init&gt;(FileInputStream.java:106) at java.io.FileInputStream.&lt;init&gt;(FileInputStream.java:66) at java.io.FileReader.&lt;init&gt;(FileReader.java:41) at com.test9.Test.f(Test.java:17) ... 2 more 5、异常的使用误区1234567891011121314OutputStreamWriter out = null;java.sql.Connection conn = null;try { // ---------1 Statement stat = conn.createStatement(); ResultSet rs = stat.executeQuery(\"select *from user\"); while (rs.next()){ out.println(\"name:\" + rs.getString(\"name\") + \"sex:\"+ rs.getString(\"sex\"));} conn.close(); //------2 out.close();} catch (Exception ex){ //------3 ex.printStackTrace(); //------4} 减小try代码块对于这个try…catch块是为捕获SQL的异常，但是这个try块是不是包含太多的信息。这是代码坏习惯。将一大块的代码全部包含在一个try块里面，因为这样省事，反正有异常它就会抛出，而不愿意花时间来分析这个大代码块有哪些会产生异常，产生什么类型的异常，反正就是一篓子全部搞定。所有对于一个异常块，应该仔细分清楚每块的抛出异常，因为一个大代码块有太多的地方会出现异常。 解决方式1：把一个catch()拆分成N个catch()，分别进行异常捕获123456789try{}catch(IOException e1){}catch(SQLException e2){}catch(Exception e){} 解决方式2：使用N个try…catch()进行捕获异常1234567891011121314151617try{}catch(IOException e1){ //IO Exception}try{}catch(SQLException e2){ //SQL Exception}try{}catch(Exception e){ } 保证所有资源都被正确释放，充分运用finally关键词如果该程序发生异常那么conn.close(); out.close(); 是不可能执行得到的，这样势必会导致资源不能释放掉。所以如果程序用到文件、Socket、JDBC连接之类的资源，即使遇到异常，也要确保能够正确释放占用的资源。这里finally就有用武之地：不管是否出现异常，finally总是有机会运行的，所以finally用于释放资源是再适合不过。 catch语句应当尽量指定具体的异常类型，而不应该指定涵盖范围太广的Exception类首先catch块所表示是它预期会出现何种异常，并且需要做何种处理，而使用Exception就表示要处理所有的异常信息，但是不可能处理所有异常。不要一个Exception试图处理所有可能出现的异常。主要是特定异常，有特定的修复方法。补充：用Exception要放在最后一个catch，保证所有意料之外的异常都能被捕获，但是catch(Exception e)虽然能捕获所有异常对象，但是其处理方法却只能有一种，无针对性，不建议这么使用。这里再来看看上面的程序实例，很显然它可能需要抛出两个异常信息，SQLException和IOException。所以一个catch处理两个截然不同的Exception明显的不合适(if...else可以处理)。如果用两个catch，一个处理SQLException、一个处理IOException就好多。 既然捕获异常，就要对它进行适当的处理这里涉及到两个问题，一是，捕获异常不做处理，二是异常信息不够明确。尽量不要在catch中就用一句话来处理异常ex.printStackTrace()。有异常时要处理的。 异常处理方法 处理异常。对所发生的的异常进行一番处理，如修正错误、提醒。再次申明ex.printStackTrace()算不上已经“处理好异常”。 重新抛出异常。如果本方法没有办法处理异常，则抛给上一个方法。 封装异常。对异常信息进行分类，然后进行封装处理。 不要捕获异常。则发生异常抛给JVM处理。 异常信息不明确。对于这样的java.io.FileNotFoundException: ………！所以在出现异常后，最好能够提供一些文字信息，例如当前正在执行的类、方法和其他状态信息，包括以一种更适合阅读的方式整理和组织printStackTrace提供的信息。对代码层次结构的污染经常将代码分 Service、Business Logic、DAO 等不同的层次结构，DAO 层中会包含抛出异常的方法，如所示123public Customer retrieveCustomerById(Long id) throw SQLException { //根据 ID 查询数据库} 上面这段代码没什么问题，但是从设计耦合角度仔细考虑一下，这里的SQLException污染到上层调用代码，调用层需要显式的利用try-catch捕捉，或者向更上层次进一步抛出。根据设计隔离原则，可以适当修改成：使用非检测性的异常封装检测性异常，向上一层进行抛Exception。1234567891011public Customer retrieveCustomerById(Long id) { try{ //根据ID查询数据库 }catch(SQLException e){ //利用非检测异常封装检测异常，降低层次耦合 //对异常进行转换，抛向上一层 throw new RuntimeException(SQLErrorCode, e); }finally{ //关闭连接，清理资源 }} 将异常包含在循环语句块中异常在for里和for外，整体性能差异不大，根据业务来实现不同try...catch...方式。 如果需要在for执行时候报异常，下一次for依然要执行。try...catch放在for中。因为try...catch...只捕获当前的异常，然后执行catch之后的程序。 1234567for(,,){ try{ }catch(Exception e){ }} 在for执行时候报异常，不执行下一次for语句，直接执行for代码块后面的程序。try...catch...放在for外。 1234567try{ for(,,){ }}catch(Exception e){} 6、总结Think in java应该在下列情况下使用异常。 在恰当的级别处理问题，在知道该如何处理异常的情况下才捕获异常，未有异常的代码，可以不做捕获。 解决问题并且重新调用产生异常的方法。 进行少许修补，然后绕过异常发生的地方继续执行。能修补就修补，不能继续执行异常后程序。如果一段业务需要执行，但是这段业务不影响主要业务，报错，需要继续执行后续业务，则这段业务捕获异常，出错就会执行异常后的代码。 用别的数据进行计算，以代替方法预计会返回的值。比如，返回一个默认值。 把当前运行环境下能做的事情尽量做完。然后把相同的异常重新抛到更高层。比如，Dao-&gt;Service-&gt;Controller 终止程序。 进行简化。 让类库和程序更加安全。这既是在为调试做短期投资，也是在为程序的健壮做长期投资。 异常的重要准则是只有在知道如何处理的情况下才捕获异常。把错误处理的代码同错误发生的地点相分离。举个列子service-dao两层，在dao里产生SQLException我无需处理直接抛出，到service层，我知道要将其转换成自己的业务异常。异常的转移，异常链，在Action转换成客户端的错误！Effective java 基于异常的模式：用try...catch，不能忽略异常打印的信息，以免照成有异常抛出，也不能及时发现（catch放空） 异常应该只用于异常的情况下，它们永远不应该用于正常的控制流。 对可恢复的情况使用受检异常，对编程错误使用运行时异常。何为可恢复的情况，是指不改变代码的基础上，这个异常情况是可以恢复的，比喻IOExcepion可能是网络的问题，解决网络，代码就能继续运行下去；何为错误，当然指不能恢复的啦，比喻从你控制范围之外传递进来的null引用，所以，此类异常都是程序员的问题，作为程序员，应该在代码中进行必要的检查。 异常类越少，意味着内存印迹就越小，装载这些类的时间开销也越少。 异常转译：高层的实现应该捕获低层的异常，同时抛出可以按照高层抽象进行解释的异常。异常链就是一种特殊的异常转译形式，高层异常可以通过getCause来获得低层的异常。 异常的细节信息应该包含所有的对该异常有贡献的参数和域的值。比喻IndexOutOfBoundsException应该包含lowerBound，upperBound，Index三个参数。遗憾的是Java平台里并没有广泛的使用这种做法，而是全部清一色的简单继承下父Exception。 失败原子性：失败的方法调用应该使对象保持在调用前的状态。原子性的操作，应该保证之前对象的状态。","link":"/Java-Exception/"},{"title":"Fork-Join源码分析","text":"1 Fork ForkJoinTask#fork() ForkJoinWorkerThread#pushTask() ForkJoinWorkerThread#growQueue() 2 Join ForkJoinTask#doJoin() ForkJoinWorkerThread#unpushTask() ForkJoinWorkerThread#joinTask() ForkJoinWorkerThread#localHelpJoinTask() ForkJoinWorkerThread#tryDeqAndExec() ForkJoinWorkerThread#helpJoinTask() ForkJoinPool#tryAwaitJoin() ForkJoinPool#tryPreBlock() ForkJoinTask#tryAwaitDone() ForkJoinPool#postBlock() ForkJoinTask#cancelIgnoringExceptions() cancelIgnoringExceptions() ForkJoinTask#getRawResult() RecursiveTask#getRawResult() ForkJoinTask#reportResult() 3 总结 这篇源码分析基于JDK7。 1 Fork通过分析一个Fork-Join任务的执行过程来分析Fork-Join的相关代码，主要侧重于分裂(Fork)/合并(Join)过程。 SumTask123456789101112131415161718192021222324252627282930313233public class SumTask extends RecursiveTask&lt;Long&gt;{ private static final int THRESHOLD = 10; private long start; private long end; public SumTask(long n) { this(1,n); } private SumTask(long start, long end) { this.start = start; this.end = end; } @Override protected Long compute() { long sum = 0; if((end - start) &lt;= THRESHOLD){ for(long l = start; l &lt;= end; l++){ sum += l; } }else{ long mid = (start + end) &gt;&gt;&gt; 1; SumTask left = new SumTask(start, mid); SumTask right = new SumTask(mid + 1, end); left.fork(); right.fork(); sum = left.join() + right.join(); } return sum; } private static final long serialVersionUID = 1L; } ForkJoinTask#fork()1234567891011121314151617181920212223/** * Arranges to asynchronously execute this task. While it is not * necessarily enforced, it is a usage error to fork a task more * than once unless it has completed and been reinitialized. * Subsequent modifications to the state of this task or any data * it operates on are not necessarily consistently observable by * any thread other than the one executing it unless preceded by a * call to {@link #join} or related methods, or a call to {@link * #isDone} returning {@code true}. * * &lt;p&gt;This method may be invoked only from within {@code * ForkJoinPool} computations (as may be determined using method * {@link #inForkJoinPool}). Attempts to invoke in other contexts * result in exceptions or errors, possibly including {@code * ClassCastException}. * * @return {@code this}, to simplify usage */ public final ForkJoinTask&lt;V&gt; fork() { ((ForkJoinWorkerThread) Thread.currentThread()) .pushTask(this); return this; } ForkJoinWorkerThread#pushTask()123456789101112131415161718192021/** * Pushes a task. Call only from this thread. * * @param t the task. Caller must ensure non-null. */ final void pushTask(ForkJoinTask&lt;?&gt; t) { ForkJoinTask&lt;?&gt;[] q; int s, m; if ((q = queue) != null) { // ignore if queue removed // 1 long u = (((s = queueTop) &amp; (m = q.length - 1)) &lt;&lt; ASHIFT) + ABASE; // 2 UNSAFE.putOrderedObject(q, u, t); // 3 queueTop = s + 1; // or use putOrderedInt if ((s -= queueBase) &lt;= 2) pool.signalWork(); else if (s == m) // 4 growQueue(); } } 标注代码分析 这里首先根据当前的queueTop对队列(数组)长度取模来算出放置任务的下标,然后再通过下标算出偏移地址，提供给Unsafe使用。 设置任务。 修改queueTop。 如果队列满了，扩展一下队列容量。ForkJoinWorkerThread#growQueue()12345678910111213141516171819202122232425262728/** * Creates or doubles queue array. Transfers elements by * emulating steals (deqs) from old array and placing, oldest * first, into new array. */ private void growQueue() { ForkJoinTask&lt;?&gt;[] oldQ = queue; int size = oldQ != null ? oldQ.length &lt;&lt; 1 : INITIAL_QUEUE_CAPACITY; // 1 if (size &gt; MAXIMUM_QUEUE_CAPACITY) throw new RejectedExecutionException(\"Queue capacity exceeded\"); // 2 if (size &lt; INITIAL_QUEUE_CAPACITY) size = INITIAL_QUEUE_CAPACITY; ForkJoinTask&lt;?&gt;[] q = queue = new ForkJoinTask&lt;?&gt;[size]; int mask = size - 1; int top = queueTop; int oldMask; if (oldQ != null &amp;&amp; (oldMask = oldQ.length - 1) &gt;= 0) { for (int b = queueBase; b != top; ++b) { long u = ((b &amp; oldMask) &lt;&lt; ASHIFT) + ABASE; Object x = UNSAFE.getObjectVolatile(oldQ, u); if (x != null &amp;&amp; UNSAFE.compareAndSwapObject(oldQ, u, x, null)) UNSAFE.putObjectVolatile (q, ((b &amp; mask) &lt;&lt; ASHIFT) + ABASE, x); } } } 标注代码分析 容量为原来的2倍，不超过MAXIMUM_QUEUE_CAPACITY(1 &lt;&lt; 24)。 最小为INITIAL_QUEUE_CAPACITY(1 &lt;&lt; 13)。 2 Join123456789101112131415161718/** * Returns the result of the computation when it {@link #isDone is * done}. This method differs from {@link #get()} in that * abnormal completion results in {@code RuntimeException} or * {@code Error}, not {@code ExecutionException}, and that * interrupts of the calling thread do &lt;em&gt;not&lt;/em&gt; cause the * method to abruptly return by throwing {@code * InterruptedException}. * * @return the computed result */public final V join() { // 1 if (doJoin() != NORMAL) return reportResult(); else return getRawResult();} 标注代码分析 先调用doJoin()，如果doJoin()返回NORMAL，那么通过getRawResult()来获取结果；否则会调用reportResult()来处理和获取结果。ForkJoinTask#doJoin()123456789101112131415161718192021222324252627/** * Primary mechanics for join, get, quietlyJoin. * @return status upon completion */ private int doJoin() { Thread t; ForkJoinWorkerThread w; int s; boolean completed; if ((t = Thread.currentThread()) instanceof ForkJoinWorkerThread) { // 1 if ((s = status) &lt; 0) return s; // 2 if ((w = (ForkJoinWorkerThread)t).unpushTask(this)) { try { completed = exec(); } catch (Throwable rex) { return setExceptionalCompletion(rex); } if (completed) return setCompletion(NORMAL); } // 3 return w.joinTask(this); } else // 4 return externalAwaitDone(); } 标注代码分析 如果当前任务已经完成，直接返回状态。 如果当前任务恰好是当前工作线程的队列顶端的第一个任务，那么将该任务出队，然后执行。 否则调用当前工作线程的joinTask()。 如果当前线程不是ForkJoin工作线程，那么调用externalAwaitDone()。ForkJoinWorkerThread#unpushTask()1234567891011121314151617/** * Specialized version of popTask to pop only if topmost element * is the given task. Called only by this thread. * * @param t the task. Caller must ensure non-null. */final boolean unpushTask(ForkJoinTask&lt;?&gt; t) { ForkJoinTask&lt;?&gt;[] q; int s; if ((q = queue) != null &amp;&amp; (s = queueTop) != queueBase &amp;&amp; UNSAFE.compareAndSwapObject (q, (((q.length - 1) &amp; --s) &lt;&lt; ASHIFT) + ABASE, t, null)) { queueTop = s; // or putOrderedInt return true; } return false;} 这是另一个版本的pop。unpushTash()中仅当给定的t是队列顶端的任务，才会返回并移除t。 ForkJoinWorkerThread#joinTask()12345678910111213141516171819202122232425262728293031323334353637383940/** * Possibly runs some tasks and/or blocks, until joinMe is done. * * @param joinMe the task to join * @return completion status on exit */ final int joinTask(ForkJoinTask&lt;?&gt; joinMe) { // 1 ForkJoinTask&lt;?&gt; prevJoin = currentJoin; // 2 currentJoin = joinMe; for (int s, retries = MAX_HELP;;) { if ((s = joinMe.status) &lt; 0) { // 3 currentJoin = prevJoin; // 4 return s; } if (retries &gt; 0) { if (queueTop != queueBase) { // 5 if (!localHelpJoinTask(joinMe)) retries = 0; // cannot help } else if (retries == MAX_HELP &gt;&gt;&gt; 1) { --retries; // check uncommon case // 6 if (tryDeqAndExec(joinMe) &gt;= 0) // 7 Thread.yield(); // for politeness } else retries = helpJoinTask(joinMe) ? MAX_HELP : retries - 1; } else { retries = MAX_HELP; // restart if not done pool.tryAwaitJoin(joinMe); } } } 标注代码分析 记录之前的合并任务。 设置当前工作线程的合并任务。 如果合并任务已经完成，恢复之前的合并任务。 返回任务状态。 如果当前任务队列中有任务，尝试从当前队列顶端获取给定任务 (如果给定任务恰好在当前任务队列顶端的话)或者其他一个已经被取消的任务。 这里尝试一种特殊情况：如果给定的任务正好在其他工作线程的队列的底部，那么尝试窃取这个任务并执行。 如果没成功，这里出让一下CPU。 joinTask方法中主体是一个无限循环，里面会先尝试帮助合并的一些操作，失败的话会继续重试，最多尝试MAX_HELP次。超过了MAX_HELP无法继续尝试的话，就会调用tryAwaitJoin()等待合并任务。尝试过程中，如果当前任务队列中有任务，会调用localHelpJoinTask()，如果方法调用失败会直接进入合并等待；否则会先进行helpJoinTask()的尝试，尝试MAX_HELP/2次，成功的话会一直尝试，直到给定的任务完成；如果helpJoinTask()尝试了MAX_HELP/2次都没有成功过，且本地队列一直没有任务，那么会进行一个特殊的尝试，会假设给定的任务在其他工作线程的任务队列的底部，然后去窃取这个任务，也会尝试MAX_HELP/2次。 ForkJoinWorkerThread#localHelpJoinTask()1234567891011121314151617181920212223/** * If present, pops and executes the given task, or any other * cancelled task * * @return false if any other non-cancelled task exists in local queue */ private boolean localHelpJoinTask(ForkJoinTask&lt;?&gt; joinMe) { int s, i; ForkJoinTask&lt;?&gt;[] q; ForkJoinTask&lt;?&gt; t; if ((s = queueTop) != queueBase &amp;&amp; (q = queue) != null &amp;&amp; (i = (q.length - 1) &amp; --s) &gt;= 0 &amp;&amp; (t = q[i]) != null) { if (t != joinMe &amp;&amp; t.status &gt;= 0) // 1 return false; if (UNSAFE.compareAndSwapObject (q, (i &lt;&lt; ASHIFT) + ABASE, t, null)) { // 2 queueTop = s; // or putOrderedInt t.doExec(); } } return true; } 标注代码分析 如果当前工作线程的任务队列顶端的任务不是给定任务，且任务的状态是未取消(这里如果&lt;0，一定是取消的任务)，返回false。 取出给定任务或者一个被取消的任务。 如果当前任务队列顶端的任务是要合并的任务，或者是一个被取消的任务，那么尝试处理这个任务，返回成功；否则失败。 ForkJoinWorkerThread#tryDeqAndExec()12345678910111213141516171819202122232425262728293031323334353637/** * Performs an uncommon case for joinTask: If task t is at base of * some workers queue, steals and executes it. * * @param t the task * @return t's status */ private int tryDeqAndExec(ForkJoinTask&lt;?&gt; t) { int m = pool.scanGuard &amp; SMASK; ForkJoinWorkerThread[] ws = pool.workers; // 1 if (ws != null &amp;&amp; ws.length &gt; m &amp;&amp; t.status &gt;= 0) { for (int j = 0; j &lt;= m; ++j) { ForkJoinTask&lt;?&gt;[] q; int b, i; ForkJoinWorkerThread v = ws[j]; if (v != null &amp;&amp; (b = v.queueBase) != v.queueTop &amp;&amp; (q = v.queue) != null &amp;&amp; (i = (q.length - 1) &amp; b) &gt;= 0 &amp;&amp; q[i] == t) { // 2 long u = (i &lt;&lt; ASHIFT) + ABASE; if (v.queueBase == b &amp;&amp; UNSAFE.compareAndSwapObject(q, u, t, null)) { v.queueBase = b + 1; v.stealHint = poolIndex; ForkJoinTask&lt;?&gt; ps = currentSteal; currentSteal = t; t.doExec(); currentSteal = ps; } break; } } } return t.status; } 标注代码分析 扫描所有工作线程。 如果有工作线程的任务队列的底部正好是给定任务t。尝试窃取t后执行。 如果有工作线程的队列底部的任务正好是要合并的任务，那么窃取该任务然后处理之。 ForkJoinWorkerThread#helpJoinTask()123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384/** * Tries to locate and execute tasks for a stealer of the given * task, or in turn one of its stealers, Traces * currentSteal-&gt;currentJoin links looking for a thread working on * a descendant of the given task and with a non-empty queue to * steal back and execute tasks from. The implementation is very * branchy to cope with potential inconsistencies or loops * encountering chains that are stale, unknown, or of length * greater than MAX_HELP links. All of these cases are dealt with * by just retrying by caller. * * @param joinMe the task to join * @param canSteal true if local queue is empty * @return true if ran a task */ private boolean helpJoinTask(ForkJoinTask&lt;?&gt; joinMe) { boolean helped = false; int m = pool.scanGuard &amp; SMASK; ForkJoinWorkerThread[] ws = pool.workers; if (ws != null &amp;&amp; ws.length &gt; m &amp;&amp; joinMe.status &gt;= 0) { int levels = MAX_HELP; // remaining chain length ForkJoinTask&lt;?&gt; task = joinMe; // base of chain outer:for (ForkJoinWorkerThread thread = this;;) { // Try to find v, the stealer of task, by first using hint // 1 ForkJoinWorkerThread v = ws[thread.stealHint &amp; m]; if (v == null || v.currentSteal != task) { // 2 for (int j = 0; ;) { // search array if ((v = ws[j]) != null &amp;&amp; v.currentSteal == task) { // 3 thread.stealHint = j; break; // save hint for next time } if (++j &gt; m) // 4 break outer; // can't find stealer } } // Try to help v, using specialized form of deqTask // 5 for (;;) { ForkJoinTask&lt;?&gt;[] q; int b, i; if (joinMe.status &lt; 0) // 6 break outer; if ((b = v.queueBase) == v.queueTop || (q = v.queue) == null || (i = (q.length-1) &amp; b) &lt; 0) // 7 break; // empty long u = (i &lt;&lt; ASHIFT) + ABASE; ForkJoinTask&lt;?&gt; t = q[i]; if (task.status &lt; 0) // 8 break outer; // stale // 9 if (t != null &amp;&amp; v.queueBase == b &amp;&amp; UNSAFE.compareAndSwapObject(q, u, t, null)) { // 10 v.queueBase = b + 1; v.stealHint = poolIndex; ForkJoinTask&lt;?&gt; ps = currentSteal; currentSteal = t; t.doExec(); currentSteal = ps; helped = true; } } // Try to descend to find v's stealer // 11 ForkJoinTask&lt;?&gt; next = v.currentJoin; if (--levels &gt; 0 &amp;&amp; task.status &gt;= 0 &amp;&amp; next != null &amp;&amp; next != task) { task = next; thread = v; } else // 12 break; // max levels, stale, dead-end, or cyclic } } return helped; } 标注代码分析 找到线程thread的窃取者v。 如果thread没有窃取者或者v当前窃取的任务不是task，扫描工作线程数组。 如果找到了窃取线程，将其设置为thread的窃取线程。 没找到的话，直接跳出outer循环。 找到了窃取者v。 如果joinMe任务已经完成，跳出outer循环。 如果v的队列是空的，跳出当前循环。 如果task任务已经完成，跳出outer循环。 尝试窃取v的任务队列底部的任务。 窃取成功后，执行任务。 再去找v的窃取者，注意这里是一个链。 如果超过最大深度(MAX_HELP)或者task已经执行完成 或者 找到了头(next==null)或者出现循环退出。 这个方法的前提是当前线程需要join给定的任务joinMe，但是这个任务被其他线程(窃取者)窃取了。所以方法中首先找到窃取joinMe任务的工作线程v，如果找到了窃取者v，就会从v的任务队列中窃取任务来完成(帮助v完成任务)。但也有可能v也在join其他的任务(比如当前线程执行任务过程中，分裂出一个子任务A，工作线程v窃取了A，然后执行，执行过程中A由分裂出子任务A1，A1又被另一个工作线程v1给窃取了…是一个链)，所以方法中要顺着这个链一直找下去，目的就是能尽快的合并joinMe任务。为了避免一些情况，这里尝试的最大链深度限定为MAX_HELP。 ForkJoinPool#tryAwaitJoin()1234567891011121314151617181920212223/** * Possibly blocks waiting for the given task to complete, or * cancels the task if terminating. Fails to wait if contended. * * @param joinMe the task */ final void tryAwaitJoin(ForkJoinTask&lt;?&gt; joinMe) { int s; Thread.interrupted(); // clear interrupts before checking termination // 1 if (joinMe.status &gt;= 0) { // 2 if (tryPreBlock()) { // 3 joinMe.tryAwaitDone(0L); // 4 postBlock(); } else if ((ctl &amp; STOP_BIT) != 0L) // 5 joinMe.cancelIgnoringExceptions(); } } 标注代码分析 如果joinMe未完成。 尝试阻塞等待之前的预操作。 在joinMe任务上阻塞等待。 被唤醒后的操作。 如果Pool关闭了，取消任务。调用其cancelIgnoringExceptions()。ForkJoinPool#tryPreBlock()12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758/** * Tries to increment blockedCount, decrement active count * (sometimes implicitly) and possibly release or create a * compensating worker in preparation for blocking. Fails * on contention or termination. * * @return true if the caller can block, else should recheck and retry */ private boolean tryPreBlock() { int b = blockedCount; // 1 if (UNSAFE.compareAndSwapInt(this, blockedCountOffset, b, b + 1)) { int pc = parallelism; do { ForkJoinWorkerThread[] ws; ForkJoinWorkerThread w; int e, ac, tc, rc, i; long c = ctl; int u = (int)(c &gt;&gt;&gt; 32); // 2 if ((e = (int)c) &lt; 0) { // skip -- terminating } else if ((ac = (u &gt;&gt; UAC_SHIFT)) &lt;= 0 &amp;&amp; e != 0 &amp;&amp; (ws = workers) != null &amp;&amp; (i = ~e &amp; SMASK) &lt; ws.length &amp;&amp; (w = ws[i]) != null) { // 3 long nc = ((long)(w.nextWait &amp; E_MASK) | (c &amp; (AC_MASK|TC_MASK))); if (w.eventCount == e &amp;&amp; UNSAFE.compareAndSwapLong(this, ctlOffset, c, nc)) { w.eventCount = (e + EC_UNIT) &amp; E_MASK; if (w.parked) UNSAFE.unpark(w); return true; // release an idle worker } } else if ((tc = (short)(u &gt;&gt;&gt; UTC_SHIFT)) &gt;= 0 &amp;&amp; ac + pc &gt; 1) { // 4 long nc = ((c - AC_UNIT) &amp; AC_MASK) | (c &amp; ~AC_MASK); if (UNSAFE.compareAndSwapLong(this, ctlOffset, c, nc)) return true; // no compensation needed } else if (tc + pc &lt; MAX_ID) { // 5 long nc = ((c + TC_UNIT) &amp; TC_MASK) | (c &amp; ~TC_MASK); if (UNSAFE.compareAndSwapLong(this, ctlOffset, c, nc)) { addWorker(); return true; // create a replacement } } // try to back out on any failure and let caller retry // 6 } while (!UNSAFE.compareAndSwapInt(this, blockedCountOffset, b = blockedCount, b - 1)); } return false; } 标注代码分析 累加等待join任务的计数。 如果Pool关闭了，跳过。 如果当前活动的工作线程不大于cpu核数，且有线程在等待任务(处于空闲状态)。那么唤醒这个工作线程。 如果总的工作线程数量不少于cpu核心数量，且至少有一个活动的工作线程。尝试在总控信息上将AC递减。 如果不满足上面条件，这里会增加一个工作线程。 如果失败，这里会把刚才对b增加的1给减回去。ForkJoinTask#tryAwaitDone()1234567891011121314151617181920212223/** * Tries to block a worker thread until completed or timed out. * Uses Object.wait time argument conventions. * May fail on contention or interrupt. * * @param millis if &gt; 0, wait time. */final void tryAwaitDone(long millis) { int s; try { if (((s = status) &gt; 0 || (s == 0 &amp;&amp; UNSAFE.compareAndSwapInt(this, statusOffset, 0, SIGNAL))) &amp;&amp; status &gt; 0) { synchronized (this) { if (status &gt; 0) wait(millis); } } } catch (InterruptedException ie) { // caller must check termination }} 阻塞等待(join任务)时，首先会检查join任务的状态，如果join任务未完成的话，才可以在join任务上等待。也就是说，join的运行状态(再回顾一下task的运行状态定义)必须大于等于0。如果join#status大于0，说明join任务上已经有其他工作线程等待了，当前线程直接等待就可以了；如果join#status等于0，说明当前线程是第一个要在join任务上阻塞等待的线程，那么会尝试将join的status改为SIGNAL(1)，然后进行阻塞等待工作。注意方法中不会处理中断异常，需要外部来处理。 ForkJoinPool#postBlock()12345678910111213/** * Decrements blockedCount and increments active count */ private void postBlock() { long c; // 1 do {} while (!UNSAFE.compareAndSwapLong(this, ctlOffset, // no mask c = ctl, c + AC_UNIT)); int b; // 2 do {} while (!UNSAFE.compareAndSwapInt(this, blockedCountOffset, b = blockedCount, b - 1)); } 标注代码分析 累加活动线程计数。 递减等待join任务的计数。ForkJoinTask#cancelIgnoringExceptions()123456789101112/** * Cancels, ignoring any exceptions thrown by cancel. Used during * worker and pool shutdown. Cancel is spec'ed not to throw any * exceptions, but if it does anyway, we have no recourse during * shutdown, so guard against this case. */final void cancelIgnoringExceptions() { try { cancel(false); } catch (Throwable ignore) { }} 123456789101112131415161718192021222324252627282930/** * Attempts to cancel execution of this task. This attempt will * fail if the task has already completed or could not be * cancelled for some other reason. If successful, and this task * has not started when {@code cancel} is called, execution of * this task is suppressed. After this method returns * successfully, unless there is an intervening call to {@link * #reinitialize}, subsequent calls to {@link #isCancelled}, * {@link #isDone}, and {@code cancel} will return {@code true} * and calls to {@link #join} and related methods will result in * {@code CancellationException}. * * &lt;p&gt;This method may be overridden in subclasses, but if so, must * still ensure that these properties hold. In particular, the * {@code cancel} method itself must not throw exceptions. * * &lt;p&gt;This method is designed to be invoked by &lt;em&gt;other&lt;/em&gt; * tasks. To terminate the current task, you can just return or * throw an unchecked exception from its computation method, or * invoke {@link #completeExceptionally}. * * @param mayInterruptIfRunning this value has no effect in the * default implementation because interrupts are not used to * control cancellation. * * @return {@code true} if this task is now cancelled */ public boolean cancel(boolean mayInterruptIfRunning){ return setCompletion(CANCELLED) == CANCELLED; } 123456789101112131415161718/** * Marks completion and wakes up threads waiting to join this task, * also clearing signal request bits. * * @param completion one of NORMAL, CANCELLED, EXCEPTIONAL * @return completion status on exit */ private int setCompletion(int completion) { for (int s;;) { if ((s = status) &lt; 0) return s; if (UNSAFE.compareAndSwapInt(this, statusOffset, s, completion)) { if (s != 0) synchronized (this) { notifyAll(); } return completion; } } } 1private static final int CANCELLED = -2; cancelIgnoringExceptions()cancelIgnoringExceptions()中的逻辑就是将任务运行状态设置为CANCELLED，然后唤醒在任务上等待的线程。 ForkJoinTask#getRawResult()回到ForkJoinTask#join()，如果正常完成会调用getRawResult()。12345678910/** * Returns the result that would be returned by {@link #join}, even * if this task completed abnormally, or {@code null} if this task * is not known to have been completed. This method is designed * to aid debugging, as well as to support extensions. Its use in * any other context is discouraged. * * @return the result, or {@code null} if not completed */public abstract V getRawResult(); ForkJoinTask#getRawResult()未实现，交由子类去实现，比如在RecursiveTask。 RecursiveTask#getRawResult()1234567public final V getRawResult() { return result;}protected final void setRawResult(V value) { result = value;} ForkJoinTask#reportResult()1234567891011121314/** * Report the result of invoke or join; called only upon * non-normal return of internal versions. */ private V reportResult() { int s; Throwable ex; // 1 if ((s = status) == CANCELLED) throw new CancellationException(); // 2 if (s == EXCEPTIONAL &amp;&amp; (ex = getThrowableException()) != null) UNSAFE.throwException(ex); return getRawResult(); } 如果ForkJoinTask#join()中，任务非正常结束，会调用reportResult()。标注代码分析 如果任务状态为取消，抛出取消异常； 如果任务状态是异常结束，会从异常表中获取异常，获取到的话，抛出异常。3 总结 fork()会将任务添加到当前工作线程的任务队列的里面。 join()某个任务后，当前线程要做的首先是想办法完成这个任务，或者帮助加快这个任务的完成，如果这些尝试失败，当前线程就会在要join的任务(等待队列)上进行阻塞等待，等任务完成后被唤醒。","link":"/Fork-Join-Source/"},{"title":"Java Class文件的结构(理论篇)","text":"1 Class文件字节编码存储顺序统一 2 无符号数和表 3 class文件中的字节流 4 Class文件中的字节流每项的含义 u4 magic u2 minor_version u2 major_version u2 constant_pool_count cp_info 字面量 符号引用 14个常量 u2 access_flags u2 this_class u2 super_class u2 interface_counts u2 interface[interface_counts] u2 fields_count field_info fields[fields_count] access_flags name_index descriptor_index attributes_count u2 methods_count method_info access_flags name_index descriptor_index attribute_info attribute_count 5 常量池结构 CONSTANT_Class_info结构 tag name_index CONSTANT_Fieldref_info结构 tag class_index name_and_type_index CONSTANT_Methodref_info结构 tag class_index name_and_type_index CONSTANT_InterfaceMethodref_info结构 tag class_index name_and_type_index CONSTANT_String_info结构 tag string_index CONSTANT_Integer_info结构 tag bytes CONSTANT_Float_info结构 tag bytes CONSTANT_Long_info结构 tag high_bytes 和 low_bytes CONSTANT_Double_info结构 tag high_bytes 和 low_bytes CONSTANT_NameAndType_info 结构 tag name_index descriptor_index CONSTANT_Utf8_info结构 tag length bytes[] CONSTANT_MethodHandle_info 结构 tag reference_kind reference_index CONSTANT_MethodType_info 结构 tag descriptor_index CONSTANT_InvokeDynamic_info 结构 tag bootstrap_method_attr_index name_and_type_index 6 属性表集合（attributes_count和attribute） Code属性 max_stack max_locals code_length和code ConstantValue属性 Exceptions属性 number_of_exceptions exception_index_table InnerClasses属性 inner_classes inner_class_info_index和outer_class_info_index inner_name_index inner_name_access_flags LineNumberTale属性 line_number_table line_number_info LocalVariableTable属性 local_variable_table local_variable_info SourceFile属性 Deprecated属性和Synthetic属性 学习Java的朋友应该都知道Java从刚开始的时候就打着平台无关性的旗号，说“一次编写，到处运行”，其实说到无关性，Java平台还有另外一个无关性那就是语言无关性，要实现语言无关性，那么Java体系中的class的文件结构或者说是字节码就显得相当重要了，其实Java从刚开始的时候就有两套规范，一个是Java语言规范，另外一个是Java虚拟机规范，Java语言规范只是规定了Java语言相关的约束以及规则，而虚拟机规范则才是真正从跨平台的角度去设计的。今天我们就以一个实际的例子来看看，到底Java中一个Class文件对应的字节码应该是什么样子。 这篇文章将首先总体上阐述一下Class到底由哪些内容构成，然后再用一个实际的Java类入手去分析class的文件结构。 1 Class文件字节编码存储顺序统一Class文件是有8位为基础的字节流构成的，这些字节流之间都严格按照规定的顺序排列，并且字节之间不存在任何空隙，对于超过8位的数据，将按照Big-Endian的顺序存储的，也就是说高位字节存储在低的地址上面，而低位字节存储到高地址上面，其实这也是class文件要跨平台的关键，因为PowerPC架构的处理采用Big-Endian的存储顺序，而x86系列的处理器则采用Little-Endian的存储顺序，因此为了Class文件在各中处理器架构下保持统一的存储顺序，虚拟机规范必须对起进行统一。 2 无符号数和表Class文件结构采用类似C语言的结构体来存储数据的，主要有两类数据项，无符号数和表。无符号数用来表述数字，索引引用以及字符串等，比如u1，u2，u4，u8分别代表1个字节，2个字节，4个字节，8个字节的无符号数，而表是有多个无符号数以及其它的表组成的复合结构。可能大家看到这里对无符号数和表到底是上面也不是很清楚，不过不要紧，等下面实例的时候，我会再以实例来解释。 3 class文件中的字节流Class文件结构。图来自The Java Virtual Machine Specification Java SE 7 Edition比如cp_info，cp_info表示常量池，上图中用constant_pool[constant_pool_count-1]的方式来表示常量池有constant_pool_count-1个常量，它这里是采用数组的表现形式，但是大家不要误以为所有的常量池的常量长度都是一样的，其实这个地方只是为了方便描述采用了数组的方式，但是这里并不像编程语言那里，一个int型的数组，每个int长度都一样。 4 Class文件中的字节流每项的含义每一项都具体代表含义。 u4 magic表示魔数，并且魔数占用了4个字节，魔数到底是做什么的呢？它其实就是表示一下这个文件的类型是一个Class文件，而不是一张JPG图片，或者AVI的电影。而Class文件对应的魔数是0xCAFEBABE。 u2 minor_version表示Class文件的次版本号，并且此版本号是u2类型的无符号数表示。 u2 major_version表示Class文件的主版本号，并且主版本号是u2类型的无符号数表示。major_version和minor_version主要用来表示当前的虚拟机是否接受当前这种版本的Class文件。不同版本的Java编译器编译的Class文件对应的版本是不一样的。高版本的虚拟机支持低版本的编译器编译的Class文件结构。比如Java SE 6.0对应的虚拟机支持Java SE 5.0的编译器编译的Class文件结构，反之则不行。 u2 constant_pool_count常量池的数量。 cp_info表示常量池，这里面就存储了各种各样的字面量和符号引用。放到常量池的中数据项在The Java Virtual Machine Specification Java SE 7 Edition中一共有14个常量，每一种常量都是一个表，并且每种常量都用一个公共的部分tag（标识符）来表示是哪种类型的常量。这里我们需要重点来说一下常量池是什么东西，请大家不要与JVM内存模型中的运行时常量池混淆了，Class文件中常量池主要存储了字面量以及符号引用。 字面量包括字符串，final常量的值或者某个属性的初始值等等。 符号引用存储类和接口的全限定名称，字段的名称以及描述符，方法的名称以及描述符。这里名称可能大家都容易理解，至于描述符的概念，放到下面说字段表以及方法表的时候再说。另外大家都知道JVM的内存模型中有堆、栈、方法区、程序计数器构成，而方法区中又存在一块区域叫运行时常量池，运行时常量池中存放的东西其实也就是编译器产生的各种字面量以及符号引用，只不过运行时常量池具有动态性，它可以在运行的时候向其中增加其它的常量进去，最具代表性的就是String的intern()。 14个常量 名字 tag(标识位) 说明 CONSTANT_Utf8_info 1 UTF-8编码的字符串 CONSTANT_Integer_info 3 整形字面量 CONSTANT_Float_info 4 浮点型字面量 CONSTANT_Long_info 5 长整形字面量 CONSTANT_Double_info 6 双精度字面量 CONSTANT_Class_info 7 类或接口的符号引用 CONSTANT_String_info 8 字符串类型的字面量 CONSTANT_Fieldref_info 9 字段的符号引用 CONSTANT_Methodref_info 10 类中方法的符号引用 CONSTANT_InterfaceMethodref_info 11 接口中方法的符号引用 CONSTANT_NameAndType_info 12 字段和方法的名称以及类型的符号引用 u2 access_flags类或者接口的访问信息（权限），如下图。 u2 this_class类的常量池索引，指向常量池中CONSTANT_Class_info的常量。 u2 super_class超类的索引，指向常量池中CONSTANT_Class_info的常量。 u2 interface_counts接口的数量 u2 interface[interface_counts]接口表，它里面每一项都指向常量池中CONSTANT_Class_info常量。 u2 fields_count类的实例变量和类变量的数量。 field_info fields[fields_count]字段表的信息，其中字段表的属性结构如下图。 access_flags字段的访问标示，比如字段是public，private，protect等。 name_index字段名称，指向常量池中类型是CONSTANT_UTF8_info的常量。 descriptor_index字段的描述符，它也指向常量池中类型为CONSTANT_UTF8_info的常量。 attributes_count字段表中的属性表的数量，而属性表是则是一种用与描述字段，方法以及类的属性的可扩展的结构，不同版本的Java虚拟机所支持的属性表的数量是不同的。 u2 methods_count方法表的数量。 method_info方法表，方法表的具体结构如下图。 access_flags方法的访问标示。 name_index名称的索引。 descriptor_index方法的描述符。 attribute_info类似字段表中的属性表，只不过字段表和方法表中属性表中的属性是不同的，比如方法表中就Code属性，表示方法的代码，而字段表中就没有Code属性。其中具体Class中到底有多少种属性，等到Class文件结构中的属性表的时候再说说。 attribute_count属性表的数量，说到属性表，需要明确以下2点。 属性表存在于Class文件结构的最后，字段表，方法表以及Code属性中，也就是说属性表中也可以存在属性表。 属性表的长度是不固定的，不同的属性，属性表的长度是不同的。5 常量池结构CONSTANT_Class_info结构CONSTANT_Class_info结构用于表示类或接口，格式如下。 1234CONSTANT_Class_info { u1 tag; u2 name_index;} tagCONSTANT_Class_info结构的tag项的值为CONSTANT_Class(7) name_index值，必须是对常量池的一个有效索引。 常量池在该索引处的项必须是CONSTANT_Utf8_info结构， 代表一个有效的类或接口二进制名称的内部形式。 CONSTANT_Fieldref_info结构12345CONSTANT_Fieldref_info { u1 tag; u2 class_index; u2 name_and_type_index;} tag值是CONSTANT_Fieldref(9) class_index值必须是对常量池的有效索引，常量池在该索引处的项必须是CONSTANT_Class_info结构，表示一个类或接口，当前字段或方法是这个类或接口的成员。类型既可以是类也可以是接口。 name_and_type_index值必须是对常量池的有效索引，常量池在该索引处的项必须是CONSTANT_NameAndType_info结构，它表示当前字段或方法的名字和描述符。给定的描述符必须是字段描述符。 CONSTANT_Methodref_info结构12345CONSTANT_Methodref_info { u1 tag; u2 class_index; u2 name_and_type_index;} tag值是CONSTANT_Methodref（10） class_index值必须是对常量池的有效索引，常量池在该索引处的项必须是CONSTANT_Class_info结构，表示一个类或接口，当前字段或方法是这个类或接口的成员。类型必须是类（不能是接口）。 name_and_type_index值必须是对常量池的有效索引， 常量池在该索引处的项必须是CONSTANT_NameAndType_info结构，它表示当前字段或方法的名字和描述符。给定的描述符必须是方法描述符。如果一个CONSTANT_Methodref_info结构的方法名以&lt;`(‘\\u003c’)开头，则说明这个方法名是特殊的`，即这个方法是实例初始化方法，它的返回类型必须为空。 CONSTANT_InterfaceMethodref_info结构12345CONSTANT_InterfaceMethodref_info { u1 tag; u2 class_index; u2 name_and_type_index;} tag值是CONSTANT_InterfaceMethodref（11） class_index值必须是对常量池的有效索引，常量池在该索引处的项必须是CONSTANT_Class_info结构，表示一个类或接口，当前字段或方法是这个类或接口的成员。类型必须是接口（不能是类）。 name_and_type_index值必须是对常量池的有效索引， 常量池在该索引处的项必须是CONSTANT_NameAndType_info结构，它表示当前字段或方法的名字和描述符。给定的描述符必须是方法描述符。 CONSTANT_String_info结构CONSTANT_String_info用于表示java.lang.String类型的常量对象。1234CONSTANT_String_info { u1 tag; u2 string_index;} tag值是CONSTANT_String(8)。 string_indexstring_index项的值必须是对常量池的有效索引， 常量池在该索引处的项必须是CONSTANT_Utf8_info结构，表示一组Unicode码点序列，这组Unicode码点序列最终会被初始化为一个String对象。 CONSTANT_Integer_info结构CONSTANT_Intrger_info结构表示4字节(int和float)的数值常量。1234CONSTANT_Integer_info { u1 tag; u4 bytes;} tag值是CONSTANT_Integer(3)。 bytesint常量的值，按照Big-Endian的顺序存储。 CONSTANT_Float_info结构1234CONSTANT_Float_info { u1 tag; u4 bytes;} tag值是CONSTANT_Float(4)。 bytesbytes项按照IEEE 754单精度浮点格式。表示float常量的值，按照Big-Endian的顺序存储。CONSTANT_Float_info结构表示的值将按照下列方式来表示，bytes项的值首先被转换成一个 int常量的bits。 如果bits值为0x7f800000，表示float值为正无穷。 如果bits值为0xff800000，表示float值为负无穷。 如果bits值在范围0x7f800001到0x7fffffff或者0xff800001到0xffffffff内，表示float值为NaN。 在其它情况下，设 s、 e、 m，它们值根据bits和如下公式计算。float的浮点值为数值表达式 s·m·2e–150的计算结果。12345int s =((bits &gt;&gt; 31) == 0) ? 1 : -1;int e =((bits &gt;&gt; 23) &amp; 0xff);int m =(e == 0） ?bits &amp; 0x7fffff) &lt;&lt; 1 :(bits &amp; 0x7fffff) | 0x800000; CONSTANT_Long_info结构CONSTANT_Long_info结构表示8字节(long和double)的数值常量。12345CONSTANT_Long_info { u1 tag; u4 high_bytes; u4 low_bytes;} 在Class文件的常量池中，所有的8字节的常量都占两个表成员（项）的空间。CONSTANT_Long_info结构的项在常量池中的索引为n，则常量池中下一个有效的项的索引为n+2，此时常量池中索引为n+1的项有效但必须被认为不可用。 tag值是CONSTANT_Long(5)。 high_bytes 和 low_bytes无符号的 high_bytes 和 low_bytes 项用于共同表示 long 型常量，构造形式为((long) high_bytes &lt;&lt; 32) + low_bytes，high_bytes 和 low_bytes 都按照 Big-Endian顺序存储。 CONSTANT_Double_info结构CONSTANT_Double_info 结构表示8字节（long和double）的数值常量。12345CONSTANT_Double_info { u1 tag; u4 high_bytes; u4 low_bytes;} 在Class 文件的常量池中，所有的8字节的常量都占两个表成员（项）的空间。 CONSTANT_Double_info 结构的项在常量池中的索引为n，则常量池中下一个有效的项的索引为n+2， 此时常量池中索引为n+1的项有效但必须被认为不可用。 tag值是 CONSTANT_Double(6)。 high_bytes 和 low_byteshigh_bytes和low_bytes共同按照IEEE 754双精度浮点格式表示double常量的值。high_bytes和low_bytes都按照Big-Endian顺序存储。CONSTANT_Double_info结构表示的值将按照下列方式来表示，high_bytes和low_bytes 首先被转换成一个long常量的bits。 如果bits值为0x7ff0000000000000L，表示double值为正无穷。 如果bits值为0xfff0000000000000L，表示double值为负无穷。 如果bits值在范围0x7ff0000000000001L到0x7fffffffffffffffL或者0xfff0000000000001L到0xffffffffffffffffL内，表示double值为NaN。 在其它情况下，设s、 e、 m，它们的值根据bits和如下公式计算。double的浮点值为数学表达式s·m·2e – 1075的计算结果。12345int s =((bits &gt;&gt; 63) == 0) ? 1 : -1;int e =(int)((bits &gt;&gt; 52) &amp; 0x7ffL);long m =(e == 0) ?(bits &amp; 0xfffffffffffffL) &lt;&lt; 1 :(bits &amp; 0xfffffffffffffL) | 0x10000000000000L; CONSTANT_NameAndType_info 结构CONSTANT_NameAndType_info结构没有标识出它所属的类或接口，格式如下。12345CONSTANT_NameAndType_info { u1 tag; u2 name_index; u2 descriptor_index;} tag值为CONSTANT_NameAndType(12)。 name_indexname_index 项的值必须是对常量池的有效索引， 常量池在该索引处的项必须是CONSTANT_Utf8_info结构，这个结构要么表示特殊的方法名&lt;init&gt;，要么表示一个有效的字段或方法的非限定名Unqualified Name。 descriptor_indexdescriptor_index项的值必须是对常量池的有效索引， 常量池在该索引处的项必须是CONSTANT_Utf8_info结构，这个结构表示一个有效的字段描述符或方法描述符。 CONSTANT_Utf8_info结构CONSTANT_Utf8_info结构用于表示字符串常量的值。12345CONSTANT_Utf8_info { u1 tag; u2 length; u1 bytes[length];} tag值为CONSTANT_Utf8(1)。 lengthbytes[]数组的长度（注意，不能等同于当前结构所表示的String对象的长度）， CONSTANT_Utf8_info结构中的内容是以length属性确定长度而不是以null作为字符串的终结符。 bytes[]bytes[]是表示字符串值的byte数组，bytes[]数组中每个成员的byte值都不会是0，也不在0xf0至0xff范围内。字符串常量采用改进过的UTF-8编码表示。 这种以改进过的UTF-8编码中，用于表示的字符串的码点字符序列可以包含ASCII中的所有非空（Non-Null）字符和所有 Unicode编码的字符，一个字符占一个byte。（1个英文字符占1个byte，1个中文字符占2个byte），长度=byte长度。码点在范围’\\u0001‘至’\\u007F‘内的字符用一个单字节表示。| 0 | bits 6-0 |byte的后7位数据表示一个码点值。字符为’\\u0000‘（表示字符’null’），或者在范围’\\u0080‘至’\\u07FF‘的字符用一对字节x和y表示。x:| 1 | 1 | 0 | bits 10-6 |y:| 1 | 0 | bits 5-0 |x 和 y 计算字符值的公式:((x &amp; 0x1f) &lt;&lt; 6) + (y &amp; 0x3f)在范围’\\u0800‘至’\\uFFFF‘中的字符用 3 个字节 x， y 和 z 表示。x:| 1 | 1 | 1 | 0 | bits 15-12 |y:| 1 | 0 | bits 11-6 |z:| 1 | 0 | bits 5-0 |x，y和z计算字符值的公式:((x &amp; 0xf) &lt;&lt; 12) + ((y &amp; 0x3f) &lt;&lt; 6) + (z &amp; 0x3f)超过U+FFFF范围的字符（ 称为补充字符，Supplementary Characters），在UTF-16编码中也需要2个UTF-16字符单元来表示，而UTF-16中的每个字符单元占3个字节，这就意味着在我们的编码方式中，补充字符需要6个字节来表示，u，v，w，x，y和z。字符值的公式为0x10000+((v&amp;0x0f)&lt;&lt;16)+((w&amp;0x3f)&lt;&lt;10)+(y&amp;0x0f)&lt;&lt;6)+(z&amp;0x3f)x:| 1 | 1 | 1 | 0 | 1 | 1 | 0 | 1 |y:| 1 | 0 | 1 | 1 | bits 9-6 |z:| 1 | 0 | bits 5-0 |u:| 1 | 1 | 1 | 0 | 1 | 1 | 0 | 1 |v:| 1 | 0 | 1 | 0 | (bits 20-16)-1 |w:| 1 | 0 | bits 15-10 |在Class文件中，多字节字符按照Big-Endian顺序存储。和“标准”版UTF-8格式相比， Java虚拟机采用的改进版UTF-8格式有2点不同。 “null”字符(char) 0用双字节格式编码表示而不是单字节，所以，改进版UTF-8格式不会直接出现null值。 改进版的UTF-8只使用标准版UTF-8中的单字节、双字节和三字节格式。 Java虚拟机不能识别标准版UTF-8格式定义4字节格式，而是使用自定义的二次三字节（Two-Times-Three-Byte）格式来代替。 更多关于标准版UTF-8格式的内容可以参考《The Unicode Standard》（版本 6.0.0）的第 3.9 章节“Unicode Encoding Forms”。 CONSTANT_MethodHandle_info 结构CONSTANT_MethodHandle_info结构用于表示方法句柄12345CONSTANT_MethodHandle_info { u1 tag; u1 reference_kind; u2 reference_index;} tag值为 CONSTANT_MethodHandle。 reference_kind值必须在1至9之间（包括1和9），它决定了方法句柄的类型。方法句柄类型的值表示方法句柄的字节码行为（Bytecode Behavior）。 reference_index值必须是对常量池的有效索引。 reference_kind项的值为1（REF_getField）、2（REF_getStatic）、3（REF_putField）或4（REF_putStatic），那么常量池在reference_index索引处的项必须是CONSTANT_Fieldref_info（§4.4.2）结构，表示由一个字段创建的方法句柄。 reference_kind项的值是5（REF_invokeVirtual）、6（REF_invokeStatic）、7（REF_invokeSpecial）或8（REF_newInvokeSpecial），那么常量池在reference_index索引处的项必须是CONSTANT_Methodref_info（§4.4.2）结构，表示由类的方法或构造函数创建的方法句柄。如果reference_kind项的值是9（REF_invokeInterface），那么常量池在reference_index索引处的项必须是CONSTANT_InterfaceMethodref_info（§4.4.2）结构，表示由接口方法创建的方法句柄。 reference_kind项的值是5（REF_invokeVirtual）、6（REF_invokeStatic）、7（REF_invokeSpecial）或9（REF_invokeInterface），那么方法句柄对应的方法不能为实例初始化&lt;init&gt;方法或类初始化方法&lt;clinit&gt;。 reference_kind项的值是8（REF_newInvokeSpecial），那么方法句柄对应的方法必须为实例初始化&lt;init&gt;方法。CONSTANT_MethodType_info 结构1234CONSTANT_MethodType_info { u1 tag; u2 descriptor_index;} tag值为CONSTANT_MethodType(16)。 descriptor_index值是对常量池的有效索引，常量池在该索引处的项必须是CONSTANT_Utf8_info结构，表示方法的描述符。 CONSTANT_InvokeDynamic_info 结构CONSTANT_InvokeDynamic_info用于表示invokedynamic指令所使用到的引导方法（Bootstrap Method）、引导方法使用到动态调用名称（Dynamic Invocation Name）、 参数和请求返回类型、以及可以选择性的附加被称为静态参数（Static Arguments）的常量序列。12345CONSTANT_InvokeDynamic_info { u1 tag; u2 bootstrap_method_attr_index; u2 name_and_type_index;} tag值为CONSTANT_InvokeDynamic（18）。 bootstrap_method_attr_index值是对当前Class文件中引导方法表的bootstrap_methods[]数组的有效索引。 name_and_type_index值是对当前常量池的有效索引，常量池在该索引处的项必须是CONSTANT_NameAndType_info结构，表示方法名和方法描述符。 6 属性表集合（attributes_count和attribute）在Class文件、属性表、方法表中都可以包含自己的属性表集合，用于描述某些场景的专有信息。与Class文件中其它数据项对长度、顺序、格式的严格要求不同，属性表集合不要求其中包含的属性表具有严格的顺序，并且只要属性的名称不与已有的属性名称重复，任何人实现的编译器可以向属性表中写入自己定义的属性信息。虚拟机在运行时会忽略不能识别的属性，为了能正确解析Class文件，虚拟机规范中预定义虚拟机实现必须能够识别的9项属性。属性名称 | 使用位置 | 含义—–|——|—Code | 方法表 | Java代码编译成的字节码指令ConstantValue | 字段表 | final关键字定义的常量值Deprecated | 类文件、字段表、方法表 | 被声明为deprecated的方法和字段Exceptions | 方法表 | 方法抛出的异常InnerClasses | 类文件 | 内部类列表LineNumberTale | Code属性 | Java源码的行号与字节码指令的对应关系LocalVariableTable | Code属性 | 方法的局部变量描述SourceFile | 类文件 | 源文件名称Synthetic | 类文件、方法表、字段表 | 标识方法或字段是由编译器自动生成的每种属性均有各自的表结构。这9种表结构有一个共同的特点，即均由一个u2类型的属性名称开始，可以通过这个属性名称来判段属性的类型。 Code属性Java程序方法体中的代码经过Javac编译器处理后，最终变为字节码指令存储在Code属性中。当然不是所有的方法都必须有这个属性（接口中的方法或抽象方法就不存在Code属性），Code属性表结构如下。类型 | 名称 | 数量—|—-|—u2 | attribute_name_index | 1u4 | attribute_length | 1u2 | max_stack | 1u2 | max_locals | 1u4 | code_length | 1u1 | code | code_lengthu2 | exception_table_length | 1exception_info | exception_table | exception_table_lengthu2 | attributes_count | 1attribute_info | attributes | attributes_count max_stack操作数栈深度最大值，在方法执行的任何时刻，操作数栈深度都不会超过这个值。虚拟机运行时根据这个值来分配栈帧的操作数栈深度。 max_locals局部变量表所需存储空间，单位为Slot。并不是所有局部变量占用的Slot之和，当一个局部变量的生命周期结束后，其所占用的Slot将分配给其它依然存活的局部变量使用，按此方式计算出方法运行时局部变量表所需的存储空间。 code_length和code用来存放Java源程序编译后生成的字节码指令。code_length代表字节码长度，code是用于存储字节码指令的一系列字节流。每一个指令是一个u1类型的单字节，当虚拟机读到code中的一个字节码（一个字节能表示256种指令，Java虚拟机规范定义了其中约200个编码对应的指令），就可以判断出该字节码代表的指令，指令后面是否带有参数，参数该如何解释，虽然code_length占4个字节，但是Java虚拟机规范中限制一个方法不能超过65535条字节码指令，如果超过，Javac将拒绝编译。 ConstantValue属性通知虚拟机自动为静态变量赋值，只有被static关键字修饰的变量（类变量）才可以使用这项属性。类型 | 名称 | 数量—|—-|—u2 | attribute_name_index | 1u4 | attribute_length | 1u2 | constantvalue_index | 1可以看出ConstantValue属性是一个定长属性，其中attribute_length的值固定为0x00000002，constantvalue_index为一常量池字面量类型常量索引（Class文件格式的常量类型中只有与基本类型和字符串类型相对应的字面量常量，所以ConstantValue属性只支持基本类型和字符串类型）。对非static类型变量（实例变量，如：int a = 123;）的赋值是在实例构造器&lt;init&gt;方法中进行的。对类变量（如：static int a = 123;）的赋值有2种选择，在类构造器&lt;clinit&gt;方法中或使用ConstantValue属性。当前Javac编译器的选择是：如果变量同时被static和final修饰（虚拟机规范只要求有ConstantValue属性的字段必须设置ACC_STATIC标志，对final关键字的要求是Javac编译器自己加入的要求），并且该变量的数据类型为基本类型或字符串类型，就生成ConstantValue属性进行初始化；否则在类构造器&lt;clinit&gt;方法中进行初始化。 Exceptions属性列举出方法中可能抛出的受查异常（即方法描述时throws关键字后列出的异常），与Code属性平级，与Code属性包含的异常表不同。类型 | 名称 | 数量—|—-|—u2 | attribute_name_index | 1u4 | attribute_length | 1u2 | number_of_exceptions | 1u2 | exception_index_table | number_of_exceptions number_of_exceptions抛出number_of_exceptions种受查异常。 exception_index_table异常索引集合，一组u2类型exception_index的集合，每一个exception_index为一个指向常量池中CONSTANT_Class_info型常量的索引，代表该受查异常的类型。 InnerClasses属性该属性用于记录内部类和宿主类之间的关系。如果一个类中定义了内部类，编译器将会为这个类与这个类包含的内部类生成InnerClasses属性。类型 | 名称 | 数量—|—-|—u2 | attribute_name_index | 1u4 | attribute_length | 1u2 | number_of_classes | 1inner_classes_info | inner_classes | number_of_classes inner_classes内部类表集合，一组内部类表类型数据的集合，number_of_classes即为集合中内部类表类型数据的个数。每一个内部类的信息都由一个inner_classes_info表来描述，inner_classes_info表结构如下。类型 | 名称 | 数量—|—-|—u2 | inner_class_info_index | 1u2 | outer_class_info_index | 1u2 | inner_name_index | 1u2 | inner_name_access_flags | 1 inner_class_info_index和outer_class_info_index指向常量池中CONSTANT_Class_info类型常量索引，该CONSTANT_Class_info类型常量指向常量池中CONSTANT_Utf8_info类型常量，分别为内部类的全限定名和宿主类的全限定名。 inner_name_index指向常量池中CONSTANT_Utf8_info类型常量的索引，为内部类名称，如果为匿名内部类，则该值为0。 inner_name_access_flags和access_flags一样，是内部类的访问标志。标志名称 | 标志值 | 含义—–|—–|—ACC_PUBLIC | 0x0001 | 内部类是否为publicACC_PRIVATE | 0x0002 | 内部类是否为privateACC_PROTECTED | 0x0004 | 内部类是否为protectedACC_STATIC | 0x0008 | 内部类是否为staticACC_FINAL | 0x0010 | 内部类是否为finalACC_INTERFACE | 0x0020 | 内部类是否为一个接口ACC_ABSTRACT | 0x0400 | 内部类是否为abstractACC_SYNTHETIC | 0x1000 | 内部类是否为编译器自动产生ACC_ANNOTATION | 0x4000 | 内部类是否是一个注解ACC_ENUM | 0x4000 | 内部类是否是一个枚举 LineNumberTale属性用于描述Java源码的行号与字节码行号之间的对应关系，非运行时必需属性，会默认生成至Class文件中，可以使用Javac的-g:none或-g:lines关闭或要求生成该项属性信息，其结构如下。类型 | 名称 | 数量—|—-|—u2 | attribute_name_index | 1u4 | attribute_length | 1u2 | line_number_table_length | 1line_number_info | line_number_table | line_number_table_length line_number_table一组line_number_info类型数据的集合，其所包含的line_number_info类型数据的数量为line_number_table_length。 line_number_info 类型 名称 数量 说明 u2 start_pc 1 字节码行号 u2 line_number 1 Java源码行号 不生成该属性的最大影响。 抛出异常时，堆栈将不会显示出错的行号。 调试程序时无法按照源码设置断点。LocalVariableTable属性用于描述栈帧中局部变量表中的变量与Java源码中定义的变量之间的关系，非运行时必需属性，默认不会生成至Class文件中，可以使用Javac的-g:none或-g:vars关闭或要求生成该项属性信息，其结构如下。类型 | 名称 | 数量—|—-|—u2 | attribute_name_index | 1u4 | attribute_length | 1u2 | local_variable_table_length | 1local_variable_info | local_variable_table | local_variable_table_lengthlocal_variable_table一组local_variable_info类型数据的集合，其所包含的local_variable_info类型数据的数量为local_variable_table_length。local_variable_info类型 | 名称 | 数量 | 说明—|—-|—-|—u2 | start_pc | 1 | 局部变量的生命周期开始的字节码偏移量。u2 | length | 1 | 局部变量作用范围覆盖的长度。u2 | name_index | 1 | 指向常量池中CONSTANT_Utf8_info类型常量的索引，局部变量名称。u2 | descriptor_index | 1 | 指向常量池中CONSTANT_Utf8_info类型常量的索引，局部变量描述符。u2 | index | 1 | 局部变量在栈帧局部变量表中Slot的位置，如果这个变量的数据类型为64位类型（long或double），它占用的Slot为index和index+1这2个位置。start_pc + length即为该局部变量在字节码中的作用域范围。不生成该属性的最大影响。 当其他人引用这个方法时，所有的参数名称都将丢失，IDE可能会使用诸如arg0、arg1之类的占位符代替原有的参数名称，对代码运行无影响，会给代码的编写带来不便。 调试时调试器无法根据参数名称从运行上下文中获取参数值。SourceFile属性用于记录生成这个Class文件的源码文件名称，为可选项，可以使用Javac的-g:none或-g:source关闭或要求生成该项属性信息，其结构如下。类型 | 名称 | 数量—|—-|—u2 | attribute_name_index | 1u4 | attribute_length | 1u2 | sourcefile_index | 1可以看出SourceFile属性是一个定长属性，sourcefile_index是指向常量池中CONSTANT_Utf8_info类型常量的索引，常量的值为源码文件的文件名。对大多数文件，类名和文件名是一致的，少数特殊类除外（如：内部类），此时如果不生成这项属性，当抛出异常时，堆栈中将不会显示出错误代码所属的文件名。 Deprecated属性和Synthetic属性这两个属性都属于标志类型的布尔属性，只存在有和没有的区别，没有属性值的概念。Deprecated属性表示某个类、字段或方法已经被程序作者定为不再推荐使用，可在代码中使用@Deprecated注解进行设置。Synthetic属性表示该字段或方法不是由Java源码直接产生的，而是由编译器自行添加的（当然也可设置访问标志中的ACC_SYNTHETIC标志，所有由非用户代码产生的类、方法和字段都应当至少设置Synthetic属性和ACC_SYNTHETIC标志位中的一项，唯一的例外是实例构造器&lt;init&gt;和类构造器&lt;clinit&gt;方法）Deprecated属性、Synthetic属性结构如下。类型 | 名称 | 数量—|—-|—u2 | attribute_name_index | 1u4 | attribute_length | 1attribute_length的值必须为0x00000000。","link":"/Java-Class-structure-theory/"},{"title":"Fork-Join其他方法","text":"1 ForkJoinTask ForkJoinTask#cancel() ForkJoinTask#setCompletion() ForkJoinPool#shutdown() ForkJoinPool#shutdownNow() ForkJoinPool#tryTerminate() now==true now==false ForkJoinPool#startTerminating() ForkJoinPool#awaitTermination() ForkJoinPool#isTerminated() ForkJoinPool#isTerminating() ForkJoinPool#isAtLeastTerminating() ForkJoinPool#isShutdown() 2 ForkJoinWorkerThread ForkJoinWorkerThread#casSlotNull() ForkJoinWorkerThread#writeSlot() ForkJoinWorkerThread#peekTask() ForkJoinTask#peekNextLocalTask() ForkJoinWorkerThread#drainTasksTo() ForkJoinPool#drainTasksTo() ForkJoinWorkerThread#getQueueSize() ForkJoinTask#getQueuedTaskCount() ForkJoinWorkerThread#pollTask() ForkJoinWorkerThread#pollLocalTask() ForkJoinTask#pollTask() ForkJoinWorkerThread#getEstimatedSurplusTaskCount() ForkJoinPool#idlePerActive() ForkJoinTask#getSurplusQueuedTaskCount() ForkJoinWorkerThread#helpQuiescePool() ForkJoinPool#isQuiescent() ForkJoinPool#addQuiescerCount() ForkJoinPool#addActiveCount() ForkJoinTask#getSurplusQueuedTaskCount() ForkJoinTask#externalAwaitDone() ForkJoinTask#get() ForkJoinTask#externalInterruptibleAwaitDone() ForkJoinTask#get(timeout,unit) ForkJoin线程 非ForkJoin线程 ForkJoinPool#timedAwaitJoin() ForkJoinTask#tryAwaitDone() ForkJoinTask#invoke() ForkJoinTask#doInvoke() ForkJoinTask#invokeAll() ForkJoinTask#invokeAll(ForkJoinTask&lt;?&gt;… tasks) ForkJoinTask#invokeAll(Collection tasks) ForkJoinTask#isCompletedAbnormally() ForkJoinTask#isCompletedNormally() ForkJoinTask#quietlyJoin() ForkJoinTask#quietlyInvoke() ForkJoinTask#reinitialize() ForkJoinTask#tryUnfork() ForkJoinTask#getPool() ForkJoinTask#inForkJoinPool() 3 ForkJoinPool ForkJoinPool#managedBlock() ForkJoin工作线程 非ForkJoin工作线程 ForkJoinPool#awaitBlocker() ForkJoinPool#ManagedBlocker ManagedBlocker#doc#ManagedLocker ForkJoinPool#invoke() ForkJoinPool#execute() ForkJoinPool#invokeAll() ForkJoinPool#other() 1 ForkJoinTaskForkJoinTask本身也是Future的实现，所以也会有取消过程。 ForkJoinTask#cancel()123456789101112131415161718192021222324252627282930/** * Attempts to cancel execution of this task. This attempt will * fail if the task has already completed or could not be * cancelled for some other reason. If successful, and this task * has not started when {@code cancel} is called, execution of * this task is suppressed. After this method returns * successfully, unless there is an intervening call to {@link * #reinitialize}, subsequent calls to {@link #isCancelled}, * {@link #isDone}, and {@code cancel} will return {@code true} * and calls to {@link #join} and related methods will result in * {@code CancellationException}. * * &lt;p&gt;This method may be overridden in subclasses, but if so, must * still ensure that these properties hold. In particular, the * {@code cancel} method itself must not throw exceptions. * * &lt;p&gt;This method is designed to be invoked by &lt;em&gt;other&lt;/em&gt; * tasks. To terminate the current task, you can just return or * throw an unchecked exception from its computation method, or * invoke {@link #completeExceptionally}. * * @param mayInterruptIfRunning this value has no effect in the * default implementation because interrupts are not used to * control cancellation. * * @return {@code true} if this task is now cancelled */ public boolean cancel(boolean mayInterruptIfRunning) { return setCompletion(CANCELLED) == CANCELLED; } ForkJoinTask#setCompletion()123456789101112131415161718/** * Marks completion and wakes up threads waiting to join this task, * also clearing signal request bits. * * @param completion one of NORMAL, CANCELLED, EXCEPTIONAL * @return completion status on exit */ private int setCompletion(int completion) { for (int s;;) { if ((s = status) &lt; 0) return s; if (UNSAFE.compareAndSwapInt(this, statusOffset, s, completion)) { if (s != 0) synchronized (this) { notifyAll(); } return completion; } } } 设置任务运行状态为取消，然后唤醒在任务上等待的线程。 ForkJoinPool#shutdown()1234567891011121314151617/** * Initiates an orderly shutdown in which previously submitted * tasks are executed, but no new tasks will be accepted. * Invocation has no additional effect if already shut down. * Tasks that are in the process of being submitted concurrently * during the course of this method may or may not be rejected. * * @throws SecurityException if a security manager exists and * the caller is not permitted to modify threads * because it does not hold {@link * java.lang.RuntimePermission}{@code (\"modifyThread\")} */ public void shutdown() { checkPermission(); shutdown = true; tryTerminate(false); } ForkJoinPool#shutdownNow()12345678910111213141516171819202122/** * Attempts to cancel and/or stop all tasks, and reject all * subsequently submitted tasks. Tasks that are in the process of * being submitted or executed concurrently during the course of * this method may or may not be rejected. This method cancels * both existing and unexecuted tasks, in order to permit * termination in the presence of task dependencies. So the method * always returns an empty list (unlike the case for some other * Executors). * * @return an empty list * @throws SecurityException if a security manager exists and * the caller is not permitted to modify threads * because it does not hold {@link * java.lang.RuntimePermission}{@code (\"modifyThread\")} */ public List&lt;Runnable&gt; shutdownNow() { checkPermission(); shutdown = true; tryTerminate(true); return Collections.emptyList(); } 可以用过调用shutdown()或者shutdownNow()来关闭pool，shutdown()会等待之前提交到ForkJoinPool#task()完成再真正关闭pool，同时不会接受新提交的任务；而shutdownNow()会尝试取消之前提交到pool且没有完成的任务并关闭pool，也不会接受新提交的任务。 ForkJoinPool#tryTerminate()12345678910111213141516171819202122232425262728293031323334/** * Possibly initiates and/or completes termination. * * @param now if true, unconditionally terminate, else only * if shutdown and empty queue and no active workers * @return true if now terminating or terminated */ private boolean tryTerminate(boolean now) { long c; while (((c = ctl) &amp; STOP_BIT) == 0) { if (!now) { if ((int)(c &gt;&gt; AC_SHIFT) != -parallelism) return false; if (!shutdown || blockedCount != 0 || quiescerCount != 0 || queueBase != queueTop) { if (ctl == c) // staleness check return false; continue; } } if (UNSAFE.compareAndSwapLong(this, ctlOffset, c, c | STOP_BIT)) startTerminating(); } if ((short)(c &gt;&gt;&gt; TC_SHIFT) == -parallelism) { // signal when 0 workers final ReentrantLock lock = this.submissionLock; lock.lock(); try { termination.signalAll(); } finally { lock.unlock(); } } return true; } now==true首先会尝试设置停止标记总控信息ctl，设置成功的话为调用startTerminating()开始结束pool(设置失败会再次尝试直到成功)，然后会判断pool中是否还有工作线程，没有的话会唤醒termination条件上的等待线程，然后返回true；没有就直接返回true。 now==false如果当前还有活动工作线程，或还有阻塞等待join的工作线程，或者还有未完成的任务，方法会直接返回false。调用shutdown，里面的tryTerminate()返回false的话，因为shutdown里面设置了关闭状态shutdown为true，当工作线程处理完所有任务，空闲(idle)的时候会判断shutdown标识，如果为true的话会再次调用tryTerminate()。所以pool最终会关闭。 ForkJoinPool#startTerminating()12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667 /** * Runs up to three passes through workers: (0) Setting * termination status for each worker, followed by wakeups up to * queued workers; (1) helping cancel tasks; (2) interrupting * lagging threads (likely in external tasks, but possibly also * blocked in joins). Each pass repeats previous steps because of * potential lagging thread creation. */ private void startTerminating() { cancelSubmissions(); for (int pass = 0; pass &lt; 3; ++pass) { ForkJoinWorkerThread[] ws = workers; if (ws != null) { for (ForkJoinWorkerThread w : ws) { if (w != null) { w.terminate = true; if (pass &gt; 0) { w.cancelTasks(); if (pass &gt; 1 &amp;&amp; !w.isInterrupted()) { try { w.interrupt(); } catch (SecurityException ignore) { } } } } } terminateWaiters(); } } }``` 1. 取消`pool`中`submissionQueue`中的任务。2. 将所有的工作线程的结束状态设置为true。3. 取消所有工作线程的任务队列中未完成的任务。4. 中断所有工作线程。5. 结束还在等待的工作线程。## ForkJoinPool#awaitTermination()``` java /** * Blocks until all tasks have completed execution after a shutdown * request, or the timeout occurs, or the current thread is * interrupted, whichever happens first. * * @param timeout the maximum time to wait * @param unit the time unit of the timeout argument * @return {@code true} if this executor terminated and * {@code false} if the timeout elapsed before termination * @throws InterruptedException if interrupted while waiting */ public boolean awaitTermination(long timeout, TimeUnit unit) throws InterruptedException { long nanos = unit.toNanos(timeout); final ReentrantLock lock = this.submissionLock; lock.lock(); try { for (;;) { if (isTerminated()) return true; if (nanos &lt;= 0) return false; nanos = termination.awaitNanos(nanos); } } finally { lock.unlock(); } } 根据注释很好理解，判断pool是否真正结束了，没结束的话，就会在termination条件上等待；关闭了就返回true。这个方法可能超时。 ForkJoinPool#isTerminated()12345678910/** * Returns {@code true} if all tasks have completed following shut down. * * @return {@code true} if all tasks have completed following shut down */ public boolean isTerminated() { long c = ctl; return ((c &amp; STOP_BIT) != 0L &amp;&amp; (short)(c &gt;&gt;&gt; TC_SHIFT) == -parallelism); } 同时满足pool的总控信息中有停止标记且总的工作线程数为0。 ForkJoinPool#isTerminating()123456789101112131415161718/** * Returns {@code true} if the process of termination has * commenced but not yet completed. This method may be useful for * debugging. A return of {@code true} reported a sufficient * period after shutdown may indicate that submitted tasks have * ignored or suppressed interruption, or are waiting for IO, * causing this executor not to properly terminate. (See the * advisory notes for class {@link ForkJoinTask} stating that * tasks should not normally entail blocking operations. But if * they do, they must abort them on interrupt.) * * @return {@code true} if terminating but not yet terminated */ public boolean isTerminating() { long c = ctl; return ((c &amp; STOP_BIT) != 0L &amp;&amp; (short)(c &gt;&gt;&gt; TC_SHIFT) != -parallelism); } 判断pool是否正在结束过程中，判断逻辑是pool的总控信息中有停止标记，但总的工作线程数不为0。 ForkJoinPool#isAtLeastTerminating()123456/** * Returns true if terminating or terminated. Used by ForkJoinWorkerThread. */ final boolean isAtLeastTerminating() { return (ctl &amp; STOP_BIT) != 0L; } 判断pool是否正在结束过程中或者已经结束，只要pool的总控信息中有停止标记就可以了。 ForkJoinPool#isShutdown()12345678/** * Returns {@code true} if this pool has been shut down. * * @return {@code true} if this pool has been shut down */ public boolean isShutdown() { return shutdown; } 判断pool是否关闭，只要调用过shutdown或者shutdownNow()，这个就是true了。 2 ForkJoinWorkerThreadForkJoinWorkerThread中定义了casSlotNull()和writeSlot()，为了提高性能，这两个方法已经被UNSAFE实现了。 ForkJoinWorkerThread#casSlotNull()12345678/** * CASes slot i of array q from t to null. Caller must ensure q is * non-null and index is in range. */ private static final boolean casSlotNull(ForkJoinTask&lt;?&gt;[] q, int i, ForkJoinTask&lt;?&gt; t) { return UNSAFE.compareAndSwapObject(q, (i &lt;&lt; ASHIFT) + ABASE, t, null); } ForkJoinWorkerThread#writeSlot()123456789/** * Performs a volatile write of the given task at given slot of * array q. Caller must ensure q is non-null and index is in * range. This method is used only during resets and backouts. */ private static final void writeSlot(ForkJoinTask&lt;?&gt;[] q, int i, ForkJoinTask&lt;?&gt; t) { UNSAFE.putObjectVolatile(q, (i &lt;&lt; ASHIFT) + ABASE, t); } ForkJoinWorkerThread#peekTask()1234567891011/** * Returns next task, or null if empty or contended. */ final ForkJoinTask&lt;?&gt; peekTask() { int m; ForkJoinTask&lt;?&gt;[] q = queue; if (q == null || (m = q.length - 1) &lt; 0) return null; int i = locallyFifo ? queueBase : (queueTop - 1); return q[i &amp; m]; } 获取当前任务队列中的下一个(可获取的)任务。 ForkJoinTask#peekNextLocalTask()12345678910111213141516171819202122/** * Returns, but does not unschedule or execute, a task queued by * the current thread but not yet executed, if one is immediately * available. There is no guarantee that this task will actually * be polled or executed next. Conversely, this method may return * null even if a task exists but cannot be accessed without * contention with other threads. This method is designed * primarily to support extensions, and is unlikely to be useful * otherwise. * * &lt;p&gt;This method may be invoked only from within {@code * ForkJoinPool} computations (as may be determined using method * {@link #inForkJoinPool}). Attempts to invoke in other contexts * result in exceptions or errors, possibly including {@code * ClassCastException}. * * @return the next task, or {@code null} if none are available */ protected static ForkJoinTask&lt;?&gt; peekNextLocalTask() { return ((ForkJoinWorkerThread) Thread.currentThread()) .peekTask(); } ForkJoinTask#peekNextLocalTask()由ForkJoinPool#peekTask()实现。 ForkJoinWorkerThread#drainTasksTo()12345678910111213141516/** * Drains tasks to given collection c. * * @return the number of tasks drained */ final int drainTasksTo(Collection&lt;? super ForkJoinTask&lt;?&gt;&gt; c) { int n = 0; while (queueBase != queueTop) { ForkJoinTask&lt;?&gt; t = deqTask(); if (t != null) { c.add(t); ++n; } } return n; } 将当前任务队列中所有方法拿出来放到一个给定的集合里面，并返回放入的任务数量。 ForkJoinPool#drainTasksTo()1234567891011121314151617181920212223242526272829303132333435/** * Removes all available unexecuted submitted and forked tasks * from scheduling queues and adds them to the given collection, * without altering their execution status. These may include * artificially generated or wrapped tasks. This method is * designed to be invoked only when the pool is known to be * quiescent. Invocations at other times may not remove all * tasks. A failure encountered while attempting to add elements * to collection {@code c} may result in elements being in * neither, either or both collections when the associated * exception is thrown. The behavior of this operation is * undefined if the specified collection is modified while the * operation is in progress. * * @param c the collection to transfer elements into * @return the number of elements transferred */ protected int drainTasksTo(Collection&lt;? super ForkJoinTask&lt;?&gt;&gt; c) { int count = 0; while (queueBase != queueTop) { ForkJoinTask&lt;?&gt; t = pollSubmission(); if (t != null) { c.add(t); ++count; } } ForkJoinWorkerThread[] ws; if ((short)(ctl &gt;&gt;&gt; TC_SHIFT) &gt; -parallelism &amp;&amp; (ws = workers) != null) { for (ForkJoinWorkerThread w : ws) if (w != null) count += w.drainTasksTo(c); } return count; } 由ForkJoinWorkerThread#drainTasksTo()实现。ForkJoinPool#drainTasksTo()的逻辑是将自身任务队列中的任务和所有工作线程中任务队列的任务都拿出来，放入一个给定集合，并返回放入集合的任务数量。 ForkJoinWorkerThread#getQueueSize()123456/** * Returns an estimate of the number of tasks in the queue. */ final int getQueueSize() { return queueTop - queueBase; } 返回当前工作线程任务队列中的任务数量。 ForkJoinTask#getQueuedTaskCount()123456789101112131415161718/** * Returns an estimate of the number of tasks that have been * forked by the current worker thread but not yet executed. This * value may be useful for heuristic decisions about whether to * fork other tasks. * * &lt;p&gt;This method may be invoked only from within {@code * ForkJoinPool} computations (as may be determined using method * {@link #inForkJoinPool}). Attempts to invoke in other contexts * result in exceptions or errors, possibly including {@code * ClassCastException}. * * @return the number of tasks */ public static int getQueuedTaskCount() { return ((ForkJoinWorkerThread) Thread.currentThread()) .getQueueSize(); } ForkJoinTask#getQueuedTaskCount()由ForkJoinWorkerThread#getQueueSize()实现。 ForkJoinWorkerThread#pollTask()123456789101112131415161718192021222324/** * Gets and removes a local or stolen task. * * @return a task, if available */ final ForkJoinTask&lt;?&gt; pollTask() { ForkJoinWorkerThread[] ws; ForkJoinTask&lt;?&gt; t = pollLocalTask(); if (t != null || (ws = pool.workers) == null) return t; int n = ws.length; // cheap version of FJP.scan int steps = n &lt;&lt; 1; int r = nextSeed(); int i = 0; while (i &lt; steps) { ForkJoinWorkerThread w = ws[(i++ + r) &amp; (n - 1)]; if (w != null &amp;&amp; w.queueBase != w.queueTop &amp;&amp; w.queue != null) { if ((t = w.deqTask()) != null) return t; i = 0; } } return null; } ForkJoinWorkerThread#pollLocalTask()12345678/** * Gets and removes a local task. * * @return a task, if available */ final ForkJoinTask&lt;?&gt; pollLocalTask() { return locallyFifo ? locallyDeqTask() : popTask(); } pollTask()中首先通过pollLocalTask()来获取一个本地任务。如果没获取到的话，会继续扫描其它工作线程，来窃取一个任务。如果最后没扫描到，就返回null。 ForkJoinTask#pollTask()12345678910111213141516171819202122/** * Unschedules and returns, without executing, the next task * queued by the current thread but not yet executed, if one is * available, or if not available, a task that was forked by some * other thread, if available. Availability may be transient, so a * {@code null} result does not necessarily imply quiescence * of the pool this task is operating in. This method is designed * primarily to support extensions, and is unlikely to be useful * otherwise. * * &lt;p&gt;This method may be invoked only from within {@code * ForkJoinPool} computations (as may be determined using method * {@link #inForkJoinPool}). Attempts to invoke in other contexts * result in exceptions or errors, possibly including {@code * ClassCastException}. * * @return a task, or {@code null} if none are available */ protected static ForkJoinTask&lt;?&gt; pollTask() { return ((ForkJoinWorkerThread) Thread.currentThread()) .pollTask(); } 由ForkJoinWorkerThread#pollTask()实现。 ForkJoinWorkerThread#getEstimatedSurplusTaskCount()123final int getEstimatedSurplusTaskCount() { return queueTop - queueBase - pool.idlePerActive();} 返回估计的剩余任务数量。 ForkJoinPool#idlePerActive()1234567891011121314/** * Returns the approximate (non-atomic) number of idle threads per * active thread. */ final int idlePerActive() { // Approximate at powers of two for small values, saturate past 4 int p = parallelism; int a = p + (int)(ctl &gt;&gt; AC_SHIFT); return (a &gt; (p &gt;&gt;&gt;= 1) ? 0 : a &gt; (p &gt;&gt;&gt;= 1) ? 1 : a &gt; (p &gt;&gt;&gt;= 1) ? 2 : a &gt; (p &gt;&gt;&gt;= 1) ? 4 : 8); } 当前活动线程的数量越少，返回的值越大。假设p(当前并行度，默认是cpu核数)为32，那么有a=1，返回8；a=3，返回4；a=5，返回2；a=9，返回1；a&gt;16，都返回0。ForkJoinWorkerThread#getEstimatedSurplusTaskCount()来说就是，如果当前活动的工作线程越多，那么估计的剩余任务数量就越接近自身任务队列中的任务数量(因为大家都在忙，被别人窃取的可能性少一些)。 ForkJoinTask#getSurplusQueuedTaskCount()12345678910111213141516171819202122/** * Returns an estimate of how many more locally queued tasks are * held by the current worker thread than there are other worker * threads that might steal them. This value may be useful for * heuristic decisions about whether to fork other tasks. In many * usages of ForkJoinTasks, at steady state, each worker should * aim to maintain a small constant surplus (for example, 3) of * tasks, and to process computations locally if this threshold is * exceeded. * * &lt;p&gt;This method may be invoked only from within {@code * ForkJoinPool} computations (as may be determined using method * {@link #inForkJoinPool}). Attempts to invoke in other contexts * result in exceptions or errors, possibly including {@code * ClassCastException}. * * @return the surplus number of tasks, which may be negative */ public static int getSurplusQueuedTaskCount() { return ((ForkJoinWorkerThread) Thread.currentThread()) .getEstimatedSurplusTaskCount(); } 由ForkJoinWorkerThread#getEstimatedSurplusTaskCount()实现。通过这个方法的判断来决定是否fork任务，减少任务的窃取率，提高整体性能。 ForkJoinWorkerThread#helpQuiescePool()1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465/** * Runs tasks until {@code pool.isQuiescent()}. We piggyback on * pool's active count ctl maintenance, but rather than blocking * when tasks cannot be found, we rescan until all others cannot * find tasks either. The bracketing by pool quiescerCounts * updates suppresses pool auto-shutdown mechanics that could * otherwise prematurely terminate the pool because all threads * appear to be inactive. */final void helpQuiescePool() { boolean active = true; ForkJoinTask&lt;?&gt; ps = currentSteal; // to restore below ForkJoinPool p = pool; // 1 p.addQuiescerCount(1); for (;;) { ForkJoinWorkerThread[] ws = p.workers; ForkJoinWorkerThread v = null; int n; // 2 if (queueTop != queueBase) // 3 v = this; // 4 else if (ws != null &amp;&amp; (n = ws.length) &gt; 1) { ForkJoinWorkerThread w; // 5 int r = nextSeed(); // cheap version of FJP.scan int steps = n &lt;&lt; 1; for (int i = 0; i &lt; steps; ++i) { if ((w = ws[(i + r) &amp; (n - 1)]) != null &amp;&amp; w.queueBase != w.queueTop) { v = w; break; } } } if (v != null) { ForkJoinTask&lt;?&gt; t; if (!active) { active = true; p.addActiveCount(1); } // 6 if ((t = (v != this) ? v.deqTask() : locallyFifo ? locallyDeqTask() : popTask()) != null) { currentSteal = t; t.doExec(); currentSteal = ps; } } else { if (active) { active = false; p.addActiveCount(-1); } // 7 if (p.isQuiescent()) { p.addActiveCount(1); p.addQuiescerCount(-1); break; } } }} 标注代码分析 增加Pool的quiescerCount。 选一个窃取牺牲者。 当前队列有任务就选自己。 扫描工作线程数组，选一个队列里有任务的作为牺牲者。 就是xor-shift算法。 窃取并执行任务。 直到Pool休眠再推出。 helpQuiescePool()不断的窃取任务(包括从自身的任务队列中窃取)来执行，直到Pool处于休眠状态。方法执行过程中会修改Pool的quiescerCount和activeCount数量，这起到了防止Pool过早结束的作用，可以回头看一下ForkJoinPool#tryAwaitWork()，里面可能会tryTerminate()，会有一个自动结束Pool的代码路径。 ForkJoinPool#isQuiescent()1234567891011121314/** * Returns {@code true} if all worker threads are currently idle. * An idle worker is one that cannot obtain a task to execute * because none are available to steal from other threads, and * there are no pending submissions to the pool. This method is * conservative; it might not return {@code true} immediately upon * idleness of all threads, but will eventually become true if * threads remain inactive. * * @return {@code true} if all threads are currently idle */ public boolean isQuiescent() { return parallelism + (int)(ctl &gt;&gt; AC_SHIFT) + blockedCount == 0; } 逻辑就是当前活动线程数量为0，且阻塞等到join的工作线程数量也为0。 ForkJoinPool#addQuiescerCount()123456789101112/** * Increment or decrement quiescerCount. Needed only to prevent * triggering shutdown if a worker is transiently inactive while * checking quiescence. * * @param delta 1 for increment, -1 for decrement */ final void addQuiescerCount(int delta) { int c; do {} while (!UNSAFE.compareAndSwapInt(this, quiescerCountOffset, c = quiescerCount, c + delta)); } ForkJoinPool#addActiveCount()1234567891011121314/** * Directly increment or decrement active count without * queuing. This method is used to transiently assert inactivation * while checking quiescence. * * @param delta 1 for increment, -1 for decrement */ final void addActiveCount(int delta) { long d = delta &lt; 0 ? -AC_UNIT : AC_UNIT; long c; do {} while (!UNSAFE.compareAndSwapLong(this, ctlOffset, c = ctl, ((c + d) &amp; AC_MASK) | (c &amp; ~AC_MASK))); } ForkJoinTask#getSurplusQueuedTaskCount()12345678910111213141516171819202122/** * Returns an estimate of how many more locally queued tasks are * held by the current worker thread than there are other worker * threads that might steal them. This value may be useful for * heuristic decisions about whether to fork other tasks. In many * usages of ForkJoinTasks, at steady state, each worker should * aim to maintain a small constant surplus (for example, 3) of * tasks, and to process computations locally if this threshold is * exceeded. * * &lt;p&gt;This method may be invoked only from within {@code * ForkJoinPool} computations (as may be determined using method * {@link #inForkJoinPool}). Attempts to invoke in other contexts * result in exceptions or errors, possibly including {@code * ClassCastException}. * * @return the surplus number of tasks, which may be negative */ public static int getSurplusQueuedTaskCount() { return ((ForkJoinWorkerThread) Thread.currentThread()) .getEstimatedSurplusTaskCount(); } getEstimatedSurplusTaskCount()实现ForkJoinTask#getSurplusQueuedTaskCount()。 ForkJoinTask#externalAwaitDone()123456789101112131415161718192021222324252627/** * Blocks a non-worker-thread until completion. * @return status upon completion */ private int externalAwaitDone() { int s; if ((s = status) &gt;= 0) { boolean interrupted = false; synchronized (this) { while ((s = status) &gt;= 0) { if (s == 0) UNSAFE.compareAndSwapInt(this, statusOffset, 0, SIGNAL); else { try { wait(); } catch (InterruptedException ie) { interrupted = true; } } } } if (interrupted) Thread.currentThread().interrupt(); } return s; } 非ForkJoin工作线程合并ForkJoinTask的时候会调用到。ForkJoinTask加个SIGNAL状态(没有的话)，然后在ForkJoinTask上等待，注意被唤醒后会传递中断状态。 ForkJoinTask#get()123456789101112131415161718192021/** * Waits if necessary for the computation to complete, and then * retrieves its result. * * @return the computed result * @throws CancellationException if the computation was cancelled * @throws ExecutionException if the computation threw an * exception * @throws InterruptedException if the current thread is not a * member of a ForkJoinPool and was interrupted while waiting */ public final V get() throws InterruptedException, ExecutionException { int s = (Thread.currentThread() instanceof ForkJoinWorkerThread) ? doJoin() : externalInterruptibleAwaitDone(0L); Throwable ex; if (s == CANCELLED) throw new CancellationException(); if (s == EXCEPTIONAL &amp;&amp; (ex = getThrowableException()) != null) throw new ExecutionException(ex); return getRawResult(); } 如果当前线程是ForkJoin工作线程，那么调用doJoin()来获取结果；否则调用externalInterruptibleAwaitDone()来获取结果。后面还会处理取消和异常的情况，里面涉及到的方法大部分都分析过，这里只看一下externalInterruptibleAwaitDone()。 ForkJoinTask#externalInterruptibleAwaitDone()123456789101112131415161718192021222324/** * Blocks a non-worker-thread until completion or interruption or timeout. */ private int externalInterruptibleAwaitDone(long millis) throws InterruptedException { int s; if (Thread.interrupted()) throw new InterruptedException(); if ((s = status) &gt;= 0) { synchronized (this) { while ((s = status) &gt;= 0) { if (s == 0) UNSAFE.compareAndSwapInt(this, statusOffset, 0, SIGNAL); else { wait(millis); if (millis &gt; 0L) break; } } } } return s; } 在非ForkJoin线程调用时执行的。当前ForkJoin任务加个SIGNAL状态(没有的话)，然后在ForkJoinTask上等待，方法支持等待超时和中断。 ForkJoinTask#get(timeout,unit)12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152/** * Waits if necessary for at most the given time for the computation * to complete, and then retrieves its result, if available. * * @param timeout the maximum time to wait * @param unit the time unit of the timeout argument * @return the computed result * @throws CancellationException if the computation was cancelled * @throws ExecutionException if the computation threw an * exception * @throws InterruptedException if the current thread is not a * member of a ForkJoinPool and was interrupted while waiting * @throws TimeoutException if the wait timed out */ public final V get(long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException { Thread t = Thread.currentThread(); if (t instanceof ForkJoinWorkerThread) { ForkJoinWorkerThread w = (ForkJoinWorkerThread) t; long nanos = unit.toNanos(timeout); if (status &gt;= 0) { boolean completed = false; if (w.unpushTask(this)) { try { completed = exec(); } catch (Throwable rex) { setExceptionalCompletion(rex); } } if (completed) setCompletion(NORMAL); else if (status &gt;= 0 &amp;&amp; nanos &gt; 0) w.pool.timedAwaitJoin(this, nanos); } } else { long millis = unit.toMillis(timeout); if (millis &gt; 0) externalInterruptibleAwaitDone(millis); } int s = status; if (s != NORMAL) { Throwable ex; if (s == CANCELLED) throw new CancellationException(); if (s != EXCEPTIONAL) throw new TimeoutException(); if ((ex = getThrowableException()) != null) throw new ExecutionException(ex); } return getRawResult(); } ForkJoin线程先尝试从自己的任务队列里pop出给定任务(如果给定任务恰好在当前任务队列的顶端)，然后执行任务；否则会调用一个支持超时版本的等待合并任务的方法timedAwaitJoin()，等待任务完成。最后返回任务执行结果。 非ForkJoin线程会调用externalInterruptibleAwaitDone()，等待任务完成。最后返回任务执行结果。 ForkJoinPool#timedAwaitJoin()123456789101112131415161718192021222324252627282930313233343536373839404142/** * Possibly blocks the given worker waiting for joinMe to * complete or timeout * * @param joinMe the task * @param millis the wait time for underlying Object.wait */ final void timedAwaitJoin(ForkJoinTask&lt;?&gt; joinMe, long nanos) { // 1 while (joinMe.status &gt;= 0) { // 2 Thread.interrupted(); if ((ctl &amp; STOP_BIT) != 0L) { // 3 joinMe.cancelIgnoringExceptions(); break; } // 4 if (tryPreBlock()) { long last = System.nanoTime(); while (joinMe.status &gt;= 0) { long millis = TimeUnit.NANOSECONDS.toMillis(nanos); if (millis &lt;= 0) break; // 5 joinMe.tryAwaitDone(millis); if (joinMe.status &lt; 0) break; if ((ctl &amp; STOP_BIT) != 0L) { joinMe.cancelIgnoringExceptions(); break; } long now = System.nanoTime(); nanos -= now - last; last = now; } // 6 postBlock(); break; } } } 标注代码分析 如果任务状态是未完成。 先清空中断标记。 如果Pool关闭了，取消任务。 阻塞前的工作。 等待任务完成。 唤醒后的工作。ForkJoinTask#tryAwaitDone()1234567891011121314151617181920212223/** * Tries to block a worker thread until completed or timed out. * Uses Object.wait time argument conventions. * May fail on contention or interrupt. * * @param millis if &gt; 0, wait time. */ final void tryAwaitDone(long millis) { int s; try { if (((s = status) &gt; 0 || (s == 0 &amp;&amp; UNSAFE.compareAndSwapInt(this, statusOffset, 0, SIGNAL))) &amp;&amp; status &gt; 0) { synchronized (this) { if (status &gt; 0) wait(millis); } } } catch (InterruptedException ie) { // caller must check termination } } ForkJoinTask#invoke()1234567891011121314/** * Commences performing this task, awaits its completion if * necessary, and returns its result, or throws an (unchecked) * {@code RuntimeException} or {@code Error} if the underlying * computation did so. * * @return the computed result */ public final V invoke() { if (doInvoke() != NORMAL) return reportResult(); else return getRawResult(); } ForkJoinTask#doInvoke()123456789101112131415161718/** * Primary mechanics for invoke, quietlyInvoke. * @return status upon completion */ private int doInvoke() { int s; boolean completed; if ((s = status) &lt; 0) return s; try { completed = exec(); } catch (Throwable rex) { return setExceptionalCompletion(rex); } if (completed) return setCompletion(NORMAL); else return doJoin(); } 先执行任务，然后判断任务是否结束，结束的话设置完成状态；否则join任务等待结果。 ForkJoinTask#invokeAll()123456.....public static void invokeAll(ForkJoinTask&lt;?&gt; t1, ForkJoinTask&lt;?&gt; t2) { t2.fork(); t1.invoke(); t2.join();} 同时执行两个方法，都执行完毕后返回。注意如果其中有一个方法抛异常的话，另一个方法就可能会被取消。Check Exception的原因。 ForkJoinTask#invokeAll(ForkJoinTask&lt;?&gt;… tasks)123456789101112131415161718192021222324252627.....public static void invokeAll(ForkJoinTask&lt;?&gt;... tasks) { Throwable ex = null; int last = tasks.length - 1; for (int i = last; i &gt;= 0; --i) { ForkJoinTask&lt;?&gt; t = tasks[i]; if (t == null) { if (ex == null) ex = new NullPointerException(); } else if (i != 0) t.fork(); else if (t.doInvoke() &lt; NORMAL &amp;&amp; ex == null) ex = t.getException(); } for (int i = 1; i &lt;= last; ++i) { ForkJoinTask&lt;?&gt; t = tasks[i]; if (t != null) { if (ex != null) t.cancel(false); else if (t.doJoin() &lt; NORMAL &amp;&amp; ex == null) ex = t.getException(); } } if (ex != null) UNSAFE.throwException(ex);} ForkJoinTask#invokeAll(Collection tasks)1234567891011121314151617181920212223242526272829303132333435.....public static &lt;T extends ForkJoinTask&lt;?&gt;&gt; Collection&lt;T&gt; invokeAll(Collection&lt;T&gt; tasks) { if (!(tasks instanceof RandomAccess) || !(tasks instanceof List&lt;?&gt;)) { invokeAll(tasks.toArray(new ForkJoinTask&lt;?&gt;[tasks.size()])); return tasks; } @SuppressWarnings(\"unchecked\") List&lt;? extends ForkJoinTask&lt;?&gt;&gt; ts = (List&lt;? extends ForkJoinTask&lt;?&gt;&gt;) tasks; Throwable ex = null; int last = ts.size() - 1; for (int i = last; i &gt;= 0; --i) { ForkJoinTask&lt;?&gt; t = ts.get(i); if (t == null) { if (ex == null) ex = new NullPointerException(); } else if (i != 0) t.fork(); else if (t.doInvoke() &lt; NORMAL &amp;&amp; ex == null) ex = t.getException(); } for (int i = 1; i &lt;= last; ++i) { ForkJoinTask&lt;?&gt; t = ts.get(i); if (t != null) { if (ex != null) t.cancel(false); else if (t.doJoin() &lt; NORMAL &amp;&amp; ex == null) ex = t.getException(); } } if (ex != null) UNSAFE.throwException(ex); return tasks;} ForkJoinTask#isCompletedAbnormally()12345678/** * Returns {@code true} if this task threw an exception or was cancelled. * * @return {@code true} if this task threw an exception or was cancelled */public final boolean isCompletedAbnormally() { return status &lt; NORMAL;} 判断任务是否异常结束。 ForkJoinTask#isCompletedNormally()12345678910 /** * Returns {@code true} if this task completed without throwing an * exception and was not cancelled. * * @return {@code true} if this task completed without throwing an * exception and was not cancelled */public final boolean isCompletedNormally() { return status == NORMAL;} 判断任务是否正常完成。 ForkJoinTask#quietlyJoin()123456789/** * Joins this task, without returning its result or throwing its * exception. This method may be useful when processing * collections of tasks when some have been cancelled or otherwise * known to have aborted. */public final void quietlyJoin() { doJoin();} ForkJoinTask#quietlyInvoke()12345678/** * Commences performing this task and awaits its completion if * necessary, without returning its result or throwing its * exception. */public final void quietlyInvoke() { doInvoke();} quietlyJoin()和quietlyInvoke()它们不会返回结果或者抛出异常。 ForkJoinTask#reinitialize()12345678.....public void reinitialize() { if (status == EXCEPTIONAL) // 1 clearExceptionalCompletion(); else status = 0;} reinitialize()是重置方法。标注代码分析 如果发生过异常，清空异常表。ForkJoinTask#tryUnfork()1234567891011121314151617181920/** * Tries to unschedule this task for execution. This method will * typically succeed if this task is the most recently forked task * by the current thread, and has not commenced executing in * another thread. This method may be useful when arranging * alternative local processing of tasks that could have been, but * were not, stolen. * * &lt;p&gt;This method may be invoked only from within {@code * ForkJoinPool} computations (as may be determined using method * {@link #inForkJoinPool}). Attempts to invoke in other contexts * result in exceptions or errors, possibly including {@code * ClassCastException}. * * @return {@code true} if unforked */public boolean tryUnfork() { return ((ForkJoinWorkerThread) Thread.currentThread()) .unpushTask(this);} 方法内部会尝试将自身从当前工作线程的队列顶端移除，相当于在当前任务没有被调度执行之前取消了自己。 ForkJoinTask#getPool()123456789101112/** * Returns the pool hosting the current task execution, or null * if this task is executing outside of any ForkJoinPool. * * @see #inForkJoinPool * @return the pool, or {@code null} if none */public static ForkJoinPool getPool() { Thread t = Thread.currentThread(); return (t instanceof ForkJoinWorkerThread) ? ((ForkJoinWorkerThread) t).pool : null;} ForkJoinTask#inForkJoinPool()1234567891011/** * Returns {@code true} if the current thread is a {@link * ForkJoinWorkerThread} executing as a ForkJoinPool computation. * * @return {@code true} if the current thread is a {@link * ForkJoinWorkerThread} executing as a ForkJoinPool computation, * or {@code false} otherwise */public static boolean inForkJoinPool() { return Thread.currentThread() instanceof ForkJoinWorkerThread;} 3 ForkJoinPoolForkJoinPool#managedBlock()12345678910111213141516171819202122232425262728293031/** * Blocks in accord with the given blocker. If the current thread * is a {@link ForkJoinWorkerThread}, this method possibly * arranges for a spare thread to be activated if necessary to * ensure sufficient parallelism while the current thread is blocked. * * &lt;p&gt;If the caller is not a {@link ForkJoinTask}, this method is * behaviorally equivalent to * &lt;pre&gt; {@code * while (!blocker.isReleasable()) * if (blocker.block()) * return; * }&lt;/pre&gt; * * If the caller is a {@code ForkJoinTask}, then the pool may * first be expanded to ensure parallelism, and later adjusted. * * @param blocker the blocker * @throws InterruptedException if blocker.block did so */public static void managedBlock(ManagedBlocker blocker) throws InterruptedException { Thread t = Thread.currentThread(); if (t instanceof ForkJoinWorkerThread) { ForkJoinWorkerThread w = (ForkJoinWorkerThread) t; w.pool.awaitBlocker(blocker); } else { do {} while (!blocker.isReleasable() &amp;&amp; !blocker.block()); }} ForkJoin工作线程会调用工作线程所在的Pool的awaitBlocker()。 非ForkJoin工作线程相当于在blocker上阻塞，被唤醒后方法就结束了。 ForkJoinPool#awaitBlocker()12345678910111213141516/** * If necessary, compensates for blocker, and blocks */private void awaitBlocker(ManagedBlocker blocker) throws InterruptedException { while (!blocker.isReleasable()) { if (tryPreBlock()) { try { do {} while (!blocker.isReleasable() &amp;&amp; !blocker.block()); } finally { postBlock(); } break; } }} 和managedBlock中非ForkJoin工作的逻辑差不多，只是加了阻塞前后的处理。可以回顾一下这两个方法都做了哪些工作。managedBlock的目的是为了保证Pool的并行性。假设具体的ForkJoinTask在执行过程中，被外部阻塞了，相当于执行当前任务的ForkJoin工作线程在Pool以外的阻塞对象(blocker)上阻塞了，对于Pool来说，它还认为这个工作线程是活动的(不像内部阻塞，如join某个任务，在内部会有记录)，如果这个阻塞过程持续的时间很长的话，一定会影响Pool的并行性能。如果能将这种外部阻塞也记录到Pool里面，那么工作线程被外部阻塞(阻塞时间很长)的话，Pool就可能会产生一个新的工作线程来保证并行性能。managedBlock()的目的就是这个，具体使用方式就是通过实现ManagedBlocker接口将外部阻塞记录进来。 ForkJoinPool#ManagedBlocker123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172/** * Interface for extending managed parallelism for tasks running * in {@link ForkJoinPool}s. * * &lt;p&gt;A {@code ManagedBlocker} provides two methods. Method * {@code isReleasable} must return {@code true} if blocking is * not necessary. Method {@code block} blocks the current thread * if necessary (perhaps internally invoking {@code isReleasable} * before actually blocking). These actions are performed by any * thread invoking {@link ForkJoinPool#managedBlock}. The * unusual methods in this API accommodate synchronizers that may, * but don't usually, block for long periods. Similarly, they * allow more efficient internal handling of cases in which * additional workers may be, but usually are not, needed to * ensure sufficient parallelism. Toward this end, * implementations of method {@code isReleasable} must be amenable * to repeated invocation. * * &lt;p&gt;For example, here is a ManagedBlocker based on a * ReentrantLock: * &lt;pre&gt; {@code * class ManagedLocker implements ManagedBlocker { * final ReentrantLock lock; * boolean hasLock = false; * ManagedLocker(ReentrantLock lock) { this.lock = lock; } * public boolean block() { * if (!hasLock) * lock.lock(); * return true; * } * public boolean isReleasable() { * return hasLock || (hasLock = lock.tryLock()); * } * }}&lt;/pre&gt; * * &lt;p&gt;Here is a class that possibly blocks waiting for an * item on a given queue: * &lt;pre&gt; {@code * class QueueTaker&lt;E&gt; implements ManagedBlocker { * final BlockingQueue&lt;E&gt; queue; * volatile E item = null; * QueueTaker(BlockingQueue&lt;E&gt; q) { this.queue = q; } * public boolean block() throws InterruptedException { * if (item == null) * item = queue.take(); * return true; * } * public boolean isReleasable() { * return item != null || (item = queue.poll()) != null; * } * public E getItem() { // call after pool.managedBlock completes * return item; * } * }}&lt;/pre&gt; */public static interface ManagedBlocker { /** * Possibly blocks the current thread, for example waiting for * a lock or condition. * * @return {@code true} if no additional blocking is necessary * (i.e., if isReleasable would return true) * @throws InterruptedException if interrupted while waiting * (the method is not required to do so, but is allowed to) */ boolean block() throws InterruptedException; /** * Returns {@code true} if blocking is unnecessary. */ boolean isReleasable();} ManagedBlocker#doc#ManagedLockerManagedBlocker#doc上还提供示例。12345678910111213class ManagedLocker implements ManagedBlocker { final ReentrantLock lock; boolean hasLock = false; ManagedLocker(ReentrantLock lock) { this.lock = lock; } public boolean block() { if (!hasLock) lock.lock(); return true; } public boolean isReleasable() { return hasLock || (hasLock = lock.tryLock()); } }} ForkJoinPool#invoke()123456789101112131415161718192021222324252627282930/** * Performs the given task, returning its result upon completion. * If the computation encounters an unchecked Exception or Error, * it is rethrown as the outcome of this invocation. Rethrown * exceptions behave in the same way as regular exceptions, but, * when possible, contain stack traces (as displayed for example * using {@code ex.printStackTrace()}) of both the current thread * as well as the thread actually encountering the exception; * minimally only the latter. * * @param task the task * @return the task's result * @throws NullPointerException if the task is null * @throws RejectedExecutionException if the task cannot be * scheduled for execution */public &lt;T&gt; T invoke(ForkJoinTask&lt;T&gt; task) { Thread t = Thread.currentThread(); if (task == null) throw new NullPointerException(); if (shutdown) throw new RejectedExecutionException(); if ((t instanceof ForkJoinWorkerThread) &amp;&amp; ((ForkJoinWorkerThread)t).pool == this) return task.invoke(); // bypass submit if in same pool else { addSubmission(task); return task.join(); }} 执行任务然后返回结果，不是异步的。如果当前线程是ForkJoin工作线程，就执行给定任务的invoke()；否则将任务提交到Pool的任务队列里面，然后join等待任务。 ForkJoinPool#execute()12345678910111213141516171819202122232425262728293031/** * Arranges for (asynchronous) execution of the given task. * * @param task the task * @throws NullPointerException if the task is null * @throws RejectedExecutionException if the task cannot be * scheduled for execution */ public void execute(ForkJoinTask&lt;?&gt; task) { if (task == null) throw new NullPointerException(); forkOrSubmit(task); } // AbstractExecutorService methods /** * @throws NullPointerException if the task is null * @throws RejectedExecutionException if the task cannot be * scheduled for execution */ public void execute(Runnable task) { if (task == null) throw new NullPointerException(); ForkJoinTask&lt;?&gt; job; if (task instanceof ForkJoinTask&lt;?&gt;) // avoid re-wrap job = (ForkJoinTask&lt;?&gt;) task; else job = ForkJoinTask.adapt(task, null); forkOrSubmit(job); } 两个execute()是异步执行的。 ForkJoinPool#invokeAll()12345678910111213141516171819202122232425/** * @throws NullPointerException {@inheritDoc} * @throws RejectedExecutionException {@inheritDoc} */public &lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks) { ArrayList&lt;ForkJoinTask&lt;T&gt;&gt; forkJoinTasks = new ArrayList&lt;ForkJoinTask&lt;T&gt;&gt;(tasks.size()); for (Callable&lt;T&gt; task : tasks) forkJoinTasks.add(ForkJoinTask.adapt(task)); invoke(new InvokeAll&lt;T&gt;(forkJoinTasks)); @SuppressWarnings({\"unchecked\", \"rawtypes\"}) List&lt;Future&lt;T&gt;&gt; futures = (List&lt;Future&lt;T&gt;&gt;) (List) forkJoinTasks; return futures;}static final class InvokeAll&lt;T&gt; extends RecursiveAction { final ArrayList&lt;ForkJoinTask&lt;T&gt;&gt; tasks; InvokeAll(ArrayList&lt;ForkJoinTask&lt;T&gt;&gt; tasks) { this.tasks = tasks; } public void compute() { try { invokeAll(tasks); } catch (Exception ignore) {} } private static final long serialVersionUID = -7914297376763021607L;} 内部调用的是ForkJoinTask#invokeAll()。 ForkJoinPool#other()123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143/** * Returns the factory used for constructing new workers. * * @return the factory used for constructing new workers */// 1public ForkJoinWorkerThreadFactory getFactory() { return factory;}/** * Returns the handler for internal worker threads that terminate * due to unrecoverable errors encountered while executing tasks. * * @return the handler, or {@code null} if none */// 2public Thread.UncaughtExceptionHandler getUncaughtExceptionHandler() { return ueh;}/** * Returns the targeted parallelism level of this pool. * * @return the targeted parallelism level of this pool */// 3public int getParallelism() { return parallelism;}/** * Returns the number of worker threads that have started but not * yet terminated. The result returned by this method may differ * from {@link #getParallelism} when threads are created to * maintain parallelism when others are cooperatively blocked. * * @return the number of worker threads */// 4public int getPoolSize() { return parallelism + (short)(ctl &gt;&gt;&gt; TC_SHIFT);}/** * Returns {@code true} if this pool uses local first-in-first-out * scheduling mode for forked tasks that are never joined. * * @return {@code true} if this pool uses async mode */// 5public boolean getAsyncMode() { return locallyFifo;}/** * Returns an estimate of the number of worker threads that are * not blocked waiting to join tasks or for other managed * synchronization. This method may overestimate the * number of running threads. * * @return the number of worker threads */// 6public int getRunningThreadCount() { int r = parallelism + (int)(ctl &gt;&gt; AC_SHIFT); return (r &lt;= 0) ? 0 : r; // suppress momentarily negative values}/** * Returns an estimate of the number of threads that are currently * stealing or executing tasks. This method may overestimate the * number of active threads. * * @return the number of active threads */// 7public int getActiveThreadCount() { int r = parallelism + (int)(ctl &gt;&gt; AC_SHIFT) + blockedCount; return (r &lt;= 0) ? 0 : r; // suppress momentarily negative values}/** * Returns an estimate of the total number of tasks stolen from * one thread's work queue by another. The reported value * underestimates the actual total number of steals when the pool * is not quiescent. This value may be useful for monitoring and * tuning fork/join programs: in general, steal counts should be * high enough to keep threads busy, but low enough to avoid * overhead and contention across threads. * * @return the number of steals */// 8public long getStealCount() { return stealCount;}/** * Returns an estimate of the total number of tasks currently held * in queues by worker threads (but not including tasks submitted * to the pool that have not begun executing). This value is only * an approximation, obtained by iterating across all threads in * the pool. This method may be useful for tuning task * granularities. * * @return the number of queued tasks */// 9public long getQueuedTaskCount() { long count = 0; ForkJoinWorkerThread[] ws; if ((short)(ctl &gt;&gt;&gt; TC_SHIFT) &gt; -parallelism &amp;&amp; (ws = workers) != null) { for (ForkJoinWorkerThread w : ws) if (w != null) count -= w.queueBase - w.queueTop; // must read base first } return count;}/** * Returns an estimate of the number of tasks submitted to this * pool that have not yet begun executing. This method may take * time proportional to the number of submissions. * * @return the number of queued submissions */// 10public int getQueuedSubmissionCount() { return -queueBase + queueTop;}/** * Returns {@code true} if there are any tasks submitted to this * pool that have not yet begun executing. * * @return {@code true} if there are any queued submissions */// 11public boolean hasQueuedSubmissions() { return queueBase != queueTop;} 标注代码分析 获取工作线程工厂。 获取内部工作线程未获取异常处理器。 获取当前Pool的并行度。 获取总的工作线程数量。 获取工作模式(是否异步模式)。 获取运行中的工作线程数量。(近似值) 获取活动的工作数量(包括阻塞的，近似值)。 获取Pool内部所有工作线程窃取的任务总数。(近似值) 获取所有工作线程任务队列中的任务总数。(近似值) 获取Pool的任务队列中的任务数量。(近似值) 判断Pool的任务队列中是否有任务。","link":"/Fork-Join-Other/"},{"title":"JDK1.6 ConcurrentSkipListSet","text":"ConcurrentSkipListSet基于ConcurrentSkipListMap实现。123456789101112131415161718192021public class ConcurrentSkipListSet&lt;E&gt; extends AbstractSet&lt;E&gt; implements NavigableSet&lt;E&gt;, Cloneable, java.io.Serializable { private static final long serialVersionUID = -2479143111061671589L; /** * The underlying map. Uses Boolean.TRUE as value for each * element. This field is declared final for the sake of thread * safety, which entails some ugliness in clone() */ private final ConcurrentNavigableMap&lt;E,Object&gt; m; /** * Constructs a new, empty set that orders its elements according to * their {@linkplain Comparable natural ordering}. */ public ConcurrentSkipListSet() { m = new ConcurrentSkipListMap&lt;E,Object&gt;(); } ...","link":"/JDK1.6-ConcurrentSkipListSet/"},{"title":"Java递归生成XML","text":"生成XML步骤： 生成根节点（root）； 判断root节点，是否有子节点，生成root节点子节点（二级节点）； 判断root节点的节点（二级节点）是否有子节点（三级节点）； 3这2步骤就可以写成递归，在写一个判断是否有子节点的函数和中文格式化。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129/*** 创建文件的Xml* * @param filename* @param map* @return* @throws Exception*/public Map&lt;String, String&gt; createXMLFile(String filename, Map&lt;String, List&lt;String&gt;&gt; map) throws Exception{ // 存放 file下每一个对象的值 Map&lt;String, String&gt; mapString = new LinkedHashMap&lt;String, String&gt;(); // 取得所有key Set&lt;String&gt; set = map.keySet(); Iterator&lt;String&gt; iterator = set.iterator(); Document document = null; while (iterator.hasNext()) { // 建立document对象 document = DocumentHelper.createDocument(); // 加入第一个节点 String keyString = iterator.next(); String[] arrayString = keyString.split(\",\"); String idString = arrayString[0]; String nameString = arrayString[1]; String pIdString = arrayString[2]; Integer id = Integer.parseInt(arrayString[3]); String fileID = arrayString[4]; String fileName = arrayString[5]; String path = arrayString[6]; // 判断根节点 创建root if (\"-2\".equals(pIdString)) { // 建立XML文档的根root Element rootElement = document.addElement(nameString); Integer nodeID = Integer.parseInt(idString); // 判断根节点的子节点 isFileChild(map, rootElement, nodeID, id, fileID); } // 将document中的内容写入文件中，生成一个xml XMLWriter writer = new XMLWriter(new FileWriter(new java.io.File(filename))); writer.write(document); writer.close(); // 读取xml StringBuilder stringBuilder = new StringBuilder(); File file = new File(filename); BufferedReader bf = new BufferedReader(new FileReader(file)); String temp; while ((temp = bf.readLine()) != null) { stringBuilder.append(temp); } //判断xml是否是空 if (!\"&lt;?xml version=\\\"1.0\\\" encoding=\\\"UTF-8\\\"?&gt;\".equals(stringBuilder.toString())) { String data = stringBuilder.toString(); String kString = id.toString() + \",\" + fileName + \",\" + path; mapString.put(kString, data); } } return mapString;}/*** 文件xml-获取 当前节点 是 其他节点的父节点* * @param map* @param element* 当前文件节点* @param nodeId* 当前文件content的id* @param id* @param fileID* 当前文件节点id* @throws Exception*/public void isFileChild(Map&lt;String, List&lt;String&gt;&gt; map, Element element, Integer nodeId, Integer id, String fileID) throws Exception{ Set&lt;String&gt; set = map.keySet(); Iterator&lt;String&gt; it = set.iterator(); while (it.hasNext()) { String kString = it.next(); String[] setString = kString.split(\",\"); // 当前节点id 是 其他节点的父id,当前节点有子节点, 属于同一个文件 if (!\"root\".equals(setString[2]) &amp;&amp; id == Integer.parseInt((setString[3])) &amp;&amp; Integer.parseInt(setString[2]) == nodeId &amp;&amp; setString[4].equals(fileID)) { List&lt;String&gt; valueList = map.get(kString); //创建当前节点的xml Element nodElement = createFileXML(element, valueList, kString); Integer cid = Integer.parseInt(setString[0]); // 查询当前节点是否有子节点,有子节点，传递当前节点 isFileChild(map, nodElement, cid, Integer.parseInt(setString[3]), setString[4]);}}}/*** 创建节点的xml* * @param element* 当前节点* @param list* @param keyString* @return* @throws Exception*/public Element createFileXML(Element element, List&lt;String&gt; list, String keyString) throws Exception{ String[] kStrings = keyString.split(\",\"); //添加节点 Element nodeEle = element.addElement(kStrings[1]); for (int i = 0; i &lt; list.size(); i++) { String data = list.get(i); String[] dataStrings = data.split(\",\"); //添加属性 nodeEle.addAttribute(dataStrings[0], dataStrings[1]); } return nodeEle;}/*** 格式化XML文档,并解决中文问题* * @param filename* @return*/public void formatXML(Document document, String filename) throws Exception{ XMLWriter writer = null; OutputFormat format = OutputFormat.createPrettyPrint(); // 指定XML编码 format.setEncoding(\"utf-8\"); //格式化XML文件 writer = new XMLWriter(new FileWriter(new File(filename)), format); //输出XML文件 writer.write(document); writer.close();}","link":"/Java-XML/"},{"title":"Java序列化和反序列化","text":"1 基础 1.1 算法 1.2 使用场景 2 字节码解析 字节分类意义 3 源码解析 3.1 ObjectOutputStream 3.2 ObjectInputStream 1 基础序列化：将数据结构或对象转换成二进制串的过程。反序列化：将在序列化过程中所生成的二进制串转换成数据结构或者对象的过程。调用writeObject()序列化一个对象，是将其写入磁盘，以后在程序再次调用readObject()时，根据wirteObject()磁盘的文件重新恢复那个对象。Externalizable接口扩展Serializable，并增添两个方法：writeExternal()和readExternal()。在序列化和重新装配的过程中，会自动调用这两个方法。Externalizable是Serializable接口的子类，有时不希望序列化那么多，可以使用这个接口，这个接口的writeExternal()和readExternal()可以指定序列化哪些属性。 1.1 算法算法一般会按步骤做如下事情： 将对象实例相关的类元数据输出。 递归地输出类的超类描述直到不再有超类。 类元数据完以后，开始从最顶层的超类开始输出对象实例的实际数据值。 从上至下递归输出实例的数据。 1.2 使用场景语言里增加对象序列化的概念后，可提供对两种主要特性的支持。 远程方法调用（RMI）使本来存在于其他机器的对象可以表现出好象就在本地机器上的行为。将消息发给远程对象时，需要通过对象序列化来传输参数和返回值。 使用一个Java Bean时，它的状态信息通常在设计期间配置好。程序启动以后，这种状态信息必须保存下来，以便程序启动以后恢复；具体工作由对象序列化完成。2 字节码解析保存对象序列化字节码123456789package demo1;import java.io.Serializable;class Parent implements Serializable { private static final long serialVersionUID = 1L; int parentVersion = 10; } 123456789package demo1;import java.io.Serializable;public class Contain implements Serializable{ private static final long serialVersionUID = 1L; int containVersion = 11; } 12345678910111213141516171819202122232425262728293031323334353637package demo1;import java.io.File;import java.io.FileOutputStream;import java.io.IOException;import java.io.ObjectOutputStream;import java.io.Serializable;/** * * 序列化字节码 * */public class SerialTest extends Parent implements Serializable { private static final long serialVersionUID = 1L; int version = 66; Contain con = new Contain(); public int getVersion() { return version; } //序列化 public static void main(String args[]) throws IOException { File file=new File(\"D:\\\\temp.out\"); if(!file.exists()){ file.createNewFile(); } FileOutputStream fos = new FileOutputStream(file); ObjectOutputStream oos = new ObjectOutputStream(fos); SerialTest st = new SerialTest(); oos.writeObject(st); oos.flush(); oos.close(); }} 反序列化123456789public static void main(String[] args) throws IOException, ClassNotFoundException { File file=new File(\"D:\\\\temp.out\"); FileInputStream fis = new FileInputStream(file); ObjectInputStream ois = new ObjectInputStream(fis); SerialTest st1 = (SerialTest) ois.readObject(); System.out.println(\"getVersion()：\"+st1.getVersion()); ois.close(); fis.close();} 控制台输出1getVersion()：66 temp.out输出12345678910AC ED 00 05 73 72 00 0A 53 65 72 69 61 6C 54 6573 74 05 52 81 5A AC 66 02 F6 02 00 02 49 00 0776 65 72 73 69 6F 6E 4C 00 03 63 6F 6E 74 00 094C 63 6F 6E 74 61 69 6E 3B 78 72 00 06 70 61 7265 6E 74 0E DB D2 BD 85 EE 63 7A 02 00 01 49 000D 70 61 72 65 6E 74 56 65 72 73 69 6F 6E 78 7000 00 00 0A 00 00 00 42 73 72 00 07 63 6F 6E 7461 69 6E FC BB E6 0E FB CB 60 C7 02 00 01 49 000E 63 6F 6E 74 61 69 6E 56 65 72 73 69 6F 6E 7870 00 00 00 0B 字节码分析123456789101112131415161718192021222324252627282930313233343536373839404142434445AC ED：STREAM_MAGIC。声明使用序列化协议。00 05：STREAM_VERSION。序列化协议版本。0x73：TC_OBJECT。声明这是一个新的对象。0x72：TC_CLASSDESC。 声明这里开始一个新Class。00 0A：Class名字的长度。53 65 72 69 61 6c 54 65 73 74：SerialTest，Class类名。05 52 81 5A AC 66 02 F6：SerialVersionUID，序列化ID，如果没有指定，则会由算法随机生成一个8byte的ID。0x02：标记号。该值声明该对象支持序列化。00 02：该类所包含的域个数。0x49：域类型。49 代表&quot;I&quot;，也就是Int。00 07：域名字的长度。76 65 72 73 69 6F 6E：version，域名字描述。0x4C：域的类型。00 03：域名字长度。63 6F 6E：域名字描述，con。0x74：TC_STRING。代表一个new String，用String来引用对象。00 09：该String长度。4C 63 6F 6E 74 61 69 6E 3B：Lcontain；JVM的标准对象签名表示法。0x78：TC_ENDBLOCKDATA，对象数据块结束的标志。0x72：TC_CLASSDESC。声明这个是个新类。00 06：类名长度。70 61 72 65 6E 74：parent，类名描述。0E DB D2 BD 85 EE 63 7A：SerialVersionUID，序列化ID。0x02: 标记号. 该值声明该对象支持序列化。00 01: 类中域的个数。0x49：域类型. 49 代表&quot;I&quot;，也就是Int。00 0D：域名字长度。70 61 72 65 6E 74 56 65 72 73 69 6F 6E：parentVersion，域名字描述。0x78：TC_ENDBLOCKDATA,对象块结束的标志。0x70：TC_NULL，说明没有其他超类的标志。00 00 00 0A：10，parentVersion域的值。00 00 00 42：66, version域的值。0x73：TC_OBJECT，声明这是一个新的对象。0x72：TC_CLASSDESC声明这里开始一个新Class。00 07：类名的长度。63 6F 6E 74 61 69 6E：contain，类名描述。FC BB E6 0E FB CB 60 C7：SerialVersionUID，序列化ID。0x02：Various flags. 标记号。该值声明该对象支持序列化。00 01：类内的域个数。0x49：域类型. 49 代表&quot;I&quot;，也就是Int..00 0E：域名字长度。63 6F 6E 74 61 69 6E 56 65 72 73 69 6F 6E：containVersion，域名字描述。0x78：TC_ENDBLOCKDATA对象块结束的标志。0x70：TC_NULL，没有超类。00 00 00 0B：11，containVersion的值。 字节分类意义 字节 说明 AC-73 输出对象相关类的描述。 72-02 SerialTest类的描述。 49-6E int version=66。 4C-78 contain con = new contain()；这个有点特殊，是个对象。描述对象类型引用时需要使用JVM的标准对象签名表示法。 72-70 输出parent类的域描述，int parentVersion=100。 00-42 实例对象的实际值，Parent类，SerialTest类。 73-0B 描述contain类的信息，要记住，现在还没有对contain类进行过描述。 3 源码解析3.1 ObjectOutputStreamobjectOutputStream#writeObject(obj)1234567891011121314public ObjectOutputStream(OutputStream out) throws IOException { verifySubclass(); bout = new BlockDataOutputStream(out); handles = new HandleTable(10, (float) 3.00); subs = new ReplaceTable(10, (float) 3.00); enableOverride = false; writeStreamHeader(); bout.setBlockDataMode(true); if (extendedDebugInfo) { debugInfoStack = new DebugTraceInfoStack(); } else { debugInfoStack = null; }} writeObject(obj)1234567891011121314public final void writeObject(Object obj) throws IOException { if (enableOverride) { writeObjectOverride(obj); return; } try { writeObject0(obj, false); } catch (IOException ex) { if (depth == 0) { writeFatalException(ex); } throw ex; }} writeObject0(Object obj, boolean unshared)12345678910111213141516if (obj instanceof String) { writeString((String) obj, unshared); } else if (cl.isArray()) { writeArray(obj, desc, unshared); } else if (obj instanceof Enum) { writeEnum((Enum) obj, desc, unshared); } else if (obj instanceof Serializable) { writeOrdinaryObject(obj, desc, unshared); } else { if (extendedDebugInfo) { throw new NotSerializableException( cl.getName() + \"\\n\" + debugInfoStack.toString()); } else { throw new NotSerializableException(cl.getName()); } } 从上可以看出，如果对象没有实现Serializable接口，在序列化的时候会抛出NotSerializableException异常。上述SerialTest是一个类对象，所以会执行writeOrdinaryObject(obj, desc, unshared)。writeOrdinaryObject(obj, desc, unshared)12345if (desc.isExternalizable() &amp;&amp; !desc.isProxy()) { writeExternalData((Externalizable) obj);} else { writeSerialData(obj, desc);} 如果对象实现Externalizable接口，那么执行writeExternalData((Externalizable) obj)。如果对象实现的是Serializable接口，那么执行的是writeSerialData(obj, desc)。writeSerialData()1234567891011121314151617181920212223242526272829303132ObjectStreamClass.ClassDataSlot[] slots = desc.getClassDataLayout(); for (int i = 0; i &lt; slots.length; i++) { ObjectStreamClass slotDesc = slots[i].desc; if (slotDesc.hasWriteObjectMethod()) { PutFieldImpl oldPut = curPut; curPut = null; SerialCallbackContext oldContext = curContext; if (extendedDebugInfo) { debugInfoStack.push( \"custom writeObject data (class \\\"\" + slotDesc.getName() + \"\\\")\"); } try { curContext = new SerialCallbackContext(obj, slotDesc); bout.setBlockDataMode(true); slotDesc.invokeWriteObject(obj, this); bout.setBlockDataMode(false); bout.writeByte(TC_ENDBLOCKDATA); } finally { curContext.setUsed(); curContext = oldContext; if (extendedDebugInfo) { debugInfoStack.pop(); } } curPut = oldPut; } else { defaultWriteFields(obj, slotDesc); } } 如果没有默认writer()，执行defaultWriteFields()defaultWriteFields()12345678910111213141516171819202122232425262728293031323334353637private void defaultWriteFields(Object obj, ObjectStreamClass desc) throws IOException{ Class&lt;?&gt; cl = desc.forClass(); if (cl != null &amp;&amp; obj != null &amp;&amp; !cl.isInstance(obj)) { throw new ClassCastException(); } desc.checkDefaultSerialize(); int primDataSize = desc.getPrimDataSize(); if (primVals == null || primVals.length &lt; primDataSize) { primVals = new byte[primDataSize]; } desc.getPrimFieldValues(obj, primVals); bout.write(primVals, 0, primDataSize, false); ObjectStreamField[] fields = desc.getFields(false); Object[] objVals = new Object[desc.getNumObjFields()]; int numPrimFields = fields.length - objVals.length; desc.getObjFieldValues(obj, objVals); for (int i = 0; i &lt; objVals.length; i++) { if (extendedDebugInfo) { debugInfoStack.push( \"field (class \\\"\" + desc.getName() + \"\\\", name: \\\"\" + fields[numPrimFields + i].getName() + \"\\\", type: \\\"\" + fields[numPrimFields + i].getType() + \"\\\")\"); } try { writeObject0(objVals[i], fields[numPrimFields + i].isUnshared()); } finally { if (extendedDebugInfo) { debugInfoStack.pop(); } } }} writeExternalData()1234567891011121314151617181920212223242526private void writeExternalData(Externalizable obj) throws IOException { PutFieldImpl oldPut = curPut; curPut = null; if (extendedDebugInfo) { debugInfoStack.push(\"writeExternal data\"); } SerialCallbackContext oldContext = curContext; try { curContext = null; if (protocol == PROTOCOL_VERSION_1) { obj.writeExternal(this); } else { bout.setBlockDataMode(true); obj.writeExternal(this); bout.setBlockDataMode(false); bout.writeByte(TC_ENDBLOCKDATA); } } finally { curContext = oldContext; if (extendedDebugInfo) { debugInfoStack.pop(); } } curPut = oldPut;} 在此方法中 obj.writeExternal(this) 执行序列化对象实现的writeExternal。 3.2 ObjectInputStreamobjectInputStream#readObject()12345678910111213141516171819202122232425public final Object readObject() throws IOException, ClassNotFoundException{ if (enableOverride) { return readObjectOverride(); } // if nested read, passHandle contains handle of enclosing object int outerHandle = passHandle; try { Object obj = readObject0(false); handles.markDependency(outerHandle, passHandle); ClassNotFoundException ex = handles.lookupException(passHandle); if (ex != null) { throw ex; } if (depth == 0) { vlist.doCallbacks(); } return obj; } finally { passHandle = outerHandle; if (closed &amp;&amp; depth == 0) { clear(); } }} objectInputStream#readObject()执行readObject0(false)readObject0(false)123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960try { switch (tc) { case TC_NULL: return readNull(); case TC_REFERENCE: return readHandle(unshared); case TC_CLASS: return readClass(unshared); case TC_CLASSDESC: case TC_PROXYCLASSDESC: return readClassDesc(unshared); case TC_STRING: case TC_LONGSTRING: return checkResolve(readString(unshared)); case TC_ARRAY: return checkResolve(readArray(unshared)); case TC_ENUM: return checkResolve(readEnum(unshared)); case TC_OBJECT: return checkResolve(readOrdinaryObject(unshared)); case TC_EXCEPTION: IOException ex = readFatalException(); throw new WriteAbortedException(\"writing aborted\", ex); case TC_BLOCKDATA: case TC_BLOCKDATALONG: if (oldMode) { bin.setBlockDataMode(true); bin.peek(); // force header read throw new OptionalDataException( bin.currentBlockRemaining()); } else { throw new StreamCorruptedException( \"unexpected block data\"); } case TC_ENDBLOCKDATA: if (oldMode) { throw new OptionalDataException(true); } else { throw new StreamCorruptedException( \"unexpected end of block data\"); } default: throw new StreamCorruptedException( String.format(\"invalid type code: %02X\", tc)); }} finally { depth--; bin.setBlockDataMode(oldMode);} 根据不同的对象类型做相应的处理，这里关注的是TC_OBJECT，执行的方法是checkResolve(readOrdinaryObject(unshared));readOrdinaryObject()加载序列化对象的Class，如果可以实例化，那么创建它的实例desc.newInstance()readOrdinaryObject()123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354private Object readOrdinaryObject(boolean unshared) throws IOException{ if (bin.readByte() != TC_OBJECT) { throw new InternalError(); } ObjectStreamClass desc = readClassDesc(false); desc.checkDeserialize(); Class&lt;?&gt; cl = desc.forClass(); if (cl == String.class || cl == Class.class || cl == ObjectStreamClass.class) { throw new InvalidClassException(\"invalid class descriptor\"); } Object obj; try { obj = desc.isInstantiable() ? desc.newInstance() : null; } catch (Exception ex) { throw (IOException) new InvalidClassException( desc.forClass().getName(), \"unable to create instance\").initCause(ex); } passHandle = handles.assign(unshared ? unsharedMarker : obj); ClassNotFoundException resolveEx = desc.getResolveException(); if (resolveEx != null) { handles.markException(passHandle, resolveEx); } if (desc.isExternalizable()) { readExternalData((Externalizable) obj, desc); } else { readSerialData(obj, desc); } handles.finish(passHandle); if (obj != null &amp;&amp; handles.lookupException(passHandle) == null &amp;&amp; desc.hasReadResolveMethod()) { Object rep = desc.invokeReadResolve(obj); if (unshared &amp;&amp; rep.getClass().isArray()) { rep = cloneArray(rep); } if (rep != obj) { handles.setObject(passHandle, obj = rep); } } return obj;}","link":"/Java-Serialization-Deserialization/"},{"title":"JDK1.6 ConcurrentLinkedQueue","text":"1 介绍 2 源码分析 ConcurrentLinkedQueue ConcurrentLinkedQueue#add() ConcurrentLinkedQueue#offer() 没有竞争 有竞争 ConcurrentLinkedQueue#succ() ConcurrentLinkedQueue#HOPS ConcurrentLinkedQueue#poll() ConcurrentLinkedQueue#updateHead() ConcurrentLinkedQueue#peek() ConcurrentLinkedQueue#first() ConcurrentLinkedQueue#isEmpty() ConcurrentLinkedQueue#size() 3 总结 ConcurrentLinkedQueue#iterator() 1 介绍 ConcurrentLinkedQueue是一种基于单向链表实现的无界的线程安全队列。队列中的元素遵循先入先出(FIFO)的规则。新元素插入到队列的尾部，从队列头部取出元素。 ConcurrentLinkedQueue内部采用一种wait-free(无等待)算法来实现。2 源码分析ConcurrentLinkedQueue123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990public class ConcurrentLinkedQueue&lt;E&gt; extends AbstractQueue&lt;E&gt; implements Queue&lt;E&gt;, java.io.Serializable { private static final long serialVersionUID = 196745693267521676L; /* * ...略 */ private static class Node&lt;E&gt; { private volatile E item; private volatile Node&lt;E&gt; next; Node(E item) { // Piggyback on imminent casNext() lazySetItem(item); } E getItem() { return item; } boolean casItem(E cmp, E val) { return UNSAFE.compareAndSwapObject(this, itemOffset, cmp, val); } void setItem(E val) { item = val; } void lazySetItem(E val) { UNSAFE.putOrderedObject(this, itemOffset, val); } void lazySetNext(Node&lt;E&gt; val) { UNSAFE.putOrderedObject(this, nextOffset, val); } Node&lt;E&gt; getNext() { return next; } boolean casNext(Node&lt;E&gt; cmp, Node&lt;E&gt; val) { return UNSAFE.compareAndSwapObject(this, nextOffset, cmp, val); } // Unsafe mechanics private static final sun.misc.Unsafe UNSAFE = sun.misc.Unsafe.getUnsafe(); private static final long nextOffset = objectFieldOffset(UNSAFE, \"next\", Node.class); private static final long itemOffset = objectFieldOffset(UNSAFE, \"item\", Node.class); } /** * A node from which the first live (non-deleted) node (if any) * can be reached in O(1) time. * Invariants: * - all live nodes are reachable from head via succ() * - head != null * - (tmp = head).next != tmp || tmp != head * Non-invariants: * - head.item may or may not be null. * - it is permitted for tail to lag behind head, that is, for tail * to not be reachable from head! */ // 1 private transient volatile Node&lt;E&gt; head = new Node&lt;E&gt;(null); /** * A node from which the last node on list (that is, the unique * node with node.next == null) can be reached in O(1) time. * Invariants: * - the last node is always reachable from tail via succ() * - tail != null * Non-invariants: * - tail.item may or may not be null. * - it is permitted for tail to lag behind head, that is, for tail * to not be reachable from head! * - tail.next may or may not be self-pointing to tail. */ // 2 private transient volatile Node&lt;E&gt; tail = head; /** * Creates a {@code ConcurrentLinkedQueue} that is initially empty. */ public ConcurrentLinkedQueue() {} 标注代码分析 节点head可以指向live nodes（live节点）；head != null，head.item == null||head.item != null；节点head有可能无法指向节点tail。 tail != null；节点tail是最后1个节点；节点head有可能无法指向节点tail；tail.next可能指向自己或者不指向自己。 ConcurrentLinkedQueue#add()123456789/** * Inserts the specified element at the tail of this queue. * * @return {@code true} (as specified by {@link Collection#add}) * @throws NullPointerException if the specified element is null */public boolean add(E e) { return offer(e);} ConcurrentLinkedQueue#offer()123456789101112131415161718192021222324252627282930313233/** * Inserts the specified element at the tail of this queue. * * @return {@code true} (as specified by {@link Queue#offer}) * @throws NullPointerException if the specified element is null */ public boolean offer(E e) { if (e == null) throw new NullPointerException(); Node&lt;E&gt; n = new Node&lt;E&gt;(e); retry: for (;;) { Node&lt;E&gt; t = tail; Node&lt;E&gt; p = t; for (int hops = 0; ; hops++) { // 1 Node&lt;E&gt; next = succ(p); if (next != null) { // 2 if (hops &gt; HOPS &amp;&amp; t != tail) continue retry; // 3 p = next; } else if (p.casNext(null, n)) {// 4 // 5 if (hops &gt;= HOPS) casTail(t, n); // Failure is OK. return true; } else {// 6 p = succ(p); } } } } 标注代码分析 获取p的后继节点。(如果p的next指向自身，返回head节点) 如果自旋次数大于HOPS，且t不是尾节点，跳出2层循环重试。 如果自旋字数小于HOPS或者t是尾节点，将p指向next。 如果next为null，尝试将p的next节点设置为n，然后自旋。 如果设置成功且自旋次数大于HOPS，尝试将n设置为尾节点，失败也没关系。 如果第5步尝试将p的next节点设置为n失败，那么将p指向p的后继节点，然后自旋。 没有竞争初始状态时head和tail都指向一个节点，这时来了一个新节点n1，代码走向上面注释第1行，得到的next为null，然后走向第5行，然后将p(也就是tail节点)的next节点设置为n1，成功返回。注意这里并没有调整tail指针，head和tail还是指向之前的节点。然后再来一个新节点n2，还是走向第1行，得到的next是n1，然后走向第8行，将p指向n1，自旋一次，又来到第1行，得到的next为null，然后走向第5行，将p(也就是n1)的next节点设置为n2。由于已经自旋一次，所以这时还会走向第6行，将tail指向n2。 有竞争假设在注释第5行竞争失败，那么会走向第8行，将p向队尾推进一步，然后重试；如果重试了多次后(超过一次)，在注释第一行获取的next仍然不为空，且同时尾节点也被其他线程推进了，那说明当前节点离尾节点太远了，跳出循环，重新定位尾节点然后再试，这样可以减少自旋次数。 ConcurrentLinkedQueue#succ()12345678910/** * Returns the successor of p, or the head node if p.next has been * linked to self, which will only be true if traversing with a * stale pointer that is now off the list. */ final Node&lt;E&gt; succ(Node&lt;E&gt; p) { Node&lt;E&gt; next = p.getNext(); // 1 return (p == next) ? head : next; } 标注代码分析 如果p节点的next节点指向自身，那么返回head节点；否则返回p的next节点。ConcurrentLinkedQueue#HOPS123456/** * We don't bother to update head or tail pointers if fewer than * HOPS links from \"true\" location. We assume that volatile * writes are significantly more expensive than volatile reads. */ private static final int HOPS = 1; 节点head\\tail离true的距离小于HOPS时，不会去更新节点head\\tail。 ConcurrentLinkedQueue#poll()123456789101112131415161718192021222324252627public E poll() { Node&lt;E&gt; h = head; Node&lt;E&gt; p = h; for (int hops = 0; ; hops++) { // 1 E item = p.getItem(); // 2 if (item != null &amp;&amp; p.casItem(item, null)) { if (hops &gt;= HOPS) { Node&lt;E&gt; q = p.getNext(); // 3 updateHead(h, (q != null) ? q : p); } return item; } // 4 Node&lt;E&gt; next = succ(p); // 5 if (next == null) { updateHead(h, p); break; } p = next; } // 6 return null; } 标注代码分析 获取p节点上的元素item。 如果item不为null，尝试将p的item设置为null。 如果自旋次数大于HOPS，尝试更新头节点。 获取p的后继节点。(如果p的next指向自身，那么返回head节点) 如果p的后继节点为null，尝试将p设置为头节点，然后跳出循环。 没有成功获取元素，返回null。 ConcurrentLinkedQueue#updateHead()123456789/** * Try to CAS head to p. If successful, repoint old head to itself * as sentinel for succ(), below. */ final void updateHead(Node&lt;E&gt; h, Node&lt;E&gt; p) { if (h != p &amp;&amp; casHead(h, p)) // 1 h.lazySetNext(h); } 标注代码分析 CAS将head设值p，将h的next指向自身。 ConcurrentLinkedQueue#peek()1234567891011121314151617public E peek() { Node&lt;E&gt; h = head; Node&lt;E&gt; p = h; E item; for (;;) { item = p.getItem(); if (item != null) break; Node&lt;E&gt; next = succ(p); if (next == null) { break; } p = next; } updateHead(h, p); return item;} peek()只获取元素，不移除节点。 ConcurrentLinkedQueue#first()12345678910111213141516171819202122232425262728/** * Returns the first live (non-deleted) node on list, or null if none. * This is yet another variant of poll/peek; here returning the * first node, not element. We could make peek() a wrapper around * first(), but that would cost an extra volatile read of item, * and the need to add a retry loop to deal with the possibility * of losing a race to a concurrent poll(). */ Node&lt;E&gt; first() { Node&lt;E&gt; h = head; Node&lt;E&gt; p = h; Node&lt;E&gt; result; for (;;) { E item = p.getItem(); if (item != null) { result = p; break; } Node&lt;E&gt; next = succ(p); if (next == null) { result = null; break; } p = next; } updateHead(h, p); return result; } peek()逻辑基本一致。但之所以没有利用first来实现peek，而是单独写peek，是因为可以减少一次volatile读(result)。 ConcurrentLinkedQueue#isEmpty()12345678/*** Returns {@code true} if this queue contains no elements.** @return {@code true} if this queue contains no elements*/ public boolean isEmpty() { return first() == null;} ConcurrentLinkedQueue#size()1234567891011121314151617181920212223/** * Returns the number of elements in this queue. If this queue * contains more than {@code Integer.MAX_VALUE} elements, returns * {@code Integer.MAX_VALUE}. * * &lt;p&gt;Beware that, unlike in most collections, this method is * &lt;em&gt;NOT&lt;/em&gt; a constant-time operation. Because of the * asynchronous nature of these queues, determining the current * number of elements requires an O(n) traversal. * * @return the number of elements in this queue */ public int size() { int count = 0; for (Node&lt;E&gt; p = first(); p != null; p = succ(p)) { if (p.getItem() != null) { // Collections.size() spec says to max out if (++count == Integer.MAX_VALUE) break; } } return count; } isEmpty()、size()、contains()、remove()基于first()实现。 3 总结ConcurrentLinkedQueue#iterator()1234567891011121314/** * Returns an iterator over the elements in this queue in proper sequence. * The returned iterator is a \"weakly consistent\" iterator that * will never throw {@link java.util.ConcurrentModificationException * ConcurrentModificationException}, * and guarantees to traverse elements as they existed upon * construction of the iterator, and may (but is not guaranteed to) * reflect any modifications subsequent to construction. * * @return an iterator over the elements in this queue in proper sequence */public Iterator&lt;E&gt; iterator() { return new Itr();} 由注释可以知道ConcurrentLinkedQueue的迭代器是弱一致。ConcurrentLinkedQueue内部在插入或者移除元素时，不会即时设置头尾节点，而是有一个缓冲期(一个节点长的距离)，这样能减少一些CAS操作；其次在设置头尾节点的时候，也不会CAS-Loop直到成功，只尝试一次，失败也没关系，下一次操作或者其他线程在操作时会帮忙推进头尾节点(将头尾指针指向正确位置)。","link":"/JDK1.6-ConcurrentLinkedQueue/"},{"title":"JDK1.6 CountDownLatch","text":"1 介绍CountDownLatch 2 源码分析 CountDownLatch#Sync CountDownLatch 3 总结 1 介绍CountDownLatch一种锁，称为闭锁。可以让一个或多个线程等待另外一个或多个线程执行完毕后再执行。CountDownLatch是基于AQS构建，使用共享模式。CountDownLatch中提供一个count值来表示要等待的(其他任务)完成次数，常规用法有两种：Count(1)和Count(N)。举个栗子，百米赛跑，N个选手，每个选手可以看成是一个线程。起跑前，选手准备(线程启动，然后在Count(1)上阻塞)，当发令枪响后(相当于Count(1)闭锁释放)，选手一起起跑(相当于线程通过Count(1)继续执行)，当所有选手都通过终点(相当于Count(N)闭锁释放)，然后再统计成绩。 2 源码分析CountDownLatch#Sync123456789101112131415161718192021222324252627282930313233/** * Synchronization control For CountDownLatch. * Uses AQS state to represent count. */private static final class Sync extends AbstractQueuedSynchronizer { private static final long serialVersionUID = 4982264981922014374L; Sync(int count) { setState(count); } int getCount() { return getState(); } // 1 public int tryAcquireShared(int acquires) { return getState() == 0? 1 : -1; } // 2 public boolean tryReleaseShared(int releases) { // Decrement count; signal when transition to zero for (;;) { int c = getState(); if (c == 0) return false; int nextc = c-1; if (compareAndSetState(c, nextc)) return nextc == 0; } }} 标注代码分析 如果当前count为0，那么方法返回1，按照之前对AQS的分析，请求成功，并唤醒同步队列里下一个共享模式的线程(这里都是共享模式的)。如果当前count不为0，那么方法返回-1，请求失败，当前线程最终会被阻塞(之前会不止一次调用tryAcquireShared)。 如果count为0，返回false，相当于释放失败，因为此时闭锁处于开放状态，没有必要在打开。如果count不为0，递减count。最后如果count为0，说明关闭的闭锁打开了，那么返回true，后面会唤醒等待队列中的线程。如果count不为0，说明闭锁还是处于关闭状态，返回false。 CountDownLatch123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129private final Sync sync; /** * Constructs a {@code CountDownLatch} initialized with the given count. * * @param count the number of times {@link #countDown} must be invoked * before threads can pass through {@link #await} * @throws IllegalArgumentException if {@code count} is negative */ public CountDownLatch(int count) { if (count &lt; 0) throw new IllegalArgumentException(\"count &lt; 0\"); this.sync = new Sync(count); } /** * Causes the current thread to wait until the latch has counted down to * zero, unless the thread is {@linkplain Thread#interrupt interrupted}. * * &lt;p&gt;If the current count is zero then this method returns immediately. * * &lt;p&gt;If the current count is greater than zero then the current * thread becomes disabled for thread scheduling purposes and lies * dormant until one of two things happen: * &lt;ul&gt; * &lt;li&gt;The count reaches zero due to invocations of the * {@link #countDown} method; or * &lt;li&gt;Some other thread {@linkplain Thread#interrupt interrupts} * the current thread. * &lt;/ul&gt; * * &lt;p&gt;If the current thread: * &lt;ul&gt; * &lt;li&gt;has its interrupted status set on entry to this method; or * &lt;li&gt;is {@linkplain Thread#interrupt interrupted} while waiting, * &lt;/ul&gt; * then {@link InterruptedException} is thrown and the current thread's * interrupted status is cleared. * * @throws InterruptedException if the current thread is interrupted * while waiting */ // 1 public void await() throws InterruptedException { sync.acquireSharedInterruptibly(1); } /** * Causes the current thread to wait until the latch has counted down to * zero, unless the thread is {@linkplain Thread#interrupt interrupted}, * or the specified waiting time elapses. * * &lt;p&gt;If the current count is zero then this method returns immediately * with the value {@code true}. * * &lt;p&gt;If the current count is greater than zero then the current * thread becomes disabled for thread scheduling purposes and lies * dormant until one of three things happen: * &lt;ul&gt; * &lt;li&gt;The count reaches zero due to invocations of the * {@link #countDown} method; or * &lt;li&gt;Some other thread {@linkplain Thread#interrupt interrupts} * the current thread; or * &lt;li&gt;The specified waiting time elapses. * &lt;/ul&gt; * * &lt;p&gt;If the count reaches zero then the method returns with the * value {@code true}. * * &lt;p&gt;If the current thread: * &lt;ul&gt; * &lt;li&gt;has its interrupted status set on entry to this method; or * &lt;li&gt;is {@linkplain Thread#interrupt interrupted} while waiting, * &lt;/ul&gt; * then {@link InterruptedException} is thrown and the current thread's * interrupted status is cleared. * * &lt;p&gt;If the specified waiting time elapses then the value {@code false} * is returned. If the time is less than or equal to zero, the method * will not wait at all. * * @param timeout the maximum time to wait * @param unit the time unit of the {@code timeout} argument * @return {@code true} if the count reached zero and {@code false} * if the waiting time elapsed before the count reached zero * @throws InterruptedException if the current thread is interrupted * while waiting */ // 2 public boolean await(long timeout, TimeUnit unit) throws InterruptedException { return sync.tryAcquireSharedNanos(1, unit.toNanos(timeout)); } /** * Decrements the count of the latch, releasing all waiting threads if * the count reaches zero. * * &lt;p&gt;If the current count is greater than zero then it is decremented. * If the new count is zero then all waiting threads are re-enabled for * thread scheduling purposes. * * &lt;p&gt;If the current count equals zero then nothing happens. */ // 3 public void countDown() { sync.releaseShared(1); } /** * Returns the current count. * * &lt;p&gt;This method is typically used for debugging and testing purposes. * * @return the current count */ public long getCount() { return sync.getCount(); } /** * Returns a string identifying this latch, as well as its state. * The state, in brackets, includes the String {@code \"Count =\"} * followed by the current count. * * @return a string identifying this latch, as well as its state */ public String toString() { return super.toString() + \"[Count = \" + sync.getCount() + \"]\"; } 标注代码分析 如果当前count=0，那么方法立即返回。 如果当前count!=0，那么当前线程会一直等待，直到count被(其他线程)减到0或者当前线程被中断。 如果当前count=0，那么方法立即返回true。如果当前count!=0，那么当前线程会一直等待，直到count被(其他线程)减到0或者当前线程被中断或者超时。 如果当前count大于0，递减count。如果递减后，count等于0，那么AQS中所有等待线程都被唤醒。如果当前count等于0，什么事都不会发生。 3 总结 建立一个count为n的闭锁后，闭锁的内部计数为n，这时如果有线程调用闭锁的await方法，会阻塞。 每一次调用闭锁的countDown方法，内部计数就会减1，当闭锁的countDown方法被调用n次后，内部计数减为0，这时在闭锁await方法上等待的线程就被唤醒了。","link":"/JDK1.6-CountDownLatch/"},{"title":"Java值传递","text":"1 引用和对象在JVM内存中分布结构 1.1 Thinking In Java 3版的第二章 2 基本数据类型作为参数传递的案例分析 2.1 例子1 2.1 例子2 3 引用对象作为参数传递的案例分析 3.1 例子1 3.2 例子2 3.3 例子3 4 总结 1 引用和对象在JVM内存中分布结构在Java中，创建的实体对象在堆内存中开辟空间，而引用对象在栈内存中开辟空间。基本数据类型、引用对象在栈内存中开辟空间。引用对象存储的是实体对象的地址。 1.1 Thinking In Java 3版的第二章Java里存放数据大都放在栈和堆里面。引用和基本类型放在栈里面，因为这样会比较快。对象内容放在堆里面。但是引用所在栈里面存放的是它对应的对象所在堆的地址，栈里的值，也就是堆的地址。其实用引用作为参数说是值传递（堆中值的传递）和地址传递都可以。只是理解的角度不同。 2 基本数据类型作为参数传递的案例分析2.1 例子11234567891011121314151617package valueParam;public class Demo1 { public static void main(String[] args) { Double num = new Double(5); System.out.println(\"num hashcode main=\"+num.hashCode()); System.out.println(num); changeValue(num); System.out.println(num); } public static void changeValue(Double x) { System.out.println(\"x hashcode before=\"+x.hashCode()); x = x * 2; System.out.println(\"x hashcode after=\"+x.hashCode()); }} 12345num hashcode main=10750525445.0x hashcode before=1075052544x hashcode after=10761011205.0 基本数据类型（装箱和拆箱）作为参数传递，值不会发生改变。String，Integer，Double，Float都是final类型的类，是不可以变。changeValue方法参数x的值，是在栈中创建的一个引用对象，x的引用对象指向的地址和num引用对象指向同一个地址（num=5的值，赋值给x）。因为Integer不可变，$x=x2$的时候，新建一个Integer的堆对象，这时changeValue的x栈对象指向这个$x=x2$堆对象。所以，main()中的num栈对象还是指向原来的堆对象，num值不会发生改变，改变的只是changeValue()内x堆对象的值。看hashcode值，前后发生了变化。如果是基本数据类型（int，float，double），main()的double num=5，changeValue(double x)。这种情况，因为基本数据类型都是在栈中创建的，即num在栈中创建存储单元值（5），把这值（5）赋值给x变量在栈中创建的存储单元，x和num都指向栈中的值5，但这是不同的存储单元。 2.1 例子212345678910111213141516171819202122package valueParam;public class Demo2 { String str = new String(\"good\"); char[] ch = { 'a', 'b', 'c' }; public static void main(String args[]) { Demo2 ex = new Demo2(); System.out.println(\"ex.str.hashcode=\"+ex.str.hashCode()); ex.change(ex.str, ex.ch); System.out.println(\"str：\"+ex.str); System.out.println(ex.ch); } public void change(String str, char ch[]) { System.out.println(\"str.hashcode before=\"+str.hashCode()); str = \"test ok\"; System.out.println(\"str.hashcode after=\"+str.hashCode()); ch[0] = 'g'; }} 12345ex.str.hashcode=3178685str.hashcode before=3178685str.hashcode after=-1422516182str：goodgbc String是不可变的，所以在test ok新建一个String对象，Main#str和change#str是指向不同的堆对象地址，change#str的改变，不会影响main#str的值。ch数组是引用对象，ch[0] = 'g';这一句，意思把内部ch指向的数据区域(也就是实际存放数组内容的地方)里面的第一个字符改成g，还是在原来指向的数据区域上操作，并没有改变内部ch的数据地址，所以这个修改也会反映到外部的ch。数组是引用数据类型（非基本数据类型），数组就是一个用来存储一系列变量值的命名区域，因此可以用数组来组织变量，其实,数组也是一个变量，它存储的是相同类型的一组数据。 3 引用对象作为参数传递的案例分析3.1 例子1123456789101112131415161718192021222324252627282930package valueParam;public class Demo5 { // 定义一个改变对象属性的方法 public static void changeName(Person p) { p.setName(\"Rose\"); } public static void main(String[] args) { // 定义一个Person对象，person是这个对象的引用 Person person = new Person(); // 先显示这个对象的name属性 System.out.println(person.getName()); // 调用changeName(Person p)方法 changeName(person); // 再显示这个对象的name属性，看是否发生了变化 System.out.println(person.getName()); }}class Person { private String name = \"Jack\"; public String getName() { return name; } public void setName(String name) { this.name = name; }} 12JackRose main()中new一个对象Person，实际分配了两个对象：堆：新创建的Person类的实体对象。栈：指向该对象的引用对象person。changeName()中，在栈中新建一个引用对象p，引用对象p指向main()中创建的堆对象persion。【注意：在java中，新创建的实体对象在堆内存中开辟空间，而引用变量在栈内存中开辟空间】如上图所示，左侧是堆空间，用来分配内存给新创建的实体对象，红色框是新建的Person类的实体对象，000012是该实体对象的起始地址；而右侧是栈空间，用来给引用变量和一些临时变量分配内存，新实体对象的引用person就在其中，可以看到它的存储单元的内容是000012，记录的正是新建Person类实体对象的起始地址，也就是说它指向该实体对象。调用了changeName()方法，person引用对象的将自己的存储单元传递给p引用对象（person和p指向同一个堆空间地址），也就是将实体对象的地址传给了p引用对象。在changeName()方法中对p的一切操作都是针对p所指向的这个存储单元（堆空间的地址）。那为什么对象内部能够发生变化呢？那是p所指向的那个存储单元中的内容是实体对象的地址，使得p也指向了该实体对象，所以才能改变对象内部的属性！这也是我们大多数人会误以为是“引用传递”的终极原因！ 3.2 例子2123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354package valueParam;public class Demo3 { public static void main(String[] args) { /** * Test 1: Methods can't modify numeric parameters * 基本数据类型 */ System.out.println(\"Testing tripleValue:\"); double percent = 10; System.out.println(\"Before: percent=\" + percent); tripleValue(percent); System.out.println(\"After: percent=\" + percent); /** * Test 2: Methods can change the state of object parameters */ System.out.println(\"\\nTesting tripleSalary:\"); Employee harry = new Employee(\"Harry\", 50000); System.out.println(\"Before: \"+harry.hashCode()+\" salary=\" + harry.getSalary()); tripleSalary(harry); System.out.println(\"After: salary=\" + harry.getSalary()); /** * Test 3: Methods can't attach new objects to object parameters */ System.out.println(\"\\nTesting swap:\"); Employee a = new Employee(\"Alice\", 70000); Employee b = new Employee(\"Bob\", 60000); System.out.println(\"Before: \"+a.hashCode()+\" a=\" + a.getName()); System.out.println(\"Before: \"+b.hashCode()+\" b=\" + b.getName()); swap(a, b); System.out.println(\"After: \"+a.hashCode()+\" a=\" + a.getName()); System.out.println(\"After: \"+b.hashCode()+\" b=\" + b.getName()); } private static void swap(Employee x, Employee y) { Employee temp = x; x = y; y = temp; System.out.println(\"End of method: \"+x.hashCode()+\" x=\" + x.getName()); System.out.println(\"End of method: \"+y.hashCode()+\" y=\" + y.getName()); } private static void tripleSalary(Employee x) { x.raiseSalary(200); System.out.println(\"End of method: \"+x.hashCode()+\" salary=\" + x.getSalary()); } private static void tripleValue(double x) { x = 3 * x; System.out.println(\"End of Method X= \" + x); }} 1234567891011121314151617Testing tripleValue:基本数据类型，在栈开辟独立的存储单元，2个栈对象操作独立的存储单元，相互不影响；在tripleValue方法中，percent栈对象值赋值给x栈对象。Before: percent=10.0x End = 30.0After: percent=10.0Testing tripleSalary:栈引用对象harry和x都是指向同一个堆地址。在tripleSalary方法中，栈对象x对堆中实体对象的修改，直接影响harry引用对象指向堆对象的值。harry Before hashCode: 581409841 salary=50000 x End hashCode: 581409841 salary=10000000harry After hashCode: 581409841 salary=10000000Testing swap:栈对象a、b指向2个不同的堆对象空间，在swap方法内，新建2个栈对象x、y指向栈对象a、b所指的堆对象。那么a,x和b，y都是指向同一个堆对象，那么x，y栈对象的值进行交换，并不会影响a和b，只是x，y所指的堆对象地址变化。如果，x和y对堆对象进行操作，必然会影响到a和b获取的值。Before: 704603837 a=AliceBefore: 1051858901 b=Bobx End hashCode: 1051858901 x=Boby End hashCode: 704603837 y=AliceAfter: 704603837 a=AliceAfter: 1051858901 b=Bob 3.3 例子3123456789101112131415161718package valueParam;public class Demo4 { static void swap(StringBuffer a2, StringBuffer b2) { a2.append(\" more\"); System.out.println(\"--------a-----------\" + a2); // One more System.out.println(\"--------b-----------\" + b2); // Two b2 = a2; System.out.println(\"--------b-----------\" + b2); // One more } public static void main(String args[]) { StringBuffer a1 = new StringBuffer(\"One\"); StringBuffer b1 = new StringBuffer(\"Two\"); swap(a1, b1); System.out.println(\"a is \" + a1 + \"\\nb is \" + b1); }} 12345--------a-----------One more--------b-----------Two--------b-----------One morea is One moreb is Two b2 = a2;这里是指b2指向a2的堆地址，对应main中的b1并没有影响。 4 总结Java 编程语言只有值传递参数。当一个对象实例作为一个参数被传递到方法中时，参数的值就是该对象的引用一个复制，指向同一个堆地址。指向同一个对象，对象的内容可以在被调用的方法中改变，但对象的引用是永远不会改变的。Java程序运行永远都是在栈中进行的，因而参数传递时，只存在传递基本类型和对象引用的问题，传递的是栈对象。不会直接传堆对象本身。Java中方法参数传递方式是按值传递。如果参数是基本类型，传递的是基本类型的字面量值的拷贝。如果参数是引用类型，传递的是该参量所引用的对象在堆中地址值的拷贝。（实际上创建2个栈对象）值传递的精髓是：传递的是存储单元中的内容，而非地址或者引用！值传递和引用传递的参数类型是值类型还是引用类型无关。对于值传递，无论是值类型还是引用类型，都会在调用栈上创建一个副本，不同是，对于值类型而言，这个副本就是整个原始值的复制。而对于引用类型而言，由于引用类型的实例在堆中，在栈上只有它的一个引用（一般情况下是指针），其副本也只是这个引用的复制，而不是整个原始对象的复制。值类型和引用类型（这不是在说值传递）的最大区别：值类型用做参数会被复制，但是很多人误以为这个区别是值类型的特性。其实这是值传递带来的效果，和值类型本身没有关系。真正的引用传递（pass by reference）是指当引用传递给函数时，被调用的函数获得的是对原值的引用，而非原值的副本。如果函数修改了参数值，那么调用代码中的值也会改变，那是因为引用和参数使用了内存中的同一块地址。","link":"/Java-value/"},{"title":"Java泛型","text":"1 extend（上限） 2 super 多态特性 3 泛型擦除 3.1 概述 3.2 编译器处理泛型 Code specialization Code sharing 3.3 泛型擦除 3.4 先检查，再编译 3.5 泛型类型自动转换 3.6 类型擦除和多态冲突，JVM解决方法 4 附件 1 extend（上限）上限用extends关键字声明，表示参数化的类型可能是所指定的类型，或者是此类型的子类。1234567public void upperBound(List&lt;? extends Date&gt; list, Date date) { Date now = list.get(0); System.out.println(\"now==&gt;\" + now); //list.add(date); //这句话无法编译 list.add(null);//这句可以编译，因为null没有类型信息 } 为什么会无法编译呢，实际调用时传入的list可能是java.util.Date的某个子类的参数化类型。123456public void testUpperBound() { List&lt;Timestamp&gt; list = new ArrayList&lt;Timestamp&gt;(); Date date = new Date(); upperBound(list,date); } 也就是说，现在upperBound方法中实际的list是List&lt;Timestamp&gt;，向它添加一个Date类型，肯定是不行的。相反，读取数据时，不管实际的list是什么类型，但可以知道它至少会返回一个Date类型，所以用foreach，get等没有问题。可以使用泛型方法。1234public &lt;T extends Date&gt; void upperBound2(List&lt;T&gt; list, T date) //泛型的方法，需要泛型标识{ list.add(date); } 这里方法声明中的T作为一种泛型参数化信息，会存储在java字节码中，T的实际类型由调用时的参数决定的。12345678public void testUpperBound2() { List&lt;Timestamp&gt; list = new ArrayList&lt;Timestamp&gt;(); Date date = new Date(); Timestamp time = new Timestamp(date.getTime()); upperBound2(list,time); //T的类型：Timestamp，list添加Timestamp是没有问题的 //upperBound2(list,date);//这句同样无法编译 } 上面代码中的list的类型参数决定了方法中T的类型，所以会看到注释掉的内容不能编译。而换成下面代码，编译就没有任何问题了。12List&lt;Date&gt; list2 = new ArrayList&lt;Date&gt;();upperBound2(list2,date); 2 super下限用super进行声明，表示参数化的类型可能是所指定的类型，或者是此类型的父类型，直至Object。如下面的代码。123456public void lowerBound(List&lt;? super Timestamp&gt; list) { Timestamp now = new Timestamp(System.currentTimeMillis()); list.add(now); //Timestamp time = list.get(0); //不能编译 } 这又为什么不能通过编译呢，看看调用代码。123456public void testLowerBound() { List&lt;Date&gt; list = new ArrayList&lt;Date&gt;(); list.add(new Date()); lowerBound(list); } lowerBound方法中的List&lt;? super Timestamp&gt;表示这个list的参数类型可能是Timestamp或Timestamp的父类。测试代码里，实际传入的是一个List&lt;Date&gt;类型。向List&lt;Date&gt;中add一个Timestamp肯定是没有问题的，但list.get()方法返回的对象类型可能是Date甚至是Object，你不能说list.get(0)返回的就是一个Timestamp，这里是向下类型转换了，编译器无法处理，所以这里不能编译。用Java泛型实现的擦拭法解释，编译后会是如下的伪代码。123456789101112public void lowerBound(List list) { Timestamp now = new Timestamp(System.currentTimeMillis()); list.add(now); Timestamp time = (Timestamp)list.get(0); //1 } public void testLowerBound() { List list = new ArrayList(); list.add(new Date()); lowerBound(list); } 代码1进行了强制类型转换，但实际添加进去的是一个Date类型，肯定会报ClassCastException，编译器无法保证向下类型转换的安全，所以这一句自然就无法编译了。 多态特性 子类转父类：自动类型转换 父类转子类：编译器不能保证转换安全性，首先向上转型，然后在向下转型。3 泛型擦除3.1 概述Java泛型的处理在编译器中进行，编译器生成的字节码是不包涵泛型信息的，泛型类型信息将在编译处理是被擦除，这个过程即类型擦除。 虚拟机中没有泛型，只有普通类和普通方法。Java中将泛型类型转换为普通方法，并被转换成字节。 泛型类的类型参数在编译时都会被擦除。泛型类被转换成泛型类型的最高父类，然后移除泛型类型。最高父类：其限定类型，无限定的变量用Object，限定类型包括：上限、下限 创建泛型对象时请指明类型，让编译器尽早的做参数检查（Effective Java，第23条：请不要在新代码中使用原生态类型）3.2 编译器处理泛型C++的编译器使用Code Specialization的方式；而Java的编译器在处理泛型时采用的是Code Sharing的方式。Code specialization在实例化一个泛型类或泛型方法时都产生一份新的目标代码（字节码或者二进制代码）。例如，针对一个泛型List，可能需要针对String，Integer，Float产生三份目标代码。Code sharing对每个泛型类只生成唯一的一份目标代码，该泛型类的所有实例都映射到这份目标代码上，在需要的时候执行类型检查和类型转换。Code specialization另外一个弊端是在引用类型系统中，浪费空间，因为引用类型集合中元素本质上都是一个指针。没必要为每个类型都产生一份执行代码。而这也是Java编译器中采用Code sharing方式处理泛型的主要原因。Java编译器通过Code sharing方式为每个泛型类型创建唯一的字节码表示，并且将该泛型类型的实例都映射到这个唯一的字节码表示上。将多种泛型类形实例映射到唯一的字节码表示是通过类型擦除（type erasue）实现的。3.3 泛型擦除Java的泛型是伪泛型。在编译期间，所有的泛型信息都会被擦除掉。Java中的泛型基本上都是在编译器这个层次来实现的。在生成的Java字节码中是不包含泛型中的类型信息的。使用泛型的时候加上的类型参数，会在编译器在编译的时候去掉。这个过程就称为类型擦除。1234567public static void main(String[] args) { ArrayList&lt;String&gt; arrayList1 = new ArrayList&lt;String&gt;(); arrayList1.add(\"abc\"); ArrayList&lt;Integer&gt; arrayList2 = new ArrayList&lt;Integer&gt;(); arrayList2.add(123); System.out.println(arrayList1.getClass() == arrayList2.getClass());} 1true 说明泛型类型String和Integer都被擦除掉了，只剩下了原始类型。原始类型（raw type）就是擦除去了泛型信息，最后在字节码中的类型变量的真正类型。无论何时定义一个泛型类型，相应的原始类型都会被自动地提供。类型变量被擦除（crased），使用其限定类型替换。 3.4 先检查，再编译类型变量会在编译的时候擦除掉，那为什么往ArrayList&lt;String&gt; arrayList=new ArrayList&lt;String&gt;();所创建的数组列表arrayList中，不能使用add()添加整形呢？不是说泛型变量Integer会在编译时候擦除变为原始类型Object吗，为什么不能存别的类型呢？既然类型擦除了，如何保证只能使用泛型变量限定的类型呢？Java是如何解决这个问题的呢？Java编译器是通过先检查代码中泛型的类型，然后再进行类型擦除，在进行编译的。 3.5 泛型类型自动转换因为类型擦除的问题，所以所有的泛型类型变量最后都会被替换为原始类型。这样就引起了一个问题，既然都被替换为原始类型，那List.get()数据的时候，不需要进行强制类型转换呢？看下ArrayList和get()。1234public E get(int index) { RangeCheck(index); return (E) elementData[index]; } 12345678public class Tes { public static void main(String[] args) { ArrayList&lt;Date&gt; list = new ArrayList&lt;Date&gt;(); list.add(new Date()); Date myDate = list.get(0); }} Javap -verbose Tes123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107D:\\&gt;javap -verbose TesClassfile /D:/Tes.class Last modified 2016-12-8; size 692 bytes MD5 checksum b74df56b94251dc7e4e1b3c3cebab208 Compiled from \"Tes.java\"public class Tes minor version: 0 major version: 52 flags: ACC_PUBLIC, ACC_SUPERConstant pool: #1 = Class #2 // Tes #2 = Utf8 Tes #3 = Class #4 // java/lang/Object #4 = Utf8 java/lang/Object #5 = Utf8 &lt;init&gt; #6 = Utf8 ()V #7 = Utf8 Code #8 = Methodref #3.#9 // java/lang/Object.\"&lt;init&gt;\":()V #9 = NameAndType #5:#6 // \"&lt;init&gt;\":()V #10 = Utf8 LineNumberTable #11 = Utf8 LocalVariableTable #12 = Utf8 this #13 = Utf8 LTes; #14 = Utf8 main #15 = Utf8 ([Ljava/lang/String;)V #16 = Class #17 // java/util/ArrayList #17 = Utf8 java/util/ArrayList #18 = Methodref #16.#9 // java/util/ArrayList.\"&lt;init&gt;\":()V #19 = Class #20 // java/util/Date #20 = Utf8 java/util/Date #21 = Methodref #19.#9 // java/util/Date.\"&lt;init&gt;\":()V #22 = Methodref #16.#23 // java/util/ArrayList.add:(Ljava/lang/Object;)Z #23 = NameAndType #24:#25 // add:(Ljava/lang/Object;)Z #24 = Utf8 add #25 = Utf8 (Ljava/lang/Object;)Z #26 = Methodref #16.#27 // java/util/ArrayList.get:(I)Ljava/lang/Object; #27 = NameAndType #28:#29 // get:(I)Ljava/lang/Object; #28 = Utf8 get #29 = Utf8 (I)Ljava/lang/Object; #30 = Utf8 args #31 = Utf8 [Ljava/lang/String; #32 = Utf8 list #33 = Utf8 Ljava/util/ArrayList; #34 = Utf8 myDate #35 = Utf8 Ljava/util/Date; #36 = Utf8 LocalVariableTypeTable #37 = Utf8 Ljava/util/ArrayList&lt;Ljava/util/Date;&gt;; #38 = Utf8 SourceFile #39 = Utf8 Tes.java{ public Tes(); descriptor: ()V flags: ACC_PUBLIC Code: stack=1, locals=1, args_size=1 0: aload_0 1: invokespecial #8 // Method java/lang/Object.\"&lt;init&gt;\":()V 4: return LineNumberTable: line 4: 0 LocalVariableTable: Start Length Slot Name Signature 0 5 0 this LTes; public static void main(java.lang.String[]); descriptor: ([Ljava/lang/String;)V flags: ACC_PUBLIC, ACC_STATIC Code: stack=3, locals=3, args_size=1 0: new #16 // class java/util/ArrayList 3: dup 4: invokespecial #18 // Method java/util/ArrayList.\"&lt;init&gt;\":()V 7: astore_1 8: aload_1 9: new #19 // class java/util/Date 12: dup 13: invokespecial #21 // Method java/util/Date.\"&lt;init&gt;\":()V 16: invokevirtual #22 // Method java/util/ArrayList.add:(Ljava/lang/Object;)Z 19: pop 20: aload_1 21: iconst_0 22: invokevirtual #26 // Method java/util/ArrayList.get:(I)Ljava/lang/Object; 25: checkcast #19 // class java/util/Date 28: astore_2 29: return LineNumberTable: line 7: 0 line 8: 8 line 9: 20 line 10: 29 LocalVariableTable: Start Length Slot Name Signature 0 30 0 args [Ljava/lang/String; 8 22 1 list Ljava/util/ArrayList; 29 1 2 myDate Ljava/util/Date; LocalVariableTypeTable: Start Length Slot Name Signature 8 22 1 list Ljava/util/ArrayList&lt;Ljava/util/Date;&gt;;}SourceFile: \"Tes.java\" 第22 ，它调用的是ArrayList#get()，方法返回值是Object，说明类型擦除了。 第25，它做了一个checkcast操作，即检查类型#19， 找#19引用的类型，9: new #19 // class java/util/Date是一个Date类型，即做Date类型的强转。所以不是在get()里强转的，是在调用的地方强转的。1return (E) elementData[index]; 3.6 类型擦除和多态冲突，JVM解决方法123456789class Pair&lt;T&gt; { private T value; public T getValue() { return value; } public void setValue(T value) { this.value = value; } } 123456789101112import java.util.Date;class DateInter extends Pair&lt;Date&gt; { @Override public void setValue(Date value) { super.setValue(value); } @Override public Date getValue() { return super.getValue(); } } 查询Pair编译字节码1234567891011121314151617181920212223D:\\&gt;javap -c PairCompiled from \"Pair.java\"class Pair&lt;T&gt; { Pair(); Code: 0: aload_0 1: invokespecial #12 // Method java/lang/Object.\"&lt;init&gt;\":()V 4: return public T getValue(); Code: 0: aload_0 1: getfield #23 // Field value:Ljava/lang/Object; 4: areturn public void setValue(T); Code: 0: aload_0 1: aload_1 2: putfield #23 // Field value:Ljava/lang/Object; 5: return} 查询DateInter编译字节码1234567891011121314151617181920212223242526272829303132333435363738394041D:\\&gt;javap -c DateInterCompiled from \"DateInter.java\"class DateInter extends Pair&lt;java.util.Date&gt; { DateInter(); Code: 0: aload_0 1: invokespecial #8 // Method Pair.\"&lt;init&gt;\":()V 4: return public void setValue(java.util.Date); Code: 0: aload_0 1: aload_1 2: invokespecial #16 // Method Pair.setValue:(Ljava/lang/Object;)V 5: return public java.util.Date getValue(); Code: 0: aload_0 1: invokespecial #23 // Method Pair.getValue:()Ljava/lang/Object; 4: checkcast #26 // class java/util/Date 7: areturn public java.lang.Object getValue(); Code: 0: aload_0 1: invokevirtual #28 // Method getValue:()Ljava/util/Date; 4: areturn public void setValue(java.lang.Object); Code: 0: aload_0 1: aload_1 2: checkcast #26 // class java/util/Date 5: invokevirtual #30 // Method setValue:(Ljava/util/Date;)V 8: return} 查询DateInter字节码，有2个get()和2个set()， setValue(java.lang.Object)和Object getValue()是JVM生成的桥接方法，桥接方法的类型都是Object，DateInter覆盖Pair两个方法的就是这两个看不到的桥方法，在DateInter中定义的setvalue和getValue方法上面的@Oveerride只不过是假象，桥方法的内部实现去调用DateInter覆写的那两个方法。虚拟机巧妙的使用了巧方法，来解决了类型擦除和多态的冲突。Object#getValue()和Date#getValue()是同时存在的，可是如果是常规的两个方法，方法签名是一样的，也就是说虚拟机根本不能分别这两个方法。这样的代码是无法通过编译器的检查的，但是虚拟机却是允许这样做的，因为虚拟机通过参数类型和返回类型来确定一个方法，所以编译器为了实现泛型的多态允许自己做这个看起来“不合法”的事情，然后交给虚拟器去区别。 4 附件DateInter.classPair.classPair_2.classPair_3.classTes.class","link":"/Java-Type/"},{"title":"JDK1.6 ConcurrentHashMap","text":"1 简介 2 源码分析 ConcurrentMap#putIfAbsent() ConcurrentMap#remove() ConcurrentMap#replace(K key, V oldValue, V newValue) ConcurrentMap#replace(K key, V value) ConcurrentHashMap属性 ConcurrentHashMap#Segment&lt;K,V&gt; ConcurrentHashMap#Segment&lt;K,V&gt;属性 ConcurrentHashMap#Segment&lt;K,V&gt;构造 ConcurrentHashMap#Segment&lt;K,V&gt;#setTable ConcurrentHashMap#HashEntry ConcurrentHashMap#Constants ConcurrentHashMap构造方法 ConcurrentHashMap#put() ConcurrentHashMap#hash() ConcurrentHashMap#segmentFor() ConcurrentHashMap#Segment#put() ConcurrentHashMap#Segment#rehash() ConcurrentHashMap#get() ConcurrentHashMap#Segment#get() ConcurrentHashMap#Segment#getFirst() ConcurrentHashMap#Segment#readValueUnderLock() ConcurrentHashMap#Segment#remove() ConcurrentHashMap#size() 3 总结 count lock() 1 简介ConcurrentHashMap是一种线程安全的HashMap。相对于HashTable和Collections.synchronizedMap()，ConcurrentHashMap具有更好的性能和伸缩性，是由于其使用了分段锁的策略，将内部数据分为多个段，每个段单独加锁，而不是整个HashMap加锁，这样能减少很多不必要的锁争用。 2 源码分析类结构图 ConcurrentMap#putIfAbsent()1234567891011121314/** * If the specified key is not already associated * with a value, associate it with the given value. * This is equivalent to * &lt;pre&gt; * if (!map.containsKey(key)) * return map.put(key, value); * else * return map.get(key);&lt;/pre&gt; * except that the action is performed atomically. * ... * ... */ V putIfAbsent(K key, V value); 如果map中已经存在给定的key，返回map中key对应的value；如果不存在给定的key，插入给定的key和value。这个是一个原子操作，逻辑相当于如下代码。1234if (!map.containsKey(key)) return map.put(key, value); else return map.get(key); ConcurrentMap#remove()12345678910111213/** * Removes the entry for a key only if currently mapped to a given value. * This is equivalent to * &lt;pre&gt; * if (map.containsKey(key) &amp;amp;&amp;amp; map.get(key).equals(value)) { * map.remove(key); * return true; * } else return false;&lt;/pre&gt; * except that the action is performed atomically. * ... * ... */boolean remove(Object key, Object value); 如果map中存在给定的key，并且map中对应的value等于给定的value，那么删除这个key和value。这是一个原子操作，逻辑相当于如下代码。1234if (map.containsKey(key) &amp;&amp; map.get(key).equals(value)) { map.remove(key); return true; } else return false; ConcurrentMap#replace(K key, V oldValue, V newValue)12345678910111213/** * Replaces the entry for a key only if currently mapped to a given value. * This is equivalent to * &lt;pre&gt; * if (map.containsKey(key) &amp;amp;&amp;amp; map.get(key).equals(oldValue)) { * map.put(key, newValue); * return true; * } else return false;&lt;/pre&gt; * except that the action is performed atomically. * ... * ... */ boolean replace(K key, V oldValue, V newValue); 如果map中存在给定的key，并且map中对应的value也等于给定的oldValue，那么将这个key对应的value替换成newValue。这是一个原子操作，逻辑相当于如下代码。1234if (map.containsKey(key) &amp;amp;&amp;amp; map.get(key).equals(oldValue)) { map.put(key, newValue); return true;} else return false; ConcurrentMap#replace(K key, V value)123456789101112/** * Replaces the entry for a key only if currently mapped to some value. * This is equivalent to * &lt;pre&gt; * if (map.containsKey(key)) { * return map.put(key, value); * } else return null;&lt;/pre&gt; * except that the action is performed atomically. * ... * ... */ V replace(K key, V value); 如果map中已经存在给定的key，那么将这个key对应的value替换成给定的value。这是一个原子操作，逻辑相当于如下代码。123if (map.containsKey(key)) { return map.put(key, value);} else return null; ConcurrentHashMap属性12345678910111213141516171819202122/** * Mask value for indexing into segments. The upper bits of a * key's hash code are used to choose the segment. */// 1final int segmentMask;/** * Shift value for indexing within segments. */// 2final int segmentShift;/** * The segments, each of which is a specialized hash table */// 3final Segment&lt;K,V&gt;[] segments;transient Set&lt;K&gt; keySet;transient Set&lt;Map.Entry&lt;K,V&gt;&gt; entrySet;transient Collection&lt;V&gt; values; 标注代码分析 用于key的hash code计算，在segment数组中选择合适的segment。 segment#hash索引的偏移量。 segment是一个特殊的hash table。 ConcurrentHashMap#Segment&lt;K,V&gt;Segment结构图 ConcurrentHashMap#Segment&lt;K,V&gt;属性1234567891011121314151617181920212223242526272829303132333435363738/** * The number of elements in this segment's region. */// 1transient volatile int count;/** * Number of updates that alter the size of the table. This is * used during bulk-read methods to make sure they see a * consistent snapshot: If modCounts change during a traversal * of segments computing size or checking containsValue, then * we might have an inconsistent view of state so (usually) * must retry. */// 2transient int modCount;/** * The table is rehashed when its size exceeds this threshold. * (The value of this field is always &lt;tt&gt;(int)(capacity * * loadFactor)&lt;/tt&gt;.) */// 3transient int threshold;/** * The per-segment table. */transient volatile HashEntry&lt;K,V&gt;[] table;/** * The load factor for the hash table. Even though this value * is same for all segments, it is replicated to avoid needing * links to outer object. * @serial */// 4final float loadFactor; 标注代码分析 记录segment中的元素数量。其他操作会利用count的volatile读写来保证可见性，避免使用锁。 统计跟踪修改，用来保证一些批量操作的一致性。如果modCount计算siez()或检查value的遍历过程中发生变化，那么可能会有一个不一致的状态，必须重新检测状态。 当哈希表的容量超过这个阀值会扩容，里面的元素会重新散列。 capacity * loadFactor 哈希表的加载因子。 ConcurrentHashMap#Segment&lt;K,V&gt;构造1234Segment(int initialCapacity, float lf) { loadFactor = lf; setTable(HashEntry.&lt;K,V&gt;newArray(initialCapacity)); } 初始化加载因子，初始化HashEntry数组，数组容量为initialCapacity。哈希表内部一般会有初始容量size和加载因子loadFactor，当哈希表中的元素数量达到(size * loadFactor)的时候，就会触发哈希表进行rehash()。假设哈希表使用链表法来解决哈希冲突，那么如果加载因子太大，会导致哈希表中每个桶里面的链表平均长度过长，这样会影响查询性能；但如果加载因子过小，又会浪费太多内存空间。时间和空间的权衡，需要按实际情况来选择合适的加载因子。 ConcurrentHashMap#Segment&lt;K,V&gt;#setTable12345678/** * Sets table to new HashEntry array. * Call only while holding lock or in constructor. */ void setTable(HashEntry&lt;K,V&gt;[] newTable) { threshold = (int)(newTable.length * loadFactor); table = newTable; } 初始化threshold、HashEntry&lt;K,V&gt;[] table。 ConcurrentHashMap#HashEntry123456789101112131415161718static final class HashEntry&lt;K,V&gt; { final K key; final int hash; volatile V value; final HashEntry&lt;K,V&gt; next; HashEntry(K key, int hash, HashEntry&lt;K,V&gt; next, V value) { this.key = key; this.hash = hash; this.next = next; this.value = value; }@SuppressWarnings(\"unchecked\")static final &lt;K,V&gt; HashEntry&lt;K,V&gt;[] newArray(int i) { return new HashEntry[i];} } HashEntry#newArray()生成HashEntry数组，数组容量是i。volatile V value是volatile根据Java Menory Mode的Happen-Before保证可见性。 ConcurrentHashMap#Constants123456789101112131415161718192021222324252627282930313233343536373839404142434445/** * The default initial capacity for this table, * used when not otherwise specified in a constructor. */ // 1 static final int DEFAULT_INITIAL_CAPACITY = 16; /** * The default load factor for this table, used when not * otherwise specified in a constructor. */ // 2 static final float DEFAULT_LOAD_FACTOR = 0.75f; /** * The default concurrency level for this table, used when not * otherwise specified in a constructor. */ // 3 static final int DEFAULT_CONCURRENCY_LEVEL = 16; /** * The maximum capacity, used if a higher value is implicitly * specified by either of the constructors with arguments. MUST * be a power of two &lt;= 1&lt;&lt;30 to ensure that entries are indexable * using ints. */ // 4 static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30; /** * The maximum number of segments to allow; used to bound * constructor arguments. */ // 5 static final int MAX_SEGMENTS = 1 &lt;&lt; 16; // slightly conservative /** * Number of unsynchronized retries in size and containsValue * methods before resorting to locking. This is used to avoid * unbounded retries if tables undergo continuous modification * which would make it impossible to obtain an accurate result. */ // 6 static final int RETRIES_BEFORE_LOCK = 2; 标注代码分析 默认capacity值，segment中hashTable长度。 默认加载因子。 默认Segment#table的并发级别，影响Segment#table容量。 Segment#table的最大容量。 允许的最大的Segment#table容量。 在size()和containsValue()，加锁之前的尝试操作次数。 ConcurrentHashMap构造方法123456789101112131415161718192021222324252627282930313233public ConcurrentHashMap(int initialCapacity, float loadFactor, int concurrencyLevel) { if (!(loadFactor &gt; 0) || initialCapacity &lt; 0 || concurrencyLevel &lt;= 0) throw new IllegalArgumentException(); if (concurrencyLevel &gt; MAX_SEGMENTS) concurrencyLevel = MAX_SEGMENTS; // Find power-of-two sizes best matching arguments int sshift = 0; int ssize = 1; while (ssize &lt; concurrencyLevel) { ++sshift; // 1 ssize &lt;&lt;= 1; } segmentShift = 32 - sshift; segmentMask = ssize - 1; this.segments = Segment.newArray(ssize); if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; int c = initialCapacity / ssize; if (c * ssize &lt; initialCapacity) ++c; int cap = 1; // 2 while (cap &lt; c) cap &lt;&lt;= 1; //3 for (int i = 0; i &lt; this.segments.length; ++i) this.segments[i] = new Segment&lt;K,V&gt;(cap, loadFactor); } 标注代码分析 ssize最后是比concurrencyLevel大的最小的2的幂。如果concurrencyLevel是50，那么ssize是64，segmentShift是26，segmentMask是 00000000 00000000 00000000 00111111。 cap是比总体容量平均分到每个segment的数量大的最小的2的幂。 初始化segments[]。 ConcurrentMap内部包含一个segment的数组；而segment本身又是一个哈希表(HashEntry&lt;K,V&gt;[] table)，并且自带锁(继承ReentrantLock)；内部哈希表使用链表法解决哈希冲突，每个数组元素是一个单链表(HashEntry)。 ConcurrentHashMap#put()12345678public V put(K key, V value) { if (value == null) throw new NullPointerException(); // 1 int hash = hash(key.hashCode()); // 2 return segmentFor(hash).put(key, hash, value, false);} 标注代码分析 重新计算hash值，根据hash值确认segment。 执行segment#put。 ConcurrentHashMap#hash()12345678910private static int hash(int h) { // Spread bits to regularize both segment and index locations, // using variant of single-word Wang/Jenkins hash. h += (h &lt;&lt; 15) ^ 0xffffcd7d; h ^= (h &gt;&gt;&gt; 10); h += (h &lt;&lt; 3); h ^= (h &gt;&gt;&gt; 6); h += (h &lt;&lt; 2) + (h &lt;&lt; 14); return h ^ (h &gt;&gt;&gt; 16); } key#hashCode再次hash一次，使得hash值更加散列。因为ConcurrentHashMap中哈希表的长度都是2的幂，会增加一些冲突几率，比如两个hashCode高位不同但低位相同，对哈希表长度取模时正好忽略了这些高位，造成冲突。这里是采用了Wang/Jenkins哈希算法的一个变种。 ConcurrentHashMap#segmentFor()12345678/** * Returns the segment that should be used for key with given hash * @param hash the hash code for the key * @return the segment */ final Segment&lt;K,V&gt; segmentFor(int hash) { return segments[(hash &gt;&gt;&gt; segmentShift) &amp; segmentMask]; } &amp; segmentMask除去高位确定segments下标。 ConcurrentHashMap#Segment#put()123456789101112131415161718192021222324252627282930313233343536373839V put(K key, int hash, V value, boolean onlyIfAbsent) { // 1 lock(); try { int c = count; // 2 if (c++ &gt; threshold) // ensure capacity rehash(); HashEntry&lt;K,V&gt;[] tab = table; // 3 int index = hash &amp; (tab.length - 1); HashEntry&lt;K,V&gt; first = tab[index]; HashEntry&lt;K,V&gt; e = first; // 4 while (e != null &amp;&amp; (e.hash != hash || !key.equals(e.key))) e = e.next; V oldValue; // 5 if (e != null) { oldValue = e.value; if (!onlyIfAbsent) e.value = value; } else { oldValue = null; // 6 ++modCount; // 7 tab[index] = new HashEntry&lt;K,V&gt;(key, hash, first, value); // 8 count = c; // write-volatile } return oldValue; } finally { // 9 unlock(); } } 标注代码分析 Segment继承ReentrantLock，put()加锁。锁是Segment对象上。 超过扩容阀值，那么进行rehash()，扩容。 hash &amp; (tab.length - 1)取模高效一种方式。获取链表HashEntry下标。 遍历链表，判断key是否相同，找到系统的key，结束循环或者e = null。 链表HashEntry#key与key相同，判断是否覆盖旧value。 没有找到链表HashEntry#key与key相同，则新增一个节点，modCount作为ConcurrentHashMap#size()、ConcurrentHashMap#isEmpty()、、ConcurrentHashMap#containsValue()重新检测segments数组状态。 在HashEntry[index]上HashEntry新建1个节点。 操作执行成功，保证volatile的写可见性。 解锁。 ConcurrentHashMap#Segment#rehash()1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253void rehash() { HashEntry&lt;K,V&gt;[] oldTable = table; int oldCapacity = oldTable.length; if (oldCapacity &gt;= MAXIMUM_CAPACITY) return; HashEntry&lt;K,V&gt;[] newTable = HashEntry.newArray(oldCapacity&lt;&lt;1); threshold = (int)(newTable.length * loadFactor); int sizeMask = newTable.length - 1; for (int i = 0; i &lt; oldCapacity ; i++) { // We need to guarantee that any existing reads of old Map can // proceed. So we cannot yet null out each bin. HashEntry&lt;K,V&gt; e = oldTable[i]; // 1 if (e != null) { HashEntry&lt;K,V&gt; next = e.next; int idx = e.hash &amp; sizeMask; // Single node on list // 2 if (next == null) newTable[idx] = e; else { // Reuse trailing consecutive sequence at same slot // 3 HashEntry&lt;K,V&gt; lastRun = e; int lastIdx = idx; // 4 for (HashEntry&lt;K,V&gt; last = next; last != null; last = last.next) { int k = last.hash &amp; sizeMask; if (k != lastIdx) { lastIdx = k; lastRun = last; } } // 5 newTable[lastIdx] = lastRun; // 6 // Clone all remaining nodes for (HashEntry&lt;K,V&gt; p = e; p != lastRun; p = p.next) { int k = p.hash &amp; sizeMask; HashEntry&lt;K,V&gt; n = newTable[k]; newTable[k] = new HashEntry&lt;K,V&gt;(p.key, p.hash, n, p.value); } } } } table = newTable; } 标注代码分析 获取Segment#table的HashEntry&lt;K,V&gt;对象，对象不存在，直接返回newTable。 e#next对象是否存在，如果不存在，赋值当前e对象到newTable新位置。newTable新位置下标是根据e.hash &amp; sizeMask计算出来。 HashEntry e#next存在，假设当前e和e的下标作为newTable的最后一个链表HashEntry对象。 for循环寻找节点e#next的后续节点，寻找最后1个HashEntry对象以及下标。 确定newTable数组下标边界，且赋值最后1个newTable数组对象HashEntry。 从e对象循环查询到最后1个对象last，从而克隆原table数据到newTable。 ConcurrentHashMap#get()1234public V get(Object key) { int hash = hash(key.hashCode()); return segmentFor(hash).get(key, hash); } ConcurrentHashMap#Segment#get()123456789101112131415161718192021V get(Object key, int hash) { // 1 if (count != 0) { // read-volatile // 2 HashEntry&lt;K,V&gt; e = getFirst(hash); while (e != null) { // 3 if (e.hash == hash &amp;&amp; key.equals(e.key)) { V v = e.value; if (v != null) return v; return // 4 readValueUnderLock(e); // recheck } // 5 e = e.next; } } return null; } 标注代码分析 volatile的读可见性。 根据hash获取正确的链表HashEntry对象e。 判断当前e#hash和e#key是否一致。一致则返回e#value。 读取操作加锁，e#value=null有可能是在Segment#table的HashEntry初始化时候发生。 如果e不匹配，寻找e#next。 ConcurrentHashMap#Segment#getFirst()1234567/** * Returns properly casted first entry of bin for given hash. */ HashEntry&lt;K,V&gt; getFirst(int hash) { HashEntry&lt;K,V&gt;[] tab = table; return tab[hash &amp; (tab.length - 1)]; } 返回Segment#table数组HashEntry对象。 ConcurrentHashMap#Segment#readValueUnderLock()123456789101112131415/** * Reads value field of an entry under lock. Called if value * field ever appears to be null. This is possible only if a * compiler happens to reorder a HashEntry initialization with * its table assignment, which is legal under memory model * but is not known to ever occur. */ V readValueUnderLock(HashEntry&lt;K,V&gt; e) { lock(); try { return e.value; } finally { unlock(); } } 根据注释可以理解，e#value是null，可能发生在HashEntry初始化阶段。 ConcurrentHashMap#Segment#remove()1234567891011121314151617181920212223242526272829303132333435V remove(Object key, int hash, Object value) { lock(); try { int c = count - 1; HashEntry&lt;K,V&gt;[] tab = table; int index = hash &amp; (tab.length - 1); HashEntry&lt;K,V&gt; first = tab[index]; HashEntry&lt;K,V&gt; e = first; while (e != null &amp;&amp; (e.hash != hash || !key.equals(e.key))) e = e.next; V oldValue = null; if (e != null) { V v = e.value; if (value == null || value.equals(v)) { oldValue = v; // All entries following removed node can stay // in list, but all preceding ones need to be // cloned. ++modCount; // 1 HashEntry&lt;K,V&gt; newFirst = e.next; for (HashEntry&lt;K,V&gt; p = first; p != e; p = p.next) newFirst = new HashEntry&lt;K,V&gt;(p.key, p.hash, newFirst, p.value); // 2 tab[index] = newFirst; count = c; // write-volatile } } return oldValue; } finally { unlock(); } } 123456情况1first(e) e#next p newfirst情况2first ... e1(e) e1#next p newfirst 标注代码分析 分为2种情况。情况1，while循环第1次就判断e正确，e=first，且e=frist=p，不执行for循环。e#index替换e原来的位置tab[index]。情况2，while循环第1次未找到正确e，e=e#next之后e!=first，如代码图e的新位置是e1，p=first，p!=e1，新建HashEntry对象，key、value、hash都是p，但是next是e1#nextp!=e1,就循环的把p-e1之间差额，新建HashEntry，同时把next指向e1#next。直到p=e1时候退出循环，这时候newFirst是e1的上一个节点。替换e1的位置也就是index。 e上一个节点HashEntry替换e在tab的位置index。 ConcurrentHashMap#size()123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354/** * Returns the number of key-value mappings in this map. If the * map contains more than &lt;tt&gt;Integer.MAX_VALUE&lt;/tt&gt; elements, returns * &lt;tt&gt;Integer.MAX_VALUE&lt;/tt&gt;. * * @return the number of key-value mappings in this map */ public int size() { final Segment&lt;K,V&gt;[] segments = this.segments; // 1 long sum = 0; long check = 0; int[] mc = new int[segments.length]; // Try a few times to get accurate count. On failure due to // continuous async changes in table, resort to locking. // 2 for (int k = 0; k &lt; RETRIES_BEFORE_LOCK; ++k) { check = 0; sum = 0; int mcsum = 0; // 3 for (int i = 0; i &lt; segments.length; ++i) { sum += segments[i].count; mcsum += mc[i] = segments[i].modCount; } // 4 if (mcsum != 0) { for (int i = 0; i &lt; segments.length; ++i) { check += segments[i].count; if (mc[i] != segments[i].modCount) { check = -1; // force retry break; } } } // 5 if (check == sum) break; } // 6 if (check != sum) { // Resort to locking all segments sum = 0; for (int i = 0; i &lt; segments.length; ++i) segments[i].lock(); for (int i = 0; i &lt; segments.length; ++i) sum += segments[i].count; for (int i = 0; i &lt; segments.length; ++i) segments[i].unlock(); } if (sum &gt; Integer.MAX_VALUE) return Integer.MAX_VALUE; else return (int)sum; } 标注代码分析 sum是所有segment#HashEntry#count总和。check是segment#HashEntry有变化时候的count总和。mc是segment#HashEntry变化数字。 执行2次无锁检查。新建mcsum属性，segment#HashEntry变化数字总和。 循环segment数组，计算sum、mcsum、mc。 如果mcsum!=0，说明有segment#HashEntry数据变化，计算check。如果mc[]!=segment[]#modcount，segment#HashEntry数据又变化(modCount在ConcurrentHashMap#put()、ConcurrentHashMap#remove()、ConcurrentHashMap#clear()才会发生变化)，结束本次for循环，再执行for循环后面计算无意义。 如果2次计算count一致，那么数量就一致，返回count。 2次无锁统计count不一致，segment[]每个HashEntry对象都加锁，执行count统计。3 总结count All (synchronized) write operations should write to the “count” field after structurally changing any bin. bin是HashEntry，HashEntry结构发生变化(添加或者删除)，才会写count，保证count可见性。HashEntry属性中value是volatile，所以本身就保证可见性。覆盖value(、ConcurrentHashMap#replace())时候，不需要重写count。 lock()锁粒度在segment[]的HashEntry上，所以可以保证segment可以并发操作。","link":"/JDK1.6-ConcurrentHashMap/"},{"title":"Java软引用、弱引用和虚引用","text":"1 介绍 1.1 强引用（StrongReference） 1.2 软引用（SoftReference） 1.3 弱引用（WeakReference） 1.4 虚引用（PhantomReference） 1.5 垃圾回收 1.5.1 例子1 1.5.2 例子2 1.5.3 综合例子1和例子2 1.6 对象再生和引用队列问题 2 示例 2.1 示例 2.2 2.3 2.4 2.5 2.2 软引用 2.3 软引用实现缓存 2.4 弱引用 1 介绍在JDK 1.2以前的版本中，若一个对象不被任何变量引用，那么程序就无法再使用这个对象。也就是说，只有对象处于可触及（reachable）状态，程序才能使用它。从JDK 1.2版本开始，把对象的引用分为4种级别，从而使程序能更加灵活地控制对象的生命周期。这4种级别由高到低依次为：强引用、软引用、弱引用和虚引用。 1.1 强引用（StrongReference）强引用是使用最普遍的引用。如果一个对象具有强引用，那垃圾回收器绝不会回收它。当内存空间不足，Java虚拟机宁愿抛出OutOfMemoryError错误，使程序异常终止，也不会靠随意回收具有强引用的对象来解决内存不足的问题。 1.2 软引用（SoftReference）如果一个对象只具有软引用，则内存空间足够，垃圾回收器就不会回收它；如果内存空间不足，就会回收这些对象的内存。只要垃圾回收器没有回收它，该对象就可以被程序使用。软引用可用来实现内存敏感的高速缓存。软引用可以和一个引用队列（ReferenceQueue）联合使用，如果软引用所引用的对象被垃圾回收器回收，Java虚拟机就会把这个软引用加入到与之关联的引用队列（ReferenceQueue）中。软引用是在垃圾回收之后，才加入队列。 1.3 弱引用（WeakReference）弱引用与软引用的区别在于：只具有弱引用的对象拥有更短暂的生命周期。在垃圾回收器线程扫描它所管辖的内存区域的过程中，一旦发现只具有弱引用的对象，不管当前内存空间足够与否都会回收它的内存。不过，由于垃圾回收器是一个优先级很低的线程，因此不一定会很快发现那些只具有弱引用的对象。弱引用可以和一个引用队列（ReferenceQueue）联合使用，如果弱引用所引用的对象被垃圾回收，Java虚拟机就会把这个弱引用加入到与之关联的引用队列（ReferenceQueue）中。弱引用是在垃圾回收之后，才加入队列。 1.4 虚引用（PhantomReference）“虚引用”顾名思义，就是形同虚设，与其他几种引用都不同，虚引用并不会决定对象的生命周期。如果一个对象仅持有虚引用，那么它就和没有任何引用一样，在任何时候都可能被垃圾回收器回收。虚引用主要用来跟踪对象被垃圾回收器回收的活动。虚引用与软引用和弱引用的一个区别在于：虚引用必须和引用队列（ReferenceQueue）联合使用。当垃圾回收器准备回收一个对象时，如果发现它还有虚引用，就会在回收对象的内存之前，把这个虚引用加入到与之关联的引用队列中。程序可以通过判断引用队列中是否已经加入虚引用，来了解被引用的对象是否将要被垃圾回收。如果程序发现某个虚引用已经被加入到引用队列，那么就可以在所引用的对象的内存被回收之前采取必要的行动。在任何时候，我们都可以调用ReferenceQueue#poll()来检查是否有它所关心的非强可及对象被回收。如果队列为空，将返回一个null，否则该方法返回队列中前面的一个Reference对象。利用这个方法，我们可以检查哪个SoftReference所软引用的对象已经被回收。 1.5 垃圾回收在垃圾回收时，软引用和弱引用差别不大，JVM都是先把SoftReference和WeakReference#referent字段值设置成null，referent可以认为对象销毁的标志，也就是referent=null时，之后加入到引用队列（我们可以认为JVM先回收堆对象占用的内存，然后才将软引用或弱引用加入到引用队列。这里回收是在对象不会再生的情况下，因为对象可能在finalize()中再生）；而虚引用则不同，如果某个堆中的对象，只有虚引用，那么JVM会将PhantomReference加入到引用队列中，JVM不会自动将referent字段值设置成null（先保留堆对象的内存空间）。referent是java.lang.ref.Reference类的私有字段，虽然没有暴露出共有API来访问这个字段，但是我们可以通过反射拿到这个字段的值，这样就能知道引用被加入到引用队列的时候，referent到底是不是null。SoftReference和WeakReference是一样的，这里我们以WeakReference为例。 1.5.1 例子1123456789101112131415161718192021222324252627282930313233343536373839404142434445import java.lang.ref.Reference;import java.lang.ref.ReferenceQueue;import java.lang.ref.WeakReference;import java.lang.reflect.Field;// 会报空指针:WeakReference中的referent被设置成null,之后加入到ReferenceQueuepublic class TestWeakReference { private static volatile boolean isRun = true; private static volatile ReferenceQueue&lt;String&gt; referenceQueue = new ReferenceQueue&lt;String&gt;(); public static void main(String[] args) throws Exception { String abc = new String(\"abc\"); System.out.println(abc.getClass() + \"@\" + abc.hashCode()); new Thread() { public void run() { while (isRun) { Object o = referenceQueue.poll(); if (o != null) { try { Field rereferent = Reference.class.getDeclaredField(\"referent\"); rereferent.setAccessible(true); Object result = rereferent.get(o); //说明result是null System.out.println(\"gc will collect:\" + result.getClass() + \"@\" + result.hashCode()); } catch (Exception e) { e.printStackTrace(); } } } } }.start(); // 对象是弱可达的 WeakReference&lt;String&gt; weak = new WeakReference&lt;String&gt;(abc, referenceQueue); System.out.println(\"weak=\" + weak); // 清除强引用,触发GC abc = null; System.gc(); //等待GC被回收 Thread.sleep(3000); isRun = false; }} 控制台1234class java.lang.String@96354weak=java.lang.ref.WeakReference@54624a40java.lang.NullPointerException at TestWeakReference$1.run(TestWeakReference.java:25) 结论：当我们清除强引用，触发GC的时候，JVM检测到new String(&quot;abc&quot;)这个堆中的对象只有WeakReference，那么JVM会释放堆对象的内存，并自动将WeakReference#referent字段设置成null，所以result.getClass()会报空指针异常。换成PhantomReference控制台打印123class java.lang.String@96354weak=java.lang.ref.PhantomReference@54624a40gc will collect:class java.lang.String@96354 结论：当PhantomReference加入到引用队列的时候，referent字段的值并不是null，而且堆对象占用的内存空间仍然存在。也就是说对于虚引用，JVM是先将其加入引用队列（然后才删除对象），当我们从引用队列删除PhantomReference对象之后(此时堆中的对象是unreachable的)，那么JVM才会释放堆对象占用的内存空间。由此可见，使用虚引用有潜在的内存泄露风险，因为JVM不会自动帮助我们释放，我们必须要保证它指向的堆对象是不可达的。（这里有个问题，如果sleep(3000)，GC并没有回收它，因为是回收之前加入队列，如果没有回收它，自然会存在对象）所有的 PhantomReference对象都必须用经过关联的ReferenceQueue来创建。 1.5.2 例子2验证软引用，弱引用，虚引用进入队列是不是需要执行finalize()1234567891011package demo6;import java.util.Date;class B { @Override protected void finalize() throws Throwable { System.out.println(\"finalize at \" + new Date()); } } 123456789101112131415161718192021222324252627package demo6;import java.lang.ref.PhantomReference;import java.lang.ref.ReferenceQueue;import java.util.Date;public class Tem { public static void main(String[] args) throws Exception { ReferenceQueue queue = new ReferenceQueue(); //SoftReference ref = new SoftReference(new B(), queue); //WeakReference ref = new WeakReference(new B(), queue); PhantomReference ref = new PhantomReference(new B(), queue); while (true) { Object obj = queue.poll(); if (obj != null) { System.out.println(\"queue.poll at \" + new Date() + \" \" + obj); break; } System.gc(); System.out.println(\"run once.\"); } Thread.sleep(100000); } } 结果：WeakReference不是必须进入finalize()才能进入队列。PhantomReference则必须进入finalize()才能进入队列。但这并不能说明对象销毁和队列的顺序。 1.5.3 综合例子1和例子2WeakReference1234567891011121314151617181920212223242526272829303132333435363738394041424344package demo1;import java.lang.ref.PhantomReference;import java.lang.ref.Reference;import java.lang.ref.ReferenceQueue;import java.lang.ref.WeakReference;import java.lang.reflect.Field;import java.util.Date;public class Tem { public static void main(String[] args) throws Exception { B b=new B(); ReferenceQueue queue = new ReferenceQueue(); //SoftReference ref1 = new SoftReference(new B(), queue); WeakReference ref2 = new WeakReference(b, queue); //PhantomReference ref3 = new PhantomReference(b, queue); b=null; while (true) { Object obj = queue.poll(); if (obj != null) { System.out.println(\"queue.poll at \" + new Date() + \" \" + obj); try { Field rereferent = Reference.class.getDeclaredField(\"referent\"); rereferent.setAccessible(true); Object result = rereferent.get(obj); //说明result是null System.out.println(\"gc will collect：\" + result.getClass() + \"@\" + result.hashCode()); } catch (Exception e) { e.printStackTrace(); } break; } System.gc(); System.out.println(\"run once.\"); } Thread.sleep(100000); } } 弱引用，finalize()和引用队列不是一个线程，没有必须进入finalize()，才进入引用队列的条件。进入引用队列前，referent已经是null。12345run once.finalize at Mon Sep 26 17:10:13 CST 2016queue.poll at Mon Sep 26 17:10:13 CST 2016 java.lang.ref.WeakReference@8c9dee3java.lang.NullPointerException at demo1.Tem.main(Tem.java:33) PhantomReference虚引用，必须进入finalize()才能进入队列，进入队列referent还是有值存在。（回收对象之前，加入队列）1234567run once.run once.run once.finalize at Mon Sep 26 17:33:09 CST 2016run once.queue.poll at Mon Sep 26 17:33:11 CST 2016 java.lang.ref.PhantomReference@4ec8c719gc will collect：class demo1.B@1591599764 1.6 对象再生和引用队列问题12345678910111213package demo2;public class A { static A a; public A(){ } @Override public void finalize() { a = this; } } WeakReference12345678910111213141516171819202122232425262728293031323334353637383940package demo2;import java.lang.ref.ReferenceQueue;import java.lang.ref.WeakReference;/** * * 弱引用对象再生，依然进入引用队列 * */public class M { public static void main(String[] args) throws InterruptedException { A a=new A(); System.out.println(a.hashCode()); ReferenceQueue queue = new ReferenceQueue(); WeakReference ref = new WeakReference(a, queue); System.out.println(ref.get()); a=null; Object obj = null; obj = queue.poll(); System.out.println(\"1=\"+obj); System.gc(); Thread.sleep(10000); System.gc(); System.out.println(\"2=\"+ref.get()); obj = queue.poll(); //弱引用队列有值，说明对象已经被销毁 //但是A对象又在finalize里再生 //所以不能用队列来控制软引用，弱引用对象的生命周期 //执行GC的时候，A对象状态变成finalized，进入队列，至于对象再生，则状态不能再改变 //因为,进入队列和finalize()是2个不同的线程。可能先进入队列之后，才进入finalize() System.out.println(\"3=\"+obj); System.out.println(A.a.hashCode()); }} 123456366712642test.A@15db97421=null2=null3=java.lang.ref.WeakReference@6d06d69c366712642 弱引用队列有值，说明对象已经被销毁，但是A对象又在finalize里再生，所以不能用队列来控制软引用，弱引用对象的生命周期，执行GC的时候，A对象状态变成finalized，进入队列，至于对象再生，则状态不能再改变。因为进入队列和finalize()是2个不同的线程。可能先进入队列之后，才进入finalize()，对象的状态来不及改变。1234561022736404demo2.A@3cf5b8141=null2=null3=java.lang.ref.WeakReference@773de2bd1022736404 PhantomReference12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849package demo2;import java.lang.ref.PhantomReference;import java.lang.ref.ReferenceQueue;/** * * 虚引用再生问题，finalize和进入队列顺序问题 * */public class W { public static void main(String[] args) throws InterruptedException { ReferenceQueue queue = new ReferenceQueue(); PhantomReference ref = new PhantomReference(new A(), queue); System.out.println(ref.get()); Object obj = null; obj = queue.poll(); System.out.println(\"1=\" + obj); // 第一次gc System.gc(); Thread.sleep(10000); System.gc(); System.out.println(\"2=\"+ref.get()); obj = queue.poll(); System.out.println(\"3=\"+obj); //第1次gc，对象再生，没有加入队列。 //虚引用是必须进入finalize方法才能进入队列，如果对象在此处再生，就不会进入队列。 A.a = null; // 第二次gc System.gc(); Thread.sleep(10000); obj = queue.poll(); //第2次gc，再生对象=null，加入队列。 System.out.println(obj); }}//虚引用更容易控制对象生命周期/*null1=null2=null3=nulljava.lang.ref.PhantomReference@1e638ee4*/ 虚引用是必须进入finalize()才能进入队列，如果对象在此处再生，就不会进入队列，所以队列里为null。12345null1=null2=null3=nulljava.lang.ref.PhantomReference@1e638ee4 2 示例2.1 示例图画的有点问题，str1是指向字符串，并不是指向weak1。1234567891011121314151617181920212223242526272829303132import java.lang.ref.ReferenceQueue;import java.lang.ref.WeakReference;public class ReferenceDemo { public static void main(String[] args) { // 引用队列 ReferenceQueue&lt;String&gt; referenceQueue = new ReferenceQueue&lt;String&gt;(); String str = new String(\"字符串\"); // 弱引用 WeakReference&lt;String&gt; weakReference1 = new WeakReference&lt;String&gt;(str, referenceQueue); WeakReference&lt;String&gt; weakReference2 = new WeakReference&lt;String&gt;(str, referenceQueue); // 强引用str没有指向字符串 str = null; // 弱引用指向的字符串，此时指向str1；str1是个强引用 // 如果这里没有强引用，弱引用就会在Gc执行之后被消除 String str1 = weakReference1.get(); // System.out.println(\"弱引用：\" + str1); System.out.println(\"引用队列里的引用：\" + referenceQueue.poll()); // 执行GC回收 System.out.println(\"------------------------------------GC回收----------------------------------------------\"); for (int i = 0; i &lt; 100; i++) { System.gc(); } // 此时弱引用没有被消除，因为str1是强引用 str1 = weakReference1.get(); System.out.println(\"弱引用1：\" + weakReference1.get()); System.out.println(\"弱引用2：\" + weakReference2.get()); System.out.println(str1); // 引用队列添加被回收的对象 System.out.println(\"引用队列：\" + referenceQueue.poll()); }} 123456引用队列里的引用：null------------------------------------GC回收----------------------------------------------弱引用1：字符串弱引用2：字符串字符串引用队列：null 结论： 但是str=null,str1=weakReference1.get()；str1指向字符串，并且weak1和weak2同时有字符串的引用，“字符串”没有销毁，所以weak1，weak2都是强引用。 2.2创建一个String对象、ReferenceQueue对象和WeakReference对象。123456// 创建一个强引用String str = new String(\"hello\");// 创建引用队列；表明队列中存放String对象的引用ReferenceQueue rq = new ReferenceQueue();// 创建一个弱引用，它引用\"hello\"对象，并且与rq引用队列关联WeakReference wf = new WeakReference(str, rq); 在图中，带实线的箭头表示强引用，带虚线的箭头表示弱引用。从图中可以看出，此时”hello”对象被str强引用，并且被一个WeakReference对象弱引用，因此”hello”对象不会被垃圾回收。 2.3把引用”hello”对象的str变量置为null，然后再通过WeakReference弱引用的get()获得”hello”对象的引用。1234567String str = new String(&quot;hello&quot;); //1 ReferenceQueue rq = new ReferenceQueue(); //2WeakReference wf = new WeakReference(str, rq); //3 str=null; //4 取消&quot;hello&quot;对象的强引用String str1=wf.get().toString(); //5 假如&quot;hello&quot;对象没有被回收，str1引用&quot;hello&quot;对象 //假如&quot;hello&quot;对象没有被回收，rq.poll()返回null Reference ref=rq.poll(); //6 “hello”对象只具有弱引用执行完以上标记4后，内存中引用与对象的关系如图所示，此时”hello”对象仅仅具有弱引用，因此它有可能被垃圾回收。假如它还没有被垃圾回收，那么接下来在标记5执行wf.get()会返回”hello”对象的引用，并且使得这个对象被str1强引用。再接下来在标记6执行rq.poll()会返回null，因为此时引用队列中没有任何引用。ReferenceQueue#poll()用于返回队列中的引用，如果没有则返回null。 2.4123456789String str = new String(&quot;hello&quot;); //1ReferenceQueue rq = new ReferenceQueue(); // 2WeakReference wf = new WeakReference(str, rq); // 3str = null; // 4// 两次催促垃圾回收器工作，提高&quot;hello&quot;对象被回收的可能性System.gc(); // 5System.gc(); // 6String str1 = wf.get().toString(); // 7 假如&quot;hello&quot;对象被回收，str1为nullReference ref = rq.poll(); // 8 “hello”对象被垃圾回收，弱引用被加入到引用队列在以下程序代码中，执行完标记4后，”hello”对象仅仅具有弱引用。接下来两次调用System.gc()，催促垃圾回收器工作，从而提高 “hello”对象被回收的可能性。假如”hello”对象被回收，那么WeakReference对象的引用被加入到ReferenceQueue中， 接下来wf.get()返回null，并且rq.poll()返回WeakReference对象的引用。图显示执行完标记8后内存中引用与对象的关系。 2.5依次创建10个软引用、10个弱引用和10个虚引用，它们各自引用一个Grocery对象。1234567891011121314151617181920package all;class Grocery { private static final int SIZE = 10000; // 属性d使得每个Grocery对象占用较多内存，有80K左右 private double[] d = new double[SIZE]; private String id; public Grocery(String id) { this.id = id; } public String toString() { return id; } public void finalize() { System.out.println(\"Finalizing \" + id); }} 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758package all;import java.lang.ref.PhantomReference;import java.lang.ref.Reference;import java.lang.ref.ReferenceQueue;import java.lang.ref.SoftReference;import java.lang.ref.WeakReference;import java.util.HashSet;import java.util.Set;public class All_10 { @SuppressWarnings(\"rawtypes\") private static ReferenceQueue rq = new ReferenceQueue(); @SuppressWarnings(\"rawtypes\") public static void checkQueue() { Reference inq = rq.poll(); // 从队列中取出一个引用 if (inq != null) { System.out.println(\"In queue: \" + inq + \" : \" + inq.get()); } } @SuppressWarnings({ \"rawtypes\", \"unchecked\" }) public static void main(String[] args) { final int size = 10; System.out.println(\"--------------------创建10个Grocery对象以及10个软引用-------------------------------\"); // 创建10个Grocery对象以及10个软引用 Set sa = new HashSet(); for (int i = 0; i &lt; size; i++) { SoftReference ref = new SoftReference(new Grocery(\"soft-\" + i), rq); System.out.println(\"Just created soft: \" + ref.get()); sa.add(ref); } System.gc(); checkQueue(); System.out.println(\"--------------------创建10个Grocery对象以及10个弱引用-------------------------------\"); // 创建10个Grocery对象以及10个弱引用 Set wa = new HashSet(); for (int i = 0; i &lt; size; i++) { WeakReference ref = new WeakReference(new Grocery(\"weak-\" + i), rq); System.out.println(\"Just created weak: \" + ref.get()); wa.add(ref); } System.gc(); checkQueue(); System.out.println(\"--------------------创建10个Grocery对象以及10个虚引用-------------------------------\"); // 创建10个Grocery对象以及10个虚引用 Set pa = new HashSet(); for (int i = 0; i &lt; size; i++) { PhantomReference ref = new PhantomReference(new Grocery(\"Phantom-\" + i), rq); System.out.println(\"Just created Phantom: \" + ref.get());//调用phanRef.get()不管在什么情况下会一直返回null，虚引用的特点 pa.add(ref); } System.gc(); checkQueue(); }} 控制台打印123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354--------------------创建10个Grocery对象以及10个软引用-------------------------------Just created soft: soft-0Just created soft: soft-1Just created soft: soft-2Just created soft: soft-3Just created soft: soft-4Just created soft: soft-5Just created soft: soft-6Just created soft: soft-7Just created soft: soft-8Just created soft: soft-9--------------------创建10个Grocery对象以及10个弱引用-------------------------------Just created weak: weak-0Just created weak: weak-1Just created weak: weak-2Just created weak: weak-3Just created weak: weak-4Just created weak: weak-5Just created weak: weak-6Just created weak: weak-7Just created weak: weak-8Just created weak: weak-9--------------------创建10个Grocery对象以及10个虚引用-------------------------------Finalizing weak-3Finalizing weak-2Finalizing weak-1Finalizing weak-0Finalizing weak-5Finalizing weak-4Just created Phantom: nullFinalizing weak-9Finalizing weak-8Just created Phantom: nullFinalizing weak-7Just created Phantom: nullFinalizing weak-6Just created Phantom: nullJust created Phantom: nullJust created Phantom: nullJust created Phantom: nullJust created Phantom: nullJust created Phantom: nullJust created Phantom: nullIn queue: java.lang.ref.WeakReference@13883d5f : nullFinalizing Phantom-4Finalizing Phantom-6Finalizing Phantom-7Finalizing Phantom-8Finalizing Phantom-3Finalizing Phantom-5Finalizing Phantom-9Finalizing Phantom-0Finalizing Phantom-1Finalizing Phantom-2 结论：虚引用形同虚设，它所引用的对象随时可能被垃圾回收；具有弱引用的对象拥有稍微长的生命周期，当垃圾回收器执行回收操作时，有可能被垃圾回收；具有软引用的对象拥有较长的生命周期，但在Java虚拟机认为内存不足的情况下，也会被垃圾回收。 2.2 软引用12MyObject aRef=new MyObject(); SoftReference aSoftRef=new SoftReference(aRef); 对于这个MyObject对象，有两个引用路径，一个是来自SoftReference对象的软引用，一个来自变量aReference的强引用，所以这个MyObject对象是强可及对象。Java虚拟机的垃圾收集线程对软可及对象和其他一般Java对象进行区别对待：软可及对象的清理是由垃圾收集线程根据其特定算法按照内存需求决定的。也就是说，垃圾收集线程会在虚拟机抛出OutOfMemoryError之前回收软可及对象，而且虚拟机会尽可能优先回收长时间闲置不用的软可及对象，对那些刚刚构建的或刚刚使用过的“新”软可反对象会被虚拟机尽可能保留。SoftReference的特点是它的一个实例保存对一个Java对象的软引用，该软引用的存在不妨碍垃圾收集线程对该Java对象的回收。也就是说， 一旦SoftReference保存对一个Java对象的软引用后，在垃圾线程对这个Java对象回收前，SoftReference类所提供的get()返回Java对象的强引用。另外，一旦垃圾线程回收该Java对象之后，get()将返回null。 2.3 软引用实现缓存123456789101112131415161718192021222324252627282930313233343536package soft;public class Employee { private String id;// 雇员的标识号码 private String name;// 雇员姓名 // 构造方法 public Employee(String id) { this.id = id; getDataFromlnfoCenter(); } // 到数据库中取得雇员信息 private void getDataFromlnfoCenter() { // 和数据库建立连接井查询该雇员的信息，将查询结果赋值 // 给name，department，plone，salary等变量 // 同时将origin赋值为\"From DataBase\" } public String getId() { return id; } public void setId(String id) { this.id = id; } public String getName() { return name; } public void setName(String name) { this.name = name; }} 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677package soft;import java.lang.ref.ReferenceQueue;import java.lang.ref.SoftReference;import java.util.Hashtable;public class EmployeeCache { static private EmployeeCache cache;// 一个Cache实例 private Hashtable employeeRefs;// 用于Chche内容的存储 private ReferenceQueue q;// 垃圾Reference的队列 // 继承SoftReference，使得每一个实例都具有可识别的标识。 // 并且该标识与其在HashMap内的key相同。 private class EmployeeRef extends SoftReference { private String _key = \"\"; public EmployeeRef(Employee em, ReferenceQueue q) { super(em, q); _key = em.getId(); } } // 构建一个缓存器实例 private EmployeeCache() { employeeRefs = new Hashtable(); q = new ReferenceQueue(); } // 取得缓存器实例 public static EmployeeCache getInstance() { if (cache == null) { cache = new EmployeeCache(); } return cache; } // 以软引用的方式对一个Employee对象的实例进行引用并保存该引用 public void cacheEmployee(Employee em) { cleanCache();// 清除垃圾引用 EmployeeRef ref = new EmployeeRef(em, q); employeeRefs.put(em.getId(), ref); } // 依据所指定的ID号，重新获取相应Employee对象的实例 public Employee getEmployee(String ID) { Employee em = null; // 缓存中是否有该Employee实例的软引用，如果有，从软引用中取得。 if (employeeRefs.containsKey(ID)) { EmployeeRef ref = (EmployeeRef) employeeRefs.get(ID); em = (Employee) ref.get(); } // 如果没有软引用，或者从软引用中得到的实例是null，重新构建一个实例， // 并保存对这个新建实例的软引用 if (em == null) { em = new Employee(ID); System.out.println(\"Retrieve From EmployeeInfoCenter. ID=\" + ID); this.cacheEmployee(em); } return em; } // 清除那些所软引用的Employee对象已经被回收的EmployeeRef对象 private void cleanCache() { EmployeeRef ref = null; while ((ref = (EmployeeRef) q.poll()) != null) { employeeRefs.remove(ref._key); } } // 清除Cache内的全部内容 public void clearCache() { cleanCache(); employeeRefs.clear(); System.gc(); System.runFinalization(); }} 2.4 弱引用在Java集合中有一种特殊的Map类型WeakHashMap， 在这种Map中存放键对象的弱引用，当一个键对象被垃圾回收，那么相应的值对象的引用会从Map中删除。WeakHashMap能够节约存储空间，可用来缓存那些非必须存在的数据。以下代码MapCache类的main()创建一个WeakHashMap对象，它存放一组Key对象的弱引用，此外main()还创建一个数组对象，它存放部分Key对象的强引用。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162package weak;import java.util.WeakHashMap;class Key { String id; public Key(String id) { this.id = id; } public String toString() { return id; } public int hashCode() { return id.hashCode(); } public boolean equals(Object r) { return (r instanceof Key) &amp;&amp; id.equals(((Key) r).id); } public void finalize() { System.out.println(\"Finalizing Key \" + id); }}class Value { String id; public Value(String id) { this.id = id; } public String toString() { return id; } public void finalize() { System.out.println(\"Finalizing Value \" + id); }}public class MapCache { public static void main(String[] args) throws Exception { int size = 1000;// 或者从命令行获得size的大小 Key[] keys = new Key[size]; // 存放键对象的强引用 WeakHashMap whm = new WeakHashMap(); for (int i = 0; i &lt; size; i++) { Key k = new Key(Integer.toString(i)); Value v = new Value(Integer.toString(i)); if (i % 3 == 0) { keys[i] = k; // 使Key对象持有强引用 } whm.put(k, v); // 使Key对象持有弱引用 } // 催促垃圾回收器工作 System.gc();// 把CPU让给垃圾回收器线程 Thread.sleep(8000); }} 控制台打印1234567Finalizing Key 587Finalizing Key 985Finalizing Key 998Finalizing Key 997Finalizing Key 995Finalizing Key 994.................. 结果：当执行System.gc()后，垃圾回收器只会回收那些仅仅持有弱引用的Key对象。id可以被3整数的Key对象持有强引用，因此不会被回收。","link":"/Java-Soft-Reference/"},{"title":"JDK1.6 ConcurrentSkipListMap","text":"1 介绍 2 源码分析 数据结构 ConcurrentSkipListMap#Node(K key, Object value, Node&lt;K,V&gt; next) ConcurrentSkipListMap#Node(Node&lt;K,V&gt; next) ConcurrentSkipListMap#Node#原子更新 ConcurrentSkipListMap#Node#helpDelete() ConcurrentSkipListMap#Index属性 ConcurrentSkipListMap#Index#link() ConcurrentSkipListMap#Index#unlink() ConcurrentSkipListMap#HeadIndex ConcurrentSkipListMap属性 ConcurrentSkipListMap构造方法 ConcurrentSkipListMap#initialize() ConcurrentSkipListMap#put() ConcurrentSkipListMap#doPut ConcurrentSkipListMap#comparable() ConcurrentSkipListMap#addIndex() ConcurrentSkipListMap#findPredecessor() ConcurrentSkipListMap#randomLevel() ConcurrentSkipListMap#insertIndex() ConcurrentSkipListMap#addIndex() ConcurrentSkipListMap#findNode() put()总结 ConcurrentSkipListMap#get() ConcurrentSkipListMap#doGet() ConcurrentSkipListMap#getUsingFindNode() ConcurrentSkipListMap#containsKey() ConcurrentSkipListMap#remove() ConcurrentSkipListMap#doRemove() ConcurrentSkipListMap#tryReduceLevel() ConcurrentSkipListMap#containsValue() ConcurrentSkipListMap#findFirst() ConcurrentSkipListMap#size() ConcurrentSkipListMap#isEmpty() ConcurrentSkipListMap#lastKey() ConcurrentSkipListMap#findLast() ConcurrentSkipListMap#lowerEntry() ConcurrentSkipListMap#getNear() ConcurrentSkipListMap#findNear() ConcurrentSkipListMap#floorEntry() ConcurrentSkipListMap#ceilingEntry() ConcurrentSkipListMap#higherEntry() 1 介绍ConcurrentSkipListMap是一种线程安全的有序的Map。一般我们使用有序Map，不要求线程安全的情况下，可以使用TreeMap，要求线程安全的话，就可以使用ConcurrentSkipListMap。ConcurrentSkipListMap内部的数据结构是SkipList(跳表)，内部Entry顺序是由实现了Comparable的key或者构造时指定的Comparator来保证。和TreeMap一样，对ConcurrentSkipListMap中元素的put()、get()和remove()等操作的平均时间复杂度也是O(log(n))。 2 源码分析数据结构源码中也提供图形化的注释。有3中节点：Head节点、Index节点和普通的Node节点。1234567891011121314* Head nodes Index nodes* +-+ right +-+ +-+* |2|----------------&gt;| |---------------------&gt;| |-&gt;null* +-+ +-+ +-+* | down | |* v v v* +-+ +-+ +-+ +-+ +-+ +-+* |1|-----------&gt;| |-&gt;| |------&gt;| |-----------&gt;| |------&gt;| |-&gt;null* +-+ +-+ +-+ +-+ +-+ +-+* v | | | | |* Nodes next v v v v v* +-+ +-+ +-+ +-+ +-+ +-+ +-+ +-+ +-+ +-+ +-+ +-+* | |-&gt;|A|-&gt;|B|-&gt;|C|-&gt;|D|-&gt;|E|-&gt;|F|-&gt;|G|-&gt;|H|-&gt;|I|-&gt;|J|-&gt;|K|-&gt;null* +-+ +-+ +-+ +-+ +-+ +-+ +-+ +-+ +-+ +-+ +-+ +-+ ConcurrentSkipListMap#Node(K key, Object value, Node&lt;K,V&gt; next)12345678/** * Creates a new regular node. */ Node(K key, Object value, Node&lt;K,V&gt; next) { this.key = key; this.value = value; this.next = next; } 创建一个普通节点。 ConcurrentSkipListMap#Node(Node&lt;K,V&gt; next)12345678910111213141516171819202122232425262728 /** * Creates a new marker node. A marker is distinguished by * having its value field point to itself. Marker nodes also * have null keys, a fact that is exploited in a few places, * but this doesn't distinguish markers from the base-level * header node (head.node), which also has a null key. */ Node(Node&lt;K,V&gt; next) { this.key = null; this.value = this; this.next = next; }``` 创建一个标记节点。key==null无法区分标记节点和base-level链表头节点，因为base-level链表头节点的key也是null。&lt;!-- more --&gt;## ConcurrentSkipListMap#Node#原子更新指定的volatile引用字段进行原子更新。``` java /** Updater for casNext */ static final AtomicReferenceFieldUpdater&lt;Node, Node&gt; nextUpdater = AtomicReferenceFieldUpdater.newUpdater (Node.class, Node.class, \"next\"); /** Updater for casValue */ static final AtomicReferenceFieldUpdater&lt;Node, Object&gt; valueUpdater = AtomicReferenceFieldUpdater.newUpdater (Node.class, Object.class, \"value\"); nextUpdater和valueUpdater分别对next、value进行更新 ConcurrentSkipListMap#Node#helpDelete()123456789void helpDelete(Node&lt;K,V&gt; b, Node&lt;K,V&gt; f) { if (f == next &amp;&amp; this == b.next) { // 1 if (f == null || f.value != f) // not already marked appendMarker(f); else // 2 b.casNext(this, f.next); } } 标注代码分析 后继节点f是null，新增一个节点标记(marker)。 删除节点b与f.next之间的节点，b#next指向f#next。 1234567891011 +------+ +------+ +------+... | b |------&gt;| n |-----&gt;| f | ... +------+ +------+ +------+ +------+ +------+ +------+ +------+... | b |------&gt;| n |-----&gt;|marker|------&gt;| f | ... +------+ +------+ +------+ +------+ +------+ +------+... | b |-----------------------------------&gt;| f | ... +------+ +------+ 当前节点为n，n的前驱节点为b，n的后继节点为f。 现在要删除节点n，那么首先要对n进行标记。要删除节点n，首先是往节点n后面追加一个标记节点。 直接将节点n和后面的标记节点一起删除。 ConcurrentSkipListMap#Index属性Index节点表示跳表的层级。123456789101112// 1final Node&lt;K,V&gt; node;// 2final Index&lt;K,V&gt; down;// 3volatile Index&lt;K,V&gt; right; /** Updater for casRight */// 4static final AtomicReferenceFieldUpdater&lt;Index, Index&gt; rightUpdater = AtomicReferenceFieldUpdater.newUpdater (Index.class, Index.class, \"right\"); 标注代码分析 索引指向的节点, 纵向上所有索引指向链表最下面的节点。 下level层的Index。 右边的Index。 原子更新right属性。 ConcurrentSkipListMap#Index#link()12345final boolean link(Index&lt;K,V&gt; succ, Index&lt;K,V&gt; newSucc) { Node&lt;K,V&gt; n = node; newSucc.right = succ; return n.value != null &amp;&amp; casRight(succ, newSucc); } 在index本身和succ之间插入一个新的节点newSucc。 ConcurrentSkipListMap#Index#unlink()123final boolean unlink(Index&lt;K,V&gt; succ) { return !indexesDeletedNode() &amp;&amp; casRight(succ, succ.right); } 将当前的节点index设置其的right为 succ.right等于删除succ节点。 ConcurrentSkipListMap#HeadIndex12345678910/** * Nodes heading each level keep track of their level. */ static final class HeadIndex&lt;K,V&gt; extends Index&lt;K,V&gt; { final int level; HeadIndex(Node&lt;K,V&gt; node, Index&lt;K,V&gt; down, Index&lt;K,V&gt; right, int level) { super(node, down, right); this.level = level; } } 头索引节点，只是增加level属性用来标示索引层级。 ConcurrentSkipListMap属性1234567891011/** * Special value used to identify base-level header */ // 1 private static final Object BASE_HEADER = new Object(); /** * The topmost head index of the skiplist. */ // 2 private transient volatile HeadIndex&lt;K,V&gt; head; 标注代码分析 用来定义base-level的头结点。 跳表最高层的head index。 ConcurrentSkipListMap构造方法12345678/** * Constructs a new, empty map, sorted according to the * {@linkplain Comparable natural ordering} of the keys. */ public ConcurrentSkipListMap() { this.comparator = null; initialize(); } keys排序，并且调用ConcurrentSkipListMap#initialize()。 ConcurrentSkipListMap#initialize()123456789101112131415 /** * Initializes or resets state. Needed by constructors, clone, * clear, readObject. and ConcurrentSkipListSet.clone. * (Note that comparator must be separately initialized.) */final void initialize() { keySet = null; entrySet = null; values = null; descendingMap = null; randomSeed = seedGenerator.nextInt() | 0x0100; // ensure nonzero // 1 head = new HeadIndex&lt;K,V&gt;(new Node&lt;K,V&gt;(null, BASE_HEADER, null), null, null, 1);} 标注代码分析 生成头节点，该节点value是BASE_HEADER，level是1。 ConcurrentSkipListMap#put()12345public V put(K key, V value) { if (value == null) throw new NullPointerException(); return doPut(key, value, false); } ConcurrentSkipListMap#doPut123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051private V doPut(K kkey, V value, boolean onlyIfAbsent) { // 1 Comparable&lt;? super K&gt; key = comparable(kkey); for (;;) { // 2 Node&lt;K,V&gt; b = findPredecessor(key); Node&lt;K,V&gt; n = b.next; for (;;) { if (n != null) { // 3 Node&lt;K,V&gt; f = n.next; // 4 if (n != b.next) // inconsistent read break;; Object v = n.value; // 5 if (v == null) { // n is deleted n.helpDelete(b, f); break; } // 6 if (v == n || b.value == null) // b is deleted break; int c = key.compareTo(n.key); // 7 if (c &gt; 0) { b = n; n = f; continue; } if (c == 0) { // 8 if (onlyIfAbsent || n.casValue(v, value)) return (V)v; else break; // restart if lost race to replace value } // else c &lt; 0; fall through } // 9 Node&lt;K,V&gt; z = new Node&lt;K,V&gt;(kkey, value, n); if (!b.casNext(n, z)) break; // restart if lost race to append to b int level = randomLevel(); // 10 if (level &gt; 0) insertIndex(z, level); return null; } } } 标注代码分析 以key为参数生成Comparable接口的子类，用于比较key，确定前驱节点和后续节点位置。 通过key找到要插入位置的前驱节点。key的前驱节点是b，b的后续节点是n，key的Node节点是n(key会和n#key做判断，才能确定是不是节点n)。 n#next值是f，f是n的后续节点。 b#next != n 可能是put冲突，造成读不一样。结束本次put()。 节点n被删除，删除节点b和节点f之间的节点。 节点b被删除，无法找到前驱节点，退出本次循环。 n#key和key比较，c &gt; 0当前的节点应该排在n的后面，节点b和节点n重新赋值，后移1个节点。 c = 0，key的节点是n，CAS进行替换value，如果CAS失败结束本次循环。 新建1个节点z，b#next和n比较，如果相等，b#next=z。 插入成功后，随机生成一个层级。 ConcurrentSkipListMap#comparable()12345678private Comparable&lt;? super K&gt; comparable(Object key) throws ClassCastException { if (key == null) throw new NullPointerException(); if (comparator != null) return new ComparableUsingComparator&lt;K&gt;((K)key, comparator); else return (Comparable&lt;? super K&gt;)key; } 如果指定Comparator，就使用Comparator；没指定Comparator，就使用Key的自然序(Key需要实现Comparable接口)。 ConcurrentSkipListMap#addIndex()12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061/** * Adds given index nodes from given level down to 1. * @param idx the topmost index node being inserted * @param h the value of head to use to insert. This must be * snapshotted by callers to provide correct insertion level * @param indexLevel the level of the index */private void addIndex(Index&lt;K,V&gt; idx, HeadIndex&lt;K,V&gt; h, int indexLevel) { // Track next level to insert in case of retries int insertionLevel = indexLevel; Comparable&lt;? super K&gt; key = comparable(idx.node.key); if (key == null) throw new NullPointerException(); // Similar to findPredecessor, but adding index nodes along // path to key. for (;;) { int j = h.level; Index&lt;K,V&gt; q = h; Index&lt;K,V&gt; r = q.right; Index&lt;K,V&gt; t = idx; for (;;) { if (r != null) { Node&lt;K,V&gt; n = r.node; // compare before deletion check avoids needing recheck int c = key.compareTo(n.key); if (n.value == null) { if (!q.unlink(r)) break; r = q.right; continue; } if (c &gt; 0) { q = r; r = r.right; continue; } } if (j == insertionLevel) { // Don't insert index if node already deleted if (t.indexesDeletedNode()) { findNode(key); // cleans up return; } if (!q.link(r, t)) break; // restart if (--insertionLevel == 0) { // need final deletion check before return if (t.indexesDeletedNode()) findNode(key); return; } } if (--j &gt;= insertionLevel &amp;&amp; j &lt; indexLevel) t = t.down; q = q.down; r = q.right; } }} ConcurrentSkipListMap#findPredecessor()123456789101112131415161718192021222324252627282930313233343536373839/** * Returns a base-level node with key strictly less than given key, * or the base-level header if there is no such node. Also * unlinks indexes to deleted nodes found along the way. Callers * rely on this side-effect of clearing indices to deleted nodes. * @param key the key * @return a predecessor of key */ private Node&lt;K,V&gt; findPredecessor(Comparable&lt;? super K&gt; key) { if (key == null) throw new NullPointerException(); // don't postpone errors for (;;) { Index&lt;K,V&gt; q = head; Index&lt;K,V&gt; r = q.right; for (;;) { if (r != null) { Node&lt;K,V&gt; n = r.node; K k = n.key; if (n.value == null) { if (!q.unlink(r)) break; // restart r = q.right; // reread r continue; } if (key.compareTo(k) &gt; 0) { q = r; r = r.right; continue; } } Index&lt;K,V&gt; d = q.down; if (d != null) { q = d; r = d.right; } else return q.node; } } } 从最高层的头节点开始找，给定key大于当前节点，就往右找，否则就往下找，一直找到最底层链上的节点，这个节点就是给定key在base_level上的前驱节点。 ConcurrentSkipListMap#randomLevel()1234567891011121314151617181920/** * Returns a random level for inserting a new node. * Hardwired to k=1, p=0.5, max 31 (see above and * Pugh's \"Skip List Cookbook\", sec 3.4). * * This uses the simplest of the generators described in George * Marsaglia's \"Xorshift RNGs\" paper. This is not a high-quality * generator but is acceptable here. */ private int randomLevel() { int x = randomSeed; x ^= x &lt;&lt; 13; x ^= x &gt;&gt;&gt; 17; randomSeed = x ^= x &lt;&lt; 5; if ((x &amp; 0x8001) != 0) // test highest and lowest bits return 0; int level = 1; while (((x &gt;&gt;&gt;= 1) &amp; 1) != 0) ++level; return level; } 50%的几率返回0，25%的几率返回1，12.5%的几率返回2，最大返回31。 ConcurrentSkipListMap#insertIndex()123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051/** * Creates and adds index nodes for the given node. * @param z the node * @param level the level of the index */private void insertIndex(Node&lt;K,V&gt; z, int level) { HeadIndex&lt;K,V&gt; h = head; int max = h.level; if (level &lt;= max) { Index&lt;K,V&gt; idx = null; for (int i = 1; i &lt;= level; ++i) idx = new Index&lt;K,V&gt;(z, idx, null); addIndex(idx, h, level); } else { // Add a new level /* * To reduce interference by other threads checking for * empty levels in tryReduceLevel, new levels are added * with initialized right pointers. Which in turn requires * keeping levels in an array to access them while * creating new head index nodes from the opposite * direction. */ level = max + 1; Index&lt;K,V&gt;[] idxs = (Index&lt;K,V&gt;[])new Index[level+1]; Index&lt;K,V&gt; idx = null; for (int i = 1; i &lt;= level; ++i) idxs[i] = idx = new Index&lt;K,V&gt;(z, idx, null); HeadIndex&lt;K,V&gt; oldh; int k; for (;;) { oldh = head; int oldLevel = oldh.level; if (level &lt;= oldLevel) { // lost race to add level k = level; break; } HeadIndex&lt;K,V&gt; newh = oldh; Node&lt;K,V&gt; oldbase = oldh.node; for (int j = oldLevel+1; j &lt;= level; ++j) newh = new HeadIndex&lt;K,V&gt;(oldbase, newh, idxs[j], j); if (casHead(oldh, newh)) { k = oldLevel; break; } } addIndex(idxs[k], oldh, k); }} ConcurrentSkipListMap#addIndex()12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061/** * Adds given index nodes from given level down to 1. * @param idx the topmost index node being inserted * @param h the value of head to use to insert. This must be * snapshotted by callers to provide correct insertion level * @param indexLevel the level of the index */private void addIndex(Index&lt;K,V&gt; idx, HeadIndex&lt;K,V&gt; h, int indexLevel) { // Track next level to insert in case of retries int insertionLevel = indexLevel; Comparable&lt;? super K&gt; key = comparable(idx.node.key); if (key == null) throw new NullPointerException(); // Similar to findPredecessor, but adding index nodes along // path to key. for (;;) { int j = h.level; Index&lt;K,V&gt; q = h; Index&lt;K,V&gt; r = q.right; Index&lt;K,V&gt; t = idx; for (;;) { if (r != null) { Node&lt;K,V&gt; n = r.node; // compare before deletion check avoids needing recheck int c = key.compareTo(n.key); if (n.value == null) { if (!q.unlink(r)) break; r = q.right; continue; } if (c &gt; 0) { q = r; r = r.right; continue; } } if (j == insertionLevel) { // Don't insert index if node already deleted if (t.indexesDeletedNode()) { findNode(key); // cleans up return; } if (!q.link(r, t)) break; // restart if (--insertionLevel == 0) { // need final deletion check before return if (t.indexesDeletedNode()) findNode(key); return; } } if (--j &gt;= insertionLevel &amp;&amp; j &lt; indexLevel) t = t.down; q = q.down; r = q.right; } }} 给定的节点和level值，将之前建立的从上到下的Index节点链接进来。检测当前的idx节点有没有被删除，如果有，要调用一个ConcurrentSkipListMap#findNode()来做调整。 ConcurrentSkipListMap#findNode()123456789101112131415161718192021222324252627private Node&lt;K,V&gt; findNode(Comparable&lt;? super K&gt; key) { for (;;) { Node&lt;K,V&gt; b = findPredecessor(key); Node&lt;K,V&gt; n = b.next; for (;;) { if (n == null) return null; Node&lt;K,V&gt; f = n.next; if (n != b.next) // inconsistent read break; Object v = n.value; if (v == null) { // n is deleted n.helpDelete(b, f); break; } if (v == n || b.value == null) // b is deleted break; int c = key.compareTo(n.key); if (c == 0) return n; if (c &lt; 0) return null; b = n; n = f; } } } put()总结 首先要根据给定的key找出在base_level链表中对应的前驱节点(从结构图的左上角往右或往下一路找过来)，注意put方法使用的log(n)时间主要体现在这个过程，这个查找过程中会顺便帮忙推进一些节点的删除。 找到前驱节点后，然后从这个前驱节点往后找到要插入的位置(注意当前已经在base_level上，所以只需要往后找)，这个查找过程中也会顺便帮忙推进一些节点的删除。 找到了要插入的位置，尝试插入，如果竞争导致插入失败，返回到第1步重试；如果插入成功，接下来会随机生成一个level，如果这个level大于0，需要将插入的节点在垂直线上生成level(level&lt;=maxLevel + 1)个Index节点。 ConcurrentSkipListMap#get()123public V get(Object key) { return doGet(key); } ConcurrentSkipListMap#doGet()12345678910111213141516171819202122232425262728293031323334353637383940414243private V doGet(Object okey) { Comparable&lt;? super K&gt; key = comparable(okey); Node&lt;K,V&gt; bound = null; Index&lt;K,V&gt; q = head; Index&lt;K,V&gt; r = q.right; Node&lt;K,V&gt; n; K k; int c; for (;;) { Index&lt;K,V&gt; d; // Traverse rights if (r != null &amp;&amp; (n = r.node) != bound &amp;&amp; (k = n.key) != null) { if ((c = key.compareTo(k)) &gt; 0) { q = r; r = r.right; continue; } else if (c == 0) { Object v = n.value; return (v != null)? (V)v : getUsingFindNode(key); } else bound = n; } // Traverse down if ((d = q.down) != null) { q = d; r = d.right; } else break; } // Traverse nexts for (n = q.node.next; n != null; n = n.next) { if ((k = n.key) != null) { if ((c = key.compareTo(k)) == 0) { Object v = n.value; return (v != null)? (V)v : getUsingFindNode(key); } else if (c &lt; 0) break; } } return null; } 从最左最高的头节点开始往右或者往下(通过key的比较)遍历，一直找到base_level，然后往后一直找到给定节点，找不到的话返回null。 代码中还会看到，如果找到了节点，还会判断节点上的value是否为null。如果不为null，直接返回这个value；如果为null，说明这个节点被删除了(正在删除过程中)，那么需要调用一个ConcurrentSkipListMap#getUsingFindNode()。 ConcurrentSkipListMap#getUsingFindNode()123456789101112131415private V getUsingFindNode(Comparable&lt;? super K&gt; key) { /* * Loop needed here and elsewhere in case value field goes * null just as it is about to be returned, in which case we * lost a race with a deletion, so must retry. */ for (;;) { Node&lt;K,V&gt; n = findNode(key); if (n == null) return null; Object v = n.value; if (v != null) return (V)v; } } 调用前面分析过的findNode方法来查找一个key对应的Node，注意方法中外侧还是包了一层无限循环，为的是避免由于竞争导致findNode方法返回的Node又是一个被删除的节点。 ConcurrentSkipListMap#containsKey()123public boolean containsKey(Object key) { return doGet(key) != null; } ConcurrentSkipListMap#doGet()来实现。 ConcurrentSkipListMap#remove()123public V remove(Object key) { return doRemove(key, null); } ConcurrentSkipListMap#doRemove()1234567891011121314151617181920212223242526272829303132333435363738394041final V doRemove(Object okey, Object value) { Comparable&lt;? super K&gt; key = comparable(okey); for (;;) { Node&lt;K,V&gt; b = findPredecessor(key); Node&lt;K,V&gt; n = b.next; for (;;) { if (n == null) return null; Node&lt;K,V&gt; f = n.next; if (n != b.next) // inconsistent read break; Object v = n.value; if (v == null) { // n is deleted n.helpDelete(b, f); break; } if (v == n || b.value == null) // b is deleted break; int c = key.compareTo(n.key); if (c &lt; 0) return null; if (c &gt; 0) { b = n; n = f; continue; } if (value != null &amp;&amp; !value.equals(v)) return null; if (!n.casValue(v, null)) break; if (!n.appendMarker(f) || !b.casNext(n, f)) findNode(key); // Retry via findNode else { findPredecessor(key); // Clean index if (head.right == null) tryReduceLevel(); } return (V)v; } } } ConcurrentSkipListMap#tryReduceLevel()1234567891011121314private void tryReduceLevel() { HeadIndex&lt;K,V&gt; h = head; HeadIndex&lt;K,V&gt; d; HeadIndex&lt;K,V&gt; e; if (h.level &gt; 3 &amp;&amp; (d = (HeadIndex&lt;K,V&gt;)h.down) != null &amp;&amp; (e = (HeadIndex&lt;K,V&gt;)d.down) != null &amp;&amp; e.right == null &amp;&amp; d.right == null &amp;&amp; h.right == null &amp;&amp; casHead(h, d) &amp;&amp; // try to set h.right != null) // recheck casHead(d, h); // try to backout } 如果最高的前三个HeadIndex都为null(当前看起来)，那么就将level减少1层，其实就是将h(当前的head)设置为d(head的下一层)，设置完成之后，还有检测h(之前的head)的right是否为null(因为可能刚才由于竞争的原因，导致看到h的right为null)，如果这会儿又不是null，那么还得回退回来，再次将head设置为h。 ConcurrentSkipListMap#containsValue()12345678910public boolean containsValue(Object value) { if (value == null) throw new NullPointerException(); for (Node&lt;K,V&gt; n = findFirst(); n != null; n = n.next) { V v = n.getValidValue(); if (v != null &amp;&amp; value.equals(v)) return true; } return false; } base_level链的第一个节点，然后一直往后找，比较value值。 ConcurrentSkipListMap#findFirst()1234567891011Node&lt;K,V&gt; findFirst() { for (;;) { Node&lt;K,V&gt; b = head.node; Node&lt;K,V&gt; n = b.next; if (n == null) return null; if (n.value != null) return n; n.helpDelete(b, n.next); } } 就是找到head中node(BASE_HEADER节点)的next，有可能next节点被删除了，所以会做检测，删除的话，推进一下删除，然后继续获取。ConcurrentSkipListMap#size()和ConcurrentSkipListMap#isEmpty()也是基于这个方法实现的。 ConcurrentSkipListMap#size()12345678public int size() { long count = 0; for (Node&lt;K,V&gt; n = findFirst(); n != null; n = n.next) { if (n.getValidValue() != null) ++count; } return (count &gt;= Integer.MAX_VALUE)? Integer.MAX_VALUE : (int)count; } ConcurrentSkipListMap#isEmpty()123public boolean isEmpty() { return findFirst() == null; } ConcurrentSkipListMap实现ConcurrentMap接口。覆写putIfAbsent()、 remove()、replace()。ConcurrentSkipListMap同样实现SortedMap。 ConcurrentSkipListMap#lastKey()123456public K lastKey() { Node&lt;K,V&gt; n = findLast(); if (n == null) throw new NoSuchElementException(); return n.key; } ConcurrentSkipListMap#findLast()1234567891011121314151617181920212223242526272829303132333435363738394041Node&lt;K,V&gt; findLast() { /* * findPredecessor can't be used to traverse index level * because this doesn't use comparisons. So traversals of * both levels are folded together. */ Index&lt;K,V&gt; q = head; for (;;) { Index&lt;K,V&gt; d, r; if ((r = q.right) != null) { if (r.indexesDeletedNode()) { q.unlink(r); q = head; // restart } else q = r; } else if ((d = q.down) != null) { q = d; } else { Node&lt;K,V&gt; b = q.node; Node&lt;K,V&gt; n = b.next; for (;;) { if (n == null) return (b.isBaseHeader())? null : b; Node&lt;K,V&gt; f = n.next; // inconsistent read if (n != b.next) break; Object v = n.value; if (v == null) { // n is deleted n.helpDelete(b, f); break; } if (v == n || b.value == null) // b is deleted break; b = n; n = f; } q = head; // restart } } } ConcurrentSkipListMap#lowerEntry()123public Map.Entry&lt;K,V&gt; lowerEntry(K key) { return getNear(key, LT);} 找到一个比给定key小的所有key里面最大的key对应的Entry，里面调用了getNear()。 ConcurrentSkipListMap#getNear()12345678910AbstractMap.SimpleImmutableEntry&lt;K,V&gt; getNear(K key, int rel) { for (;;) { Node&lt;K,V&gt; n = findNear(key, rel); if (n == null) return null; AbstractMap.SimpleImmutableEntry&lt;K,V&gt; e = n.createSnapshot(); if (e != null) return e; } } ConcurrentSkipListMap#findNear()1234567891011121314151617181920212223242526272829Node&lt;K,V&gt; findNear(K kkey, int rel) { Comparable&lt;? super K&gt; key = comparable(kkey); for (;;) { Node&lt;K,V&gt; b = findPredecessor(key); Node&lt;K,V&gt; n = b.next; for (;;) { if (n == null) return ((rel &amp; LT) == 0 || b.isBaseHeader())? null : b; Node&lt;K,V&gt; f = n.next; if (n != b.next) // inconsistent read break; Object v = n.value; if (v == null) { // n is deleted n.helpDelete(b, f); break; } if (v == n || b.value == null) // b is deleted break; int c = key.compareTo(n.key); if ((c == 0 &amp;&amp; (rel &amp; EQ) != 0) || (c &lt; 0 &amp;&amp; (rel &amp; LT) == 0)) return n; if ( c &lt;= 0 &amp;&amp; (rel &amp; LT) != 0) return (b.isBaseHeader())? null : b; b = n; n = f; } } } 123private static final int EQ = 1;private static final int LT = 2;private static final int GT = 0; // Actually checked as !LT 这个方法其实和findNode类似，都是从head开始先找到base_level的上给定key的前驱节点，然后再往后找。区别是这里传入关系参数-EQ、LT、GT(GT在代码里面没直接用，而是通过没有LT来判断)，我们可以通过lowerEntry方法来分析，lowerEntry方法中间接调用的findNear方法传入的是LT，所以当在findNear方法中定位到目标节点n的时候，节点关系是这样的：[b-&gt;n-&gt;f]，节点key和给定key的大小关系是这样的：[b&lt;k&lt;=n&lt;f]，所以代码会从findNear中的出口3(见注释)返回。 ConcurrentSkipListMap#floorEntry()123public Map.Entry&lt;K,V&gt; floorEntry(K key) { return getNear(key, LT|EQ);} floorEntry方法中间接调用的findNear方法传入的是LT|EQ，所以当在findNear方法中定位到目标节点n的时候，节点关系是这样的：[b-&gt;n-&gt;f]，节点key和给定key的大小关系是这样的：[b&lt;k&lt;=n&lt;f]，这里分两种情况：1.如果k&lt;n，那么会从出口3退出，返回b；2.如果k=n，那么会从出口2退出(满足条件(c == 0 &amp;&amp; (rel &amp; EQ) != 0))，返回n。 ConcurrentSkipListMap#ceilingEntry()123public Map.Entry&lt;K,V&gt; ceilingEntry(K key) { return getNear(key, GT|EQ);} ceilingEntry方法中间接调用的findNear方法传入的是GT|EQ，所以当在findNear方法中定位到目标节点n的时候，节点关系是这样的：[b-&gt;n-&gt;f]，节点key和给定key的大小关系是这样的：[b&lt;k&lt;=n&lt;f]，这里分两种情况：1.如果k&lt;n(k&gt;b)，那么会从出口2退出(满足条件(c &lt; 0 &amp;&amp; (rel &amp; LT) == 0))，返回b；2.如果k=n，那么也会从出口2退出(满足条件(c == 0 &amp;&amp; (rel &amp; EQ) != 0))，返回n。 ConcurrentSkipListMap#higherEntry()123public Map.Entry&lt;K,V&gt; higherEntry(K key) { return getNear(key, GT); } higherEntry方法中间接调用的findNear方法传入的是GT，所以当在findNear方法中定位到目标节点n的时候，节点关系是这样的：[b-&gt;n-&gt;f]，节点key和给定key的大小关系是这样的：[b&lt;k&lt;=n&lt;f]，这里分两种情况：1.如果k&lt;n，那么会从出口2退出(满足条件(c &lt; 0 &amp;&amp; (rel &amp; LT) == 0))，返回b；2.如果k=n，那么会进入下一次循环，关系变成这样：[b&lt;n=k&lt;f]，这时会从出口2退出(满足条件(c &lt; 0 &amp;&amp; (rel &amp; LT) == 0))，这时返回的是f。上面分析的所有方法，都会遇到在findNear中遇到n==null的可能，这时关系图如下[b&lt;k-null]，k一定大于b，所以只有传入LT，才可以返回b；否则都是null。而且如果b本身是BaseHead，也只能返回null。","link":"/JDK1.6-ConcurrentSkipListMap/"},{"title":"JDK1.6 Map#hash#key位运算","text":"1 详解 HashMap#indexFor() HashMap#hash() Redis2.4 HashMap redis 例 反编译 2 总结 1 详解HashMap#indexFor()1234567/** * Returns index for hash code h. */static int indexFor(int h, int length) { // 1 return h &amp; (length-1);} HashMap#hash()1234567891011121314/** * Applies a supplemental hash function to a given hashCode, which * defends against poor quality hash functions. This is critical * because HashMap uses power-of-two length hash tables, that * otherwise encounter collisions for hashCodes that do not differ * in lower bits. Note: Null keys always map to hash 0, thus index 0. */static int hash(int h) { // This function ensures that hashCodes that differ only by // constant multiples at each bit position have a bounded // number of collisions (approximately 8 at default load factor). h ^= (h &gt;&gt;&gt; 20) ^ (h &gt;&gt;&gt; 12); return h ^ (h &gt;&gt;&gt; 7) ^ (h &gt;&gt;&gt; 4);} Redis2.4123456789101112131415n.size = realsize; n.sizemask = realsize-1; ....hile(de) { unsigned int h; nextde = de-&gt;next; /* Get the index in the new hash table */ h = dictHashKey(d, de-&gt;key) &amp; d-&gt;ht[1].sizemask; de-&gt;next = d-&gt;ht[1].table[h]; d-&gt;ht[1].table[h] = de; d-&gt;ht[0].used--; d-&gt;ht[1].used++; de = nextde; } 标注代码分析 a%b取模的形式都被替换成了a&amp;(b-1) ，当hashtable的长度是2的幂的情况下，这两者是等价的。 hashtable的长度最好是2的n次方。保证：分布更均匀，碰撞几率更小。HashMap1234567891011121314151617181920212223242526272829/** * Constructs an empty &lt;tt&gt;HashMap&lt;/tt&gt; with the specified initial * capacity and load factor. * * @param initialCapacity the initial capacity * @param loadFactor the load factor * @throws IllegalArgumentException if the initial capacity is negative * or the load factor is nonpositive */ public HashMap(int initialCapacity, float loadFactor) { if (initialCapacity &lt; 0) throw new IllegalArgumentException(\"Illegal initial capacity: \" + initialCapacity); if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException(\"Illegal load factor: \" + loadFactor); // Find a power of 2 &gt;= initialCapacity int capacity = 1; while (capacity &lt; initialCapacity) capacity &lt;&lt;= 1; this.loadFactor = loadFactor; threshold = (int)(capacity * loadFactor); table = new Entry[capacity]; init(); } redis123456789101112/* Our hash table capability is a power of two */ static unsigned long _dictNextPower(unsigned long size) { unsigned long i = DICT_HT_INITIAL_SIZE; if (size &gt;= LONG_MAX) return LONG_MAX; while(1) { if (i &gt;= size) return i; i *= 2; } } 位运算的效率最高，这也是&amp;取代%的原因。 例123456789101112int main(int argc, char* argv[]) { int a = 0x111; int b = 0x222; int c = 0; int d = 0; c = a &amp; (b-1); d = a % b; return 0; } 反编译123456789101113: c = a &amp; (b-1); 00401044 mov eax,dword ptr [ebp-8] 00401047 sub eax,1 0040104A mov ecx,dword ptr [ebp-4] 0040104D and ecx,eax 0040104F mov dword ptr [ebp-0Ch],ecx 14: d = a % b; 00401052 mov eax,dword ptr [ebp-4] 00401055 cdq 00401056 idiv eax,dword ptr [ebp-8] 00401059 mov dword ptr [ebp-10h],edx 可以看到，&amp;操作用3mov+1and+1sub %操作用2mov+1cdp+1idiv。可以查阅Coding_ASM_-_Intel_Instruction_Set_Codes_and_Cycles资料，发现前者只需5个CPU周期，而后者至少需要26个CPU周期（注意，是最少！！！） 效率显而易见。所以以后在写的时候，也可以使用前者的写法。Coding_ASM_-_Intel_Instruction_Set_Codes_and_Cycles 2 总结当hashtable的长度是2的幂的情况下，a%b == a&amp;(b-1)。其他条件下，是不成立的。","link":"/JDK1.6-Map-hash-key/"},{"title":"深入理解Java内存模型(重排序)","text":"1 数据的依赖性 2 as-if-serial语义 3 程序顺序规则 4 重排序对多线程的影响 5 参考 1 数据的依赖性如果两个操作访问同一个变量，且这两个操作中有一个为写操作，此时这两个操作之间就存在数据依赖性。数据依赖分下列三种类型。上面三种情况，只要重排序两个操作的执行顺序，程序的执行结果将会被改变。前面提到过，编译器和处理器可能会对操作做重排序。编译器和处理器在重排序时，会遵守数据依赖性，编译器和处理器不会改变存在数据依赖关系的两个操作的执行顺序。注意，这里所说的数据依赖性仅针对单个处理器中执行的指令序列和单个线程中执行的操作，不同处理器之间和不同线程之间的数据依赖性不被编译器和处理器考虑。 2 as-if-serial语义as-if-serial语义的意思指：不管怎么重排序（编译器和处理器为了提高并行度），（单线程）程序的执行结果不能被改变。编译器，runtime和处理器都必须遵守as-if-serial语义。为了遵守as-if-serial语义，编译器和处理器不会对存在数据依赖关系的操作做重排序，因为这种重排序会改变执行结果。但是，如果操作之间不存在数据依赖关系，这些操作可能被编译器和处理器重排序。为了具体说明，请看下面计算圆面积的代码示例。123double pi = 3.14; //Adouble r = 1.0; //Bdouble area = pi * r * r; //C 上面三个操作的数据依赖关系如下图所示。如上图所示，A和C之间存在数据依赖关系，同时B和C之间也存在数据依赖关系。因此在最终执行的指令序列中，C不能被重排序到A和B的前面（C排到A和B的前面，程序的结果将会被改变）。但A和B之间没有数据依赖关系，编译器和处理器可以重排序A和B之间的执行顺序。下图是该程序的两种执行顺序。as-if-serial语义把单线程程序保护了起来，遵守as-if-serial语义的编译器，runtime和处理器共同为编写单线程程序的程序员创建了一个幻觉：单线程程序是按程序的顺序来执行的。as-if-serial语义使单线程程序员无需担心重排序会干扰他们，也无需担心内存可见性问题。 3 程序顺序规则根据happens-before的程序顺序规则，上面计算圆的面积的示例代码存在三个happens-before关系。 A happens-before B； B happens-before C； A happens-before C； 这里的第3个happens-before关系，是根据happens-before的传递性推导出来的。这里A happens-before B，但实际执行时B却可以排在A之前执行（看上面的重排序后的执行顺序）。在happens-before章提到过，如果A happens-before B，JMM并不要求A一定要在B之前执行。JMM仅仅要求前一个操作（执行的结果）对后一个操作可见，且前一个操作按顺序排在第二个操作之前。这里操作A的执行结果不需要对操作B可见；而且重排序操作A和操作B后的执行结果，与操作A和操作B按happens-before顺序执行的结果一致。在这种情况下，JMM会认为这种重排序并不非法（not illegal），JMM允许这种重排序。在计算机中，软件技术和硬件技术有一个共同的目标：在不改变程序执行结果的前提下，尽可能的开发并行度。编译器和处理器遵从这一目标，从happens-before的定义我们可以看出，JMM同样遵从这一目标。 4 重排序对多线程的影响现在让我们来看看，重排序是否会改变多线程程序的执行结果。请看下面的示例代码：12345678910111213141516class ReorderExample { int a = 0; boolean flag = false; public void writer() { a = 1; //1 flag = true; //2 } Public void reader() { if (flag) { //3 int i = a * a; //4 …… } }} flag变量是个标记，用来标识变量a是否已被写入。这里假设有两个线程A和B，A首先执行writer()，随后B线程接着执行reader()。线程B在执行操作4时，能否看到线程A在操作1对共享变量a的写入？答案是：不一定能看到。由于操作1和操作2没有数据依赖关系，编译器和处理器可以对这两个操作重排序；同样，操作3和操作4没有数据依赖关系，编译器和处理器也可以对这两个操作重排序。让我们先来看看，当操作1和操作2重排序时，可能会产生什么效果？请看下面的程序执行时序图。如上图所示，操作1和操作2做了重排序。程序执行时，线程A首先写标记变量flag，随后线程B读这个变量。由于条件判断为真，线程B将读取变量a。此时，变量a还根本没有被线程A写入，在这里多线程程序的语义被重排序破坏了！ ※注：本文统一用红色的虚箭线表示错误的读操作，用绿色的虚箭线表示正确的读操作。 下面再让我们看看，当操作3和操作4重排序时会产生什么效果（借助这个重排序，可以顺便说明控制依赖性）。下面是操作3和操作4重排序后，程序的执行时序图。在程序中，操作3和操作4存在控制依赖关系。当代码中存在控制依赖性时，会影响指令序列执行的并行度。为此，编译器和处理器会采用猜测（Speculation）执行来克服控制相关性对并行度的影响。以处理器的猜测执行为例，执行线程B的处理器可以提前读取并计算a*a，然后把计算结果临时保存到一个名为重排序缓冲（reorder buffer ROB）的硬件缓存中。当接下来操作3的条件判断为真时，就把该计算结果写入变量i中。从图中我们可以看出，猜测执行实质上对操作3和4做了重排序。重排序在这里破坏了多线程程序的语义！在单线程程序中，对存在控制依赖的操作重排序，不会改变执行结果（这也是as-if-serial语义允许对存在控制依赖的操作做重排序的原因）；但在多线程程序中，对存在控制依赖的操作重排序，可能会改变程序的执行结果。 5 参考 深入理解Java内存模型","link":"/JMM-2/"},{"title":"JDK1.6 ExecutorCompletionService","text":"1 介绍 2 源码分析 CompletionService() ExecutorCompletionService#QueueingFuture ExecutorCompletionService 构造函数 ExecutorCompletionService#newTaskFor() AbstractExecutorService#newTaskFor ExecutorCompletionService#submit() Executor 接口 ScheduledThreadPoolExecutor#execute() FutureTask#done() ExecutorCompletionService#QueueingFuture 1 介绍ExecutorCompletionService用于执行一批任务，然后按照任务执行完成的顺序来获取任务结果。可以在获取到了若干个执行结果后，把其他的任务取消掉(ThreadPoolExecutor中的invokeAny就是通过这货实现的)。比如这样的场景：你的业务需要调用10个接口来获取一些信息，业务规定只需要其中任意2个接口的信息，那么就可以使用ExecutorCompletionService，获取前两个成功完成的任务结果，然后将其他的任务取消。 2 源码分析ExecutorCompletionService实现CompletionService接口。 CompletionService()12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970public interface CompletionService&lt;V&gt; { /** * Submits a value-returning task for execution and returns a Future * representing the pending results of the task. Upon completion, * this task may be taken or polled. * * @param task the task to submit * @return a Future representing pending completion of the task * @throws RejectedExecutionException if the task cannot be * scheduled for execution * @throws NullPointerException if the task is null */ // 1 Future&lt;V&gt; submit(Callable&lt;V&gt; task); /** * Submits a Runnable task for execution and returns a Future * representing that task. Upon completion, this task may be * taken or polled. * * @param task the task to submit * @param result the result to return upon successful completion * @return a Future representing pending completion of the task, * and whose &lt;tt&gt;get()&lt;/tt&gt; method will return the given * result value upon completion * @throws RejectedExecutionException if the task cannot be * scheduled for execution * @throws NullPointerException if the task is null */ // 2 Future&lt;V&gt; submit(Runnable task, V result); /** * Retrieves and removes the Future representing the next * completed task, waiting if none are yet present. * * @return the Future representing the next completed task * @throws InterruptedException if interrupted while waiting */ // 3 Future&lt;V&gt; take() throws InterruptedException; /** * Retrieves and removes the Future representing the next * completed task or &lt;tt&gt;null&lt;/tt&gt; if none are present. * * @return the Future representing the next completed task, or * &lt;tt&gt;null&lt;/tt&gt; if none are present */ // 4 Future&lt;V&gt; poll(); /** * Retrieves and removes the Future representing the next * completed task, waiting if necessary up to the specified wait * time if none are yet present. * * @param timeout how long to wait before giving up, in units of * &lt;tt&gt;unit&lt;/tt&gt; * @param unit a &lt;tt&gt;TimeUnit&lt;/tt&gt; determining how to interpret the * &lt;tt&gt;timeout&lt;/tt&gt; parameter * @return the Future representing the next completed task or * &lt;tt&gt;null&lt;/tt&gt; if the specified waiting time elapses * before one is present * @throws InterruptedException if interrupted while waiting */ // 5 Future&lt;V&gt; poll(long timeout, TimeUnit unit) throws InterruptedException;} 标注代码分析 提交一个有返回值的任务。 提交一个Runnable和一个返回值。 获取并移除下一个完成的任务，如果当前没有任务完成，阻塞等待。 获取并移除下一个完成的任务，如果当前没有任务完成，返回null。 获取并移除下一个完成的任务，如果当前没有任务完成，阻塞等待，如果在超时前仍然没有任务完成，返回null。 ExecutorCompletionService#QueueingFuture1234567891011121314151617public class ExecutorCompletionService&lt;V&gt; implements CompletionService&lt;V&gt; { private final Executor executor; private final AbstractExecutorService aes; private final BlockingQueue&lt;Future&lt;V&gt;&gt; completionQueue; /** * FutureTask extension to enqueue upon completion */ private class QueueingFuture extends FutureTask&lt;Void&gt; { QueueingFuture(RunnableFuture&lt;V&gt; task) { super(task, null); this.task = task; } // 1 protected void done() { completionQueue.add(task); } private final Future&lt;V&gt; task; } 标注代码分析 异步任务完成后，将其放入完成队列。 QueueingFuture用来存放完成任务的阻塞队列。 ExecutorCompletionService 构造函数12345678910111213141516171819202122232425262728293031323334353637/** * Creates an ExecutorCompletionService using the supplied * executor for base task execution and a * {@link LinkedBlockingQueue} as a completion queue. * * @param executor the executor to use * @throws NullPointerException if executor is &lt;tt&gt;null&lt;/tt&gt; */ public ExecutorCompletionService(Executor executor) { if (executor == null) throw new NullPointerException(); this.executor = executor; this.aes = (executor instanceof AbstractExecutorService) ? (AbstractExecutorService) executor : null; this.completionQueue = new LinkedBlockingQueue&lt;Future&lt;V&gt;&gt;(); } /** * Creates an ExecutorCompletionService using the supplied * executor for base task execution and the supplied queue as its * completion queue. * * @param executor the executor to use * @param completionQueue the queue to use as the completion queue * normally one dedicated for use by this service * @throws NullPointerException if executor or completionQueue are &lt;tt&gt;null&lt;/tt&gt; */ public ExecutorCompletionService(Executor executor, BlockingQueue&lt;Future&lt;V&gt;&gt; completionQueue) { if (executor == null || completionQueue == null) throw new NullPointerException(); this.executor = executor; // 1 this.aes = (executor instanceof AbstractExecutorService) ? (AbstractExecutorService) executor : null; this.completionQueue = completionQueue; } 标注代码分析1.在ExecutorCompletionService#newTaskFor()中aes作用是生成FutureTask对象。 ExecutorCompletionService#newTaskFor()12345678910111213private RunnableFuture&lt;V&gt; newTaskFor(Callable&lt;V&gt; task) { if (aes == null) return new FutureTask&lt;V&gt;(task); else return aes.newTaskFor(task);}private RunnableFuture&lt;V&gt; newTaskFor(Runnable task, V result) { if (aes == null) return new FutureTask&lt;V&gt;(task, result); else return aes.newTaskFor(task, result);} 生成FutureTask对象。 AbstractExecutorService#newTaskFor12345678910111213/** * Returns a &lt;tt&gt;RunnableFuture&lt;/tt&gt; for the given callable task. * * @param callable the callable task being wrapped * @return a &lt;tt&gt;RunnableFuture&lt;/tt&gt; which when run will call the * underlying callable and which, as a &lt;tt&gt;Future&lt;/tt&gt;, will yield * the callable's result as its result and provide for * cancellation of the underlying task. * @since 1.6 */protected &lt;T&gt; RunnableFuture&lt;T&gt; newTaskFor(Callable&lt;T&gt; callable) { return new FutureTask&lt;T&gt;(callable);} ExecutorCompletionService#submit()12345678910111213public Future&lt;V&gt; submit(Callable&lt;V&gt; task) { if (task == null) throw new NullPointerException(); RunnableFuture&lt;V&gt; f = newTaskFor(task); executor.execute(new QueueingFuture(f)); return f;}public Future&lt;V&gt; submit(Runnable task, V result) { if (task == null) throw new NullPointerException(); RunnableFuture&lt;V&gt; f = newTaskFor(task, result); executor.execute(new QueueingFuture(f)); return f;} 任务会在submit()被包装成QueueingFuture对象，由Executor#execute()执行，任务执行完成后，会被加入到内部的队列里面，外部程序就可以通过take或者poll方法来获取完成的任务了。 Executor 接口1234567891011121314public interface Executor { /** * Executes the given command at some time in the future. The command * may execute in a new thread, in a pooled thread, or in the calling * thread, at the discretion of the &lt;tt&gt;Executor&lt;/tt&gt; implementation. * * @param command the runnable task * @throws RejectedExecutionException if this task cannot be * accepted for execution. * @throws NullPointerException if command is null */ void execute(Runnable command);} 如下图所示，ScheduledThreadPoolExecutor实现Executor，覆写execute。 ScheduledThreadPoolExecutor#execute()123456789101112131415161718/** * Executes command with zero required delay. This has effect * equivalent to &lt;tt&gt;schedule(command, 0, anyUnit)&lt;/tt&gt;. Note * that inspections of the queue and of the list returned by * &lt;tt&gt;shutdownNow&lt;/tt&gt; will access the zero-delayed * {@link ScheduledFuture}, not the &lt;tt&gt;command&lt;/tt&gt; itself. * * @param command the task to execute * @throws RejectedExecutionException at discretion of * &lt;tt&gt;RejectedExecutionHandler&lt;/tt&gt;, if task cannot be accepted * for execution because the executor has been shut down. * @throws NullPointerException if command is null */public void execute(Runnable command) { if (command == null) throw new NullPointerException(); schedule(command, 0, TimeUnit.NANOSECONDS);} 调用ScheduledThreadPoolExecutor#schedule(),创建延迟任务，并且执行它。返回ScheduledFutureTask对象。根据JDK1.6 ScheduledThreadPoolExecutor那篇文章，可以知道ScheduledFutureTask继承FutureTask，FutureTask#done()可以知道，任务执行完成后可以覆写此方法(done())。作为callbacks。 FutureTask#done()12345678910/** * Protected method invoked when this task transitions to state * &lt;tt&gt;isDone&lt;/tt&gt; (whether normally or via cancellation). The * default implementation does nothing. Subclasses may override * this method to invoke completion callbacks or perform * bookkeeping. Note that you can query status inside the * implementation of this method to determine whether this task * has been cancelled. */protected void done() { } Subclasses may override this method to invoke completion callbacks or perform bookkeeping. ExecutorCompletionService#QueueingFuture1234567891011/** * FutureTask extension to enqueue upon completion */private class QueueingFuture extends FutureTask&lt;Void&gt; { QueueingFuture(RunnableFuture&lt;V&gt; task) { super(task, null); this.task = task; } protected void done() { completionQueue.add(task); } private final Future&lt;V&gt; task;} QueueingFuture#done()覆写FutureTask#done(),把完成任务添加到BlockingQueue。通过take(),poll()获取任务。1234567891011public Future&lt;V&gt; take() throws InterruptedException { return completionQueue.take();}public Future&lt;V&gt; poll() { return completionQueue.poll();}public Future&lt;V&gt; poll(long timeout, TimeUnit unit) throws InterruptedException { return completionQueue.poll(timeout, unit);}","link":"/JDK1.6-ExecutorCompletionService/"},{"title":"JDK1.6 LinkedBlockingQueue","text":"1 介绍 2 源码分析 LinkedBlockingQueue LinkedBlockingQueue#put() LinkedBlockingQueue#enqueue() LinkedBlockingQueue#signalNotEmpty() LinkedBlockingQueue#take() LinkedBlockingQueue#dequeue() LinkedBlockingQueue#signalNotFull() LinkedBlockingQueue#remove() LinkedBlockingQueue#fullyLock() LinkedBlockingQueue#fullyUnlock() 1 介绍LinkedBlockingQueue是一种基于单向链表实现的有界的(可选的，不指定默认int最大值)阻塞队列。队列中的元素遵循先入先出(FIFO)的规则。新元素插入到队列的尾部，从队列头部取出元素。(在并发程序中，基于链表实现的队列和基于数组实现的队列相比，往往具有更高的吞吐量，但性能稍差一些) 2 源码分析LinkedBlockingQueue123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187public class LinkedBlockingQueue&lt;E&gt; extends AbstractQueue&lt;E&gt; implements BlockingQueue&lt;E&gt;, java.io.Serializable { private static final long serialVersionUID = -6903933977591709194L; /* * A variant of the \"two lock queue\" algorithm. The putLock gates * entry to put (and offer), and has an associated condition for * waiting puts. Similarly for the takeLock. The \"count\" field * that they both rely on is maintained as an atomic to avoid * needing to get both locks in most cases. Also, to minimize need * for puts to get takeLock and vice-versa, cascading notifies are * used. When a put notices that it has enabled at least one take, * it signals taker. That taker in turn signals others if more * items have been entered since the signal. And symmetrically for * takes signalling puts. Operations such as remove(Object) and * iterators acquire both locks. * * ..... */ /** * Linked list node class */ static class Node&lt;E&gt; { E item; /** * One of: * - the real successor Node * - this Node, meaning the successor is head.next * - null, meaning there is no successor (this is the last node) */ Node&lt;E&gt; next; Node(E x) { item = x; } } /** The capacity bound, or Integer.MAX_VALUE if none */ private final int capacity; /** Current number of elements */ private final AtomicInteger count = new AtomicInteger(0); /** Head of linked list */ private transient Node&lt;E&gt; head; /** Tail of linked list */ private transient Node&lt;E&gt; last; /** Lock held by take, poll, etc */ private final ReentrantLock takeLock = new ReentrantLock(); /** Wait queue for waiting takes */ private final Condition notEmpty = takeLock.newCondition(); /** Lock held by put, offer, etc */ private final ReentrantLock putLock = new ReentrantLock(); /** Wait queue for waiting puts */ private final Condition notFull = putLock.newCondition(); /** * Signals a waiting take. Called only from put/offer (which do not * otherwise ordinarily lock takeLock.) */ private void signalNotEmpty() { final ReentrantLock takeLock = this.takeLock; takeLock.lock(); try { notEmpty.signal(); } finally { takeLock.unlock(); } } /** * Signals a waiting put. Called only from take/poll. */ private void signalNotFull() { final ReentrantLock putLock = this.putLock; putLock.lock(); try { notFull.signal(); } finally { putLock.unlock(); } } /** * Creates a node and links it at end of queue. * @param x the item */ private void enqueue(E x) { // assert putLock.isHeldByCurrentThread(); last = last.next = new Node&lt;E&gt;(x); } /** * Removes a node from head of queue. * @return the node */ private E dequeue() { // assert takeLock.isHeldByCurrentThread(); Node&lt;E&gt; h = head; Node&lt;E&gt; first = h.next; h.next = h; // help GC head = first; E x = first.item; first.item = null; return x; } /** * Lock to prevent both puts and takes. */ void fullyLock() { putLock.lock(); takeLock.lock(); } /** * Unlock to allow both puts and takes. */ void fullyUnlock() { takeLock.unlock(); putLock.unlock(); } /** * Tells whether both locks are held by current thread. */ boolean isFullyLocked() { return (putLock.isHeldByCurrentThread() &amp;&amp; takeLock.isHeldByCurrentThread()); } /** * Creates a &lt;tt&gt;LinkedBlockingQueue&lt;/tt&gt; with a capacity of * {@link Integer#MAX_VALUE}. */ public LinkedBlockingQueue() { this(Integer.MAX_VALUE); } /** * Creates a &lt;tt&gt;LinkedBlockingQueue&lt;/tt&gt; with the given (fixed) capacity. * * @param capacity the capacity of this queue * @throws IllegalArgumentException if &lt;tt&gt;capacity&lt;/tt&gt; is not greater * than zero */ public LinkedBlockingQueue(int capacity) { if (capacity &lt;= 0) throw new IllegalArgumentException(); this.capacity = capacity; last = head = new Node&lt;E&gt;(null); } /** * Creates a &lt;tt&gt;LinkedBlockingQueue&lt;/tt&gt; with a capacity of * {@link Integer#MAX_VALUE}, initially containing the elements of the * given collection, * added in traversal order of the collection's iterator. * * @param c the collection of elements to initially contain * @throws NullPointerException if the specified collection or any * of its elements are null */ public LinkedBlockingQueue(Collection&lt;? extends E&gt; c) { this(Integer.MAX_VALUE); final ReentrantLock putLock = this.putLock; putLock.lock(); // Never contended, but necessary for visibility try { int n = 0; for (E e : c) { if (e == null) throw new NullPointerException(); if (n == capacity) throw new IllegalStateException(\"Queue full\"); enqueue(e); ++n; } count.set(n); } finally { putLock.unlock(); } } ... takeLock对take(), poll()的锁。putLock()对put(), offer()的锁。 LinkedBlockingQueue#put()1234567891011121314151617181920212223242526272829303132333435363738394041/** * Inserts the specified element at the tail of this queue, waiting if * necessary for space to become available. * * @throws InterruptedException {@inheritDoc} * @throws NullPointerException {@inheritDoc} */ public void put(E e) throws InterruptedException { if (e == null) throw new NullPointerException(); // Note: convention in all put/take/etc is to preset local var // holding count negative to indicate failure unless set. int c = -1; final ReentrantLock putLock = this.putLock; final AtomicInteger count = this.count; putLock.lockInterruptibly(); try { /* * Note that count is used in wait guard even though it is * not protected by lock. This works because count can * only decrease at this point (all other puts are shut * out by lock), and we (or some other waiting put) are * signalled if it ever changes from * capacity. Similarly for all other uses of count in * other wait guards. */ // 1 while (count.get() == capacity) { notFull.await(); } enqueue(e); c = count.getAndIncrement(); // 2 if (c + 1 &lt; capacity) notFull.signal(); } finally { putLock.unlock(); } // 3 if (c == 0) signalNotEmpty(); } 标注代码分析 检查当前容量，如果当前没有线程，则等待。 c+1表示新增element，如果还没有达到capacity，唤醒notFull条件上等待的线程。 c初始-1，由-1到0，队列是空的情况下插入了1个元素，唤醒notNull条件上等待的线程。 LinkedBlockingQueue#enqueue()12345678/** * Creates a node and links it at end of queue. * @param x the item */ private void enqueue(E x) { // assert putLock.isHeldByCurrentThread(); last = last.next = new Node&lt;E&gt;(x); } LinkedBlockingQueue#signalNotEmpty()12345678910111213/** * Signals a waiting take. Called only from put/offer (which do not * otherwise ordinarily lock takeLock.) */private void signalNotEmpty() { final ReentrantLock takeLock = this.takeLock; takeLock.lock(); try { notEmpty.signal(); } finally { takeLock.unlock(); }} LinkedBlockingQueue#take()123456789101112131415161718192021public E take() throws InterruptedException { E x; int c = -1; final AtomicInteger count = this.count; final ReentrantLock takeLock = this.takeLock; takeLock.lockInterruptibly(); try { while (count.get() == 0) { notEmpty.await(); } x = dequeue(); c = count.getAndDecrement(); if (c &gt; 1) notEmpty.signal(); } finally { takeLock.unlock(); } if (c == capacity) signalNotFull(); return x; } LinkedBlockingQueue#dequeue()1234567891011121314/** * Removes a node from head of queue. * @return the node */ private E dequeue() { // assert takeLock.isHeldByCurrentThread(); Node&lt;E&gt; h = head; Node&lt;E&gt; first = h.next; h.next = h; // help GC head = first; E x = first.item; first.item = null; return x; } LinkedBlockingQueue#signalNotFull()123456789101112/** * Signals a waiting put. Called only from take/poll. */private void signalNotFull() { final ReentrantLock putLock = this.putLock; putLock.lock(); try { notFull.signal(); } finally { putLock.unlock(); }} take()代码原理和put()类似。 LinkedBlockingQueue#remove()12345678910111213141516171819202122232425262728/** * Removes a single instance of the specified element from this queue, * if it is present. More formally, removes an element &lt;tt&gt;e&lt;/tt&gt; such * that &lt;tt&gt;o.equals(e)&lt;/tt&gt;, if this queue contains one or more such * elements. * Returns &lt;tt&gt;true&lt;/tt&gt; if this queue contained the specified element * (or equivalently, if this queue changed as a result of the call). * * @param o element to be removed from this queue, if present * @return &lt;tt&gt;true&lt;/tt&gt; if this queue changed as a result of the call */ public boolean remove(Object o) { if (o == null) return false; fullyLock(); try { for (Node&lt;E&gt; trail = head, p = trail.next; p != null; trail = p, p = p.next) { if (o.equals(p.item)) { unlink(p, trail); return true; } } return false; } finally { fullyUnlock(); } } LinkedBlockingQueue#fullyLock()1234567/** * Lock to prevent both puts and takes. */void fullyLock() { putLock.lock(); takeLock.lock();} LinkedBlockingQueue#fullyUnlock()1234567/** * Unlock to allow both puts and takes. */void fullyUnlock() { takeLock.unlock(); putLock.unlock();} 保证原子性，做remove()操作，把take()，poll()，put()，offer()都加上锁。","link":"/JDK1.6-LinkedBlockingQueue/"},{"title":"JDK1.6 ReentrantLock","text":"1 介绍 优势 缺点 2 源码分析 Lock ReentrantLock#Sync ReentrantLock#Sync#nonfairTryAcquire() ReentrantLock#Sync#tryRelease() ReentrantLock#NonfairSync ReentrantLock#FairSync ReentrantLock构造方法 ReentrantLock#getHoldCount() 3 总结 1 介绍ReentrantLock和Synchronized一样都是可重入的。ReentrantLock与Synchronized相比较而言。 优势支持公平/非公平锁、支持可中断的锁、支持非阻塞的tryLock(可超时)、支持锁条件、可跨代码块使用(一个地方加锁，另一个地方解锁)，总之比Synchronized更加灵活。 缺点锁需要显示解锁、无法充分享用JVM内部性能提升带来的好处等等。 2 源码分析ReentrantLock实现Lock接口。 Lock12345678910111213public interface Lock { // 1 void lock(); // 2 void lockInterruptibly() throws InterruptedException; // 3 boolean tryLock(); // 4 boolean tryLock(long time, TimeUnit unit) throws InterruptedException; void unlock(); Condition newCondition();} 标注代码分析 获取锁，如果锁无法获取，当前线程被阻塞，直到锁可以获取并获取成功为止。 在当前线程没有被中断的情况下获取锁。如果锁无法获取，当前线程被阻塞，阻塞获取锁或者中断。此处有抛出InterruptedException。 尝试获取锁。 有超时时间和抛出InterruptedException。在指定时间内获取锁或者线程中断。 ReentrantLock#Sync123456/** * Base of synchronization control for this lock. Subclassed * into fair and nonfair versions below. Uses AQS state to * represent the number of holds on the lock. */ static abstract class Sync extends AbstractQueuedSynchronizer 根据注释，可以知道公平锁和非公平锁继承Sync。使用AQS state表示当前持有锁的重入数量。 ReentrantLock#Sync#nonfairTryAcquire()12345678910111213141516171819202122232425/** * Performs non-fair tryLock. tryAcquire is * implemented in subclasses, but both need nonfair * try for trylock method. */final boolean nonfairTryAcquire(int acquires) { final Thread current = Thread.currentThread(); // 1 int c = getState(); // 2 if (c == 0) { if (compareAndSetState(0, acquires)) { setExclusiveOwnerThread(current); return true; } } else if (current == getExclusiveOwnerThread()) {// 3 int nextc = c + acquires; if (nextc &lt; 0) // overflow throw new Error(\"Maximum lock count exceeded\"); setState(nextc); return true; } return false;} 标注代码分析 AbstractQueuedSynchronizer#state作为持有锁的数量。相当于重入次数。 通过CAS设置state获取锁，AbstractQueuedSynchronizer#setExclusiveOwnerThread()设置当前线程为锁的持有者。 如果当前线程是锁的持有者，叠加重入次数。重新设置锁重入次数到AbstractQueuedSynchronizer#state。这也是重入锁的核心，如果当前线程已经持有锁，并且计数值c &gt; 0，这就可以再次获取到锁。 ReentrantLock#Sync#tryRelease()123456789101112131415protected final boolean tryRelease(int releases) { // 1 int c = getState() - releases; // 2 if (Thread.currentThread() != getExclusiveOwnerThread()) throw new IllegalMonitorStateException(); boolean free = false; // 3 if (c == 0) { free = true; setExclusiveOwnerThread(null); } setState(c); return free;} 标注代码分析 锁持有线程重入次数c。 当前线程不是锁持有线程，抛出IllegalMonitorStateException。 锁持有线程重入次数 = 0，设置AbstractQueuedSynchronizer#exclusiveOwnerThread = null，AQS锁持有者是null。 ReentrantLock#NonfairSync非公平锁1234567891011121314151617181920212223/** * Sync object for non-fair locks */final static class NonfairSync extends Sync { private static final long serialVersionUID = 7316153563782823691L; /** * Performs lock. Try immediate barge, backing up to normal * acquire on failure. */ final void lock() { // 1 if (compareAndSetState(0, 1)) setExclusiveOwnerThread(Thread.currentThread()); else acquire(1); } // 2 protected final boolean tryAcquire(int acquires) { return nonfairTryAcquire(acquires); }} 标注代码分析 非公平锁的核心代码，compareAndSetState(0, 1)CAS抢占0，如果这时锁的计数是0，0表示没有其他线程竞争，当前线程竞争锁成功，设置当前线程为锁的持有者。否则调用AbstractQueuedSynchronizer#acquire()。 调用Sync#nonfairTryAcquire()尝试获取锁。 ReentrantLock#FairSync公平锁123456789101112131415161718192021222324252627282930313233343536/** * Sync object for fair locks */ final static class FairSync extends Sync { private static final long serialVersionUID = -3000897897090466540L; final void lock() { acquire(1); } /** * Fair version of tryAcquire. Don't grant access unless * recursive call or no waiters or is first. */ // 1 protected final boolean tryAcquire(int acquires) { final Thread current = Thread.currentThread(); int c = getState(); // 2 if (c == 0) { if (isFirst(current) &amp;&amp; compareAndSetState(0, acquires)) { setExclusiveOwnerThread(current); return true; } } else if (current == getExclusiveOwnerThread()) {// 3 int nextc = c + acquires; if (nextc &lt; 0) throw new Error(\"Maximum lock count exceeded\"); setState(nextc); return true; } return false; } } 标注代码分析 根据注释说，公平锁只有在递归方法（重入锁）、非等待队列、队列第1个，才能获取到锁。 AbstractQueuedSynchronizer#isFirst(current)根据注释queue is empty or if the given thread is at the head of the queue判断是否是队列中第1个。如果是队列中第1个线程且竞争到锁，设置AbstractQueuedSynchronizer#exclusiveOwnerThread作为锁的持有者。 当前线程是AbstractQueuedSynchronizer#锁的持有者，叠加重入计数。重入锁的核心，原来同ReentrantLock#Sync#nonfairTryAcquire()一样。 公平锁和ReentrantLock#Sync#nonfairTryAcquire()非公平锁获取锁的区别就在isFirst(current),公平锁需要判断是否是线程队列的第1个。ReentrantLock通过sync来实现锁操作。 ReentrantLock构造方法1234567891011121314151617/** * Creates an instance of {@code ReentrantLock}. * This is equivalent to using {@code ReentrantLock(false)}. */ public ReentrantLock() { sync = new NonfairSync(); } /** * Creates an instance of {@code ReentrantLock} with the * given fairness policy. * * @param fair {@code true} if this lock should use a fair ordering policy */ public ReentrantLock(boolean fair) { sync = (fair)? new FairSync() : new NonfairSync(); } 默认是非公平锁。 ReentrantLock#getHoldCount()1234567/** * Queries the number of holds on this lock by the current thread. ... */ public int getHoldCount() { return sync.getHoldCount(); } 当前线程持有这锁的次数。通俗的说就是重入次数。 3 总结","link":"/JDK1.6-ReentrantLock/"},{"title":"JDK1.7 Proxy","text":"Proxy 1.7 1 变量定义 2 newProxyInstance 3 getProxyClass 4 Other Code Proxy 1.7以下源码分析取核心代码 1 变量定义1234567891011121314151617181920212223 /** prefix for all proxy class names */ // #1 private final static String proxyClassNamePrefix = \"$Proxy\"; /** parameter types of a proxy class constructor */ private final static Class[] constructorParams = { InvocationHandler.class }; /** maps a class loader to the proxy class cache for that loader */ // #2 private static Map loaderToCache = new WeakHashMap(); /** marks that a particular proxy class is currently being generated */// #3 private static Object pendingGenerationMarker = new Object(); /** next number to use for generation of unique proxy class names */ private static long nextUniqueNumber = 0; private static Object nextUniqueNumberLock = new Object(); /** set of all generated proxy classes, for isProxyClass implementation */// #4 private static Map proxyClasses = Collections.synchronizedMap(new WeakHashMap()); 标注代码分析： 定义代理类名字前缀。 定义弱引用，以ClassLoader loader做为key，定义一个class load 缓存。 为了生成代理类，初始化的cache时候，一直存在的“临时”对象。 proxyClass的缓存，key存储proxy class，value存储null，用于判断是否是代理类。 2 newProxyInstance12345678910111213141516171819202122232425262728 public static Object newProxyInstance(ClassLoader loader, Class&lt;?&gt;[] interfaces, InvocationHandler h) ..... /* 5. Look up or generate the designated proxy class. */ // #1 Class cl = getProxyClass(loader, interfaces); /* 6. Invoke its constructor with the designated invocation handler. */ try { // #2 Constructor cons = cl.getConstructor(constructorParams); return (Object) cons.newInstance(new Object[] { h }); } catch (NoSuchMethodException e) { throw new InternalError(e.toString()); } catch (IllegalAccessException e) { throw new InternalError(e.toString()); } catch (InstantiationException e) { throw new InternalError(e.toString()); } catch (InvocationTargetException e) { throw new InternalError(e.toString()); }} 生成proxy class的$Proxy0。 生成$Proxy0的构造函数。 3 getProxyClass123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225 public static Class&lt;?&gt; getProxyClass(ClassLoader loader, Class&lt;?&gt;... interfaces) throws IllegalArgumentException { if (interfaces.length &gt; 65535) { throw new IllegalArgumentException(\"interface limit exceeded\"); } Class proxyClass = null; /* collect interface names to use as key for proxy class cache */ // #1 String[] interfaceNames = new String[interfaces.length]; Set interfaceSet = new HashSet(); // for detecting duplicates for (int i = 0; i &lt; interfaces.length; i++) { /* * Verify that the class loader resolves the name of this * interface to the same Class object. */ String interfaceName = interfaces[i].getName(); Class interfaceClass = null; try { // #2 interfaceClass = Class.forName(interfaceName, false, loader); } catch (ClassNotFoundException e) { } // #3 if (interfaceClass != interfaces[i]) { throw new IllegalArgumentException( interfaces[i] + \" is not visible from class loader\"); } /* * Verify that the Class object actually represents an * interface. */ if (!interfaceClass.isInterface()) { throw new IllegalArgumentException( interfaceClass.getName() + \" is not an interface\"); } /* * Verify that this interface is not a duplicate. */ // #4 if (interfaceSet.contains(interfaceClass)) { throw new IllegalArgumentException( \"repeated interface: \" + interfaceClass.getName()); } interfaceSet.add(interfaceClass); interfaceNames[i] = interfaceName; } /* * Using string representations of the proxy interfaces as * keys in the proxy class cache (instead of their Class * objects) is sufficient because we require the proxy * interfaces to be resolvable by name through the supplied * class loader, and it has the advantage that using a string * representation of a class makes for an implicit weak * reference to the class. */ Object key = Arrays.asList(interfaceNames); /* * Find or create the proxy class cache for the class loader. */ Map cache;// #5 synchronized (loaderToCache) { // #6 cache = (Map) loaderToCache.get(loader); if (cache == null) { cache = new HashMap(); loaderToCache.put(loader, cache); } /* * This mapping will remain valid for the duration of this * method, without further synchronization, because the mapping * will only be removed if the class loader becomes unreachable. */ } /* * Look up the list of interfaces in the proxy class cache using * the key. This lookup will result in one of three possible * kinds of values: * null, if there is currently no proxy class for the list of * interfaces in the class loader, * the pendingGenerationMarker object, if a proxy class for the * list of interfaces is currently being generated, * or a weak reference to a Class object, if a proxy class for * the list of interfaces has already been generated. */// #7 synchronized (cache) { /* * Note that we need not worry about reaping the cache for * entries with cleared weak references because if a proxy class * has been garbage collected, its class loader will have been * garbage collected as well, so the entire cache will be reaped * from the loaderToCache map. */ do { // #8 Object value = cache.get(key); if (value instanceof Reference) { proxyClass = (Class) ((Reference) value).get(); } if (proxyClass != null) { // proxy class already generated: return it return proxyClass; // #9 } else if (value == pendingGenerationMarker) { // proxy class being generated: wait for it try { cache.wait(); } catch (InterruptedException e) { /* * The class generation that we are waiting for should * take a small, bounded time, so we can safely ignore * thread interrupts here. */ } continue; } else { /* * No proxy class for this list of interfaces has been * generated or is being generated, so we will go and * generate it now. Mark it as pending generation. */ // #10 cache.put(key, pendingGenerationMarker); break; } } while (true); } try { String proxyPkg = null; // package to define proxy class in /* * Record the package of a non-public proxy interface so that the * proxy class will be defined in the same package. Verify that * all non-public proxy interfaces are in the same package. */ for (int i = 0; i &lt; interfaces.length; i++) { int flags = interfaces[i].getModifiers(); if (!Modifier.isPublic(flags)) { String name = interfaces[i].getName(); int n = name.lastIndexOf('.'); String pkg = ((n == -1) ? \"\" : name.substring(0, n + 1)); if (proxyPkg == null) { proxyPkg = pkg; } else if (!pkg.equals(proxyPkg)) { throw new IllegalArgumentException( \"non-public interfaces from different packages\"); } } } if (proxyPkg == null) { // if no non-public proxy interfaces, proxyPkg = \"\"; // use the unnamed package } { /* * Choose a name for the proxy class to generate. */ long num; synchronized (nextUniqueNumberLock) { num = nextUniqueNumber++; } String proxyName = proxyPkg + proxyClassNamePrefix + num; /* * Verify that the class loader hasn't already * defined a class with the chosen name. */ /* * Generate the specified proxy class. */ byte[] proxyClassFile = ProxyGenerator.generateProxyClass(proxyName, interfaces); try { //native proxyClass = defineClass0(loader, proxyName, proxyClassFile, 0, proxyClassFile.length); } catch (ClassFormatError e) { /* * A ClassFormatError here means that (barring bugs in the * proxy class generation code) there was some other * invalid aspect of the arguments supplied to the proxy * class creation (such as virtual machine limitations * exceeded). */ throw new IllegalArgumentException(e.toString()); } } // add to set of all generated proxy classes, for isProxyClass // #11 proxyClasses.put(proxyClass, null); } finally { /* * We must clean up the \"pending generation\" state of the proxy * class cache entry somehow. If a proxy class was successfully * generated, store it in the cache (with a weak reference); * otherwise, remove the reserved entry. In all cases, notify * all waiters on reserved entries in this cache. */ // #12 synchronized (cache) { if (proxyClass != null) { cache.put(key, new WeakReference(proxyClass)); } else { cache.remove(key); } cache.notifyAll(); } } return proxyClass; } 标注代码分析： 接口数组做为缓存的key。 proxy接口的class。 验证1。 验证2，检查proxyClass接口重复性，已经重复的接口不再放入interfaceNames数组中。 同步ClassLoader缓存，查询loader的缓存集合。 根据ClassLoader查找缓存。 cache是loader的缓存集合，同步代码块里cache获取proxyClass。 缓存对象value，此时的value，有可能是Object(pendingGenerationMarker)或者WeakReference对象，后续根据不同的value值，进行不同逻辑判断。 因为初始化对象是pendingGenerationMarker，此时value对象相等，说明正在生成proxyClass对象，进行等待，结束本次循环。 proxyClass is null，cache初始化默认value值pendingGenerationMarker。 proxyClass创建完毕，放入缓存。 proxyClass创建失败，清除cache中value = pendingGenerationMarker的值。 由以上得知Java动态代理只能代理接口。 4 Other Code12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182/** * Returns an instance of a proxy class for the specified interfaces * that dispatches method invocations to the specified invocation * handler. This method is equivalent to: * &lt;pre&gt; * Proxy.getProxyClass(loader, interfaces). * getConstructor(new Class[] { InvocationHandler.class }). * newInstance(new Object[] { handler }); * &lt;/pre&gt; * * &lt;p&gt;&lt;code&gt;Proxy.newProxyInstance&lt;/code&gt; throws * &lt;code&gt;IllegalArgumentException&lt;/code&gt; for the same reasons that * &lt;code&gt;Proxy.getProxyClass&lt;/code&gt; does. * * @param loader the class loader to define the proxy class * @param interfaces the list of interfaces for the proxy class * to implement * @param h the invocation handler to dispatch method invocations to * @return a proxy instance with the specified invocation handler of a * proxy class that is defined by the specified class loader * and that implements the specified interfaces * @throws IllegalArgumentException if any of the restrictions on the * parameters that may be passed to &lt;code&gt;getProxyClass&lt;/code&gt; * are violated * @throws NullPointerException if the &lt;code&gt;interfaces&lt;/code&gt; array * argument or any of its elements are &lt;code&gt;null&lt;/code&gt;, or * if the invocation handler, &lt;code&gt;h&lt;/code&gt;, is * &lt;code&gt;null&lt;/code&gt; */ public static Object newProxyInstance(ClassLoader loader, Class&lt;?&gt;[] interfaces, InvocationHandler h) throws IllegalArgumentException { if (h == null) { throw new NullPointerException(); } /* * Look up or generate the designated proxy class. */ // #1 Class cl = getProxyClass(loader, interfaces); /* * Invoke its constructor with the designated invocation handler. */ try { Constructor cons = cl.getConstructor(constructorParams); return (Object) cons.newInstance(new Object[] { h }); } catch (NoSuchMethodException e) { throw new InternalError(e.toString()); } catch (IllegalAccessException e) { throw new InternalError(e.toString()); } catch (InstantiationException e) { throw new InternalError(e.toString()); } catch (InvocationTargetException e) { throw new InternalError(e.toString()); } } /** * Returns true if and only if the specified class was dynamically * generated to be a proxy class using the &lt;code&gt;getProxyClass&lt;/code&gt; * method or the &lt;code&gt;newProxyInstance&lt;/code&gt; method. * * &lt;p&gt;The reliability of this method is important for the ability * to use it to make security decisions, so its implementation should * not just test if the class in question extends &lt;code&gt;Proxy&lt;/code&gt;. * * @param cl the class to test * @return &lt;code&gt;true&lt;/code&gt; if the class is a proxy class and * &lt;code&gt;false&lt;/code&gt; otherwise * @throws NullPointerException if &lt;code&gt;cl&lt;/code&gt; is &lt;code&gt;null&lt;/code&gt; */ public static boolean isProxyClass(Class&lt;?&gt; cl) { if (cl == null) { throw new NullPointerException(); } return proxyClasses.containsKey(cl); } 标注代码分析： 生成指定接口的proxClass对象。","link":"/JDK1.7-Proxy/"},{"title":"JDK1.6 LinkedBlockingDeque","text":"1 介绍 2 源码分析 LinkedBlockingDeque LinkedBlockingDeque#linkFirst() LinkedBlockingDeque#linkLast() LinkedBlockingDeque#unlinkFirst() LinkedBlockingDeque#unlinkLast() LinkedBlockingDeque#unlink() LinkedBlockingDeque#putFirst() LinkedBlockingDeque#putLast() LinkedBlockingDeque#takeFirst() LinkedBlockingDeque#takeLast() LinkedBlockingDeque#iterator() LinkedBlockingDeque#Itr 1 介绍LinkedBlockingDeque是一种基于双向链表实现的有界的(可选的，不指定默认int最大值)阻塞双端队列。双端队列一般适用于工作密取模式，即每个消费者都拥有自己的双端队列，如果某个消费者完成了自己队列的全部任务，可以到其他消费者双端队列尾部秘密获取任务来处理。 2 源码分析LinkedBlockingDeque123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104public class LinkedBlockingDeque&lt;E&gt; extends AbstractQueue&lt;E&gt; implements BlockingDeque&lt;E&gt;, java.io.Serializable { /* * Implemented as a simple doubly-linked list protected by a * single lock and using conditions to manage blocking. * * To implement weakly consistent iterators, it appears we need to * keep all Nodes GC-reachable from a predecessor dequeued Node. * That would cause two problems: * - allow a rogue Iterator to cause unbounded memory retention * - cause cross-generational linking of old Nodes to new Nodes if * a Node was tenured while live, which generational GCs have a * hard time dealing with, causing repeated major collections. * However, only non-deleted Nodes need to be reachable from * dequeued Nodes, and reachability does not necessarily have to * be of the kind understood by the GC. We use the trick of * linking a Node that has just been dequeued to itself. Such a * self-link implicitly means to advance to head. */ /* * We have \"diamond\" multiple interface/abstract class inheritance * here, and that introduces ambiguities. Often we want the * BlockingDeque javadoc combined with the AbstractQueue * implementation, so a lot of method specs are duplicated here. */ private static final long serialVersionUID = -387911632671998426L; /** Doubly-linked list node class */ static final class Node&lt;E&gt; { /** * The item, or null if this node has been removed. */ // 1 E item; /** * One of: * - the real predecessor Node * - this Node, meaning the predecessor is tail * - null, meaning there is no predecessor */ // 2 Node&lt;E&gt; prev; /** * One of: * - the real successor Node * - this Node, meaning the successor is head * - null, meaning there is no successor */ // 3 Node&lt;E&gt; next; Node(E x, Node&lt;E&gt; p, Node&lt;E&gt; n) { item = x; prev = p; next = n; } } /** Pointer to first node */ // 4 transient Node&lt;E&gt; first; /** Pointer to last node */ // 5 transient Node&lt;E&gt; last; /** Number of items in the deque */ // 6 private transient int count; /** Maximum number of items in the deque */ // 7 private final int capacity; /** Main lock guarding all access */ // 8 final ReentrantLock lock = new ReentrantLock(); /** Condition for waiting takes */ // 9 private final Condition notEmpty = lock.newCondition(); /** Condition for waiting puts */ // 10 private final Condition notFull = lock.newCondition(); /** * Creates a &lt;tt&gt;LinkedBlockingDeque&lt;/tt&gt; with a capacity of * {@link Integer#MAX_VALUE}. */ // 11 public LinkedBlockingDeque() { this(Integer.MAX_VALUE); } /** * Creates a &lt;tt&gt;LinkedBlockingDeque&lt;/tt&gt; with the given (fixed) capacity. * * @param capacity the capacity of this deque * @throws IllegalArgumentException if &lt;tt&gt;capacity&lt;/tt&gt; is less than 1 */ public LinkedBlockingDeque(int capacity) { if (capacity &lt;= 0) throw new IllegalArgumentException(); this.capacity = capacity; } 标注代码分析 保存元素的域，如果为nul说明当前节点已被删除。 指向其前驱节点。如果指向自身，说明前面是队尾节点。如果为null，说明没有前驱节点。 指向其后继节点。如果指向自身，说明后面是队头节点。如果为null，说明没有后继节点。 指向队头节点。 指向队尾节点。 队列中元素数量。 队列最大容量。 队列中保护访问使用的锁。 获取元素的等待条件(队列非空)。 插入元素的等待条件(队列非满)。 不指定容量，默认为Integer.MAX_VALUE。 LinkedBlockingDeque#linkFirst()12345678910111213141516171819202122232425/** * Links e as first element, or returns false if full. */private boolean linkFirst(E e) { // assert lock.isHeldByCurrentThread(); // 1 if (count &gt;= capacity) return false; Node&lt;E&gt; f = first; // 2 Node&lt;E&gt; x = new Node&lt;E&gt;(e, null, f); // 3 first = x; if (last == null) // 4 last = x; else // 5 f.prev = x; // 6 ++count; // 7 notEmpty.signal(); return true;} 标注代码分析 如果队列已满，返回false。 新建节点x，用来存放数据e，将e插入到队头节点前面。 然后将e设置为队头节点。 如果没有队尾节点，那么将x设置为队尾节点。 如果有队尾节点，那么将f的prev指向x，完成节点拼接。 累加当前元素计数。 有元素入队，唤醒在notEmpty上等待的获取元素的线程。 linkFirst()将一个元素插入到队头，并成为新的队头元素。 LinkedBlockingDeque#linkLast()1234567891011121314151617181920212223/** * Links e as last element, or returns false if full. */private boolean linkLast(E e) { // assert lock.isHeldByCurrentThread(); if (count &gt;= capacity) return false; Node&lt;E&gt; l = last; // 1 Node&lt;E&gt; x = new Node&lt;E&gt;(e, l, null); last = x; if (first == null) // 2 first = x; else // 3 l.next = x; // 4 ++count; // 5 notEmpty.signal(); return true;} 标注代码分析 新建节点x，用来存放数据e，将e插入到队尾节点后面。 如果没有队头节点，那么将x设置为队头节点。 如果有队头节点，那么将l的next指向x，完成节点拼接。 累加当前元素计数。 有元素入队，唤醒在notEmpty上等待的获取元素的线程。 linkLast()将一个元素插入到队尾，并成为新的队尾元素。 LinkedBlockingDeque#unlinkFirst()123456789101112131415161718192021222324252627282930313233/** * Removes and returns first element, or null if empty. */private E unlinkFirst() { // assert lock.isHeldByCurrentThread(); // 1 Node&lt;E&gt; f = first; // 2 if (f == null) return null; // 3 Node&lt;E&gt; n = f.next; // 4 E item = f.item; // 5 f.item = null; // 6 f.next = f; // help GC // 7 first = n; if (n == null) // 8 last = null; else // 9 n.prev = null; // 10 --count; // 11 notFull.signal(); // 12 return item;} 标注代码分析 获取队头节点f。 如果没有队头节点，返回null。 获取f的后继节点。 获取f的元素item。 将f的item域置空。 将f的next域指向自身，帮助GC。 将f的后继节点n设置为新的队头节点。 如果n为空，说明队列为空了，把队尾节点也置空一下。 如果n不为空，现在n是队头节点，需要将其prev域置空。 递减当前元素计数。 有元素出队了，唤醒在notFull上等待的插入元素的线程。 返回元素item。 unlinkFirst()就是将现有的队头节点移除，并将其后继节点设置为新的队头节点，并返回移除的队头节点中保存的元素。 LinkedBlockingDeque#unlinkLast()123456789101112131415161718192021222324252627282930313233/** * Removes and returns last element, or null if empty. */private E unlinkLast() { // assert lock.isHeldByCurrentThread(); // 1 Node&lt;E&gt; l = last; // 2 if (l == null) return null; // 3 Node&lt;E&gt; p = l.prev; // 4 E item = l.item; // 5 l.item = null; // 6 l.prev = l; // help GC // 7 last = p; if (p == null) // 8 first = null; else // 9 p.next = null; // 10 --count; // 11 notFull.signal(); // 12 return item;} 标注代码分析 获取队尾节点l。 如果没有队尾节点，返回null。 获取l的前驱节点。 获取l的元素item。 将l的item域置空。 将f的prev域指向自身，帮助GC。 将l的前驱节点p设置为新的队尾节点。 如果p为空，说明队列为空了，把队头节点也置空一下。 如果p不为空，现在p是队尾节点，需要将其next域置空。 递减当前元素计数 有元素出队，唤醒在notFull上等待的插入元素的线程。 返回元素item。 unlinkLast()就是将现有的队尾节点移除，并将其前驱节点设置为新的队尾节点，并返回移除的队尾节点中保存的元素。 LinkedBlockingDeque#unlink()12345678910111213141516171819202122232425262728/** * Unlinks x */void unlink(Node&lt;E&gt; x) { // assert lock.isHeldByCurrentThread(); Node&lt;E&gt; p = x.prev; Node&lt;E&gt; n = x.next; if (p == null) { // 1 unlinkFirst(); } else if (n == null) { // 2 unlinkLast(); } else { // 3 p.next = n; // 4 n.prev = p; // 5 x.item = null; // Don't mess with x's links. They may still be in use by // an iterator. // 6 --count; // 7 notFull.signal(); }} 标注代码分析 如果x没有前驱节点，那么x就是队头节点，所以调用一下unlinkFirst就可以了。 如果x没有后继节点，那么x就是队尾节点，所以调用一下unlinkLast就可以了。 将x的前驱节点p的next指向x的后继节点n。 将x的后继节点n的prev指向x的前驱节点n。 置空x的item域。注意没有清理x本身的prev和next域，因为它们可能正在被某个迭代器使用中。 递减当前元素计数 有元素出队，唤醒在notFull上等待的插入元素的线程。 LinkedBlockingDeque#putFirst()12345678910111213141516/** * @throws NullPointerException {@inheritDoc} * @throws InterruptedException {@inheritDoc} */public void putFirst(E e) throws InterruptedException { if (e == null) throw new NullPointerException(); final ReentrantLock lock = this.lock; lock.lock(); try { // 1 while (!linkFirst(e)) notFull.await(); } finally { lock.unlock(); }} 标注代码分析 如果插入元素到队头失败，在notFull条件上等待。 LinkedBlockingDeque#putLast()12345678910111213141516/** * @throws NullPointerException {@inheritDoc} * @throws InterruptedException {@inheritDoc} */public void putLast(E e) throws InterruptedException { if (e == null) throw new NullPointerException(); final ReentrantLock lock = this.lock; lock.lock(); try { // 1 while (!linkLast(e)) notFull.await(); } finally { lock.unlock(); }} 标注代码分析 如果插入元素到队尾失败，在notFull条件上等待。 LinkedBlockingDeque#takeFirst()12345678910111213public E takeFirst() throws InterruptedException { final ReentrantLock lock = this.lock; lock.lock(); try { E x; // 1 while ( (x = unlinkFirst()) == null) notEmpty.await(); return x; } finally { lock.unlock(); } } 标注代码分析 如果从队头获取并删除元素失败，在notEmpty条件上等待。 LinkedBlockingDeque#takeLast()12345678910111213public E takeLast() throws InterruptedException { final ReentrantLock lock = this.lock; lock.lock(); try { E x; // 1 while ( (x = unlinkLast()) == null) notEmpty.await(); return x; } finally { lock.unlock(); } } 标注代码分析 如果从队尾获取并删除元素失败，在notEmpty条件上等待。 LinkedBlockingDeque#iterator()1234567891011121314/** * Returns an iterator over the elements in this deque in proper sequence. * The elements will be returned in order from first (head) to last (tail). * The returned &lt;tt&gt;Iterator&lt;/tt&gt; is a \"weakly consistent\" iterator that * will never throw {@link ConcurrentModificationException}, * and guarantees to traverse elements as they existed upon * construction of the iterator, and may (but is not guaranteed to) * reflect any modifications subsequent to construction. * * @return an iterator over the elements in this deque in proper sequence */ public Iterator&lt;E&gt; iterator() { return new Itr(); } 根据注释，可以知道迭代器是弱一致性，支持双向迭代。类似LinkedBlockingDeque#descendingIterator()也是弱一致性，支持双向迭代器。与iterator()的差别在返回顺序。 LinkedBlockingDeque#Itr12345/** Forward iterator */private class Itr extends AbstractItr { Node&lt;E&gt; firstNode() { return first; } Node&lt;E&gt; nextNode(Node&lt;E&gt; n) { return n.next; }}","link":"/JDK1.6-LinkedBlockingDeque/"},{"title":"深入理解Java内存模型(基础)","text":"1 并发编程模型的分类 2 Java内存模型的抽象 3 重排序 4 处理器重排序与内存屏障指令 5 Happens-Before 6 参考 1 并发编程模型的分类在并发编程中，我们需要处理两个关键问题：线程之间如何通信及线程之间如何同步。通信是指线程之间以何种机制来交换信息。在命令式编程中，线程之间的通信机制有两种：共享内存和消息传递。在共享内存的并发模型里，线程之间共享程序的公共状态，线程之间通过写-读内存中的公共状态来隐式进行通信。在消息传递的并发模型里，线程之间没有公共状态，线程之间必须通过明确的发送消息来显式进行通信。同步是指程序用于控制不同线程之间操作发生相对顺序的机制。在共享内存并发模型里，同步是显式进行的。程序员必须显式指定某个方法或某段代码需要在线程之间互斥执行。在消息传递的并发模型里，由于消息的发送必须在消息的接收之前，因此同步是隐式进行的。Java的并发采用的是共享内存模型（主内存共享），Java线程之间的通信总是隐式进行，整个通信过程对程序员完全透明。如果编写多线程程序的Java程序员不理解隐式进行的线程之间通信的工作机制，很可能会遇到各种奇怪的内存可见性问题。 2 Java内存模型的抽象在Java中，所有实例域、静态域和数组元素存储在堆内存中，堆内存在线程之间共享（本文使用“共享变量”这个术语代指实例域，静态域和数组元素）。局部变量（Local variables），方法定义参数（java语言规范称之为formal method parameters）和异常处理器参数（exception handler parameters）不会在线程之间共享，它们不会有内存可见性问题，也不受内存模型的影响。Java线程之间的通信由Java内存模型（JMM）控制，JMM决定一个线程对共享变量的写入何时对另一个线程可见。从抽象的角度来看，JMM定义了线程和主内存之间的抽象关系：线程之间的共享变量存储在主内存（main memory）中，每个线程都有一个私有的本地内存（local memory），本地内存中存储了该线程以读/写共享变量的副本。本地内存是JMM的一个抽象概念，并不真实存在（是cpu的寄存器和高速缓存的抽象描述）。它涵盖了缓存，写缓冲区，寄存器以及其他的硬件和编译器优化。Java内存模型的抽象示意图如下：从上图来看，线程A与线程B之间如要通信的话，必须要经历下面2个步骤： 线程A把本地内存A中更新过的共享变量刷新到主内存中去。 线程B到主内存中去读取线程A之前已更新过的共享变量。 下面通过示意图来说明这两个步骤：如上图所示，本地内存A和B有主内存中共享变量x的副本。假设初始时，这三个内存中的x值都为0。线程A在执行时，把更新后的x值（假设值为1）临时存放在自己的本地内存A中。当线程A和线程B需要通信时，线程A首先会把自己本地内存中修改后的x值刷新到主内存中，此时主内存中的x值变为了1。随后，线程B到主内存中去读取线程A更新后的x值，此时线程B的本地内存的x值也变为了1。从整体来看，这两个步骤实质上是线程A在向线程B发送消息，而且这个通信过程必须要经过主内存。JMM通过控制主内存与每个线程的本地内存之间的交互，来为Java程序员提供内存可见性保证。 3 重排序在执行程序时为了提高性能，编译器和处理器常常会对指令做重排序。重排序分三种类型： 编译器优化的重排序。编译器在不改变单线程程序语义的前提下，可以重新安排语句的执行顺序。 指令级并行的重排序（处理器重排序）。现代处理器采用了指令级并行技术（Instruction-Level Parallelism， ILP）来将多条指令重叠执行。如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序。 内存系统的重排序（处理器重排序）。由于处理器使用缓存和读/写缓冲区，这使得加载和存储操作看上去可能是在乱序执行。注：处理器重排序可以理解为运行时重排序。 从Java源代码到最终实际执行的指令序列，会分别经历下面三种重排序：上述的1属于编译器重排序，2和3属于处理器重排序。这些重排序都可能会导致多线程程序出现内存可见性问题。对于编译器，JMM的编译器重排序规则会禁止特定类型的编译器重排序（不是所有的编译器重排序都要禁止）。对于处理器重排序，JMM的处理器重排序规则会要求Java编译器在生成指令序列时，插入特定类型的内存屏障（memory barriers，intel称之为memory fence）指令，通过内存屏障指令来禁止特定类型的处理器重排序（不是所有的处理器重排序都要禁止）。JMM属于语言级的内存模型，它确保在不同的编译器和不同的处理器平台之上，通过禁止特定类型的编译器重排序和处理器重排序，为程序员提供一致的内存可见性保证。 4 处理器重排序与内存屏障指令现代的处理器使用写缓冲区来临时保存向内存写入的数据。写缓冲区可以保证指令流水线持续运行，它可以避免由于处理器停顿下来等待向内存写入数据而产生的延迟。同时，通过以批处理的方式刷新写缓冲区，以及合并写缓冲区中对同一内存地址的多次写，可以减少对内存总线的占用。虽然写缓冲区有这么多好处，但每个处理器上的写缓冲区，仅仅对它所在的处理器可见。这个特性会对内存操作的执行顺序产生重要的影响：处理器（写缓冲区属于处理器）对内存的读/写操作的执行顺序，不一定与内存实际发生的读/写操作顺序一致！（在并发里，处理器只能见到自己对内存的读写，不能见到其他处理器对内存的读写，这对整个内存执行顺序有影响）为了具体说明，请看下面示例：假设处理器A和处理器B按程序的顺序并行执行内存访问，最终却可能得到x = y = 0的结果。具体的原因如下图所示：这里处理器A和处理器B可以同时把共享变量写入自己的写缓冲区（A1，B1），然后从内存中读取另一个共享变量（A2，B2），最后才把自己写缓存区中保存的脏数据刷新到内存中（A3，B3）。当以这种时序执行时，程序就可以得到x = y = 0的结果。从内存操作实际发生的顺序来看，直到处理器A执行A3来刷新自己的写缓存区，写操作A1才算真正执行了。虽然处理器A执行内存操作的顺序为：A1-&gt;A2，但内存操作实际发生的顺序却是：A2-&gt;A1。此时，处理器A的内存操作顺序被重排序了（处理器B的情况和处理器A一样，这里就不赘述了）。这里的关键是，由于写缓冲区仅对自己的处理器可见，它会导致处理器执行内存操作的顺序可能会与内存实际的操作执行顺序不一致（多个处理器的情况下）。由于现代的处理器都会使用写缓冲区，因此现代的处理器都会允许对写-读操做重排序。下面是常见处理器允许的重排序类型的列表：上表单元格中的“N”表示处理器不允许两个操作重排序，“Y”表示允许重排序。从上表我们可以看出：常见的处理器都允许Store-Load重排序；常见的处理器都不允许对存在数据依赖的操作做重排序。sparc-TSO和x86拥有相对较强的处理器内存模型，它们仅允许对写-读操作做重排序（因为它们都使用了写缓冲区）。 ※注1：sparc-TSO是指以TSO(Total Store Order)内存模型运行时，sparc处理器的特性。 ※注2：上表中的x86包括x64及AMD64。 ※注3：由于ARM处理器的内存模型与PowerPC处理器的内存模型非常类似，本文将忽略它。 ※注4：数据依赖性后文会专门说明。 为了保证内存可见性，Java编译器在生成指令序列的适当位置会插入内存屏障指令来禁止特定类型的处理器重排序。JMM把内存屏障指令分为下列四类：StoreLoad Barriers是一个“全能型”的屏障，它同时具有其他三个屏障的效果。现代的多处理器大都支持该屏障（其他类型的屏障不一定被所有处理器支持）。执行该屏障开销会很昂贵，因为当前处理器通常要把写缓冲区中的数据全部刷新到内存中（buffer fully flush）。 Load：装载数据（读取数据）。 Store：写入数据，把数据写入主内存。 LoadLoad Barriers：确保Load1数据的装载，之前于Load2及所有后续装载指令的装载。 StoreStore Barriers：确保Store1数据对其他处理器可见（刷新到内存），之前于Store2及所有后续存储指令的存储。 LoadStore Barriers：确保Load1数据装载，之前于Store2及所有后续的存储指令刷新到内存。 StoreLoad Barriers：确保Store1数据对其他处理器变得可见（指刷新到内存），之前于Load2及所有后续装载指令的装载。5 Happens-Before从JDK5开始，Java使用新的JSR-133内存模型（本文除非特别说明，针对的都是JSR-133内存模型）。JSR-133提出了happens-before的概念，通过这个概念来阐述操作之间的内存可见性。如果一个操作执行的结果需要对另一个操作可见，那么这两个操作之间必须存在happens-before关系。这里提到的两个操作既可以是在一个线程之内，也可以是在不同线程之间。与程序员密切相关的happens-before规则如下： 程序顺序规则：一个线程中的每个操作，happens-before于该线程中的任意后续操作。 监视器锁规则：对一个监视器锁的解锁，happens-before于随后对这个监视器锁的加锁。 volatile变量规则：对一个volatile域的写，happens-before于任意后续对这个volatile域的读。 传递性：如果A happens-before B，且B happens-before C，那么A happens-before C。 注意，两个操作之间具有happens-before关系，并不意味着前一个操作必须要在后一个操作之前执行！happens-before仅仅要求前一个操作（执行的结果）对后一个操作可见，且前一个操作按顺序排在第二个操作之前（the first is visible to and ordered before the second）。happens-before的定义很微妙，后文会具体说明happens-before为什么要这么定义。happens-before与JMM的关系如下图所示：如上图所示，一个happens-before规则通常对应于多个编译器重排序规则和处理器重排序规则。对于Java程序员来说，happens-before规则简单易懂，它避免程序员为了理解JMM提供的内存可见性保证而去学习复杂的重排序规则以及这些规则的具体实现。 6 参考 深入理解Java内存模型","link":"/JMM-1/"},{"title":"深入理解Java内存模型(锁)","text":"1 锁的释放-获取建立的Happens-Before关系 2 锁释放和获取的内存语义 3 锁内存语义的实现 ReentrantLock公平锁 ReentrantLock非公平锁 intel的手册对lock前缀的说明如下 公平锁和非公平锁的内存语义总结 4 Concurrent包的实现 5 参考 1 锁的释放-获取建立的Happens-Before关系锁是Java并发编程中最重要的同步机制。锁除了让临界区互斥执行外，还可以让释放锁的线程向获取同一个锁的线程发送消息。下面是锁释放-获取的示例代码。123456789101112class MonitorExample { int a = 0; public synchronized void writer() { //1 a++; //2 } //3 public synchronized void reader() { //4 int i = a; //5 …… } //6} 假设线程A执行writer()，随后线程B执行reader()。根据happens-before规则，这个过程包含的happens-before关系可以分为两类。 根据程序次序规则，1 happens-before 2，2 happens-before 3，4 happens-before 5，5 happens-before 6。 根据监视器锁规则，3 happens-before 4。 根据happens-before的传递性，2 happens-before 5。 上述happens-before关系的图形化表现形式如下。在上图中，每一个箭头链接的两个节点，代表了一个happens-before关系。黑色箭头表示程序顺序规则；橙色箭头表示监视器锁规则；蓝色箭头表示组合这些规则后提供的happens-before保证。上图表示在线程A释放了锁之后，随后线程B获取同一个锁。在上图中，2 happens-before 5。因此，线程A在释放锁之前所有可见的共享变量，在线程B获取同一个锁之后，将立刻变得对B线程可见。 2 锁释放和获取的内存语义当线程释放锁时，JMM会把该线程对应的本地内存中的共享变量刷新到主内存中（类似volatile的写）。以上面的MonitorExample程序为例，A线程释放锁后，共享数据的状态示意图如下。当线程获取锁时，JMM会把该线程对应的本地内存置为无效（类似volatile的读）。从而使得被监视器保护的临界区代码必须要从主内存中去读取共享变量。下面是锁获取的状态示意图。对比锁释放-获取的内存语义与volatile写-读的内存语义，可以看出：锁释放与volatile写有相同的内存语义；锁获取与volatile读有相同的内存语义。下面对锁释放和锁获取的内存语义做个总结。 线程A释放一个锁，实质上是线程A向接下来将要获取这个锁的某个线程发出了（线程A对共享变量所做修改的）消息。 线程B获取一个锁，实质上是线程B接收了之前某个线程发出的（在释放这个锁之前对共享变量所做修改的）消息。 线程A释放锁，随后线程B获取这个锁，这个过程实质上是线程A通过主内存向线程B发送消息。3 锁内存语义的实现本文将借助ReentrantLock的源代码，来分析锁内存语义的具体实现机制。 1234567891011121314151617181920212223class ReentrantLockExample { int a = 0; ReentrantLock lock = new ReentrantLock(); public void writer() { lock.lock(); //获取锁 try { a++; } finally { lock.unlock(); //释放锁 }} public void reader () { lock.lock(); //获取锁 try { int i = a; …… } finally { lock.unlock(); //释放锁 } }} 在ReentrantLock中，调用lock()获取锁；调用unlock()释放锁。ReentrantLock的实现依赖于Java同步器框架AbstractQueuedSynchronizer（本文简称之为AQS）。AQS使用一个整型的volatile变量（命名为state）来维护同步状态，马上我们会看到，这个volatile变量是ReentrantLock内存语义实现的关键。 下面是ReentrantLock的类图（仅画出与本文相关的部分）。ReentrantLock分为公平锁和非公平锁，我们首先分析公平锁。 ReentrantLock公平锁使用公平锁时，加锁方法lock()的调用轨迹如下。1234ReentrantLock#lock()FairSync#lock()AbstractQueuedSynchronizer#acquire(int arg)ReentrantLock#tryAcquire(int acquires) 在第4步真正开始加锁，下面是该方法的源代码。12345678910111213141516171819protected final boolean tryAcquire(int acquires) { final Thread current = Thread.currentThread(); int c = getState(); //获取锁的开始，首先读volatile变量state if (c == 0) { if (isFirst(current) &amp;&amp; compareAndSetState(0, acquires)) { setExclusiveOwnerThread(current); return true; } } else if (current == getExclusiveOwnerThread()) { int nextc = c + acquires; if (nextc &lt; 0) throw new Error(\"Maximum lock count exceeded\"); setState(nextc); return true; } return false;} 从上面源代码中我们可以看出，加锁方法首先读volatile变量state。在使用公平锁时，解锁方法unlock()的调用轨迹如下。123ReentrantLock#unlock()AbstractQueuedSynchronizer#release(int arg)Sync#tryRelease(int releases) 在第3步真正开始释放锁，下面是该方法的源代码。123456789101112protected final boolean tryRelease(int releases) { int c = getState() - releases; if (Thread.currentThread() != getExclusiveOwnerThread()) throw new IllegalMonitorStateException(); boolean free = false; if (c == 0) { free = true; setExclusiveOwnerThread(null); } setState(c); //释放锁的最后，写volatile变量state return free;} 从上面的源代码我们可以看出，在释放锁的最后写volatile变量state。公平锁在释放锁的最后写volatile变量state；在获取锁时首先读这个volatile变量。根据volatile的happens-before规则，释放锁的线程在写volatile变量之前可见的共享变量，在获取锁的线程读取同一个volatile变量后将立即变的对获取锁的线程可见。 ReentrantLock非公平锁现在我们分析非公平锁的内存语义的实现。非公平锁的释放和公平锁完全一样，所以这里仅仅分析非公平锁的获取（加锁）。使用非公平锁时，加锁方法lock()的方法调用轨迹如下。123ReentrantLock#lock()NonfairSync#lock()AbstractQueuedSynchronizer#compareAndSetState(int expect, int update) 在第3步真正开始加锁，下面是该方法的源代码。123protected final boolean compareAndSetState(int expect, int update) { return unsafe.compareAndSwapInt(this, stateOffset, expect, update);} 该方法以原子操作的方式更新state变量，本文把Java的compareAndSet()调用简称为CAS（具有volatile读和volatile写的内存语义）。JDK文档对该方法的说明如下：如果当前状态值等于预期值，则以原子方式将同步状态设置为给定的更新值。此操作具有 volatile读和写的内存语义。这里我们分别从编译器和处理器的角度来分析，CAS如何同时具有volatile读和volatile写的内存语义。前文我们提到过，编译器不会对volatile读与volatile读后面的任意内存操作重排序；编译器不会对volatile写与volatile写前面的任意内存操作重排序。组合这两个条件，意味着为了同时实现volatile读和volatile写的内存语义，编译器不能对CAS与CAS前面和后面的任意内存操作重排序。下面我们来分析在常见的intel x86处理器中，CAS是如何同时具有volatile读和volatile写的内存语义的。sun.misc.Unsafe#compareAndSwapInt()的源代码。1public final native boolean compareAndSwapInt(Object o, long offset,int expected,int x); 可以看到这是个本地方法调用。这个本地方法在openjdk中依次调用的C++代码为。unsafe.cpp，atomic.cpp和atomicwindowsx86.inline.hpp。这个本地方法的最终实现在openjdk的如下位置： openjdk-7-fcs-src-b147-27jun2011\\openjdk\\hotspot\\src\\oscpu\\windowsx86\\vm\\ atomicwindowsx86.inline.hpp（对应于windows操作系统，X86处理器）。下面是对应于intel x86处理器的源代码的片段。1234567891011121314151617181920// Adding a lock prefix to an instruction on MP machine// VC++ doesn't like the lock prefix to be on a single line// so we can't insert a label after the lock prefix.// By emitting a lock prefix, we can define a label after it.#define LOCK_IF_MP(mp) __asm cmp mp, 0 \\ __asm je L0 \\ __asm _emit 0xF0 \\ __asm L0:inline jint Atomic::cmpxchg (jint exchange_value, volatile jint* dest, jint compare_value) { // alternative for InterlockedCompareExchange int mp = os::is_MP(); __asm { mov edx, dest mov ecx, exchange_value mov eax, compare_value LOCK_IF_MP(mp) cmpxchg dword ptr [edx], ecx }} 如上面源代码所示，程序会根据当前处理器的类型来决定是否为cmpxchg指令添加lock前缀。如果程序是在多处理器上运行，就为cmpxchg指令加上lock前缀（lock cmpxchg）。反之，如果程序是在单处理器上运行，就省略lock前缀（单处理器自身会维护单处理器内的顺序一致性，不需要lock前缀提供的内存屏障效果）。 intel的手册对lock前缀的说明如下 确保对内存的读-改-写操作原子执行。在Pentium及Pentium之前的处理器中，带有lock前缀的指令在执行期间会锁住总线，使得其他处理器暂时无法通过总线访问内存（同步总线）。很显然，这会带来昂贵的开销。从Pentium 4，Intel Xeon及P6处理器开始，intel在原有总线锁的基础上做了一个很有意义的优化：如果要访问的内存区域（Area Of Memory）在lock前缀指令执行期间已经在处理器内部的缓存中被锁定（即包含该内存区域的缓存行当前处于独占或以修改状态），并且该内存区域被完全包含在单个缓存行（Cache Line）中，那么处理器将直接执行该指令。由于在指令执行期间该缓存行会一直被锁定，其它处理器无法读/写该指令要访问的内存区域，因此能保证指令执行的原子性。这个操作过程叫做缓存锁定（Cache Locking），缓存锁定将大大降低lock前缀指令的执行开销，但是当多处理器之间的竞争程度很高或者指令访问的内存地址未对齐时，仍然会锁住总线。 禁止该指令与之前和之后的读和写指令重排序。（volatile特性） 把写缓冲区中的所有数据刷新到内存中。（volatile特性） 上面的第2点和第3点所具有的内存屏障效果，足以同时实现volatile读和volatile写的内存语义。经过上面的这些分析，现在我们终于能明白为什么JDK文档说CAS同时具有volatile读和volatile写的内存语义了。 公平锁和非公平锁的内存语义总结 公平锁和非公平锁释放时，最后都要写一个volatile变量state。 公平锁获取时，首先会去读这个volatile变量。 非公平锁获取时，首先会用CAS更新这个volatile变量，这个操作同时具有volatile读和volatile写的内存语义。 从本文对ReentrantLock的分析可以看出，锁释放-获取的内存语义的实现至少有下面两种方式。 利用volatile变量的写-读所具有的内存语义。 利用CAS所附带的volatile读和volatile写的内存语义。4 Concurrent包的实现由于Java的CAS同时具有volatile读和volatile写的内存语义，因此Java线程之间的通信现在有了下面四种方式。 A线程写volatile变量，随后B线程读这个volatile变量。 A线程写volatile变量，随后B线程用CAS更新这个volatile变量。 A线程用CAS更新一个volatile变量，随后B线程用CAS更新这个volatile变量。 A线程用CAS更新一个volatile变量，随后B线程读这个volatile变量。 Java的CAS会使用现代处理器上提供的高效机器级别原子指令，这些原子指令以原子方式对内存执行读-改-写操作，这是在多处理器中实现同步的关键（从本质上来说，能够支持原子性读-改-写指令的计算机器，是顺序计算图灵机的异步等价机器，因此任何现代的多处理器都会去支持某种能对内存执行原子性读-改-写操作的原子指令）。同时，volatile变量的读/写和CAS可以实现线程之间的通信。把这些特性整合在一起，就形成了整个concurrent包得以实现的基石。如果我们仔细分析concurrent包的源代码实现，会发现一个通用化的实现模式。首先，声明共享变量为volatile。然后，使用CAS的原子条件更新来实现线程之间的同步。同时，配合以volatile的读/写和CAS所具有的volatile读和写的内存语义来实现线程之间的通信。AQS，非阻塞数据结构和原子变量类（Java.util.concurrent.atomic包中的类），这些concurrent包中的基础类都是使用这种模式来实现的，而concurrent包中的高层类又是依赖于这些基础类来实现的。从整体来看，concurrent包的实现示意图如下。 5 参考 深入理解Java内存模型","link":"/JMM-3/"},{"title":"深入理解Java内存模型(顺序一致性)","text":"1 数据竞争与顺序一致性的保证 2 顺序一致性内存模型 3 同步程序的顺序一致性效果 4 未同步程序的执行特性 4 参考 1 数据竞争与顺序一致性的保证当程序未正确同步时，就会存在数据竞争。Java内存模型规范对数据竞争的定义如下： 在一个线程中写一个变量， 在另一个线程读同一个变量， 而且写和读没有通过同步来排序。 当代码中包含数据竞争时，程序的执行往往产生违反直觉的结果。如果一个多线程程序能正确同步，这个程序将是一个没有数据竞争的程序。JMM对正确同步的多线程程序的内存一致性做了如下保证：如果程序是正确同步的，程序的执行将具有顺序一致性（sequentially consistent）–即程序的执行结果与该程序在顺序一致性内存模型中的执行结果相同。这里的同步是指广义上的同步，包括对常用同步原语（lock，volatile和final）的正确使用。 2 顺序一致性内存模型顺序一致性内存模型是一个被计算机科学家理想化了的理论参考模型，它为程序员提供了极强的内存可见性保证。顺序一致性内存模型有两大特性： 一个线程中的所有操作必须按照程序的顺序来执行。 （不管程序是否同步）所有线程都只能看到一个单一的操作执行顺序。在顺序一致性内存模型中，每个操作都必须原子执行且立刻对所有线程可见。 顺序一致性内存模型为程序员提供的视图如下：在概念上，顺序一致性模型有一个单一的全局内存，这个内存通过一个左右摆动的开关可以连接到任意一个线程。同时，每一个线程必须按程序的顺序来执行内存读/写操作。从上图我们可以看出，在任意时间点最多只能有一个线程可以连接到内存。当多个线程并发执行时，图中的开关装置能把所有线程的所有内存读/写操作串行化。为了更好的理解，下面我们通过两个示意图来对顺序一致性模型的特性做进一步的说明。假设有两个线程A和B并发执行。其中A线程有三个操作，它们在程序中的顺序是：A1-&gt;A2-&gt;A3。B线程也有三个操作，它们在程序中的顺序是：B1-&gt;B2-&gt;B3。假设这两个线程使用监视器来正确同步：A线程的三个操作执行后释放监视器，随后B线程获取同一个监视器。那么程序在顺序一致性模型中的执行效果将如下图所示：现在我们再假设这两个线程没有做同步，下面是这个未同步程序在顺序一致性模型中的执行示意图：未同步程序在顺序一致性模型中虽然整体执行顺序是无序的，但所有线程都只能看到一个一致的整体执行顺序。以上图为例，线程A和B看到的执行顺序都是：B1-&gt;A1-&gt;A2-&gt;B2-&gt;A3-&gt;B3。之所以能得到这个保证是因为顺序一致性内存模型中的每个操作必须立即对任意线程可见。但是，在JMM中就没有这个保证。未同步程序在JMM中不但整体的执行顺序是无序的，而且所有线程看到的操作执行顺序也可能不一致。比如，在当前线程把写过的数据缓存在本地内存中，且还没有刷新到主内存之前，这个写操作仅对当前线程可见；从其他线程的角度来观察，会认为这个写操作根本还没有被当前线程执行。只有当前线程把本地内存中写过的数据刷新到主内存之后，这个写操作才能对其他线程可见。在这种情况下，当前线程和其它线程看到的操作执行顺序将不一致。 3 同步程序的顺序一致性效果下面我们对前面的示例程序ReorderExample用监视器来同步，看看正确同步的程序如何具有顺序一致性。请看下面的示例代码：12345678910111213141516class SynchronizedExample { int a = 0; boolean flag = false; public synchronized void writer() { a = 1; flag = true; } public synchronized void reader() { if (flag) { int i = a; …… } }} 上面示例代码中，假设A线程执行writer()后，B线程执行reader()。这是一个正确同步的多线程程序。根据JMM规范，该程序的执行结果将与该程序在顺序一致性模型中的执行结果相同。下面是该程序在两个内存模型中的执行时序对比图：在顺序一致性模型中，所有操作完全按程序的顺序串行执行。而在JMM中，临界区内的代码可以重排序（但JMM不允许临界区内的代码“逸出”到临界区之外，那样会破坏监视器的语义）。JMM会在退出监视器和进入监视器这两个关键时间点做一些特别处理，使得线程在这两个时间点具有与顺序一致性模型相同的内存视图（内存屏障）。虽然线程A在临界区内做了重排序，但由于监视器的互斥执行的特性，这里的线程B根本无法“观察”到线程A在临界区内的重排序。这种重排序既提高了执行效率，又没有改变程序的执行结果。从这里我们可以看到JMM在具体实现上的基本方针：在不改变（正确同步的）程序执行结果的前提下，尽可能的为编译器和处理器的优化打开方便之门。 4 未同步程序的执行特性对于未同步或未正确同步的多线程程序，JMM只提供最小安全性：线程执行时读取到的值，要么是之前某个线程写入的值，要么是默认值（0,null,false），JMM保证线程读操作读取到的值不会无中生有（out of thin air）的冒出来。为了实现最小安全性，JVM在堆上分配对象时，首先会清零内存空间，然后才会在上面分配对象（JVM内部会同步这两个操作，参考ByteBuffer）。因此，在以清零的内存空间（Pre-zeroed Memory）分配对象时，域的默认初始化已经完成了。JMM不保证未同步程序的执行结果与该程序在顺序一致性模型中的执行结果一致。因为未同步程序在顺序一致性模型中执行时，整体上是无序的，其执行结果无法预知。保证未同步程序在两个模型中的执行结果一致毫无意义。和顺序一致性模型一样，未同步程序在JMM中的执行时，整体上也是无序的，其执行结果也无法预知。同时，未同步程序在这两个模型中的执行特性有下面几个差异：（顺序一致性模型、JMM内存模型） 顺序一致性模型保证单线程内的操作会按程序的顺序执行，而JMM不保证单线程内的操作会按程序的顺序执行（比如上面正确同步的多线程程序在临界区内的重排序）。（编译器、处理器在不改变结果的前提下会发生重排序） 顺序一致性模型保证所有线程只能看到一致的操作执行顺序，而JMM不保证所有线程能看到一致的操作执行顺序。（顺序一致性模型是理想化） JMM不保证对64位的long型和double型变量的读/写操作具有原子性，而顺序一致性模型保证对所有的内存读/写操作都具有原子性。 第3个差异与处理器总线的工作机制密切相关。在计算机中，数据通过总线在处理器和内存之间传递。每次处理器和内存之间的数据传递都是通过一系列步骤来完成的，这一系列步骤称之为总线事务（Bus Transaction）。总线事务包括读事务（Read Transaction）和写事务（Write Transaction）。读事务从内存传送数据到处理器，写事务从处理器传送数据到内存，每个事务会读/写内存中一个或多个物理上连续的字。这里的关键是，总线会同步试图并发使用总线的事务。在一个处理器执行总线事务期间，总线会禁止其它所有的处理器和I/O设备执行内存的读/写。（每次使用总线事务只有一个线程使用）下面让我们通过一个示意图来说明总线的工作机制：如上图所示，假设处理器A，B和C同时向总线发起总线事务，这时总线仲裁（Bus Arbitration）会对竞争作出裁决，这里我们假设总线在仲裁后判定处理器A在竞争中获胜（总线仲裁会确保所有处理器都能公平的访问内存）。此时处理器A继续它的总线事务，而其它两个处理器则要等待处理器A的总线事务完成后才能开始再次执行内存访问。（总线事务的同步）假设在处理器A执行总线事务期间（不管这个总线事务是读事务还是写事务），处理器D向总线发起了总线事务，此时处理器D的这个请求会被总线禁止。总线的这些工作机制可以把所有处理器对内存的访问以串行化的方式来执行；在任意时间点，最多只能有一个处理器能访问内存。这个特性确保了单个总线事务之中的内存读/写操作具有原子性。注在一些32位的处理器上，如果要求对64位数据的读/写操作具有原子性，会有比较大的开销。为了照顾这种处理器，Java语言规范鼓励但不强求JVM对64位的long型变量和double型变量的读/写具有原子性。当JVM在这种处理器上运行时，会把一个64位long/double型变量的读/写操作拆分为两个32位的读/写操作来执行。这两个32位的读/写操作可能会被分配到不同的总线事务中执行，此时对这个64位变量的读/写将不具有原子性。当单个内存操作不具有原子性，将可能会产生意想不到后果。请看下面示意图：如上图所示，假设处理器A写一个long型变量，同时处理器B要读这个long型变量。处理器A中64位的写操作被拆分为两个32位的写操作，且这两个32位的写操作被分配到不同的写事务中执行。同时处理器B中64位的读操作被拆分为两个32位的读操作，且这两个32位的读操作被分配到同一个的读事务中执行。当处理器A和B按上图的时序来执行时，处理器B将看到仅仅被处理器A“写了一半“的无效值。注意，在JSR-133之前的旧内存模型中，一个64位long/double型变量的读/写操作可以被拆分为两个32位的读/写操作来执行。从JSR-133内存模型开始（从JDK5开始），仅仅只允许把一个64位long/double型变量的写操作拆分为两个32位的写操作来执行，任意的读操作在JSR-133中都必须具有原子性。（任意读操作必须要在单个读事务中执行）但是，Java虚拟机规范定义的许多规则中的一条：所有对基本类型的操作（32位下的），除了某些对long类型和double类型的操作之外，都是原子级的。要在线程间共享long与double字段是，必须在synchronized中操作，或是声明为volatile。 4 参考 深入理解Java内存模型","link":"/JMM-4/"},{"title":"JDK1.6 CyclicBarrier","text":"1 介绍 2 源码分析 CyclicBarrier#await() CyclicBarrier#dowait() CyclicBarrier#nextGeneration() CyclicBarrier#breakBarrier() CyclicBarrier 3 总结 1 介绍 CyclicBarrier是一种可重复使用的栅栏机制，可以让一组线程在某个点上相互等待，这个点就可以类比为栅栏。并且这个栅栏是可重复使用的，这点可以和前面分析过的CountDownLatch做对比，CountDownLatch只能用一次。 CyclicBarrier还支持在所有线程到达栅栏之后，在所有线程从等待状态转到可运行状态之前，执行一个命令(或者说是动作)。当然，在某些情况下，栅栏可以被打破。比如某个线程无法在规定的时间内到达栅栏。 2 源码分析123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354/** * A synchronization aid that allows a set of threads to all wait for * each other to reach a common barrier point. CyclicBarriers are * useful in programs involving a fixed sized party of threads that * must occasionally wait for each other. The barrier is called * &lt;em&gt;cyclic&lt;/em&gt; because it can be re-used after the waiting threads * are released. * * .... * * @since 1.5 * @see CountDownLatch * * @author Doug Lea */public class CyclicBarrier { /** * Each use of the barrier is represented as a generation instance. * The generation changes whenever the barrier is tripped, or * is reset. There can be many generations associated with threads * using the barrier - due to the non-deterministic way the lock * may be allocated to waiting threads - but only one of these * can be active at a time (the one to which &lt;tt&gt;count&lt;/tt&gt; applies) * and all the rest are either broken or tripped. * There need not be an active generation if there has been a break * but no subsequent reset. */ // 1 private static class Generation { boolean broken = false; } /** The lock for guarding barrier entry */ // 2 private final ReentrantLock lock = new ReentrantLock(); /** Condition to wait on until tripped */ // 3 private final Condition trip = lock.newCondition(); /** The number of parties */ // 4 private final int parties; /* The command to run when tripped */ // 5 private final Runnable barrierCommand; /** The current generation */ private Generation generation = new Generation(); /** * Number of parties still waiting. Counts down from parties to 0 * on each generation. It is reset to parties on each new * generation or when broken. */ // 6 private int count; 标注代码分析 每次对栅栏的使用可以表示为一个generation。栅栏每次开放或者重置，generation都会发生改变。使用栅栏的线程可以关联多个generations，由于等待线程可能会以多种方式请求锁，但是在特定的时间只有一个是可用的，其他的要么被打破，要么开放。如果一个栅栏已经被打破。且没有后续的重置动作，那么可以不存在可用的generation。 用于保护栅栏的锁。 栅栏开放的条件。 当前使用栅栏的使用方(线程)数量。 当栅栏开放时，要使用的命令。 处于等待状态的使用方(线程)的数量，在每一个generation上从parties递减为0。当新建generation(栅栏开放)或者栅栏被打破时，重置为parties。 CyclicBarrier内部使用ReentrantLock来实现，并包含一个trip条件，来作为栅栏模拟栅栏的行为。具体使用栅栏时，各个线程会在要互相等待的地方调用一个await()，然后在这个方法处等待。当所有线程都到达次方法时，栅栏打开，所有线程从等待出继续执行。接下来就从这个await()入手开始分析。 CyclicBarrier#await()12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273/** * Waits until all {@linkplain #getParties parties} have invoked * &lt;tt&gt;await&lt;/tt&gt; on this barrier. * * &lt;p&gt;If the current thread is not the last to arrive then it is * disabled for thread scheduling purposes and lies dormant until * one of the following things happens: * &lt;ul&gt; * &lt;li&gt;The last thread arrives; or * &lt;li&gt;Some other thread {@linkplain Thread#interrupt interrupts} * the current thread; or * &lt;li&gt;Some other thread {@linkplain Thread#interrupt interrupts} * one of the other waiting threads; or * &lt;li&gt;Some other thread times out while waiting for barrier; or * &lt;li&gt;Some other thread invokes {@link #reset} on this barrier. * &lt;/ul&gt; * * &lt;p&gt;If the current thread: * &lt;ul&gt; * &lt;li&gt;has its interrupted status set on entry to this method; or * &lt;li&gt;is {@linkplain Thread#interrupt interrupted} while waiting * &lt;/ul&gt; * then {@link InterruptedException} is thrown and the current thread's * interrupted status is cleared. * * .... * * @return the arrival index of the current thread, where index * &lt;tt&gt;{@link #getParties()} - 1&lt;/tt&gt; indicates the first * to arrive and zero indicates the last to arrive * @throws InterruptedException if the current thread was interrupted * while waiting * @throws BrokenBarrierException if &lt;em&gt;another&lt;/em&gt; thread was * interrupted or timed out while the current thread was * waiting, or the barrier was reset, or the barrier was * broken when {@code await} was called, or the barrier * action (if present) failed due an exception. */ // 1 public int await() throws InterruptedException, BrokenBarrierException { try { return dowait(false, 0L); } catch (TimeoutException toe) { throw new Error(toe); // cannot happen; } } /** * Waits until all {@linkplain #getParties parties} have invoked * &lt;tt&gt;await&lt;/tt&gt; on this barrier, or the specified waiting time elapses. * * ..... * * @param timeout the time to wait for the barrier * @param unit the time unit of the timeout parameter * @return the arrival index of the current thread, where index * &lt;tt&gt;{@link #getParties()} - 1&lt;/tt&gt; indicates the first * to arrive and zero indicates the last to arrive * @throws InterruptedException if the current thread was interrupted * while waiting * @throws TimeoutException if the specified timeout elapses * @throws BrokenBarrierException if &lt;em&gt;another&lt;/em&gt; thread was * interrupted or timed out while the current thread was * waiting, or the barrier was reset, or the barrier was broken * when {@code await} was called, or the barrier action (if * present) failed due an exception */ public int await(long timeout, TimeUnit unit) throws InterruptedException, BrokenBarrierException, TimeoutException { return dowait(true, unit.toNanos(timeout)); } 标注代码分析 线程调用此方法后等待，直到所有parties都调用当前barrier的这个方法。如果当前线程是不最后一个到达此方法的线程，那么会阻塞，直到下面的事情发生。 最后的线程也到达此方法。 其他线程中断了当前线程。 其他线程中断了在栅栏处等待的某个线程。 某个线程调用了栅栏的reset方法。 CyclicBarrier#dowait()1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980/** * Main barrier code, covering the various policies. */ // 1 private int dowait(boolean timed, long nanos) throws InterruptedException, BrokenBarrierException, TimeoutException { final ReentrantLock lock = this.lock; lock.lock(); try { final Generation g = generation; // 2 if (g.broken) throw new BrokenBarrierException(); if (Thread.interrupted()) { // 3 breakBarrier(); throw new InterruptedException(); } // 4 int index = --count; // 5 if (index == 0) { // tripped boolean ranAction = false; try { final Runnable command = barrierCommand; // 6 if (command != null) // 7 command.run(); ranAction = true; // 8 nextGeneration(); return 0; } finally { // 9 if (!ranAction) breakBarrier(); } } // loop until tripped, broken, interrupted, or timed out // 10 for (;;) { try { if (!timed) trip.await(); else if (nanos &gt; 0L) nanos = trip.awaitNanos(nanos); } catch (InterruptedException ie) { if (g == generation &amp;&amp; ! g.broken) { // 11 breakBarrier(); throw ie; } else { // We're about to finish waiting even if we had not // been interrupted, so this interrupt is deemed to // \"belong\" to subsequent execution. // 12 Thread.currentThread().interrupt(); } } if (g.broken) throw new BrokenBarrierException(); // 13 if (g != generation) return index; if (timed &amp;&amp; nanos &lt;= 0L) { // 14 breakBarrier(); throw new TimeoutException(); } } } finally { lock.unlock(); } } 标注代码分析 栅栏主体代码，涵盖了所有情况。 如果当前generation状态为broken，说明栅栏被打破，抛出BrokenBarrierException异常。 如果当前线程被中断，打破栅栏，然后抛出中断异常。 计算当前到达线程的下标。 下标为0表示当前线程为最后一个使用栅栏的线程。 如果有栅栏命令，执行栅栏命令。 看来栅栏的命令是由最后一个到达栅栏的线程执行。 产生新的generation。 如果栅栏命令未执行，打破栅栏。 等待中的主循环，直到栅栏开放、栅栏被打破、线程被打断或者超时时退出。 如果出于当前generation 且generation状态为未打破，那么打破栅栏。 如果没被中断的话，我们即将完成等待。所以这个中断被算作下一次执行的中断。 如果generation改变了，说明之前的栅栏已经开放，返回index。 如果超时，打破栅栏，并返回超时异常。 从dowait方法中可以看到，当所有使用者都到达时，栅栏开放，会调用nextGeneration方法；如果有其他情况(超时、中断等)发生，会调用breakBarrier方法。 CyclicBarrier#nextGeneration()123456789101112131415/** * Updates state on barrier trip and wakes up everyone. * Called only while holding lock. */// 1private void nextGeneration() { // signal completion of last generation // 2 trip.signalAll(); // set up next generation // 3 count = parties; // 4 generation = new Generation();} 标注代码分析 更新栅栏状态，唤醒所有在栅栏处等待的线程。这个方法只有在持有锁的情况下被调用。 唤醒所有在栅栏处等待的线程。 重置count。 生成新的generation。 CyclicBarrier#breakBarrier()12345678910111213/** * Sets current barrier generation as broken and wakes up everyone. * Called only while holding lock. */ // 1 private void breakBarrier() { // 2 generation.broken = true; // 3 count = parties; // 4 trip.signalAll(); } 标注代码分析 设置当前栅栏generation状态为运行状态，并唤醒栅栏处的等待线程。这个方法只有在持有锁的情况下被调用。 设置当前栅栏generation状态为运行状态。 重置count。 唤醒所有在栅栏处等待的线程。 CyclicBarrier123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596/** * Creates a new &lt;tt&gt;CyclicBarrier&lt;/tt&gt; that will trip when the * given number of parties (threads) are waiting upon it, and which * will execute the given barrier action when the barrier is tripped, * performed by the last thread entering the barrier. * * @param parties the number of threads that must invoke {@link #await} * before the barrier is tripped * @param barrierAction the command to execute when the barrier is * tripped, or {@code null} if there is no action * @throws IllegalArgumentException if {@code parties} is less than 1 */ public CyclicBarrier(int parties, Runnable barrierAction) { if (parties &lt;= 0) throw new IllegalArgumentException(); this.parties = parties; this.count = parties; this.barrierCommand = barrierAction; } /** * Creates a new &lt;tt&gt;CyclicBarrier&lt;/tt&gt; that will trip when the * given number of parties (threads) are waiting upon it, and * does not perform a predefined action when the barrier is tripped. * * @param parties the number of threads that must invoke {@link #await} * before the barrier is tripped * @throws IllegalArgumentException if {@code parties} is less than 1 */ public CyclicBarrier(int parties) { this(parties, null); } /** * Returns the number of parties required to trip this barrier. * * @return the number of parties required to trip this barrier */ public int getParties() { return parties; } /** * Queries if this barrier is in a broken state. * * @return {@code true} if one or more parties broke out of this * barrier due to interruption or timeout since * construction or the last reset, or a barrier action * failed due to an exception; {@code false} otherwise. */ public boolean isBroken() { final ReentrantLock lock = this.lock; lock.lock(); try { return generation.broken; } finally { lock.unlock(); } } /** * Resets the barrier to its initial state. If any parties are * currently waiting at the barrier, they will return with a * {@link BrokenBarrierException}. Note that resets &lt;em&gt;after&lt;/em&gt; * a breakage has occurred for other reasons can be complicated to * carry out; threads need to re-synchronize in some other way, * and choose one to perform the reset. It may be preferable to * instead create a new barrier for subsequent use. */ public void reset() { final ReentrantLock lock = this.lock; lock.lock(); try { // 1 breakBarrier(); // break the current generation nextGeneration(); // start a new generation } finally { lock.unlock(); } } /** * Returns the number of parties currently waiting at the barrier. * This method is primarily useful for debugging and assertions. * * @return the number of parties currently blocked in {@link #await} */ // 2 public int getNumberWaiting() { final ReentrantLock lock = this.lock; lock.lock(); try { return parties - count; } finally { lock.unlock(); } } 标注代码分析 重置逻辑，先打破当前的栅栏，然后建立一个新的。 获取在栅栏处等待的使用方(线程)数量。 3 总结 当建立一个使用方数量为n的栅栏时，栅栏内部有一个为n的计数。当使用方调用await方法时，如果其他n-1个使用方没有全部到达await方法(内部计数减1后，不等于0)，那么使用方(线程)阻塞等待。 当第n个使用方调用await时，栅栏开放(内部计数减1后等于0)，会唤醒所有在await方法上等待着的使用方(线程)，大家一起通过栅栏，然后重置栅栏(内部计数又变成n)，栅栏变成新建后的状态，可以再次使用。","link":"/JDK1.6-CyclicBarrier/"},{"title":"JDK1.6 ReentrantReadWriteLock","text":"1 介绍 写锁(tryAcquire) 读锁(tryAcquireShared) 2 源码分析 Sync属性 Sync#tryAcquire() Sync#writerShouldBlock() Sync#tryRelease() Sync#HoldCounter Sync#ThreadLocalHoldCounter Sync#tryAcquireShared Sync#fullTryAcquireShared Sync#tryReleaseShared Sync#tryWriteLock Sync#tryReadLock ReentrantReadWriteLock#FairSync ReentrantReadWriteLock#NonfairSync ReentrantReadWriteLock#ReadLock#lock() ReentrantReadWriteLock#ReadLock#tryLock() ReentrantReadWriteLock#ReadLock#newCondition() ReentrantReadWriteLock#WriteLock#lock() ReentrantReadWriteLock#WriteLock#tryLock() 3 锁降级 1 介绍ReentrantReadWriteLock支持公平/非公平锁。写锁可以降级为读锁，但读锁不能升级为写锁。 写锁(tryAcquire)(读锁&amp;&amp;写锁)或者(无读锁&amp;&amp;无写锁)，根据公平锁判断queue empty或者queue head，再竞争锁，非公平锁直接竞争锁。 读锁(tryAcquireShared)读锁会阻塞写锁。也会根据公平锁判断queue empty或者queue head，再竞争锁，非公平锁队列头有写请求，那么当前读请求阻塞，返回false，CAS直接竞争锁。如果是queue head，返回true，通过fullTryAcquireShared()中的CAS竞争锁。 2 源码分析ReentrantReadWriteLock实现ReadWriteLock接口。123456789101112131415public interface ReadWriteLock { /** * Returns the lock used for reading. * * @return the lock used for reading. */ Lock readLock(); /** * Returns the lock used for writing. * * @return the lock used for writing. */ Lock writeLock();} 读锁和写锁2个方法。ReentrantReadWriteLock#Sync基于AbstractQueuedSynchronizer实现。 Sync属性123456789static final int SHARED_SHIFT = 16; static final int SHARED_UNIT = (1 &lt;&lt; SHARED_SHIFT); static final int MAX_COUNT = (1 &lt;&lt; SHARED_SHIFT) - 1; static final int EXCLUSIVE_MASK = (1 &lt;&lt; SHARED_SHIFT) - 1; /** Returns the number of shared holds represented in count */ static int sharedCount(int c) { return c &gt;&gt;&gt; SHARED_SHIFT; } /** Returns the number of exclusive holds represented in count */ static int exclusiveCount(int c) { return c &amp; EXCLUSIVE_MASK; } The lower one representing the exclusive (writer) lock hold count, and the upper the shared (reader) hold count. 由注释可以知道低位表示write独占锁持有锁次数，高位表示read持有重入锁次数。 Sync#tryAcquire()获取write锁1234567891011121314151617181920212223242526272829303132333435protected final boolean tryAcquire(int acquires) { /* * Walkthrough: * 1. if read count nonzero or write count nonzero * and owner is a different thread, fail. * 2. If count would saturate, fail. (This can only * happen if count is already nonzero.) * 3. Otherwise, this thread is eligible for lock if * it is either a reentrant acquire or * queue policy allows it. If so, update state * and set owner. */ Thread current = Thread.currentThread(); // 1 int c = getState(); // 2 int w = exclusiveCount(c); // 3 if (c != 0) { // (Note: if c != 0 and w == 0 then shared count != 0) // 4 if (w == 0 || current != getExclusiveOwnerThread()) return false; // 5 if (w + exclusiveCount(acquires) &gt; MAX_COUNT) throw new Error(\"Maximum lock count exceeded\"); } // 6 if ((w == 0 &amp;&amp; writerShouldBlock(current)) || !compareAndSetState(c, c + acquires)) return false; // 7 setExclusiveOwnerThread(current); return true; } 结合注释标注代码分析 AbstractQueuedSynchronizer#getState(),线程持有锁的数量。 write独占锁数量。 c!=0当前线程持有锁。当前线程持有read锁。 write独占锁数量是0，说明线程持有reade锁，未持有write锁。无法获取锁。或者持有write锁的线程和当前线程不一样，返回失败。 当前write独占锁+已经持有write独占锁的次数&gt;锁数量最大值，抛异常。 c == 0当前线程未持有read锁。w == 0线程未持有write锁，说明未持有读锁、写锁。writerShouldBlock分别被公平锁和非公平锁实现。公平锁FairSync#writerShouldBlock()的queue empty或者queue head，则CAS来设置state。非公平锁NonfairSync#writerShouldBlock()返回false，直接设置CAS，无需阻塞。 当前未持有write锁、read锁，CAS设置成功，则设置AbstractQueuedSynchronizer#setExclusiveOwnerThread，exclusiveOwnerThread是锁独有线程。 Sync#writerShouldBlock()123456/** * Return true if a writer thread that is otherwise * eligible for lock should block because of policy * for overtaking other waiting threads. */ abstract boolean writerShouldBlock(Thread current); 根据注释及方法名字很容易理解。线程是否阻塞写。writerShouldBlock是抽象方法由Sync的子类公平锁(FairSync)和非公平锁(NonfairSync)实现这个方法。 Sync#tryRelease()1234567891011121314protected final boolean tryRelease(int releases) { int nextc = getState() - releases; if (Thread.currentThread() != getExclusiveOwnerThread()) throw new IllegalMonitorStateException(); // 1 if (exclusiveCount(nextc) == 0) { setExclusiveOwnerThread(null); setState(nextc); return true; } else {// 2 setState(nextc); return false; } } 标注代码分析 writer独占锁数量 == 0，设置持有锁的线程是null。设置重入次数AbstractQueuedSynchronizer#state。 持有writer独占锁，重新设置重入锁次数。 Sync#HoldCounter1234567891011121314151617/** * A counter for per-thread read hold counts. * Maintained as a ThreadLocal; cached in cachedHoldCounter */ static final class HoldCounter { int count; // Use id, not reference, to avoid garbage retention // 1 final long tid = Thread.currentThread().getId(); /** Decrement if positive; return previous value */ int tryDecrement() { int c = count; if (c &gt; 0) count = c - 1; return c; } } 标注代码分析 线程id作为HoldCounter#tid。avoid garbage retention有助于垃圾回收。 A counter for per-thread read hold counts 每个线程持有read锁的次数。 Sync#ThreadLocalHoldCounter1234567891011121314151617181920212223242526272829// 1static final class ThreadLocalHoldCounter extends ThreadLocal&lt;HoldCounter&gt; { public HoldCounter initialValue() { return new HoldCounter(); } } /** * The number of read locks held by current thread. * Initialized only in constructor and readObject. */ transient ThreadLocalHoldCounter readHolds; /** * The hold count of the last thread to successfully acquire * readLock. This saves ThreadLocal lookup in the common case * where the next thread to release is the last one to * acquire. This is non-volatile since it is just used * as a heuristic, and would be great for threads to cache. */ // 2 transient HoldCounter cachedHoldCounter; Sync() { readHolds = new ThreadLocalHoldCounter(); // 3 setState(getState()); // ensures visibility of readHolds } 标注代码分析 线程存储read锁计数的ThreadLocal。 HoldCounter作为缓存，存储线程获取read锁的计数。 volatile的读写操作，似内存屏障，保证readHolds的可见性。 Sync#tryAcquireShared获取read锁123456789101112131415161718192021222324protected final int tryAcquireShared(int unused) { Thread current = Thread.currentThread(); // 1 int c = getState(); // 2 if (exclusiveCount(c) != 0 &amp;&amp; getExclusiveOwnerThread() != current) return -1; if (sharedCount(c) == MAX_COUNT) throw new Error(\"Maximum lock count exceeded\"); // 3 if (!readerShouldBlock(current) &amp;&amp; compareAndSetState(c, c + SHARED_UNIT)) { HoldCounter rh = cachedHoldCounter; // 4 if (rh == null || rh.tid != current.getId()) cachedHoldCounter = rh = readHolds.get(); // 5 rh.count++; return 1; } return fullTryAcquireShared(current); } 标注代码分析 线程持有锁的数量。 持有write独占锁，当前线程不是持有锁的线程，获取锁失败。 readerShouldBlock分别有公平锁和非公平锁实现。公平锁FairSync#readerShouldBlock只有queue empty和queue head才能获取read 锁；非公平锁NonfairSync#readerShouldBlock()的queue有write锁，read锁获取阻塞，readerShouldBlock返回true，执行fullTryAcquireShared()。如果readerShouldBlock()是first queued thread，则执行CAS获取锁，然后把缓存HoldCounter赋值给新HoldCounter作为线程持有read锁的次数。 没有read锁计数HoldCount，或者read锁计数对象HoldCounter非当前线程的HoldCounter。重新赋值cachedHoldCounter、rh。 read锁计数+1。 Sync#fullTryAcquireShared1234567891011121314151617181920212223final int fullTryAcquireShared(Thread current) { HoldCounter rh = cachedHoldCounter; // 1 if (rh == null || rh.tid != current.getId()) rh = readHolds.get(); for (;;) { int c = getState(); int w = exclusiveCount(c); // 2 if ((w != 0 &amp;&amp; getExclusiveOwnerThread() != current) || ((rh.count | w) == 0 &amp;&amp; readerShouldBlock(current))) return -1; if (sharedCount(c) == MAX_COUNT) throw new Error(\"Maximum lock count exceeded\"); // 3 if (compareAndSetState(c, c + SHARED_UNIT)) { cachedHoldCounter = rh; // cache for release rh.count++; return 1; } } } 标注代码分析 缓存的read锁计数对象HoldCounter是null，或者holdCounter#id和线程id不一样的时候，重新给HoldCounter对象赋值。 write锁计数!=0，当前线程非锁持有者（其他线程持有锁），结束方法。或者未持有锁，同时read锁是阻塞的，结束方法。 for循环中CAS获取read锁。缓存HoldCounter赋值，HoldCounter对象rh+1。 Sync#tryReleaseShared释放read锁123456789101112131415protected final boolean tryReleaseShared(int unused) { HoldCounter rh = cachedHoldCounter; Thread current = Thread.currentThread(); if (rh == null || rh.tid != current.getId()) rh = readHolds.get(); if (rh.tryDecrement() &lt;= 0) throw new IllegalMonitorStateException(); for (;;) { int c = getState(); int nextc = c - SHARED_UNIT; // 1 if (compareAndSetState(c, nextc)) return nextc == 0; } } 标注代码分析 循环的进行CAS方法，然后read锁全部释放，返回true。 Sync#tryWriteLock123456789101112131415final boolean tryWriteLock() { Thread current = Thread.currentThread(); int c = getState(); if (c != 0) { int w = exclusiveCount(c); if (w == 0 ||current != getExclusiveOwnerThread()) return false; if (w == MAX_COUNT) throw new Error(\"Maximum lock count exceeded\"); } if (!compareAndSetState(c, c + 1)) return false; setExclusiveOwnerThread(current); return true; } This is identical in effect to tryAcquire except 从注释和代码知道这和Sync#tryAcquire()类似功能，缺少writerShouldBlock()。 Sync#tryReadLock123456789101112131415161718final boolean tryReadLock() { Thread current = Thread.currentThread(); for (;;) { int c = getState(); if (exclusiveCount(c) != 0 &amp;&amp; getExclusiveOwnerThread() != current) return false; if (sharedCount(c) == MAX_COUNT) throw new Error(\"Maximum lock count exceeded\"); if (compareAndSetState(c, c + SHARED_UNIT)) { HoldCounter rh = cachedHoldCounter; if (rh == null || rh.tid != current.getId()) cachedHoldCounter = rh = readHolds.get(); rh.count++; return true; } } } tryReadLock()和tryWriteLock()一样，tryReadLock()和tryAcquireShared()功能类似，缺少readerShouldBlock()。 ReentrantReadWriteLock#FairSync公平锁1234567891011final static class FairSync extends Sync { private static final long serialVersionUID = -2274990926593161451L; final boolean writerShouldBlock(Thread current) { // only proceed if queue is empty or current thread at head return !isFirst(current); } final boolean readerShouldBlock(Thread current) { // only proceed if queue is empty or current thread at head return !isFirst(current); } } writerShouldBlock()和readerShouldBlock()都是以AbstractQueuedSynchronizer#isFirst()判断是否运行阻塞。如果是queue head或者queue empty，则非阻塞。在Sync#tryAcquireShared中if (!readerShouldBlock(current) &amp;&amp;这代码用!，所以queue head或者queue empty公平锁才能获取到锁。 ReentrantReadWriteLock#NonfairSync非公平锁123456789101112final static class NonfairSync extends Sync { private static final long serialVersionUID = -8159625535654395037L; // 1 final boolean writerShouldBlock(Thread current) { return false; // writers can always barge } // 2 final boolean readerShouldBlock(Thread current) { return apparentlyFirstQueuedIsExclusive(); } } 标注代码分析 write不允许阻塞。参考Sync#tryAcquire()中if ((w == 0 &amp;&amp; writerShouldBlock(current)) ||!compareAndSetState(c, c + acquires))，writerShouldBlock()返回false，非公平锁tryAcquire()每次都可以通过CAS竞争锁。 如果AQS同步等待队列头有写请求，那么当前读请求阻塞。 ReentrantReadWriteLock#ReadLock#lock()12345678910111213/** * Acquires the read lock. * * &lt;p&gt;Acquires the read lock if the write lock is not held by * another thread and returns immediately. * * &lt;p&gt;If the write lock is held by another thread then * the current thread becomes disabled for thread scheduling * purposes and lies dormant until the read lock has been acquired. */ public void lock() { sync.acquireShared(1); } 请求读锁。如果没有其他线程持有写锁，那么请求成功，方法返回。Sync#tryAcquireShared()中if (exclusiveCount(c) != 0 &amp;&amp;getExclusiveOwnerThread() != current)有write锁，获取read锁失败。如果当前线程被阻塞，执行fullTryAcquireShared()，直到CAS获取到锁。 ReentrantReadWriteLock#ReadLock#tryLock()123public boolean tryLock() { return sync.tryReadLock(); } 如果没有其他线程持有写锁，那么请求读锁成功。exclusiveCount(c) != 0判断是否持有writer锁。 ReentrantReadWriteLock#ReadLock#newCondition()123public Condition newCondition() { throw new UnsupportedOperationException(); } {@code ReadLocks} do not support conditions 不支持conditions，所以抛出异常。 ReentrantReadWriteLock#WriteLock#lock()123public void lock() { sync.acquire(1); } 根据注释可以知道。 如果没有其他线程持有读锁或者写锁，那么CAS请求写锁成功，并将写锁持有次数设置为acquires。if ((w == 0 &amp;&amp; writerShouldBlock(current)) ||!compareAndSetState(c, c + acquires)) 如果当前线程已经持有了写锁w &gt; 0，直接执行CAS请求成功并增加持有次数。 ReentrantReadWriteLock#WriteLock#tryLock()123public boolean tryLock( ) { return sync.tryWriteLock(); } 根据注释可以知道。 如果没有其他线程持有当前锁的读锁或者写锁，那么CAS请求读锁成功。 如果当前线程已经持有当前写锁，直接执行CAS增加写锁持有次数。 3 锁降级jdk官方实例1234567891011121314151617181920212223242526272829303132import java.util.concurrent.locks.ReentrantReadWriteLock;public class CachedData { Object data; volatile boolean cacheValid; ReentrantReadWriteLock rwl = new ReentrantReadWriteLock(); void processCachedData() { // 1 rwl.readLock().lock(); if (!cacheValid) { // Must release read lock before acquiring write lock rwl.readLock().unlock(); // 2 rwl.writeLock().lock(); // Recheck state because another thread might have acquired // write lock and changed state before we did. if (!cacheValid) { // data = ... cacheValid = true; } // Downgrade by acquiring read lock before releasing write lock // 3 rwl.readLock().lock(); rwl.writeLock().unlock(); // Unlock write, still hold read } //use(data); // 4 rwl.readLock().unlock(); }} 标注代码分析 读锁。 先释放读锁，在获取写锁。 锁降级。释放写锁前，获取读锁。 已经获取读锁，可以进行业务操作，然后再释放读锁。","link":"/JDK1.6-ReentrantReadWriteLock/"},{"title":"JDK1.6 ThreadLocal","text":"1 例 2 源码分析 ThreadLocal#Entry ThreadLocal#nextHashCode ThreadLocal#HASH_INCREMENT ThreadLocal#threadLocalHashCode Thread#threadLocals ThreadLocal#get() ThreadLocal#getMap() ThreadLocal#ThreadLocalMap#getEntry() ThreadLocal#set() ThreadLocal#createMap() ThreadLocal#ThreadLocalMap#set() ThreadLocal#ThreadLocalMap#replaceStaleEntry() ThreadLocal#ThreadLocalMap#expungeStaleEntry() ThreadLocal#ThreadLocalMap#cleanSomeSlots() 程序实例 同一个线程多个值 多个线程 4 总结 1 例Hibernate中典型的ThreadLocal的代码。1234567891011121314private static final ThreadLocal threadSession = new ThreadLocal(); public static Session getSession() throws InfrastructureException { Session s = (Session) threadSession.get(); try { if (s == null) { s = getSessionFactory().openSession(); threadSession.set(s); } } catch (HibernateException ex) { throw new InfrastructureException(ex); } return s; } 可以看到在getSession()方法中，首先判断当前线程中有没有放进去session，如果还没有，那么通过sessionFactory().openSession()来创建一个session，再将session set到线程中，实际是放到当前线程的ThreadLocalMap这个map中。这时，对于这个session的唯一引用就是当前线程中的那个ThreadLocalMap，而threadSession作为这个值的key，要取得这个session可以通过threadSession.get()来得到，里面执行的操作实际是先取得当前线程中的ThreadLocalMap，然后将threadSession作为key将对应的值取出。这个session相当于线程的私有变量，而不是public的。ThreadLocal是在每个线程中有一个map，而将ThreadLocal实例作为key，这样每个map中的项数很少，而且当线程销毁时相应的东西也一起销毁了。 这样设计也防止内存泄漏，1个线程被销毁，这个线程内的对象都被销毁。 2 源码分析ThreadLocal内部实现一个hash map的内部类。get()和set()内部都是操作TheadLocalMap#entry。 ThreadLocal#Entry1234567891011121314151617181920212223242526272829303132333435363738/** * The entries in this hash map extend WeakReference, using * its main ref field as the key (which is always a * ThreadLocal object). Note that null keys (i.e. entry.get() * == null) mean that the key is no longer referenced, so the * entry can be expunged from table. Such entries are referred to * as \"stale entries\" in the code that follows. */ static class Entry extends WeakReference&lt;ThreadLocal&gt; { /** The value associated with this ThreadLocal. */ Object value; Entry(ThreadLocal k, Object v) { super(k); value = v; } } /** * The initial capacity -- MUST be a power of two. */ private static final int INITIAL_CAPACITY = 16; /** * The table, resized as necessary. * table.length MUST always be a power of two. */ private Entry[] table; /** * The number of entries in the table. */ private int size = 0; /** * The next size value at which to resize. */ private int threshold; // Default to 0 ThreadLocal内部是由entry这个弱引用对象组成，这个entry就是一个hash map，只是是弱引用。Entry的构造函数Entry(ThreadLocal&lt;?&gt; k, Object v)，ThreadLocal引用作为key。根据注释key=null，则不是强引用，因为是弱引用，entry can be expunged from table，这个对象从table中删除。 ThreadLocal#nextHashCode123456 /** * The next hash code to be given out. Updated atomically. Starts at * zero. */ private static AtomicInteger nextHashCode = new AtomicInteger(); 获取下1个hashcode的值。 ThreadLocal#HASH_INCREMENT123456/** * The difference between successively generated hash codes - turns * implicit sequential thread-local IDs into near-optimally spread * multiplicative hash values for power-of-two-sized tables. */private static final int HASH_INCREMENT = 0x61c88647; ThreadLocal#threadLocalHashCode1234567891011/** * ThreadLocals rely on per-thread linear-probe hash maps attached * to each thread (Thread.threadLocals and * inheritableThreadLocals). The ThreadLocal objects act as keys, * searched via threadLocalHashCode. This is a custom hash code * (useful only within ThreadLocalMaps) that eliminates collisions * in the common case where consecutively constructed ThreadLocals * are used by the same threads, while remaining well-behaved in * less common cases. */ private final int threadLocalHashCode = nextHashCode(); 由后面代码可以知道threadLocalHashCode是减少ThreadLocalMap#Entry#table散列冲突。 Thread#threadLocals123/* ThreadLocal values pertaining to this thread. This map is maintained * by the ThreadLocal class. */ThreadLocal.ThreadLocalMap threadLocals = null; ThreadLocal#get()1234567891011121314151617181920/** * Returns the value in the current thread's copy of this * thread-local variable. If the variable has no value for the * current thread, it is first initialized to the value returned * by an invocation of the {@link #initialValue} method. * * @return the current thread's value of this thread-local */ public T get() { Thread t = Thread.currentThread(); // 1 ThreadLocalMap map = getMap(t); if (map != null) { // 2 ThreadLocalMap.Entry e = map.getEntry(this); if (e != null) return (T)e.value; } return setInitialValue(); } 标注代码分析 获取当前线程的ThreadLocal#ThreadLocalMap。 threadlocal#ThreadLocalMap的entry对象。 ThreadLocal#getMap()12345678910/** * Get the map associated with a ThreadLocal. Overridden in * InheritableThreadLocal. * * @param t the current thread * @return the map */ThreadLocalMap getMap(Thread t) { return t.threadLocals;} 获取thread t#threadLocal。 ThreadLocal#ThreadLocalMap#getEntry()1234567891011121314151617181920/** * Get the entry associated with key. This method * itself handles only the fast path: a direct hit of existing * key. It otherwise relays to getEntryAfterMiss. This is * designed to maximize performance for direct hits, in part * by making this method readily inlinable. * * @param key the thread local object * @return the entry associated with key, or null if no such */ private Entry getEntry(ThreadLocal key) { // 1 int i = key.threadLocalHashCode &amp; (table.length - 1); Entry e = table[i]; if (e != null &amp;&amp; e.get() == key) return e; else return getEntryAfterMiss(key, i, e); } 标注代码分析 减少散列冲突。 ThreadLocal#set()1234567891011121314151617/** * Sets the current thread's copy of this thread-local variable * to the specified value. Most subclasses will have no need to * override this method, relying solely on the {@link #initialValue} * method to set the values of thread-locals. * * @param value the value to be stored in the current thread's copy of * this thread-local. */public void set(T value) { Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value);} ThreadLocal#createMap()1234567891011/** * Create the map associated with a ThreadLocal. Overridden in * InheritableThreadLocal. * * @param t the current thread * @param firstValue value for the initial entry of the map * @param map the map to store. */void createMap(Thread t, T firstValue) { t.threadLocals = new ThreadLocalMap(this, firstValue);} ThreadLocal#ThreadLocalMap#set()1234567891011121314151617181920212223242526272829303132333435363738/** * Set the value associated with key. * * @param key the thread local object * @param value the value to be set */ private void set(ThreadLocal key, Object value) { // We don't use a fast path as with get() because it is at // least as common to use set() to create new entries as // it is to replace existing ones, in which case, a fast // path would fail more often than not. Entry[] tab = table; int len = tab.length; int i = key.threadLocalHashCode &amp; (len-1); for (Entry e = tab[i]; e != null; e = tab[i = nextIndex(i, len)]) { ThreadLocal k = e.get(); // 1 if (k == key) { e.value = value; return; } // 2 if (k == null) { replaceStaleEntry(key, value, i); return; } } // 3 tab[i] = new Entry(key, value); int sz = ++size; if (!cleanSomeSlots(i, sz) &amp;&amp; sz &gt;= threshold) rehash(); } 标注代码分析 如果threadLocal#key和entry#k相同，则覆盖原来的value。 如果k=null（entry的key是null），覆盖原来value的值，i是table的下标。 entry的table容量扩展。 ThreadLocal#ThreadLocalMap#replaceStaleEntry()12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879/** * Replace a stale entry encountered during a set operation * with an entry for the specified key. The value passed in * the value parameter is stored in the entry, whether or not * an entry already exists for the specified key. * * As a side effect, this method expunges all stale entries in the * \"run\" containing the stale entry. (A run is a sequence of entries * between two null slots.) * * @param key the key * @param value the value to be associated with key * @param staleSlot index of the first stale entry encountered while * searching for key. */ private void replaceStaleEntry(ThreadLocal key, Object value, int staleSlot) { Entry[] tab = table; int len = tab.length; Entry e; // Back up to check for prior stale entry in current run. // We clean out whole runs at a time to avoid continual // incremental rehashing due to garbage collector freeing // up refs in bunches (i.e., whenever the collector runs). // 1 int slotToExpunge = staleSlot; // 2 for (int i = prevIndex(staleSlot, len); (e = tab[i]) != null; i = prevIndex(i, len)) if (e.get() == null) slotToExpunge = i; // Find either the key or trailing null slot of run, whichever // occurs first for (int i = nextIndex(staleSlot, len); (e = tab[i]) != null; i = nextIndex(i, len)) { ThreadLocal k = e.get(); // If we find key, then we need to swap it // with the stale entry to maintain hash table order. // The newly stale slot, or any other stale slot // encountered above it, can then be sent to expungeStaleEntry // to remove or rehash all of the other entries in run. // 3 if (k == key) { e.value = value; // 4 tab[i] = tab[staleSlot]; tab[staleSlot] = e; // Start expunge at preceding stale entry if it exists // 5 if (slotToExpunge == staleSlot) slotToExpunge = i; // 6 cleanSomeSlots(expungeStaleEntry(slotToExpunge), len); return; } // If we didn't find stale entry on backward scan, the // first stale entry seen while scanning for key is the // first still present in the run. if (k == null &amp;&amp; slotToExpunge == staleSlot) slotToExpunge = i; } // If key not found, put new entry in stale slot // 7 tab[staleSlot].value = null; tab[staleSlot] = new Entry(key, value); // If there are any other stale entries in run, expunge them if (slotToExpunge != staleSlot) cleanSomeSlots(expungeStaleEntry(slotToExpunge), len); } 标注代码分析 待删除的下标。 往前轮询，如果entry#e#key == null，标记slotToExpunge = 当前i。 key相同时，value替换旧的value值。 替换tab的数据，即entry。 如果旧的slot存在，待删除的slot = i。 清楚相同的slot。 如果key不存在，创建新的entry。 ThreadLocal#ThreadLocalMap#expungeStaleEntry()1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950/** * Expunge a stale entry by rehashing any possibly colliding entries * lying between staleSlot and the next null slot. This also expunges * any other stale entries encountered before the trailing null. See * Knuth, Section 6.4 * * @param staleSlot index of slot known to have null key * @return the index of the next null slot after staleSlot * (all between staleSlot and this slot will have been checked * for expunging). */ private int expungeStaleEntry(int staleSlot) { Entry[] tab = table; int len = tab.length; // expunge entry at staleSlot tab[staleSlot].value = null; tab[staleSlot] = null; size--; // Rehash until we encounter null // 1 Entry e; int i; for (i = nextIndex(staleSlot, len); (e = tab[i]) != null; i = nextIndex(i, len)) { ThreadLocal k = e.get(); // 2 if (k == null) { e.value = null; tab[i] = null; size--; } else { // 3 int h = k.threadLocalHashCode &amp; (len - 1); // 4 if (h != i) { tab[i] = null; // Unlike Knuth 6.4 Algorithm R, we must scan until // null because multiple entries could have been stale. while (tab[h] != null) h = nextIndex(h, len); tab[h] = e; } } } return i; } 标注代码分析 ThreadLocal = null，size-1，否则重新计算tab的值。 ThreadLocal是null，删除1个entry table。 h = k#threadlocal#entry的table下标。 h!=i,tab[i]、tab[h]都是null，tab[i]原来值e赋值给tab[h]。 return i表示旧的slot的下一个是null下标。 ThreadLocal#ThreadLocalMap#cleanSomeSlots()12345678910111213141516171819202122232425262728293031323334353637383940/** * Heuristically scan some cells looking for stale entries. * This is invoked when either a new element is added, or * another stale one has been expunged. It performs a * logarithmic number of scans, as a balance between no * scanning (fast but retains garbage) and a number of scans * proportional to number of elements, that would find all * garbage but would cause some insertions to take O(n) time. * * @param i a position known NOT to hold a stale entry. The * scan starts at the element after i. * * @param n scan control: &lt;tt&gt;log2(n)&lt;/tt&gt; cells are scanned, * unless a stale entry is found, in which case * &lt;tt&gt;log2(table.length)-1&lt;/tt&gt; additional cells are scanned. * When called from insertions, this parameter is the number * of elements, but when from replaceStaleEntry, it is the * table length. (Note: all this could be changed to be either * more or less aggressive by weighting n instead of just * using straight log n. But this version is simple, fast, and * seems to work well.) * * @return true if any stale entries have been removed. */ private boolean cleanSomeSlots(int i, int n) { boolean removed = false; Entry[] tab = table; int len = tab.length; do { i = nextIndex(i, len); Entry e = tab[i]; // 1 if (e != null &amp;&amp; e.get() == null) { n = len; removed = true; i = expungeStaleEntry(i); } } while ( (n &gt;&gt;&gt;= 1) != 0); return removed; } 标注代码分析 清除entry!=null，但是entry#value = null的值。 程序实例证明每个线程在ThreadLocal都是私有的。set单值和多值，tab的下标变化。 同一个线程多个值tab下标的变化。12345678910111213141516package threadLocal;public class T { protected static ThreadLocal&lt;String&gt; threadLocal = new ThreadLocal&lt;String&gt;(); public static void main(String[] args) { System.out.println(\"threadLocal = \" + threadLocal); threadLocal.set(\"1000\"); System.out.println(\"main = \" + threadLocal.get()); threadLocal.set(\"4000\"); System.out.println(\"main = \" + threadLocal.get()); }} threadLocalMap = 64a294a6threadLocal = 6f2b958evalue=1000，i=3，存在tab[3]新建一个Entry对象，第1次e对象是null。第2次set值，value=4000，threadLocalMap和threadLocal是同一个。 多个线程12345678910111213141516171819202122232425262728293031323334353637383940414243444546package threadLocal;public class T { public static ThreadLocal&lt;String&gt; threadLocal = new ThreadLocal&lt;String&gt;(); public static void main(String[] args) { Thread t1 = new Thread(new Runnable() { @Override public void run() { System.out.println(\"执行线程1.....\"); threadLocal.set(\"1001\"); try { Thread.sleep(5000); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(\"t1 = \" + T.threadLocal.get()); } }); System.out.println(\"thread1 = \" + t1); t1.start(); Thread t2 = new Thread(new Runnable() { @Override public void run() { System.out.println(\"执行线程2.....\"); threadLocal.set(\"1002\"); try { Thread.sleep(10000); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(\"t2 = \" + T.threadLocal.get()); } }); System.out.println(\"thread2 = \" + t2); t2.start(); }} T1线程没有threadLocal，需要新建。 4 总结 ThreadLocal的get，set方法，key值都是ThreadLocal本身，但是线程（Thread）对ThreadLocal是私有的，每个线程都有自己的ThreadLocal。 线程销毁的时候，ThreadLocal也跟着销毁，这样不会造成内存溢出。 根据实例2，多线程使用ThreadLocal互不影响。因为，ThreadLocal里有个内部类ThreadLocalMap，每个线程都私有一个ThreadLocalMap，ThreadLocalMap里有个Entry的hash map结构的类，通过table[]来存取ThreadLocal，每个线程的ThreadLocalMap相互不影响。","link":"/JDK1.6-ThreadLocal/"},{"title":"JDK1.7 FutureTask","text":"1 功能简介 2 源码分析 WaitNode 2.1 分析源码 2.1.1 创建任务 FutureTask 2.1.2 执行任务 run() set() finishCompletion()。 setException() handlePossibleCancellationInterrupt() 总结run() runAndReset() 2.1.3 获取结果 get() awaitDone() removeWaiter() get()#report get(long timeout, TimeUnit unit) 总结get() cancel() 查看任务状态 JDK1.7和JDK1.6的区别 1 功能简介 FutureTask是一种异步任务(或异步计算)，举个栗子，主线程的逻辑中需要使用某个值，但这个值需要负责的运算得来，那么主线程可以提前建立一个异步任务来计算这个值(在其他的线程中计算)，然后去做其他事情，当需要这个值的时候再通过刚才建立的异步任务来获取这个值，有点并行的意思，这样可以缩短整个主线程逻辑的执行时间。 1.7与1.6版本不同，1.7的FutureTask不再基于AQS来构建，而是在内部采用简单的Treiber Stack来保存等待线程。 2 源码分析12345678910111213141516171819public class FutureTask&lt;V&gt; implements RunnableFuture&lt;V&gt; { private volatile int state; private static final int NEW = 0; private static final int COMPLETING = 1; private static final int NORMAL = 2; private static final int EXCEPTIONAL = 3; private static final int CANCELLED = 4; private static final int INTERRUPTING = 5; private static final int INTERRUPTED = 6; // 1 private Callable&lt;V&gt; callable; // 2 private Object outcome; // 3 private volatile Thread runner; // 4 private volatile WaitNode waiters; 内部状态可能得迁转过程 NEW -&gt; COMPLETING -&gt; NORMAL //正常完成 NEW -&gt; COMPLETING -&gt; EXCEPTIONAL //发生异常 NEW -&gt; CANCELLED //取消 NEW -&gt; INTERRUPTING -&gt; INTERRUPTED //中断 标注代码分析 内部的callable，运行完成后设置为null。 如果正常完成，就是执行结果，通过get方法获取；如果发生异常，就是具体的异常对象，通过get方法抛出。本身没有volatile修饰, 依赖state的读写来保证可见性。 执行内部callable的线程。 存放等待线程的Treiber Stack。 WaitNode12345static final class WaitNode { volatile Thread thread; volatile WaitNode next; WaitNode() { thread = Thread.currentThread(); } } 包含当前线程对象，并有指向下一个WaitNode的指针，所谓的Treiber Stack就是由WaitNode组成的(一个单向链表)。 2.1 分析源码按照FutureTask的运行过程来分析。 创建任务，实际使用时，一般会结合线程池(ThreadPoolExecutor)使用，所以是在线程池内部创建FutureTask。 执行任务，一般会有由工作线程(对于我们当前线程来说的其他线程)调用FutureTask#run()，完成执行。 获取结果，一般会有我们的当前线程去调用get()来获取执行结果，如果获取时，任务并没有被执行完毕，当前线程就会被阻塞，直到任务被执行完毕，然后获取结果。 取消任务，某些情况下会放弃任务的执行，进行任务取消。2.1.1 创建任务FutureTask1234567891011public FutureTask(Callable&lt;V&gt; callable) { if (callable == null) throw new NullPointerException(); this.callable = callable; this.state = NEW; // ensure visibility of callable } public FutureTask(Runnable runnable, V result) { this.callable = Executors.callable(runnable, result); this.state = NEW; // ensure visibility of callable } 构造一个FutureTask很简单，可以通过一个Callable来构建，也可以通过一个Runnable和一个result来构建。这里要注意的是必须把state的写放到最后，因为state本身由volatile修饰，所以可以保证callable的可见性。(因为后续读callable之前会先读state，还记得这个volatile写读的HB规则吧)。 2.1.2 执行任务run()12345678910111213141516171819202122232425262728293031323334public void run() { //1 if (state != NEW || !UNSAFE.compareAndSwapObject(this, runnerOffset, null, Thread.currentThread())) return; try { Callable&lt;V&gt; c = callable; if (c != null &amp;&amp; state == NEW) { V result; boolean ran; try { //2 result = c.call(); ran = true; } catch (Throwable ex) { result = null; ran = false; //3 setException(ex); } if (ran) set(result); //4 } } finally { //5 runner = null; //6 int s = state; if (s &gt;= INTERRUPTING) //7 handlePossibleCancellationInterrupt(s); } } 标注代码分析 如果state不为null或者尝试设置runner为当前线程，失败就退出。 执行任务。 如果发生异常，设置异常。 如果正常执行完成，设置执行结果。 runner必须在设置了state之后再置空，避免run方法出现并发问题。 这里还必须再读一次state，避免丢失中断。 处理可能发生的取消中断(cancel(true))。set()12345678protected void set(V v) { if (UNSAFE.compareAndSwapInt(this, stateOffset, NEW, COMPLETING)) { outcome = v; UNSAFE.putOrderedInt(this, stateOffset, NORMAL); // final state //1 finishCompletion(); } } set过程中，首先尝试将当前任务状态state从NEW改为COMPLETING。如果成功的话，再设置执行结果到outcome。然后将state再次设置为NORMAL，注意这次使用的是putOrderedInt，其实就是原子量的LazySet内部使用的方法。为什么使用这个方法？首先LazySet相对于Volatile-Write来说更廉价，因为它没有昂贵的Store/Load屏障，只有Store/Store屏障(x86下Store/Store屏障是一个空操作)，其次，后续线程不会及时的看到state从COMPLETING变为NORMAL，但这没什么关系，而且NORMAL是state的最终状态之一，以后不会在变化了。标注代码分析 唤醒Treiber Stack中所有等待线程。 finishCompletion()。12345678910111213141516171819202122232425private void finishCompletion() { for (WaitNode q; (q = waiters) != null;) { //1 if (UNSAFE.compareAndSwapObject(this, waitersOffset, q, null)) { //2 for (;;) { Thread t = q.thread; if (t != null) { q.thread = null; LockSupport.unpark(t); } WaitNode next = q.next; if (next == null) break; q.next = null; // unlink to help gc q = next; } break; } } // 3 done(); // 4 callable = null; } finishCompletion主要就是在任务执行完毕后，移除Treiber Stack，并将Treiber Stack中所有等待获取任务结果的线程唤醒，然后回调下done钩子方法。run过程中如果发生异常，调用的setException()。标注代码分析 尝试将waiters设置为null。 然后将waiters中的等待线程全部唤醒。 回调下钩子方法。 置空callable，减少内存占用。 setException()12345678910111213141516171819202122232425262728protected void setException(Throwable t) { if (UNSAFE.compareAndSwapInt(this, stateOffset, NEW, COMPLETING)) { outcome = t; UNSAFE.putOrderedInt(this, stateOffset, EXCEPTIONAL); // final state finishCompletion(); } }``` #### handlePossibleCancellationInterrupt() ``` java/** * 确保cancel(true)产生的中断发生在run或runAndReset方法过程中。 */ private void handlePossibleCancellationInterrupt(int s) { //1 if (s == INTERRUPTING) //2 while (state == INTERRUPTING) Thread.yield(); // wait out pending interrupt // We want to clear any interrupt we may have received from // cancel(true). However, it is permissible to use interrupts // as an independent mechanism for a task to communicate with // its caller, and there is no way to clear only the // cancellation interrupt. // // Thread.interrupted(); } 标注代码分析 如果当前正在中断过程中，自旋等待一下，等中断完成。 这里的state状态一定是INTERRUPTED; 这里不能清除中断标记，因为没办法区分来自cancel(true)的中断。 总结run() 只有state为NEW的时候才执行任务(调用内部callable#run())。执行前会原子的设置执行线程(runner)，防止竞争。 如果任务执行成功，任务状态从NEW迁转为COMPLETING(原子)，设置执行结果，任务状态从COMPLETING迁转为NORMAL(LazySet)；如果任务执行过程中发生异常，任务状态从NEW迁转为COMPLETING(原子)，设置异常结果，任务状态从COMPLETING迁转为EXCEPTIONAL(LazySet)。 将Treiber Stack中等待当前任务执行结果的等待节点中的线程全部唤醒，同时删除这些等待节点，将整个Treiber Stack置空。 最后别忘了等一下可能发生的cancel(true)中引起的中断，让这些中断发生在执行任务过程中(别泄露出去)。 runAndReset()周期性任务的时候用到1234567891011121314151617181920212223242526272829protected boolean runAndReset() { if (state != NEW || !UNSAFE.compareAndSwapObject(this, runnerOffset, null, Thread.currentThread())) return false; boolean ran = false; int s = state; try { Callable&lt;V&gt; c = callable; if (c != null &amp;&amp; s == NEW) { try { c.call(); // don't set result ran = true; } catch (Throwable ex) { setException(ex); } } } finally { // runner must be non-null until state is settled to // prevent concurrent calls to run() runner = null; // state must be re-read after nulling runner to prevent // leaked interrupts s = state; if (s &gt;= INTERRUPTING) handlePossibleCancellationInterrupt(s); } return ran &amp;&amp; s == NEW; } 可见runAndReset与run方法的区别只是执行完毕后不设置结果、而且有返回值表示是否执行成功。 2.1.3 获取结果get()12345678public V get() throws InterruptedException, ExecutionException { int s = state; if (s &lt;= COMPLETING) //1 s = awaitDone(false, 0L); //2 return report(s); } 标注代码分析 如果任务还没执行完毕，等待任务执行完毕。 如果任务执行完毕，获取执行结果。 awaitDone()12345678910111213141516171819202122232425262728293031323334353637383940414243private int awaitDone(boolean timed, long nanos) throws InterruptedException { //1 final long deadline = timed ? System.nanoTime() + nanos : 0L; WaitNode q = null; boolean queued = false; for (;;) { if (Thread.interrupted()) { //2 removeWaiter(q); throw new InterruptedException(); } int s = state; if (s &gt; COMPLETING) { //3 if (q != null) q.thread = null; return s; } else if (s == COMPLETING) //4 Thread.yield(); else if (q == null) q = new WaitNode(); else if (!queued) //5 queued = UNSAFE.compareAndSwapObject(this, waitersOffset, q.next = waiters, q); else if (timed) { nanos = deadline - System.nanoTime(); if (nanos &lt;= 0L) { //6 removeWaiter(q); return state; } //7 LockSupport.parkNanos(this, nanos); } else //8 LockSupport.park(this); } } 标注代码分析 先算出到期时间。 如果当前线程被中断，移除等待节点q，然后抛出中断异常。 如果任务已经执行完毕,设置thread=null。 如果当前正在完成过程中，出让CPU。 将q(包含当前线程的等待节点)入队。 如果超时，移除等待节点q。 超时的话，就阻塞给定时间。 没设置超时的话，就阻塞当前线程。 removeWaiter()123456789101112131415161718192021222324private void removeWaiter(WaitNode node) { if (node != null) { //1 node.thread = null; //2 retry: for (;;) { for (WaitNode pred = null, q = waiters, s; q != null; q = s) { s = q.next; if (q.thread != null) pred = q; else if (pred != null) { pred.next = s; if (pred.thread == null) // check for race continue retry; } else if (!UNSAFE.compareAndSwapObject(this, waitersOffset, q, s)) continue retry; } break; } } } 标注代码分析 将node的thread域置空。 下面过程中会将node从等待队列中移除，以thread域为null为依据，如果过程中发生了竞争，重试。 get()#report12345678private V report(int s) throws ExecutionException { Object x = outcome; if (s == NORMAL) return (V)x; if (s &gt;= CANCELLED) throw new CancellationException(); throw new ExecutionException((Throwable)x); } get(long timeout, TimeUnit unit)12345678910public V get(long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException { if (unit == null) throw new NullPointerException(); int s = state; if (s &lt;= COMPLETING &amp;&amp; (s = awaitDone(true, unit.toNanos(timeout))) &lt;= COMPLETING) throw new TimeoutException(); return report(s); } 总结get() 首先检查当前任务的状态，如果状态表示执行完成，进入第2步。 获取执行结果，也可能得到取消或者执行异常，get过程结束。 如果当前任务状态表示未执行或者正在执行，那么当前线程放入一个新建的等待节点，然后进入Treiber Stack进行阻塞等待。 如果任务被工作线程(对当前线程来说是其他线程)执行完毕，执行完毕时工作线程会唤醒Treiber Stack上等待的所有线程，所以当前线程被唤醒，清空当前等待节点上的线程域，然后进入第2步。 当前线程在阻塞等待结果过程中可能被中断，如果被中断，那么会移除当前线程在Treiber Stack上对应的等待节点，然后抛出中断异常，get过程结束。 当前线程也可能执行带有超时时间的阻塞等待，如果超时时间过了，还没得到执行结果，那么会除当前线程在Treiber Stack上对应的等待节点，然后抛出超时异常，get过程结束。 cancel()12345678910111213141516171819202122public boolean cancel(boolean mayInterruptIfRunning) { //1 if (state != NEW) return false; if (mayInterruptIfRunning) { //2 if (!UNSAFE.compareAndSwapInt(this, stateOffset, NEW, INTERRUPTING)) return false; Thread t = runner; //3 if (t != null) t.interrupt(); //4 UNSAFE.putOrderedInt(this, stateOffset, INTERRUPTED); // final state } //5 else if (!UNSAFE.compareAndSwapInt(this, stateOffset, NEW, CANCELLED)) return false; //6 finishCompletion(); return true; } 在设置mayInterruptIfRunning为true的情况下，内部首先通过一个原子操作将state从NEW转变为INTERRUPTING，然后中断执行任务的线程，然后在通过一个LazySet的操作将state从INTERRUPTING转变为INTERRUPTED，由于后面这个操作对其他线程并不会立即可见，所以handlePossibleCancellationInterrupt才会有一个自旋等待state从INTERRUPTING变为INTERRUPTED的过程。标注代码分析 如果任务已经执行完毕，返回false。 如果有中断任务的标志，尝试将任务状态设置为INTERRUPTING。 上面设置成功的话，这里进行线程中断。 最后将任务状态设置为INTERRUPTED，注意这里又是LazySet。 如果没有中断任务的标志，尝试将任务状态设置为CANCELLED。 最后唤醒Treiber Stack中所有等待线程。查看任务状态123456public boolean isCancelled() { return state &gt;= CANCELLED; } public boolean isDone() { return state != NEW; } JDK1.7和JDK1.6的区别JDK1.7的FutureTask不像1.6那样基于AQS构建。前面贴代码了时候故意去掉了一些注释，避免读代码的时候受影响，现在我们来看一下关键的一段。 /* * Revision notes: This differs from previous versions of this * class that relied on AbstractQueuedSynchronizer, mainly to * avoid surprising users about retaining interrupt status during * cancellation races. Sync control in the current design relies * on a &quot;state&quot; field updated via CAS to track completion, along * with a simple Treiber stack to hold waiting threads. * * Style note: As usual, we bypass overhead of using * AtomicXFieldUpdaters and instead directly use Unsafe intrinsics. */ 使用AQS的方式，可能会在取消发生竞争过程中诡异的保留了中断状态。这里之所以没有采用这种方式，是为了避免这种情况的发生。具体什么情况下会发生呢？123ThreadPoolExecutor executor = ...; executor.submit(task1).cancel(true); executor.submit(task2); 看上面的代码，虽然中断的是task1，但可能task2得到中断信号。原因是什么呢？看下JDK1.6的FutureTask的中断代码。12345678910111213141516171819boolean innerCancel(boolean mayInterruptIfRunning) { for (;;) { int s = getState(); if (ranOrCancelled(s)) return false; if (compareAndSetState(s, CANCELLED)) break; } if (mayInterruptIfRunning) { Thread r = runner; //1 if (r != null) //2 r.interrupt(); } releaseShared(0); done(); return true; } 结合上面代码例子看一下，如果主线程执行到标注1的时候，线程池可能会认为task1已经执行结束(被取消)，然后让之前执行task1工作线程去执行task2，工作线程开始执行task2之后，然后主线程执行标注2(我们会发现并没有任何同步机制来阻止这种情况的发生)，这样就会导致task2被中断了。所以现在就能更好的理解JDK1.7 FutureTask的handlePossibleCancellationInterrupt中为什么要将cancel(true)中的中断保留在当前run方法运行范围内!","link":"/JDK1.7-FutureTask/"},{"title":"JDK1.8 Proxy","text":"Proxy 1.8 1 变量定义 2 KeyFactory 3 Key1、Key2、KeyX 4 ProxyClassFactory 5 newProxyInstance 6 ProxyGenerator#generateProxyClass 7 proxy class字节码写入磁盘 demo1 完整代码例子 Mammal Primate Monkey MyInvocationHandler Main 8 proxy0.class另一种方式写入磁盘 code 9 分析$Proxy.class 总结 Proxy 1.8以下源码分析取核心代码 1 变量定义12345678910111213141516/** parameter types of a proxy class constructor */private static final Class&lt;?&gt;[] constructorParams = { InvocationHandler.class };/** * a cache of proxy classes */// #1private static final WeakCache&lt;ClassLoader, Class&lt;?&gt;[], Class&lt;?&gt;&gt; proxyClassCache = new WeakCache&lt;&gt;(new KeyFactory(), new ProxyClassFactory());/** * the invocation handler for this proxy instance. * @serial */protected InvocationHandler h; 根据注释很容易理解，1.8在1.7基础上优化代码，依然是弱引用做为缓存。key和value都采用工厂模式。 2 KeyFactory1234567891011121314151617/** * A function that maps an array of interfaces to an optimal key where * Class objects representing interfaces are weakly referenced. */private static final class KeyFactory implements BiFunction&lt;ClassLoader, Class&lt;?&gt;[], Object&gt;{ @Override public Object apply(ClassLoader classLoader, Class&lt;?&gt;[] interfaces) { switch (interfaces.length) { case 1: return new Key1(interfaces[0]); // the most frequent case 2: return new Key2(interfaces[0], interfaces[1]); case 0: return key0; default: return new KeyX(interfaces); } }} 根据上下文代码及注释，可以知道这是工厂模式。 实现BiFunction函数，BiFunction是函数式接口。 Key1、Key2、KeyX，代表接口数量。分别是1个接口、2个接口、多个接口。 3 Key1、Key2、KeyX123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119/* * a key used for proxy class with 0 implemented interfaces */// #1 private static final Object key0 = new Object();/* * Key1 and Key2 are optimized for the common use of dynamic proxies * that implement 1 or 2 interfaces. *//* * a key used for proxy class with 1 implemented interface */// #2private static final class Key1 extends WeakReference&lt;Class&lt;?&gt;&gt; { private final int hash; Key1(Class&lt;?&gt; intf) { super(intf); this.hash = intf.hashCode(); } @Override public int hashCode() { return hash; } @Override public boolean equals(Object obj) { Class&lt;?&gt; intf; return this == obj || obj != null &amp;&amp; obj.getClass() == Key1.class &amp;&amp; (intf = get()) != null &amp;&amp; intf == ((Key1) obj).get(); }}/* * a key used for proxy class with 2 implemented interfaces */// #3private static final class Key2 extends WeakReference&lt;Class&lt;?&gt;&gt; { private final int hash; private final WeakReference&lt;Class&lt;?&gt;&gt; ref2; Key2(Class&lt;?&gt; intf1, Class&lt;?&gt; intf2) { super(intf1); hash = 31 * intf1.hashCode() + intf2.hashCode(); // #4 ref2 = new WeakReference&lt;Class&lt;?&gt;&gt;(intf2); } @Override public int hashCode() { return hash; } @Override public boolean equals(Object obj) { Class&lt;?&gt; intf1, intf2; return this == obj || obj != null &amp;&amp; obj.getClass() == Key2.class &amp;&amp; (intf1 = get()) != null &amp;&amp; intf1 == ((Key2) obj).get() &amp;&amp; (intf2 = ref2.get()) != null &amp;&amp; intf2 == ((Key2) obj).ref2.get(); }}/* 1. a key used for proxy class with any number of implemented interfaces 2. (used here for 3 or more only) */// #5private static final class KeyX { private final int hash; private final WeakReference&lt;Class&lt;?&gt;&gt;[] refs; @SuppressWarnings(\"unchecked\") KeyX(Class&lt;?&gt;[] interfaces) { hash = Arrays.hashCode(interfaces); refs = (WeakReference&lt;Class&lt;?&gt;&gt;[])new WeakReference&lt;?&gt;[interfaces.length]; for (int i = 0; i &lt; interfaces.length; i++) { refs[i] = new WeakReference&lt;&gt;(interfaces[i]); } } @Override public int hashCode() { return hash; } @Override public boolean equals(Object obj) { return this == obj || obj != null &amp;&amp; obj.getClass() == KeyX.class &amp;&amp; equals(refs, ((KeyX) obj).refs); } private static boolean equals(WeakReference&lt;Class&lt;?&gt;&gt;[] refs1, WeakReference&lt;Class&lt;?&gt;&gt;[] refs2) { if (refs1.length != refs2.length) { return false; } for (int i = 0; i &lt; refs1.length; i++) { Class&lt;?&gt; intf = refs1[i].get(); if (intf == null || intf != refs2[i].get()) { return false; } } return true; }} 0个接口，proxy class的key。 同3。 Key1，Key2是proxy class实现1个接口、2个接口的实现。 第2个接口的弱引用对象。 Key3是proxy class实现3个以上接口。 4 ProxyClassFactory123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106/** 1. A factory function that generates, defines and returns the proxy class given 2. the ClassLoader and array of interfaces. */private static final class ProxyClassFactory implements BiFunction&lt;ClassLoader, Class&lt;?&gt;[], Class&lt;?&gt;&gt;{ // prefix for all proxy class names private static final String proxyClassNamePrefix = \"$Proxy\"; // next number to use for generation of unique proxy class names private static final AtomicLong nextUniqueNumber = new AtomicLong(); @Override public Class&lt;?&gt; apply(ClassLoader loader, Class&lt;?&gt;[] interfaces) { // #1 Map&lt;Class&lt;?&gt;, Boolean&gt; interfaceSet = new IdentityHashMap&lt;&gt;(interfaces.length); for (Class&lt;?&gt; intf : interfaces) { /* * Verify that the class loader resolves the name of this * interface to the same Class object. */ Class&lt;?&gt; interfaceClass = null; try { interfaceClass = Class.forName(intf.getName(), false, loader); } catch (ClassNotFoundException e) { } if (interfaceClass != intf) { throw new IllegalArgumentException( intf + \" is not visible from class loader\"); } /* * Verify that the Class object actually represents an * interface. */ if (!interfaceClass.isInterface()) { throw new IllegalArgumentException( interfaceClass.getName() + \" is not an interface\"); } /* * Verify that this interface is not a duplicate. */ if (interfaceSet.put(interfaceClass, Boolean.TRUE) != null) { throw new IllegalArgumentException( \"repeated interface: \" + interfaceClass.getName()); } } String proxyPkg = null; // package to define proxy class in int accessFlags = Modifier.PUBLIC | Modifier.FINAL; /* * Record the package of a non-public proxy interface so that the * proxy class will be defined in the same package. Verify that * all non-public proxy interfaces are in the same package. */ // #2 for (Class&lt;?&gt; intf : interfaces) { int flags = intf.getModifiers(); if (!Modifier.isPublic(flags)) { accessFlags = Modifier.FINAL; String name = intf.getName(); int n = name.lastIndexOf('.'); String pkg = ((n == -1) ? \"\" : name.substring(0, n + 1)); if (proxyPkg == null) { proxyPkg = pkg; } else if (!pkg.equals(proxyPkg)) { throw new IllegalArgumentException( \"non-public interfaces from different packages\"); } } } if (proxyPkg == null) { // if no non-public proxy interfaces, use com.sun.proxy package proxyPkg = ReflectUtil.PROXY_PACKAGE + \".\"; } /* * Choose a name for the proxy class to generate. */ // #3 long num = nextUniqueNumber.getAndIncrement(); String proxyName = proxyPkg + proxyClassNamePrefix + num; /* * Generate the specified proxy class. */ // #4 byte[] proxyClassFile = ProxyGenerator.generateProxyClass( proxyName, interfaces, accessFlags); try { return defineClass0(loader, proxyName, proxyClassFile, 0, proxyClassFile.length); } catch (ClassFormatError e) { /* * A ClassFormatError here means that (barring bugs in the * proxy class generation code) there was some other * invalid aspect of the arguments supplied to the proxy * class creation (such as virtual machine limitations * exceeded). */ throw new IllegalArgumentException(e.toString()); } }} IdentityHashMap存储接口class，并且做interfaceclass验效。 验证非public接口的package是不是都是在同一个package下。 根据原子特性，生成proxy name，proxy name规则是序号递增的。 ProxyGenerator是sun.misc包下的，生成proxy class的字节码。 由以上得知Java动态代理只能代理接口。 5 newProxyInstance12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152public static Object newProxyInstance(ClassLoader loader, Class&lt;?&gt;[] interfaces, InvocationHandler h) throws IllegalArgumentException { Objects.requireNonNull(h); final Class&lt;?&gt;[] intfs = interfaces.clone(); final SecurityManager sm = System.getSecurityManager(); if (sm != null) { checkProxyAccess(Reflection.getCallerClass(), loader, intfs); } /* * Look up or generate the designated proxy class. */ // #1 Class&lt;?&gt; cl = getProxyClass0(loader, intfs); /* * Invoke its constructor with the designated invocation handler. */ try { if (sm != null) { checkNewProxyPermission(Reflection.getCallerClass(), cl); } // #2 final Constructor&lt;?&gt; cons = cl.getConstructor(constructorParams); final InvocationHandler ih = h; if (!Modifier.isPublic(cl.getModifiers())) { AccessController.doPrivileged(new PrivilegedAction&lt;Void&gt;() { public Void run() { cons.setAccessible(true); return null; } }); } // #3 return cons.newInstance(new Object[]{h}); } catch (IllegalAccessException|InstantiationException e) { throw new InternalError(e.toString(), e); } catch (InvocationTargetException e) { Throwable t = e.getCause(); if (t instanceof RuntimeException) { throw (RuntimeException) t; } else { throw new InternalError(t.toString(), t); } } catch (NoSuchMethodException e) { throw new InternalError(e.toString(), e); } } 生成proxy class，cl = class com.sun.proxy.$Proxy0。这里$Proxy0对象是临时生成，没有java、class（第6会说明）文件。 cl.getConstructor(constructorParams)实际上就是com.sun.proxy.$Proxy0(java.lang.reflect.InvocationHandler)。 生成proxy class实例化对象。 6 ProxyGenerator#generateProxyClass12345678910111213141516171819202122232425262728293031private static final boolean saveGeneratedFiles = (Boolean)AccessController.doPrivileged(new GetBooleanAction(\"sun.misc.ProxyGenerator.saveGeneratedFiles\")); public static byte[] generateProxyClass(final String var0, Class&lt;?&gt;[] var1, int var2) { ProxyGenerator var3 = new ProxyGenerator(var0, var1, var2); final byte[] var4 = var3.generateClassFile(); // #1 if (saveGeneratedFiles) { AccessController.doPrivileged(new PrivilegedAction&lt;Void&gt;() { public Void run() { try { int var1 = var0.lastIndexOf(46); Path var2; if (var1 &gt; 0) { Path var3 = Paths.get(var0.substring(0, var1).replace('.', File.separatorChar)); Files.createDirectories(var3); var2 = var3.resolve(var0.substring(var1 + 1, var0.length()) + \".class\"); } else { var2 = Paths.get(var0 + \".class\"); } // #2 Files.write(var2, var4, new OpenOption[0]); return null; } catch (IOException var4x) { throw new InternalError(\"I/O exception saving generated file: \" + var4x); } } }); } return var4; } 判断是否存储proxy class字节码$Proxy0到磁盘。 输出流，保存到磁盘。7 proxy class字节码写入磁盘demo1根据ProxyGenerator#generateProxyClass#saveGeneratedFiles,可以把saveGeneratedFiles设置为true。在磁盘上（项目路径下）会生成$Proxy0.class文件。12// #1private static final boolean saveGeneratedFiles = (Boolean)AccessController.doPrivileged(new GetBooleanAction(\"sun.misc.ProxyGenerator.saveGeneratedFiles\")); 12345678public static boolean getBoolean(String name) { boolean result = false; try { result = parseBoolean(System.getProperty(name)); } catch (IllegalArgumentException | NullPointerException e) { } return result; } 12// #2System.getProperties().put(\"sun.misc.ProxyGenerator.saveGeneratedFiles\", \"true\"); GetBooleanAction#run，从Boolean#getBoolean获取值，从Boolean#getBoolean可以知道，最终调用的System.getProperty(name)。 由1知道，所以我们这里设置saveGeneratedFiles = true。注意jdk1.8.0_161设置String = true才生效。完整代码例子Mammal12345//接口1：Mammal（哺乳动物）public interface Mammal { void eat(String food); String type();} Primate1234//接口2：Primate（灵长类动物） public interface Primate { void think();} Monkey12345678910111213141516171819//实现类：Monkey public class Monkey implements Mammal, Primate { @Override public String type() { String type = \"哺乳动物\"; System.out.println(type); return type; } @Override public void eat(String food) { System.out.println(\"The food is \" + food + \" !\"); } @Override public void think() { System.out.println(\"思考！\"); }} MyInvocationHandler123456789101112131415161718192021222324252627282930313233343536public class MyInvocationHandler implements InvocationHandler { private Object obj; public MyInvocationHandler(Object obj) { super(); this.obj = obj; } /** * 获取目标对象的代理对象 * * @return 代理对象 */ public Object getProxy() { return Proxy.newProxyInstance(Thread.currentThread().getContextClassLoader(), obj.getClass().getInterfaces(), this); } @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { //代理方法 // #1 System.out.println(\"Invoke method Before!\"); Object returnObject = method.invoke(obj, args); System.out.println(\"Invoke method After!\"); //测试代理类覆写的方法 // #2 Class&lt;?&gt; c = ((Mammal) proxy).getClass(); Method[] methods = c.getDeclaredMethods(); for (Method m : methods) { System.out.println(m.getName()); } return proxy; }} Main1234567891011121314151617181920212223242526272829303132public class Main { public static void main(String[] args) throws InstantiationException, IllegalAccessException, IllegalArgumentException, InvocationTargetException, NoSuchMethodException, SecurityException { System.getProperties().put(\"sun.misc.ProxyGenerator.saveGeneratedFiles\", \"true\"); System.out.println(System.getProperties().get(\"sun.misc.ProxyGenerator.saveGeneratedFiles\")); // 第1种创建动态代理的方法 // #3 Object proxy1 = Proxy.newProxyInstance(Monkey.class.getClassLoader(), Monkey.class.getInterfaces(), new MyInvocationHandler(new Monkey())); // 第2种创建动态代理的方法 // #4 Class&lt;?&gt; proxyClass = Proxy.getProxyClass(Monkey.class.getClassLoader(), Monkey.class.getInterfaces()); Object proxy2 = proxyClass.getConstructor(new Class[]{InvocationHandler.class}).newInstance(new MyInvocationHandler(new Monkey())); //ProxyGeneratorUtils.writeProxyClassToHardDisk(\"D:\\\\$Proxy0.class\"); // 第3种创建动态代理的方法 // 实例化目标对象 // #5 Monkey monkey = new Monkey(); // 实例化InvocationHandler MyInvocationHandler invocationHandler = new MyInvocationHandler(monkey); // 根据目标对象生成代理对象 Primate primate = (Primate) invocationHandler.getProxy(); primate.think(); Mammal mammal = (Mammal) proxy2; mammal.eat(\"香蕉\"); mammal.type(); Primate primate2 = (Primate) proxy2; primate2.think(); }} method = public abstract void demo1.Primate.think()，method接口方法；obj=Monkey@663，obj是实现类的对象。这里通过反射调用方法。 c = com.sun.proxy.$Proxy0，在项目目录下生成的代理类对象。 动态代理生成方式一，proxy1 = （$Proxy@667）Monkey@2b80d80f，动态Proxy Class对象。 同上，proxyClass = class com.sun.proxy.$Proxy0，proxy2 = （$Proxy@685）Monkey@3ab39c39，动态Proxy Class对象。 同上 saveGeneratedFiles设置为true，默认会写入磁盘。8 proxy0.class另一种方式写入磁盘code12345678910111213141516// 获取代理类的字节码 byte[] classFile = ProxyGenerator.generateProxyClass(\"$Proxy11\", Monkey.class.getInterfaces());FileOutputStream out = null;try { out = new FileOutputStream(path); out.write(classFile); out.flush(); } catch (Exception e) { e.printStackTrace(); } finally { try { out.close(); } catch (IOException e) { e.printStackTrace(); } } 9 分析$Proxy.class123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142package com.sun.proxy;import demo1.Mammal;import demo1.Primate;import java.lang.reflect.InvocationHandler;import java.lang.reflect.Method;import java.lang.reflect.Proxy;import java.lang.reflect.UndeclaredThrowableException;// #1public final class $Proxy0 extends Proxy implements Mammal, Primate{ private static Method m1; private static Method m3; private static Method m5; private static Method m2; private static Method m4; private static Method m0; // #2 public $Proxy0(InvocationHandler paramInvocationHandler) throws { super(paramInvocationHandler); } public final boolean equals(Object paramObject) throws { try { return ((Boolean)this.h.invoke(this, m1, new Object[] { paramObject })).booleanValue(); } catch (Error|RuntimeException localError) { throw localError; } catch (Throwable localThrowable) { throw new UndeclaredThrowableException(localThrowable); } } // #3 public final String type() throws { try { return (String)this.h.invoke(this, m3, null); } catch (Error|RuntimeException localError) { throw localError; } catch (Throwable localThrowable) { throw new UndeclaredThrowableException(localThrowable); } } // #4 public final void think() throws { try { this.h.invoke(this, m5, null); return; } catch (Error|RuntimeException localError) { throw localError; } catch (Throwable localThrowable) { throw new UndeclaredThrowableException(localThrowable); } } ..... // #5 public final void eat(String paramString) throws { try { this.h.invoke(this, m4, new Object[] { paramString }); return; } catch (Error|RuntimeException localError) { throw localError; } catch (Throwable localThrowable) { throw new UndeclaredThrowableException(localThrowable); } } public final int hashCode() throws { try { return ((Integer)this.h.invoke(this, m0, null)).intValue(); } catch (Error|RuntimeException localError) { throw localError; } catch (Throwable localThrowable) { throw new UndeclaredThrowableException(localThrowable); } } // #6 static { try { m1 = Class.forName(\"java.lang.Object\").getMethod(\"equals\", new Class[] { Class.forName(\"java.lang.Object\") }); m3 = Class.forName(\"demo1.Mammal\").getMethod(\"type\", new Class[0]); m5 = Class.forName(\"demo1.Primate\").getMethod(\"think\", new Class[0]); m2 = Class.forName(\"java.lang.Object\").getMethod(\"toString\", new Class[0]); m4 = Class.forName(\"demo1.Mammal\").getMethod(\"eat\", new Class[] { Class.forName(\"java.lang.String\") }); m0 = Class.forName(\"java.lang.Object\").getMethod(\"hashCode\", new Class[0]); return; } catch (NoSuchMethodException localNoSuchMethodException) { throw new NoSuchMethodError(localNoSuchMethodException.getMessage()); } catch (ClassNotFoundException localClassNotFoundException) { throw new NoClassDefFoundError(localClassNotFoundException.getMessage()); } }} $Proxy0继承Proxy，实现Mammal, Primate接口。 这里是$Proxy0的构造函数，是前文提到的cl.getConstructor(constructorParams)。 就是调用MyInvocationHandler的public Object invoke(Object proxy, Method method, Object[] args)。根据上文例子：12Mammal mammal = (Mammal) proxy2;mammal.type()实际上就是调用(); type()实际上就是调用MyInvocationHandler#invoke。 同上。 同上。 静态代码块初始化方法，其中3个是接口必需实现的方法，通过覆写接口方法调用InvocationHandler#invoke。总结 JDK1.8相对JDK1.7，代码结构更加简洁，Proxy Cache Map的key、value都是用简单工厂模式，阅读起来很舒畅。 源码阅读起来很容易，写笔记真的好累、好累。","link":"/JDK1.8-Proxy/"},{"title":"JDK1.6 FutureTask","text":"1 功能简介 2 源码分析 RunnableFuture接口 Runnable接口 Future接口 FutureTask#Sync Callable接口 FutureTask#innerRun() FutureTask#Sync#innerSet() AbstractQueuedSynchronizer#releaseShared() AbstractQueuedSynchronizer#tryReleaseShared() FutureTask#Sync#tryReleaseShared() FutureTask#Sync#innerSetException FutureTask#Sync#innerRunAndReset() FutureTask#Sync#innerGet() FutureTask#Sync#innerGet(long nanosTimeout) FutureTask#get() AbstractQueuedSynchronizer#acquireSharedInterruptibly() AbstractQueuedSynchronizer#tryAcquireShared() FutureTask#Sync#tryAcquireShared() FutureTask#Sync#innerIsDone() FutureTask#Sync#ranOrCancelled() FutureTask#Sync#innerCancel() FutureTask#cancel() FutureTask FutureTask构造方法 Executors#callable() Executors#RunnableAdapter 3 总结 1 功能简介 FutureTask是一种异步任务(或异步计算)，举个栗子，主线程的逻辑中需要使用某个值，但这个值需要复杂的运算得来，那么主线程可以提前建立一个异步任务来计算这个值(在其他的线程中计算)，然后去做其他事情，当需要这个值的时候再通过刚才建立的异步任务来获取这个值，有点并行的意思，这样可以缩短整个主线程逻辑的执行时间。 FutureTask是基于AQS来构建的，使用共享模式，使用AQS的状态来表示异步任务的运行状态。 2 源码分析RunnableFuture接口1234567891011121314151617/** * A {@link Future} that is {@link Runnable}. Successful execution of * the &lt;tt&gt;run&lt;/tt&gt; method causes completion of the &lt;tt&gt;Future&lt;/tt&gt; * and allows access to its results. * @see FutureTask * @see Executor * @since 1.6 * @author Doug Lea * @param &lt;V&gt; The result type returned by this Future's &lt;tt&gt;get&lt;/tt&gt; method */public interface RunnableFuture&lt;V&gt; extends Runnable, Future&lt;V&gt; { /** * Sets this Future to the result of its computation * unless it has been cancelled. */ void run();} Runnable接口123456789101112131415161718192021222324252627282930313233/** * The &lt;code&gt;Runnable&lt;/code&gt; interface should be implemented by any * class whose instances are intended to be executed by a thread. The * class must define a method of no arguments called &lt;code&gt;run&lt;/code&gt;. * &lt;p&gt; * This interface is designed to provide a common protocol for objects that * wish to execute code while they are active. For example, * &lt;code&gt;Runnable&lt;/code&gt; is implemented by class &lt;code&gt;Thread&lt;/code&gt;. * Being active simply means that a thread has been started and has not * yet been stopped. * * ...... * @author Arthur van Hoff * @version %I%, %G% * @see java.lang.Thread * @see java.util.concurrent.Callable * @since JDK1.0 */publicinterface Runnable { /** * When an object implementing interface &lt;code&gt;Runnable&lt;/code&gt; is used * to create a thread, starting the thread causes the object's * &lt;code&gt;run&lt;/code&gt; method to be called in that separately executing * thread. * &lt;p&gt; * The general contract of the method &lt;code&gt;run&lt;/code&gt; is that it may * take any action whatsoever. * * @see java.lang.Thread#run() */ public abstract void run();} Future接口123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102/** * A &lt;tt&gt;Future&lt;/tt&gt; represents the result of an asynchronous * computation. Methods are provided to check if the computation is * complete, to wait for its completion, and to retrieve the result of * the computation. The result can only be retrieved using method * &lt;tt&gt;get&lt;/tt&gt; when the computation has completed, blocking if * necessary until it is ready. Cancellation is performed by the * &lt;tt&gt;cancel&lt;/tt&gt; method. Additional methods are provided to * determine if the task completed normally or was cancelled. Once a * computation has completed, the computation cannot be cancelled. * If you would like to use a &lt;tt&gt;Future&lt;/tt&gt; for the sake * of cancellability but not provide a usable result, you can * declare types of the form &lt;tt&gt;Future&amp;lt;?&amp;gt;&lt;/tt&gt; and * return &lt;tt&gt;null&lt;/tt&gt; as a result of the underlying task. * * ..... * * @see FutureTask * @see Executor * @since 1.5 * @author Doug Lea * @param &lt;V&gt; The result type returned by this Future's &lt;tt&gt;get&lt;/tt&gt; method */public interface Future&lt;V&gt; { /** * Attempts to cancel execution of this task. This attempt will * fail if the task has already completed, has already been cancelled, * or could not be cancelled for some other reason. If successful, * and this task has not started when &lt;tt&gt;cancel&lt;/tt&gt; is called, * this task should never run. If the task has already started, * then the &lt;tt&gt;mayInterruptIfRunning&lt;/tt&gt; parameter determines * whether the thread executing this task should be interrupted in * an attempt to stop the task. * * &lt;p&gt;After this method returns, subsequent calls to {@link #isDone} will * always return &lt;tt&gt;true&lt;/tt&gt;. Subsequent calls to {@link #isCancelled} * will always return &lt;tt&gt;true&lt;/tt&gt; if this method returned &lt;tt&gt;true&lt;/tt&gt;. * * @param mayInterruptIfRunning &lt;tt&gt;true&lt;/tt&gt; if the thread executing this * task should be interrupted; otherwise, in-progress tasks are allowed * to complete * @return &lt;tt&gt;false&lt;/tt&gt; if the task could not be cancelled, * typically because it has already completed normally; * &lt;tt&gt;true&lt;/tt&gt; otherwise */ // 1 boolean cancel(boolean mayInterruptIfRunning); /** * Returns &lt;tt&gt;true&lt;/tt&gt; if this task was cancelled before it completed * normally. * * @return &lt;tt&gt;true&lt;/tt&gt; if this task was cancelled before it completed */ // 2 boolean isCancelled(); /** * Returns &lt;tt&gt;true&lt;/tt&gt; if this task completed. * * Completion may be due to normal termination, an exception, or * cancellation -- in all of these cases, this method will return * &lt;tt&gt;true&lt;/tt&gt;. * * @return &lt;tt&gt;true&lt;/tt&gt; if this task completed */ // 3 boolean isDone(); /** * Waits if necessary for the computation to complete, and then * retrieves its result. * * @return the computed result * @throws CancellationException if the computation was cancelled * @throws ExecutionException if the computation threw an * exception * @throws InterruptedException if the current thread was interrupted * while waiting */ // 4 V get() throws InterruptedException, ExecutionException; /** * Waits if necessary for at most the given time for the computation * to complete, and then retrieves its result, if available. * * @param timeout the maximum time to wait * @param unit the time unit of the timeout argument * @return the computed result * @throws CancellationException if the computation was cancelled * @throws ExecutionException if the computation threw an * exception * @throws InterruptedException if the current thread was interrupted * while waiting * @throws TimeoutException if the wait timed out */ // 5 V get(long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException;} 标注代码分析 尝试取消任务的执行，如果任务已经完成或者已经被取消或者由于某种原因无法取消，方法返回false。如果任务取消成功，或者任务开始执行之前调用了取消方法，那么任务就永远不会执行了。mayInterruptIfRunning参数决定了是否要中断执行任务的线程。 判断任务是否在完成之前被取消。 判断任务是否完成。 等待，直到获取任务的执行结果。如果任务还没执行完，这个方法会阻塞。 等待，在给定的时间内获取任务的执行结果。 Future提供了取消任务接口，并提供了查看任务状态的接口，最重要的是提供有阻塞行为的获取任务执行结果的接口。 FutureTask#Sync12345678910111213141516171819202122232425262728293031323334353637383940414243/** * Synchronization control for FutureTask. Note that this must be * a non-static inner class in order to invoke the protected * &lt;tt&gt;done&lt;/tt&gt; method. For clarity, all inner class support * methods are same as outer, prefixed with \"inner\". * * Uses AQS sync state to represent run status */ private final class Sync extends AbstractQueuedSynchronizer { private static final long serialVersionUID = -7828117401763700385L; /** State value representing that task is running */ // 1 private static final int RUNNING = 1; /** State value representing that task ran */ // 2 private static final int RAN = 2; /** State value representing that task was cancelled */ // 3 private static final int CANCELLED = 4; /** The underlying callable */ // 4 private final Callable&lt;V&gt; callable; /** The result to return from get() */ // 5 private V result; /** The exception to throw from get() */ // 6 private Throwable exception; /** * The thread running task. When nulled after set/cancel, this * indicates that the results are accessible. Must be * volatile, to ensure visibility upon completion. */ // 7 private volatile Thread runner; Sync(Callable&lt;V&gt; callable) { this.callable = callable; } } 任务正在执行。 任务已经运行完毕。 任务被取消。 内部变量callable。 执行结果。 执行过程中发生的异常。 执行当前任务的线程。在set()/cancel()之后置空，说明可以了。必须使用volatile来修饰，以确保任务完成后的可见性。 Callable接口12345678910111213141516171819202122232425262728/** * A task that returns a result and may throw an exception. * Implementors define a single method with no arguments called * &lt;tt&gt;call&lt;/tt&gt;. * * &lt;p&gt;The &lt;tt&gt;Callable&lt;/tt&gt; interface is similar to {@link * java.lang.Runnable}, in that both are designed for classes whose * instances are potentially executed by another thread. A * &lt;tt&gt;Runnable&lt;/tt&gt;, however, does not return a result and cannot * throw a checked exception. * * &lt;p&gt; The {@link Executors} class contains utility methods to * convert from other common forms to &lt;tt&gt;Callable&lt;/tt&gt; classes. * * @see Executor * @since 1.5 * @author Doug Lea * @param &lt;V&gt; the result type of method &lt;tt&gt;call&lt;/tt&gt; */public interface Callable&lt;V&gt; { /** * Computes a result, or throws an exception if unable to do so. * * @return computed result * @throws Exception if unable to compute a result */ V call() throws Exception;} FutureTask#innerRun()1234567891011121314151617181920void innerRun() { // 1 if (!compareAndSetState(0, RUNNING)) // 2 return; try { // 3 runner = Thread.currentThread(); // 4 if (getState() == RUNNING) // recheck after setting thread // 5 innerSet(callable.call()); else // 6 releaseShared(0); // cancel } catch (Throwable ex) { // 7 innerSetException(ex); }} 标注代码分析 尝试设置任务运行状态为正在执行。 如果设置失败，直接返回。 设置执行线程。 再次检测任务状态。 执行任务，然后设置执行结果。 说明任务已取消。 如果执行任务过程中发生异常，设置异常。 FutureTask#Sync#innerSet()123456789101112131415161718192021222324252627 void innerSet(V v) { for (;;) { // 1int s = getState();if (s == RAN) // 2 return; if (s == CANCELLED) { // 3 // aggressively release to set runner to null, // in case we are racing with a cancel request // that will try to interrupt runner releaseShared(0); return; } // 4if (compareAndSetState(s, RAN)) { // 5 result = v; // 6 releaseShared(0); // 7 done(); return; } } } 标注代码分析 获取任务执行状态。 如果任务已经执行完毕，退出。 这里释放AQS控制权并设置runner为null，为了避免正在和一个试图中断线程的取消请求竞。 尝试将任务状态设置为执行完成。 设置执行结果。 释放AQS控制权。 子类可覆盖这个方法，做一些定制处理。 AbstractQueuedSynchronizer#releaseShared()12345678910111213141516/** * Releases in shared mode. Implemented by unblocking one or more * threads if {@link #tryReleaseShared} returns true. * * @param arg the release argument. This value is conveyed to * {@link #tryReleaseShared} but is otherwise uninterpreted * and can represent anything you like. * @return the value returned from {@link #tryReleaseShared} */ public final boolean releaseShared(int arg) { if (tryReleaseShared(arg)) { doReleaseShared(); return true; } return false; } AbstractQueuedSynchronizer#tryReleaseShared()123456789101112131415161718192021222324/** * Attempts to set the state to reflect a release in shared mode. * * &lt;p&gt;This method is always invoked by the thread performing release. * * &lt;p&gt;The default implementation throws * {@link UnsupportedOperationException}. * * @param arg the release argument. This value is always the one * passed to a release method, or the current state value upon * entry to a condition wait. The value is otherwise * uninterpreted and can represent anything you like. * @return {@code true} if this release of shared mode may permit a * waiting acquire (shared or exclusive) to succeed; and * {@code false} otherwise * @throws IllegalMonitorStateException if releasing would place this * synchronizer in an illegal state. This exception must be * thrown in a consistent fashion for synchronization to work * correctly. * @throws UnsupportedOperationException if shared mode is not supported */protected boolean tryReleaseShared(int arg) { throw new UnsupportedOperationException();} FutureTask#Sync#tryReleaseShared()12345678/** * Implements AQS base release to always signal after setting * final done status by nulling runner thread. */ protected boolean tryReleaseShared(int ignore) { runner = null; return true; } 根据注释可以明白，Sync实现AQS#tryReleaseShared()。 FutureTask#Sync#innerSetException123456789101112131415161718192021void innerSetException(Throwable t) { for (;;) { int s = getState(); if (s == RAN) return; if (s == CANCELLED) { // aggressively release to set runner to null, // in case we are racing with a cancel request // that will try to interrupt runner releaseShared(0); return; } if (compareAndSetState(s, RAN)) { exception = t; result = null; releaseShared(0); done(); return; } } } innerRun()和innerSet()类似，只不过最后要设置异常，清空result。 FutureTask#Sync#innerRunAndReset()1234567891011121314boolean innerRunAndReset() { if (!compareAndSetState(0, RUNNING)) return false; try { runner = Thread.currentThread(); if (getState() == RUNNING) callable.call(); // don't set result runner = null; return compareAndSetState(RUNNING, 0); } catch (Throwable ex) { innerSetException(ex); return false; } } innerRunAndReset()不设置执行结果，最后执行完毕后重置异步任务状态为0。 FutureTask#Sync#innerGet()123456789101112V innerGet() throws InterruptedException, ExecutionException { // 1 acquireSharedInterruptibly(0); if (getState() == CANCELLED) // 2 throw new CancellationException(); if (exception != null) // 3 throw new ExecutionException(exception); // 4 return result; } 标注代码分析 获取共享锁，无法获取时阻塞等待。 如果任务状态为取消，那么抛出CancellationException。 如果任务执行异常，抛出ExecutionException，并传递异常。 成功执行完成，返回执行结果。 FutureTask#Sync#innerGet(long nanosTimeout)123456789V innerGet(long nanosTimeout) throws InterruptedException, ExecutionException, TimeoutException { if (!tryAcquireSharedNanos(0, nanosTimeout)) throw new TimeoutException(); if (getState() == CANCELLED) throw new CancellationException(); if (exception != null) throw new ExecutionException(exception); return result; } 判断任务是否完成，要依据任务(完成或取消)状态来判断。 FutureTask#get()1234567891011121314/** * @throws CancellationException {@inheritDoc} */public V get() throws InterruptedException, ExecutionException { return sync.innerGet();}/** * @throws CancellationException {@inheritDoc} */public V get(long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException { return sync.innerGet(unit.toNanos(timeout));} FutureTask#get()由sync#innerGet()的实现。 AbstractQueuedSynchronizer#acquireSharedInterruptibly()12345678910111213141516171819/** * Acquires in shared mode, aborting if interrupted. Implemented * by first checking interrupt status, then invoking at least once * {@link #tryAcquireShared}, returning on success. Otherwise the * thread is queued, possibly repeatedly blocking and unblocking, * invoking {@link #tryAcquireShared} until success or the thread * is interrupted. * @param arg the acquire argument. * This value is conveyed to {@link #tryAcquireShared} but is * otherwise uninterpreted and can represent anything * you like. * @throws InterruptedException if the current thread is interrupted */public final void acquireSharedInterruptibly(int arg) throws InterruptedException { if (Thread.interrupted()) throw new InterruptedException(); if (tryAcquireShared(arg) &lt; 0) doAcquireSharedInterruptibly(arg);} AbstractQueuedSynchronizer#tryAcquireShared()1234567891011121314151617181920212223242526272829303132333435/** * Attempts to acquire in shared mode. This method should query if * the state of the object permits it to be acquired in the shared * mode, and if so to acquire it. * * &lt;p&gt;This method is always invoked by the thread performing * acquire. If this method reports failure, the acquire method * may queue the thread, if it is not already queued, until it is * signalled by a release from some other thread. * * &lt;p&gt;The default implementation throws {@link * UnsupportedOperationException}. * * @param arg the acquire argument. This value is always the one * passed to an acquire method, or is the value saved on entry * to a condition wait. The value is otherwise uninterpreted * and can represent anything you like. * @return a negative value on failure; zero if acquisition in shared * mode succeeded but no subsequent shared-mode acquire can * succeed; and a positive value if acquisition in shared * mode succeeded and subsequent shared-mode acquires might * also succeed, in which case a subsequent waiting thread * must check availability. (Support for three different * return values enables this method to be used in contexts * where acquires only sometimes act exclusively.) Upon * success, this object has been acquired. * @throws IllegalMonitorStateException if acquiring would place this * synchronizer in an illegal state. This exception must be * thrown in a consistent fashion for synchronization to work * correctly. * @throws UnsupportedOperationException if shared mode is not supported */ protected int tryAcquireShared(int arg) { throw new UnsupportedOperationException(); } FutureTask#Sync#tryAcquireShared()123456/*** Implements AQS base acquire to succeed if ran or cancelled*/protected int tryAcquireShared(int ignore) { return innerIsDone()? 1 : -1;} 根据注释可以明白，Sync实现AQS#tryAcquireShared()。 FutureTask#Sync#innerIsDone()123boolean innerIsDone() { return ranOrCancelled(getState()) &amp;&amp; runner == null; } FutureTask#Sync#ranOrCancelled()123private boolean ranOrCancelled(int state) { return (state &amp; (RAN | CANCELLED)) != 0; } FutureTask#Sync#innerCancel()12345678910111213141516171819202122boolean innerCancel(boolean mayInterruptIfRunning) { for (;;) { int s = getState(); if (ranOrCancelled(s)) // 1 return false; // 2 if (compareAndSetState(s, CANCELLED)) break; } if (mayInterruptIfRunning) { Thread r = runner; if (r != null) // 3 r.interrupt(); } // 4 releaseShared(0); // 5 done(); return true; } 标注代码分析 如果任务已经执行完毕或者取消。 否则尝试设置任务状态为取消。 设置mayInterruptIfRunning=true，需要中断线程， 释放AQS的控制权。 这里也会调用done()，定制子类时需要注意下。 FutureTask#cancel()123public boolean cancel(boolean mayInterruptIfRunning) { return sync.innerCancel(mayInterruptIfRunning);} 由sync#innerCancel()实现。 FutureTask123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142/** * A cancellable asynchronous computation. This class provides a base * implementation of {@link Future}, with methods to start and cancel * a computation, query to see if the computation is complete, and * retrieve the result of the computation. The result can only be * retrieved when the computation has completed; the &lt;tt&gt;get&lt;/tt&gt; * method will block if the computation has not yet completed. Once * the computation has completed, the computation cannot be restarted * or cancelled. * * &lt;p&gt;A &lt;tt&gt;FutureTask&lt;/tt&gt; can be used to wrap a {@link Callable} or * {@link java.lang.Runnable} object. Because &lt;tt&gt;FutureTask&lt;/tt&gt; * implements &lt;tt&gt;Runnable&lt;/tt&gt;, a &lt;tt&gt;FutureTask&lt;/tt&gt; can be * submitted to an {@link Executor} for execution. * * &lt;p&gt;In addition to serving as a standalone class, this class provides * &lt;tt&gt;protected&lt;/tt&gt; functionality that may be useful when creating * customized task classes. * * @since 1.5 * @author Doug Lea * @param &lt;V&gt; The result type returned by this FutureTask's &lt;tt&gt;get&lt;/tt&gt; method */public class FutureTask&lt;V&gt; implements RunnableFuture&lt;V&gt; { /** Synchronization control for FutureTask */ private final Sync sync; /** * Creates a &lt;tt&gt;FutureTask&lt;/tt&gt; that will upon running, execute the * given &lt;tt&gt;Callable&lt;/tt&gt;. * * @param callable the callable task * @throws NullPointerException if callable is null */ public FutureTask(Callable&lt;V&gt; callable) { if (callable == null) throw new NullPointerException(); sync = new Sync(callable); } /** * Creates a &lt;tt&gt;FutureTask&lt;/tt&gt; that will upon running, execute the * given &lt;tt&gt;Runnable&lt;/tt&gt;, and arrange that &lt;tt&gt;get&lt;/tt&gt; will return the * given result on successful completion. * * @param runnable the runnable task * @param result the result to return on successful completion. If * you don't need a particular result, consider using * constructions of the form: * &lt;tt&gt;Future&amp;lt;?&amp;gt; f = new FutureTask&amp;lt;Object&amp;gt;(runnable, null)&lt;/tt&gt; * @throws NullPointerException if runnable is null */ public FutureTask(Runnable runnable, V result) { sync = new Sync(Executors.callable(runnable, result)); } public boolean isCancelled() { return sync.innerIsCancelled(); } public boolean isDone() { return sync.innerIsDone(); } public boolean cancel(boolean mayInterruptIfRunning) { return sync.innerCancel(mayInterruptIfRunning); } /** * @throws CancellationException {@inheritDoc} */ public V get() throws InterruptedException, ExecutionException { return sync.innerGet(); } /** * @throws CancellationException {@inheritDoc} */ public V get(long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException { return sync.innerGet(unit.toNanos(timeout)); } /** * Protected method invoked when this task transitions to state * &lt;tt&gt;isDone&lt;/tt&gt; (whether normally or via cancellation). The * default implementation does nothing. Subclasses may override * this method to invoke completion callbacks or perform * bookkeeping. Note that you can query status inside the * implementation of this method to determine whether this task * has been cancelled. */ protected void done() { } /** * Sets the result of this Future to the given value unless * this future has already been set or has been cancelled. * This method is invoked internally by the &lt;tt&gt;run&lt;/tt&gt; method * upon successful completion of the computation. * @param v the value */ protected void set(V v) { sync.innerSet(v); } /** * Causes this future to report an &lt;tt&gt;ExecutionException&lt;/tt&gt; * with the given throwable as its cause, unless this Future has * already been set or has been cancelled. * This method is invoked internally by the &lt;tt&gt;run&lt;/tt&gt; method * upon failure of the computation. * @param t the cause of failure */ protected void setException(Throwable t) { sync.innerSetException(t); } // The following (duplicated) doc comment can be removed once // // 6270645: Javadoc comments should be inherited from most derived // superinterface or superclass // is fixed. /** * Sets this Future to the result of its computation * unless it has been cancelled. */ public void run() { sync.innerRun(); } /** * Executes the computation without setting its result, and then * resets this Future to initial state, failing to do so if the * computation encounters an exception or is cancelled. This is * designed for use with tasks that intrinsically execute more * than once. * @return true if successfully run and reset */ protected boolean runAndReset() { return sync.innerRunAndReset(); } ... 方法实现是基于FutureTask#sync实现。 FutureTask构造方法123456789101112131415/** * Creates a &lt;tt&gt;FutureTask&lt;/tt&gt; that will upon running, execute the * given &lt;tt&gt;Runnable&lt;/tt&gt;, and arrange that &lt;tt&gt;get&lt;/tt&gt; will return the * given result on successful completion. * * @param runnable the runnable task * @param result the result to return on successful completion. If * you don't need a particular result, consider using * constructions of the form: * &lt;tt&gt;Future&amp;lt;?&amp;gt; f = new FutureTask&amp;lt;Object&amp;gt;(runnable, null)&lt;/tt&gt; * @throws NullPointerException if runnable is null */ public FutureTask(Runnable runnable, V result) { sync = new Sync(Executors.callable(runnable, result)); } Executors#callable()123456789101112131415/** * Returns a {@link Callable} object that, when * called, runs the given task and returns the given result. This * can be useful when applying methods requiring a * &lt;tt&gt;Callable&lt;/tt&gt; to an otherwise resultless action. * @param task the task to run * @param result the result to return * @return a callable object * @throws NullPointerException if task null */ public static &lt;T&gt; Callable&lt;T&gt; callable(Runnable task, T result) { if (task == null) throw new NullPointerException(); return new RunnableAdapter&lt;T&gt;(task, result); } Executors#RunnableAdapter123456789101112131415/** * A callable that runs given task and returns given result */ static final class RunnableAdapter&lt;T&gt; implements Callable&lt;T&gt; { final Runnable task; final T result; RunnableAdapter(Runnable task, T result) { this.task = task; this.result = result; } public T call() { task.run(); return result; } } 3 总结 当前线程建立异步任务后，异步任务处于初始状态(内部有一个数值表示状态，初始为0)，一般交由其他线程执行任务(比如提交给线程池处理)。当前线程通过异步任务的get()来获取执行结果时，如果异步任务此时还没执行完毕(内部状态既不是完成，也不是取消)，那么当前线程会在get()处阻塞。 当其他线程(比如线程池中的工作线程)执行了异步任务，那么会将异步任务的状态改成”完成”(根据情况也可能是取消)，同时将在get()除等待的线程唤醒。","link":"/JDK1.6-FutureTask/"},{"title":"JDK1.6 Executors","text":"1 介绍 2 源码解析 Executors#newFixedThreadPool() Executors#newFixedThreadPool(ThreadFactory) Executors#newSingleThreadExecutor() Executors#FinalizableDelegatedExecutorService Executors#DelegatedExecutorService Executors#newCachedThreadPool() Executors#unconfigurableExecutorService() Executors#newScheduledThreadPool() Executors#newSingleThreadScheduledExecutor() Executors#DelegatedScheduledExecutorService Executors#unconfigurableScheduledExecutorService() Executors#DefaultThreadFactory() Executors#PrivilegedThreadFactory() Executors#callable() Executors#RunnableAdapter() Executors#PrivilegedCallable 1 介绍Executors是JUC包提供的一个工具性质的帮助类，它针对ExecutorService、ScheduledExecutorService、ThreadFactory和Callable提供了一系列工厂方法和工具方法。 2 源码解析Executors#newFixedThreadPool()1234567891011121314151617181920/** * Creates a thread pool that reuses a fixed number of threads * operating off a shared unbounded queue. At any point, at most * &lt;tt&gt;nThreads&lt;/tt&gt; threads will be active processing tasks. * If additional tasks are submitted when all threads are active, * they will wait in the queue until a thread is available. * If any thread terminates due to a failure during execution * prior to shutdown, a new one will take its place if needed to * execute subsequent tasks. The threads in the pool will exist * until it is explicitly {@link ExecutorService#shutdown shutdown}. * * @param nThreads the number of threads in the pool * @return the newly created thread pool * @throws IllegalArgumentException if &lt;tt&gt;nThreads &amp;lt;= 0&lt;/tt&gt; */public static ExecutorService newFixedThreadPool(int nThreads) { return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;());} 这个方法创建了一个核心线程数量和最大线程数量一致的，并且任务队列是无界队列的线程池。 由于默认核心线程不会超时，所以超时相关的参数也没有意义。 如果在线程关闭之前，一个工作线程由于某种原因挂了，那么线程池会自动补上一个新的工作线程。 Executors#newFixedThreadPool(ThreadFactory)12345678910111213141516171819202122232425/** * Creates a thread pool that reuses a fixed number of threads * operating off a shared unbounded queue, using the provided * ThreadFactory to create new threads when needed. At any point, * at most &lt;tt&gt;nThreads&lt;/tt&gt; threads will be active processing * tasks. If additional tasks are submitted when all threads are * active, they will wait in the queue until a thread is * available. If any thread terminates due to a failure during * execution prior to shutdown, a new one will take its place if * needed to execute subsequent tasks. The threads in the pool will * exist until it is explicitly {@link ExecutorService#shutdown * shutdown}. * * @param nThreads the number of threads in the pool * @param threadFactory the factory to use when creating new threads * @return the newly created thread pool * @throws NullPointerException if threadFactory is null * @throws IllegalArgumentException if &lt;tt&gt;nThreads &amp;lt;= 0&lt;/tt&gt; */public static ExecutorService newFixedThreadPool(int nThreads, ThreadFactory threadFactory) { return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;(), threadFactory);} 除了能定制ThreadFactory之外，和上个方法一样。 Executors#newSingleThreadExecutor()12345678910111213141516171819/** * Creates an Executor that uses a single worker thread operating * off an unbounded queue. (Note however that if this single * thread terminates due to a failure during execution prior to * shutdown, a new one will take its place if needed to execute * subsequent tasks.) Tasks are guaranteed to execute * sequentially, and no more than one task will be active at any * given time. Unlike the otherwise equivalent * &lt;tt&gt;newFixedThreadPool(1)&lt;/tt&gt; the returned executor is * guaranteed not to be reconfigurable to use additional threads. * * @return the newly created single-threaded Executor */public static ExecutorService newSingleThreadExecutor() { return new FinalizableDelegatedExecutorService (new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;()));} 这个工厂方法看上去有点类似newFixedThreadPool(1) ，但有一点儿区别，这个不能重新调整配置(比如动态增大核心线程数量)了，由于方法内返回的不是ThreadPoolExecutor实例，而是一个包装类。 Executors#FinalizableDelegatedExecutorService12345678910 static class FinalizableDelegatedExecutorServiceextends DelegatedExecutorService {FinalizableDelegatedExecutorService(ExecutorService executor) { super(executor);}protected void finalize() { // 1 super.shutdown();} } 标注代码分析 被垃圾回收时，关闭线程池。 FinalizableDelegatedExecutorService类图 Executors#DelegatedExecutorService1234567891011121314151617181920212223242526272829303132333435363738394041424344/** * A wrapper class that exposes only the ExecutorService methods * of an ExecutorService implementation. */ static class DelegatedExecutorService extends AbstractExecutorService { private final ExecutorService e; DelegatedExecutorService(ExecutorService executor) { e = executor; } public void execute(Runnable command) { e.execute(command); } public void shutdown() { e.shutdown(); } public List&lt;Runnable&gt; shutdownNow() { return e.shutdownNow(); } public boolean isShutdown() { return e.isShutdown(); } public boolean isTerminated() { return e.isTerminated(); } public boolean awaitTermination(long timeout, TimeUnit unit) throws InterruptedException { return e.awaitTermination(timeout, unit); } public Future&lt;?&gt; submit(Runnable task) { return e.submit(task); } public &lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task) { return e.submit(task); } public &lt;T&gt; Future&lt;T&gt; submit(Runnable task, T result) { return e.submit(task, result); } public &lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks) throws InterruptedException { return e.invokeAll(tasks); } public &lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, long timeout, TimeUnit unit) throws InterruptedException { return e.invokeAll(tasks, timeout, unit); } public &lt;T&gt; T invokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks) throws InterruptedException, ExecutionException { return e.invokeAny(tasks); } public &lt;T&gt; T invokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException { return e.invokeAny(tasks, timeout, unit); } } 包装类，只实现public ExecutorService定义的方法。 Executors#newCachedThreadPool()123456789101112131415161718192021/** * Creates a thread pool that creates new threads as needed, but * will reuse previously constructed threads when they are * available. These pools will typically improve the performance * of programs that execute many short-lived asynchronous tasks. * Calls to &lt;tt&gt;execute&lt;/tt&gt; will reuse previously constructed * threads if available. If no existing thread is available, a new * thread will be created and added to the pool. Threads that have * not been used for sixty seconds are terminated and removed from * the cache. Thus, a pool that remains idle for long enough will * not consume any resources. Note that pools with similar * properties but different details (for example, timeout parameters) * may be created using {@link ThreadPoolExecutor} constructors. * * @return the newly created thread pool */ public static ExecutorService newCachedThreadPool() { return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;()); } 这个方法创建了一个核心线程数量为0，最大线程(可以认为)无上限，并且任务队列是同步队列(无实际容量)的线程池。针对每一个新任务，如果当前没有空闲线程，都会创建一个新的工作线程来处理任务。工作线程默认空闲超过60秒超时被回收。 Executors#unconfigurableExecutorService()123456789101112131415/** * Returns an object that delegates all defined {@link * ExecutorService} methods to the given executor, but not any * other methods that might otherwise be accessible using * casts. This provides a way to safely \"freeze\" configuration and * disallow tuning of a given concrete implementation. * @param executor the underlying implementation * @return an &lt;tt&gt;ExecutorService&lt;/tt&gt; instance * @throws NullPointerException if executor null */public static ExecutorService unconfigurableExecutorService(ExecutorService executor) { if (executor == null) throw new NullPointerException(); return new DelegatedExecutorService(executor);} 包装成默认ExecutorService实现方式。 Executors#newScheduledThreadPool()123456789101112131415161718192021222324252627/** * Creates a thread pool that can schedule commands to run after a * given delay, or to execute periodically. * @param corePoolSize the number of threads to keep in the pool, * even if they are idle. * @return a newly created scheduled thread pool * @throws IllegalArgumentException if &lt;tt&gt;corePoolSize &amp;lt; 0&lt;/tt&gt; */public static ScheduledExecutorService newScheduledThreadPool(int corePoolSize) { return new ScheduledThreadPoolExecutor(corePoolSize);}/** * Creates a thread pool that can schedule commands to run after a * given delay, or to execute periodically. * @param corePoolSize the number of threads to keep in the pool, * even if they are idle. * @param threadFactory the factory to use when the executor * creates a new thread. * @return a newly created scheduled thread pool * @throws IllegalArgumentException if &lt;tt&gt;corePoolSize &amp;lt; 0&lt;/tt&gt; * @throws NullPointerException if threadFactory is null */public static ScheduledExecutorService newScheduledThreadPool( int corePoolSize, ThreadFactory threadFactory) { return new ScheduledThreadPoolExecutor(corePoolSize, threadFactory);} 创建指定线程数量的ScheduledThreadPoolExecutor。 Executors#newSingleThreadScheduledExecutor()1234567891011121314151617181920212223242526272829303132333435363738/** * Creates a single-threaded executor that can schedule commands * to run after a given delay, or to execute periodically. * (Note however that if this single * thread terminates due to a failure during execution prior to * shutdown, a new one will take its place if needed to execute * subsequent tasks.) Tasks are guaranteed to execute * sequentially, and no more than one task will be active at any * given time. Unlike the otherwise equivalent * &lt;tt&gt;newScheduledThreadPool(1)&lt;/tt&gt; the returned executor is * guaranteed not to be reconfigurable to use additional threads. * @return the newly created scheduled executor */ public static ScheduledExecutorService newSingleThreadScheduledExecutor() { return new DelegatedScheduledExecutorService (new ScheduledThreadPoolExecutor(1)); } /** * Creates a single-threaded executor that can schedule commands * to run after a given delay, or to execute periodically. (Note * however that if this single thread terminates due to a failure * during execution prior to shutdown, a new one will take its * place if needed to execute subsequent tasks.) Tasks are * guaranteed to execute sequentially, and no more than one task * will be active at any given time. Unlike the otherwise * equivalent &lt;tt&gt;newScheduledThreadPool(1, threadFactory)&lt;/tt&gt; * the returned executor is guaranteed not to be reconfigurable to * use additional threads. * @param threadFactory the factory to use when creating new * threads * @return a newly created scheduled executor * @throws NullPointerException if threadFactory is null */ public static ScheduledExecutorService newSingleThreadScheduledExecutor(ThreadFactory threadFactory) { return new DelegatedScheduledExecutorService (new ScheduledThreadPoolExecutor(1, threadFactory)); } new ScheduledThreadPoolExecutor(1)进行DelegatedScheduledExecutorService包装。 Executors#DelegatedScheduledExecutorService12345678910111213141516171819202122232425/** * A wrapper class that exposes only the ScheduledExecutorService * methods of a ScheduledExecutorService implementation. */ static class DelegatedScheduledExecutorService extends DelegatedExecutorService implements ScheduledExecutorService { private final ScheduledExecutorService e; DelegatedScheduledExecutorService(ScheduledExecutorService executor) { super(executor); e = executor; } public ScheduledFuture&lt;?&gt; schedule(Runnable command, long delay, TimeUnit unit) { return e.schedule(command, delay, unit); } public &lt;V&gt; ScheduledFuture&lt;V&gt; schedule(Callable&lt;V&gt; callable, long delay, TimeUnit unit) { return e.schedule(callable, delay, unit); } public ScheduledFuture&lt;?&gt; scheduleAtFixedRate(Runnable command, long initialDelay, long period, TimeUnit unit) { return e.scheduleAtFixedRate(command, initialDelay, period, unit); } public ScheduledFuture&lt;?&gt; scheduleWithFixedDelay(Runnable command, long initialDelay, long delay, TimeUnit unit) { return e.scheduleWithFixedDelay(command, initialDelay, delay, unit); } } DelegatedScheduledExecutorService作为包装类实现ScheduledExecutorService的方法。 Executors#unconfigurableScheduledExecutorService()123456789101112131415/** * Returns an object that delegates all defined {@link * ScheduledExecutorService} methods to the given executor, but * not any other methods that might otherwise be accessible using * casts. This provides a way to safely \"freeze\" configuration and * disallow tuning of a given concrete implementation. * @param executor the underlying implementation * @return a &lt;tt&gt;ScheduledExecutorService&lt;/tt&gt; instance * @throws NullPointerException if executor null */ public static ScheduledExecutorService unconfigurableScheduledExecutorService(ScheduledExecutorService executor) { if (executor == null) throw new NullPointerException(); return new DelegatedScheduledExecutorService(executor); } 包装成ScheduledExecutorService默认实现方式。 Executors#DefaultThreadFactory()1234567891011121314151617181920212223242526272829/** * The default thread factory */static class DefaultThreadFactory implements ThreadFactory { static final AtomicInteger poolNumber = new AtomicInteger(1); final ThreadGroup group; final AtomicInteger threadNumber = new AtomicInteger(1); final String namePrefix; DefaultThreadFactory() { SecurityManager s = System.getSecurityManager(); group = (s != null)? s.getThreadGroup() : Thread.currentThread().getThreadGroup(); namePrefix = \"pool-\" + poolNumber.getAndIncrement() + \"-thread-\"; } public Thread newThread(Runnable r) { Thread t = new Thread(group, r, namePrefix + threadNumber.getAndIncrement(), 0); if (t.isDaemon()) t.setDaemon(false); if (t.getPriority() != Thread.NORM_PRIORITY) t.setPriority(Thread.NORM_PRIORITY); return t; }} 简单的线程工厂，通过ThreadGroup创建Thread。 Executors#PrivilegedThreadFactory()1234567891011121314151617181920212223242526272829/** * Thread factory capturing access control and class loader */ static class PrivilegedThreadFactory extends DefaultThreadFactory { private final ClassLoader ccl; private final AccessControlContext acc; PrivilegedThreadFactory() { super(); this.ccl = Thread.currentThread().getContextClassLoader(); this.acc = AccessController.getContext(); acc.checkPermission(new RuntimePermission(\"setContextClassLoader\")); } public Thread newThread(final Runnable r) { return super.newThread(new Runnable() { public void run() { AccessController.doPrivileged(new PrivilegedAction&lt;Object&gt;() { public Object run() { Thread.currentThread().setContextClassLoader(ccl); r.run(); return null; } }, acc); } }); } } PrivilegedThreadFactory继承DefaultThreadFactory，通过ClassLoader和AccessControlContext创建定制化的Thread。 Executors#callable()123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101/** * Returns a {@link Callable} object that, when * called, runs the given task and returns the given result. This * can be useful when applying methods requiring a * &lt;tt&gt;Callable&lt;/tt&gt; to an otherwise resultless action. * @param task the task to run * @param result the result to return * @return a callable object * @throws NullPointerException if task null */ public static &lt;T&gt; Callable&lt;T&gt; callable(Runnable task, T result) { if (task == null) throw new NullPointerException(); return new RunnableAdapter&lt;T&gt;(task, result); } /** * Returns a {@link Callable} object that, when * called, runs the given task and returns &lt;tt&gt;null&lt;/tt&gt;. * @param task the task to run * @return a callable object * @throws NullPointerException if task null */ public static Callable&lt;Object&gt; callable(Runnable task) { if (task == null) throw new NullPointerException(); return new RunnableAdapter&lt;Object&gt;(task, null); } /** * Returns a {@link Callable} object that, when * called, runs the given privileged action and returns its result. * @param action the privileged action to run * @return a callable object * @throws NullPointerException if action null */ public static Callable&lt;Object&gt; callable(final PrivilegedAction&lt;?&gt; action) { if (action == null) throw new NullPointerException(); return new Callable&lt;Object&gt;() { public Object call() { return action.run(); }}; } /** * Returns a {@link Callable} object that, when * called, runs the given privileged exception action and returns * its result. * @param action the privileged exception action to run * @return a callable object * @throws NullPointerException if action null */ public static Callable&lt;Object&gt; callable(final PrivilegedExceptionAction&lt;?&gt; action) { if (action == null) throw new NullPointerException(); return new Callable&lt;Object&gt;() { public Object call() throws Exception { return action.run(); }}; } /** * Returns a {@link Callable} object that will, when * called, execute the given &lt;tt&gt;callable&lt;/tt&gt; under the current * access control context. This method should normally be * invoked within an {@link AccessController#doPrivileged} action * to create callables that will, if possible, execute under the * selected permission settings holding within that action; or if * not possible, throw an associated {@link * AccessControlException}. * @param callable the underlying task * @return a callable object * @throws NullPointerException if callable null * */ public static &lt;T&gt; Callable&lt;T&gt; privilegedCallable(Callable&lt;T&gt; callable) { if (callable == null) throw new NullPointerException(); return new PrivilegedCallable&lt;T&gt;(callable); } /** * Returns a {@link Callable} object that will, when * called, execute the given &lt;tt&gt;callable&lt;/tt&gt; under the current * access control context, with the current context class loader * as the context class loader. This method should normally be * invoked within an {@link AccessController#doPrivileged} action * to create callables that will, if possible, execute under the * selected permission settings holding within that action; or if * not possible, throw an associated {@link * AccessControlException}. * @param callable the underlying task * * @return a callable object * @throws NullPointerException if callable null * @throws AccessControlException if the current access control * context does not have permission to both set and get context * class loader. */ public static &lt;T&gt; Callable&lt;T&gt; privilegedCallableUsingCurrentClassLoader(Callable&lt;T&gt; callable) { if (callable == null) throw new NullPointerException(); return new PrivilegedCallableUsingCurrentClassLoader&lt;T&gt;(callable); } 根据上面callable()分成3种callable()。 转换Runnable适配器RunnableAdapter()。 PrivilegedAction作为参数传递(PrivilegedExceptionAction是throw Exception版本)，返回Callable对象。 返回PrivilegedCallable对象。 Executors#RunnableAdapter()123456789101112131415/** * A callable that runs given task and returns given result */static final class RunnableAdapter&lt;T&gt; implements Callable&lt;T&gt; { final Runnable task; final T result; RunnableAdapter(Runnable task, T result) { this.task = task; this.result = result; } public T call() { task.run(); return result; }} call()里运行Runnable#run()。 Executors#PrivilegedCallable123456789101112131415161718192021222324252627282930/** * A callable that runs under established access control settings */static final class PrivilegedCallable&lt;T&gt; implements Callable&lt;T&gt; { private final AccessControlContext acc; private final Callable&lt;T&gt; task; private T result; private Exception exception; PrivilegedCallable(Callable&lt;T&gt; task) { this.task = task; this.acc = AccessController.getContext(); } public T call() throws Exception { AccessController.doPrivileged(new PrivilegedAction&lt;T&gt;() { public T run() { try { result = task.call(); } catch (Exception ex) { exception = ex; } return null; } }, acc); if (exception != null) throw exception; else return result; }} AccessControlContext设置好，callable才能运行。","link":"/JDK1.6-Executors/"},{"title":"JDK1.7 Condition","text":"1 介绍 2 代码 例1 例2 例3 3 源码分析 ReentrantLock#newCondition() AbstractQueuedSynchronizer#ConditionObject#await() AbstractQueuedSynchronizer#ConditionObject#addConditionWaiter() AbstractQueuedSynchronizer#ConditionObject#fullyRelease() AbstractQueuedSynchronizer#isOnSyncQueue() AbstractQueuedSynchronizer#findNodeFromTail() AbstractQueuedSynchronizer#acquireQueued() AbstractQueuedSynchronizer#ConditionObject#signal() 4 AbstractQueuedSynchronizer和Condition AbstractQueuedSynchronizer Condition AbstractQueuedSynchronizer#ConditionObject() AbstractQueuedSynchronizer#ConditionObject#doSignal() AbstractQueuedSynchronizer#transferForSignal() 1 介绍Condition是一个多线程间协调通信的工具类。使得某个或者某些线程一起等待某个条件（Condition），只有当该条件具备(signal()或者signalAll()被带调用)时，这些等待线程才会被唤醒，从而重新争夺锁。Condition将Object监视器方法（wait()、notify()和notifyAll()）分解成截然不同的对象，以便通过将这些对象与任意Lock实现组合使用，为每个对象提供多个等待set()（wait-set）。其中，Lock替代synchronized和语句的使用，Condition替代Object监视器方法的使用。Lock对应Synchronized，使用之前都要先获取锁。 – Object Condition 休眠 wait await 唤醒个线程 notify signal 唤醒所有线程 notifyAll signalAll Condition它更强大的地方在于。能够更加精细的控制多线程的休眠与唤醒。对于同一个锁，我们可以创建多个Condition，就是多个监视器的意思。在不同的情况下使用不同的Condition。 2 代码例1将sync的1个线程通信的例子替换成用Condition实现。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273package conditions;import java.util.concurrent.locks.Condition;import java.util.concurrent.locks.Lock;import java.util.concurrent.locks.ReentrantLock;public class ThreadTest2 { public static void main(String[] args) { final Business business = new Business(); //子线程 new Thread(new Runnable() { @Override public void run() { threadExecute(business, \"sub\"); } }).start(); //主线程 threadExecute(business, \"main\"); } public static void threadExecute(Business business, String threadType) { for (int i = 0; i &lt; 5; i++) { try { if (\"main\".equals(threadType)) { business.main(i); } else { business.sub(i); } } catch (InterruptedException e) { e.printStackTrace(); } } }}class Business { private boolean bool = true; private Lock lock = new ReentrantLock(); private Condition condition = lock.newCondition(); public void main(int loop) throws InterruptedException { lock.lock(); try { while (bool) { condition.await();// this.wait(); } for (int i = 0; i &lt; 3; i++) { System.out.println(\"main thread seq of \" + i + \", loop of \" + loop); } bool = true; condition.signal();// this.notify(); } finally { lock.unlock(); } } public void sub(int loop) throws InterruptedException { lock.lock(); try { while (!bool) { condition.await();// this.wait(); } for (int i = 0; i &lt; 3; i++) { System.out.println(\"-- sub thread seq of \" + i + \", loop of \" + loop); } bool = false; condition.signal();// this.notify(); } finally { lock.unlock(); } }} 123456789101112131415161718192021222324252627282930-- sub thread seq of 0, loop of 0-- sub thread seq of 1, loop of 0-- sub thread seq of 2, loop of 0main thread seq of 0, loop of 0main thread seq of 1, loop of 0main thread seq of 2, loop of 0-- sub thread seq of 0, loop of 1-- sub thread seq of 1, loop of 1-- sub thread seq of 2, loop of 1main thread seq of 0, loop of 1main thread seq of 1, loop of 1main thread seq of 2, loop of 1-- sub thread seq of 0, loop of 2-- sub thread seq of 1, loop of 2-- sub thread seq of 2, loop of 2main thread seq of 0, loop of 2main thread seq of 1, loop of 2main thread seq of 2, loop of 2-- sub thread seq of 0, loop of 3-- sub thread seq of 1, loop of 3-- sub thread seq of 2, loop of 3main thread seq of 0, loop of 3main thread seq of 1, loop of 3main thread seq of 2, loop of 3-- sub thread seq of 0, loop of 4-- sub thread seq of 1, loop of 4-- sub thread seq of 2, loop of 4main thread seq of 0, loop of 4main thread seq of 1, loop of 4main thread seq of 2, loop of 4 lock和condition可以代替sync实现同步功能。在Condition中，用await()替换wait()，用signal()替换notify()，用signalAll()替换notifyAll()，传统线程的通信方式，Condition都可以实现。 例2Condition的强大之处在于它可以为多个线程间建立不同的Condition。例如，假如多线程读/写同一个缓冲区：当向缓冲区中写入数据之后，唤醒”读线程”；当从缓冲区读出数据之后，唤醒”写线程”；如果采用Object类中的wait(), notify(), notifyAll()实现该缓冲区，当向缓冲区写入数据之后需要唤醒”读线程”时，不可能通过notify()或notifyAll()明确的指定唤醒”读线程”，而只能通过notifyAll()唤醒所有线程(但是notifyAll()无法区分唤醒的线程是读线程，还是写线程)。通过Condition，就能明确的指定唤醒读线程。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051package conditions;import java.util.concurrent.locks.Condition;import java.util.concurrent.locks.Lock;import java.util.concurrent.locks.ReentrantLock;class BoundedBuffer { final Lock lock = new ReentrantLock();// 锁对象 final Condition notFull = lock.newCondition();// 写线程条件 final Condition notEmpty = lock.newCondition();// 读线程条件 final Object[] items = new Object[100];// 缓存队列 int putptr/* 写索引 */, takeptr/* 读索引 */, count/* 队列中存在的数据个数 */; public void put(Object x) throws InterruptedException { lock.lock(); try { while (count == items.length){ // 如果队列满了 notFull.await();// 阻塞写线程 } items[putptr] = x;// 赋值 if (++putptr == items.length){ putptr = 0;// 如果写索引写到队列的最后一个位置了，那么置为0 } ++count;// 个数++ notEmpty.signal();// 唤醒读线程 } finally { lock.unlock(); } } public Object take() throws InterruptedException { lock.lock(); try { while (count == 0){ // 如果队列为空 notEmpty.await();// 阻塞读线程 } Object x = items[takeptr];// 取值 if (++takeptr == items.length){ takeptr = 0;// 如果读索引读到队列的最后一个位置了，那么置为0 } --count;// 个数-- notFull.signal();// 唤醒写线程 return x; } finally { lock.unlock(); } }} 这是一个处于多线程工作环境下的缓存区，缓存区提供了两个方法，put()和take()，put()是存数据，take()是取数据，内部有个缓存队列，具体变量和方法说明见代码，这个缓存区类实现的功能：有多个线程往里面存数据和从里面取数据，其缓存队列（先进先出后进后出）能缓存的最大数值是100，多个线程间是互斥的，当缓存队列中存储的值达到100时，将写线程阻塞，并唤醒读线程，当缓存队列中存储的值为0时，将读线程阻塞，并唤醒写线程，这也是ArrayBlockingQueue的内部实现。 例3简单阻塞、唤醒。12345678910111213141516171819202122232425262728293031323334353637383940414243444546package conditions;import java.util.concurrent.locks.Condition;import java.util.concurrent.locks.ReentrantLock;public class Test { public static void main(String[] args) { final ReentrantLock reentrantLock =new ReentrantLock(); final Condition condition=reentrantLock.newCondition(); Thread thread1 = new Thread(new Runnable() { @Override public void run() { try { reentrantLock.lock(); System.out.println(\"我要等一个新信号！\"+this); condition.await(); } catch (Exception e) { e.printStackTrace(); } System.out.println(\"拿到一个信号！\"+this); reentrantLock.unlock(); } }); thread1.start(); Thread thread2 = new Thread(new Runnable() { @Override public void run() { reentrantLock.lock(); System.out.println(\"我拿到锁！\"+this); try { Thread.sleep(3000); } catch (Exception e) { e.printStackTrace(); } condition.signalAll(); System.out.println(\"我发一个信号！\"+this); reentrantLock.unlock(); System.out.println(\" ------------- thread 2 unlock 结束\"); } }); thread2.start(); }} 12345我要等一个新信号！conditions.Test$1@51493995我拿到锁！conditions.Test$2@892b7c2我发一个信号！conditions.Test$2@892b7c2 ------------- thread 2 unlock 结束拿到一个信号！conditions.Test$1@51493995 signalall()唤醒操作要等thread2释放锁之后，thread1才能获取到锁。锁被释放后，线程1开始沉睡，这个时候线程因为线程1沉睡时，会唤醒AQS队列中的头结点（AQS队列存着等待唤醒的线程），所以线程2会开始竞争锁，并获取到，等待3秒后，线程2会调用signal()，”发出”signal信号。 3 源码分析ReentrantLock#newCondition()123456789101112131415161718192021222324252627282930313233343536373839404142/** * Returns a {@link Condition} instance for use with this * {@link Lock} instance. * * &lt;p&gt;The returned {@link Condition} instance supports the same * usages as do the {@link Object} monitor methods ({@link * Object#wait() wait}, {@link Object#notify notify}, and {@link * Object#notifyAll notifyAll}) when used with the built-in * monitor lock. * * &lt;ul&gt; * * &lt;li&gt;If this lock is not held when any of the {@link Condition} * {@linkplain Condition#await() waiting} or {@linkplain * Condition#signal signalling} methods are called, then an {@link * IllegalMonitorStateException} is thrown. * * &lt;li&gt;When the condition {@linkplain Condition#await() waiting} * methods are called the lock is released and, before they * return, the lock is reacquired and the lock hold count restored * to what it was when the method was called. * * &lt;li&gt;If a thread is {@linkplain Thread#interrupt interrupted} * while waiting then the wait will terminate, an {@link * InterruptedException} will be thrown, and the thread's * interrupted status will be cleared. * * &lt;li&gt; Waiting threads are signalled in FIFO order. * * &lt;li&gt;The ordering of lock reacquisition for threads returning * from waiting methods is the same as for threads initially * acquiring the lock, which is in the default case not specified, * but for &lt;em&gt;fair&lt;/em&gt; locks favors those threads that have been * waiting the longest. * * &lt;/ul&gt; * * @return the Condition object */public Condition newCondition() { return sync.newCondition();} AbstractQueuedSynchronizer#ConditionObject#await()condition调用await()，调用的是AQS的内部类ConditionObject。查看ConditionObject#await()。123456789101112131415161718192021222324252627282930313233343536 /** * Implements interruptible condition wait. * &lt;ol&gt; * &lt;li&gt; If current thread is interrupted, throw InterruptedException. * &lt;li&gt; Save lock state returned by {@link #getState}. * &lt;li&gt; Invoke {@link #release} with * saved state as argument, throwing * IllegalMonitorStateException if it fails. * &lt;li&gt; Block until signalled or interrupted. * &lt;li&gt; Reacquire by invoking specialized version of * {@link #acquire} with saved state as argument. * &lt;li&gt; If interrupted while blocked in step 4, throw InterruptedException. * &lt;/ol&gt; */ public final void await() throws InterruptedException { if (Thread.interrupted()) throw new InterruptedException();// 1 Node node = addConditionWaiter();// 2 int savedState = fullyRelease(node); int interruptMode = 0;// 3 while (!isOnSyncQueue(node)) { LockSupport.park(this); if ((interruptMode = checkInterruptWhileWaiting(node)) != 0) break; }// 4 if (acquireQueued(node, savedState) &amp;&amp; interruptMode != THROW_IE) interruptMode = REINTERRUPT; if (node.nextWaiter != null) // clean up if cancelled unlinkCancelledWaiters(); if (interruptMode != 0) reportInterruptAfterWait(interruptMode); } 标注代码分析 添加当前线程到Condition的等待队列中，等待唤醒。 释放当前占有锁。在调用await()之前，当前这个线程是占有锁的。 遍历AQS的队列，看当前节点是否在队列中，如果不在队列中，说明还没有获取到锁（AQS队列，是获取到锁的线程）。isOnSyncQueue判断是否在AQS同步队列中。findNodeFromTail循环遍历，判断当前线程是不是等于AQS尾节点线程。如果是尾节点线程，则退出当前while。 被唤醒后，重新开始正式竞争锁，同样，如果竞争不到还是会将自己沉睡，等待唤醒重新开始竞争。 AbstractQueuedSynchronizer#ConditionObject#addConditionWaiter()12345678910111213141516171819/** * Adds a new waiter to wait queue. * @return its new wait node */private Node addConditionWaiter() { Node t = lastWaiter; // If lastWaiter is cancelled, clean out. if (t != null &amp;&amp; t.waitStatus != Node.CONDITION) { unlinkCancelledWaiters(); t = lastWaiter; } Node node = new Node(Thread.currentThread(), Node.CONDITION); if (t == null) firstWaiter = node; else t.nextWaiter = node; lastWaiter = node; return node;} AbstractQueuedSynchronizer#ConditionObject#fullyRelease()123456789101112131415161718192021/** * Invokes release with current state value; returns saved state. * Cancels node and throws exception on failure. * @param node the condition node for this wait * @return previous sync state */final int fullyRelease(Node node) { boolean failed = true; try { int savedState = getState(); if (release(savedState)) { failed = false; return savedState; } else { throw new IllegalMonitorStateException(); } } finally { if (failed) node.waitStatus = Node.CANCELLED; }} AbstractQueuedSynchronizer#isOnSyncQueue()123456789101112131415161718192021/** * Returns true if a node, always one that was initially placed on * a condition queue, is now waiting to reacquire on sync queue. * @param node the node * @return true if is reacquiring */final boolean isOnSyncQueue(Node node) { if (node.waitStatus == Node.CONDITION || node.prev == null) return false; if (node.next != null) // If has successor, it must be on queue return true; /* * node.prev can be non-null, but not yet on queue because * the CAS to place it on queue can fail. So we have to * traverse from tail to make sure it actually made it. It * will always be near the tail in calls to this method, and * unless the CAS failed (which is unlikely), it will be * there, so we hardly ever traverse much. */ return findNodeFromTail(node);} AbstractQueuedSynchronizer#findNodeFromTail()123456789101112131415/** * Returns true if node is on sync queue by searching backwards from tail. * Called only when needed by isOnSyncQueue. * @return true if present */private boolean findNodeFromTail(Node node) { Node t = tail; for (;;) { if (t == node) return true; if (t == null) return false; t = t.prev; }} AbstractQueuedSynchronizer#acquireQueued()1234567891011121314151617181920212223242526272829303132333435363738/* * Various flavors of acquire, varying in exclusive/shared and * control modes. Each is mostly the same, but annoyingly * different. Only a little bit of factoring is possible due to * interactions of exception mechanics (including ensuring that we * cancel if tryAcquire throws exception) and other control, at * least not without hurting performance too much. *//** * Acquires in exclusive uninterruptible mode for thread already in * queue. Used by condition wait methods as well as acquire. * * @param node the node * @param arg the acquire argument * @return {@code true} if interrupted while waiting */final boolean acquireQueued(final Node node, int arg) { boolean failed = true; try { boolean interrupted = false; for (;;) { final Node p = node.predecessor(); if (p == head &amp;&amp; tryAcquire(arg)) { setHead(node); p.next = null; // help GC failed = false; return interrupted; } if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; } } finally { if (failed) cancelAcquire(node); }} AbstractQueuedSynchronizer#ConditionObject#signal()12345678910111213141516/*** Moves the longest-waiting thread, if one exists, from the* wait queue for this condition to the wait queue for the* owning lock.** @throws IllegalMonitorStateException if {@link #isHeldExclusively}* returns {@code false}*/public final void signal() { if (!isHeldExclusively()) throw new IllegalMonitorStateException(); // 1 Node first = firstWaiter; if (first != null) doSignal(first);} 标注代码分析 firstWaiter是Condition维护的队列的第一个线程，准备唤醒此线程。4 AbstractQueuedSynchronizer和ConditionAbstractQueuedSynchronizer维护竞争到锁的线程，有锁的线程进入AQS队列。Condition维护等待队列的头节点和尾节点，该队列的作用是存放等待signal信号的线程，该线程被封装为Node节点后存放于此。AbstractQueuedSynchronizer#ConditionObject()12345678910111213141516171819202122/** * Condition implementation for a {@link * AbstractQueuedSynchronizer} serving as the basis of a {@link * Lock} implementation. * * &lt;p&gt;Method documentation for this class describes mechanics, * not behavioral specifications from the point of view of Lock * and Condition users. Exported versions of this class will in * general need to be accompanied by documentation describing * condition semantics that rely on those of the associated * &lt;tt&gt;AbstractQueuedSynchronizer&lt;/tt&gt;. * * &lt;p&gt;This class is Serializable, but all fields are transient, * so deserialized conditions have no waiters. */ public class ConditionObject implements Condition, java.io.Serializable { private static final long serialVersionUID = 1173984872572414699L; /** First node of condition queue. */ private transient Node firstWaiter; /** Last node of condition queue. */ private transient Node lastWaiter;.... AQS和Condition队列作用是不同的，实际上每个线程也仅仅存在2个队列中的一个。参考例3 线程1调用ReentrantLock#lock时，线程被加入到AQS的等待队列中。（此线程获取到锁，加入AQS中） 线程1调用await()被调用时，该线程从AQS中移除，对应操作是锁的释放。接着马上被加入到Condition的等待队列中，等待该线程唤醒信号。 线程2因为线程1释放锁的关系，被唤醒，并判断可以获取锁，于是线程2获取锁，并被加入到AQS的等待队列中。 线程2调用signal()，这个时候Condition的等待队列中只有线程1一个节点，于是它被取出来，并被加入到AQS的等待队列中。注意，这个时候，线程1 并没有被唤醒。（线程2执行unlock()时才被唤醒） signal()执行完毕，线程2调用ReentrantLock#unLock()，释放锁。这个时候因为AQS中只有线程1，于是，AQS释放锁后按从头到尾的顺序唤醒线程时，线程1被唤醒，于是线程1恢复执行。直到释放所整个过程执行完毕。 doSignal删除Condition队列的尾部等待节点线程（设置为null），头节点的下一个节点线程也是null。 AbstractQueuedSynchronizer#ConditionObject#doSignal()1234567891011121314/** * Removes and transfers nodes until hit non-cancelled one or * null. Split out from signal in part to encourage compilers * to inline the case of no waiters. * @param first (non-null) the first node on condition queue */ private void doSignal(Node first) { do { if ( (firstWaiter = first.nextWaiter) == null) lastWaiter = null; first.nextWaiter = null; } while (!transferForSignal(first) &amp;&amp; (first = firstWaiter) != null); } AbstractQueuedSynchronizer#transferForSignal()123456789101112131415161718192021222324252627 /** * Transfers a node from a condition queue onto sync queue. * Returns true if successful. * @param node the node * @return true if successfully transferred (else the node was * cancelled before signal). */ final boolean transferForSignal(Node node) { /* * If cannot change waitStatus, the node has been cancelled. */ if (!compareAndSetWaitStatus(node, Node.CONDITION, 0)) return false; /* * Splice onto queue and try to set waitStatus of predecessor to * indicate that thread is (probably) waiting. If cancelled or * attempt to set waitStatus fails, wake up to resync (in which * case the waitStatus can be transiently and harmlessly wrong). */ Node p = enq(node); int ws = p.waitStatus;// 1 if (ws &gt; 0 || !compareAndSetWaitStatus(p, ws, Node.SIGNAL)) LockSupport.unpark(node.thread); return true; } 标注代码分析 可以看到，正常情况 ws &gt; 0 || !compareAndSetWaitStatus(p, ws, Node.SIGNAL) 这个判断是不会为true的，所以，不会在这个时候唤醒该线程。 只有到发送signal信号的线程调用ReentrantLock.unlock()后因为它已经被加到AQS的等待队列中，所以才会被唤醒。","link":"/JDK1.7-Condition/"},{"title":"JDK7自带工具","text":"1 JDK7自带工具目录 2 Jstat 命令 interval count -options class类加载情况统计 compiler查看HotSpot中即时编译器编译情况的统计 GC JVM中堆的垃圾收集情况的统计 gccapacity新生代、老生代及持久代的存储容量情况 gccause用于查看垃圾收集的统计情况（这个和-gcutil选项一样） gcnew新生代垃圾收集的情况 gcnewcapacity新生代的存储容量情况 gcold老生代及持久代发生GC的情况 gcoldcapacity老生代的存储容量情况 gcpermcapacity持久代的存储容量情况 gcutil新生代、老生代及持代垃圾收集的情况 printcompilation HotSpot编译方法的统计 3 Jmap命令 histo 命令 注意 heap 命令 dump 命令 注意 permstat 命令 注意 4 内存分析工具（Memory Analyzer Tool，MAT） 修改参数配置 分析文件 1 JDK7自带工具目录1234C:\\Users\\Administrator&gt;java -versionjava version &quot;1.7.0_76&quot;Java(TM) SE Runtime Environment (build 1.7.0_76-b13)Java HotSpot(TM) 64-Bit Server VM (build 24.76-b04, mixed mode) 命令 | 说明—|—appletviewer | 用于运行并浏览applet小程序。extcheck | 扩展检测工具，主要用于检测指定jar文件与当前已安装的Java SDK扩展之间是否存在版本冲突。idlj | IDL转Java编译器(IDL-to-Java Compiler)，用于为指定的IDL文件生成Java绑定。IDL意即接口定义语言(Interface Definition Language)。jar | jar文件管理工具，主要用于打包压缩、解压jar文件。jarsigner | jar密匙签名工具。java | Java运行工具，用于运行.class字节码文件或.jar文件。javac | Java编译工具(Java Compiler)，用于编译Java源代码文件。javadoc | Java文档工具，主要用于根据Java源代码中的注释信息生成HTML格式的API帮助文档。javafxpackager | JavaFX包装器，用于执行与封装或签名JavaFX应用有关的任务。JDK 8u20已经迁移此工具到javapackager。javah | Java头文件工具，用于根据Java类生成C/C++头文件和源文件(主要用于JNI开发领域)。javap | Java反编译工具，主要用于根据Java字节码文件反汇编为Java源代码文件。javapackager | 执行针对Java应用程序和JavaFX应用程序的打包和签名的任务。包含了javafxpackager的功能。jcmd | Java 命令行(Java Command)，用于向正在运行的JVM发送诊断命令请求。jconsole | 图形化用户界面的监测工具，主要用于监测并显示运行于Java平台上的应用程序的性能和资源占用等信息jdeps | 用于分析Java class的依赖关系jdb | Java调试工具(Java Debugger)，主要用于对Java应用进行断点调试jhat | Java堆分析工具(Java Heap Analysis Tool)，用于分析Java堆内存中的对象信息。jinfo | Java配置信息工具(Java Configuration Information)，用于打印指定Java进程、核心文件或远程调试服务器的配置信息。jjs | 对Nashorn引擎的调用。Nashorn是基于Java实现一个轻量级高性能的JavaScript运行环境。jmap | Java内存映射工具(Java Memory Map)，主要用于打印指定Java进程、核心文件或远程调试服务器的共享对象内存映射或堆内存细节。jmc | Java任务控制工具(Java Mission Control)，主要用于HotSpot JVM的生产时间监测、分析、诊断。开发者可以使用jmc命令来创建JMC工具。jps | JVM进程状态工具(JVM Process Status Tool)，用于显示目标系统上的HotSpot JVM的Java进程信息。jrunscript | Java命令行脚本外壳工具(command line script shell)，主要用于解释执行javascript、groovy、ruby等脚本语言。jsadebugd | Java可用性代理调试守护进程(Java Serviceability Agent Debug Daemon)，主要用于附加到指定的Java进程、核心文件，或充当一个调试服务器。jstack | Java堆栈跟踪工具，主要用于打印指定Java进程、核心文件或远程调试服务器的Java线程的堆栈跟踪信息。jstat | JVM统计监测工具(JVM Statistics Monitoring Tool)，主要用于监测并显示JVM的性能统计信息，包括gc统计信息。jstatd | jstatd(VM jstatd Daemon)工具是一个RMI服务器应用，用于监测HotSpot JVM的创建和终止，并提供一个接口，允许远程监测工具附加到运行于本地主机的JVM上。jvisualvm | JVM监测、故障排除、分析工具，主要以图形化界面的方式提供运行于指定虚拟机的Java应用程序的详细信息。keytool | 密钥和证书管理工具，主要用于密钥和证书的创建、修改、删除等。主要用于获取或缓存Kerberos协议的票据授权票据。允许用户查看本地凭据缓存和密钥表中的条目(用于Kerberos协议)。Kerberos密钥表管理工具，允许用户管理存储于本地密钥表中的主要名称和服务密钥。native2ascii | 本地编码到ASCII编码的转换器(Native-to-ASCII Converter)，用于”任意受支持的字符编码”和与之对应的”ASCII编码和(或)Unicode转义”之间的相互转换。orbd | 对象请求代理守护进程(Object Request Broker Daemon)，它使客户端能够透明地定位和调用位于CORBA环境的服务器上的持久对象。pack200 | JAR文件打包压缩工具，它可以利用Java类特有的结构，对普通JAR文件进行高效压缩，以便于能够更快地进行网络传输。这是微软提供的对象包装程序，用于对象安装包。policytool | 策略工具，用于管理用户策略文件(.java.policy)。rmic | Java RMI 编译器，为使用JRMP或IIOP协议的远程对象生成stub、skeleton、和tie类，也用于生成OMG IDL。rmid | Java RMI 激活系统守护进程，rmid启动激活系统守护进程，允许在虚拟机中注册或激活对象。rmiregistry | Java 远程对象注册表，用于在当前主机的指定端口上创建并启动一个远程对象注册表。schemagen | XML schema生成器，用于生成XML schema文件。serialver | 序列版本命令，用于生成并返回serialVersionUID。servertool | Java IDL 服务器工具，用于注册、取消注册、启动和终止持久化的服务器。tnameserv | Java IDL瞬时命名服务。unpack200 | JAR文件解压工具，将一个由pack200打包的文件解压提取为JAR文件。wsgen | XML Web Service 2.0的Java API，生成用于JAX-WS Web Service的JAX-WS便携式产物。wsimport | XML Web Service 2.0的Java API，主要用于根据服务端发布的wsdl文件生成客户端存根及框架。xjc | 主要用于根据XML schema文件生成对应的Java类。 2 JstatJstat用于监控基于HotSpot的JVM，对其堆的使用情况进行实时的命令行的统计，使用jstat我们可以对指定的JVM做如下监控： 类的加载及卸载情况。 查看新生代、老生代及持久代的容量及使用情况。 查看新生代、老生代及持久代的垃圾收集情况，包括垃圾回收的次数及垃圾回收所占用的时间。 查看新生代中Eden区及Survior区中容量及分配情况等。 jstat工具特别强大，它有众多的可选项，通过提供多种不同的监控维度，使我们可以从不同的维度来了解到当前JVM堆的使用情况。详细查看堆内各个部分的使用量，使用的时候必须加上待统计的Java进程号，可选的不同维度参数以及可选的统计频率参数。它主要是用来显示GC及PermGen相关的信息。 命令1jstat -&lt;option&gt; [-t] [-h&lt;lines&gt;] &lt;vmid&gt; [&lt;interval&gt; [&lt;count&gt;]] interval间隔时间，单位可以是秒或者毫秒，通过指定s或ms确定，默认单位为毫秒。 count打印次数，如果缺省则打印无数次。 -options123456789101112class：用于查看类加载情况的统计。compiler：用于查看HotSpot中即时编译器编译情况的统计。gc：用于查看JVM中堆的垃圾收集情况的统计。gccapacity：用于查看新生代、老生代及持久代的存储容量情况。gccause：用于查看垃圾收集的统计情况（这个和-gcutil选项一样），如果有发生垃圾收集，它还会显示最后一次及当前正在发生垃圾收集的原因。gcnew：用于查看新生代垃圾收集的情况。gcnewcapacity：用于查看新生代的存储容量情况。gcold：用于查看老生代及持久代发生GC的情况。gcoldcapacity：用于查看老生代的容量。gcpermcapacity：用于查看持久代的容量。gcutil：用于查看新生代、老生代及持代垃圾收集的情况。printcompilation：HotSpot编译方法的统计。 class类加载情况统计 列名 说明 Loaded 加载了的类的数量 Bytes 加载了的类的大小，单为Kb Unloaded 卸载了的类的数量 Bytes 卸载了的类的大小，单为Kb Time 花在类的加载及卸载的时间 compiler查看HotSpot中即时编译器编译情况的统计 列名 说明 Compiled 编译任务执行的次数 Failed 编译任务执行失败的次数 Invalid 编译任务非法执行的次数 Time 执行编译花费的时间 FailedType 最后一次编译失败的编译类型 FailedMethod 最后一次编译失败的类名及方法名 GC JVM中堆的垃圾收集情况的统计 列名 说明 S0C 新生代中Survivor space中S0当前容量的大小（KB） S1C 新生代中Survivor space中S1当前容量的大小（KB） S0U 新生代中Survivor space中S0容量使用的大小（KB） S1U 新生代中Survivor space中S1容量使用的大小（KB） EC Eden space当前容量的大小（KB） EU Eden space容量使用的大小（KB） OC Old space当前容量的大小（KB） OU Old space使用容量的大小（KB） PC Permanent space当前容量的大小（KB） PU Permanent space使用容量的大小（KB） YGC 从应用程序启动到采样时发生 Young GC 的次数 YGCT 从应用程序启动到采样时 Young GC 所用的时间(秒) FGC 从应用程序启动到采样时发生 Full GC 的次数 FGCT 从应用程序启动到采样时 Full GC 所用的时间(秒) GCT T从应用程序启动到采样时用于垃圾回收的总时间(单位秒)，它的值等于YGC+FGC gccapacity新生代、老生代及持久代的存储容量情况 列名 说明 NGCMN 新生代的最小容量大小（KB） NGCMX 新生代的最大容量大小（KB） NGC 当前新生代的容量大小（KB） S0C 当前新生代中survivor space 0的容量大小（KB） S1C 当前新生代中survivor space 1的容量大小（KB） EC Eden space当前容量的大小（KB） OGCMN 老生代的最小容量大小（KB） OGCMX 老生代的最大容量大小（KB） OGC 当前老生代的容量大小（KB） OC 当前老生代的空间容量大小（KB） PGCMN 持久代的最小容量大小（KB） PGCMX 持久代的最大容量大小（KB） PGC 当前持久代的容量大小（KB） PC 当前持久代的空间容量大小（KB） YGC 从应用程序启动到采样时发生 Young GC 的次数 FGC 从应用程序启动到采样时发生 Full GC 的次数 gccause用于查看垃圾收集的统计情况（这个和-gcutil选项一样）如果有发生垃圾收集，它还会显示最后一次及当前正在发生垃圾收集的原因列名 | 说明—|—LGCC | 最后一次垃圾收集的原因，可能为“unknown GCCause”、“System.gc()”等GCC | 当前垃圾收集的原因 gcnew新生代垃圾收集的情况 列名 说明 S0C 当前新生代中survivor space 0的容量大小（KB） S1C 当前新生代中survivor space 1的容量大小（KB） S0U S0已经使用的大小（KB） S1U S1已经使用的大小（KB） TT Tenuring threshold，要了解这个参数，我们需要了解一点Java内存对象的结构，在Sun JVM中，（除了数组之外的）对象都有两个机器字（words）的头部。第一个字中包含这个对象的标示哈希码以及其他一些类似锁状态和等标识信息，第二个字中包含一个指向对象的类的引用，其中第二个字节就会被垃圾收集算法使用到。 在新生代中做垃圾收集的时候，每次复制一个对象后，将增加这个对象的收集计数，当一个对象在新生代中被复制了一定次数后，该算法即判定该对象是长周期的对象，把他移动到老生代，这个阈值叫着tenuring threshold。这个阈值用于表示某个/些在执行批定次数youngGC后还活着的对象，即使此时新生的的Survior没有满，也同样被认为是长周期对象，将会被移到老生代中。 MTT Maximum tenuring threshold，用于表示TT的最大值。 DSS Desired survivor size (KB).可以参与这里：http://blog.csdn.net/yangjun2/article/details/6542357 EC Eden space当前容量的大小（KB） EU Eden space已经使用的大小（KB） YGC 从应用程序启动到采样时发生 Young GC 的次数 YGCT 从应用程序启动到采样时 Young GC 所用的时间(单位秒) gcnewcapacity新生代的存储容量情况 列名 说明 NGCMN 新生代的最小容量大小（KB） NGCMX 新生代的最大容量大小（KB） NGC 当前新生代的容量大小（KB） S0CMX 新生代中SO的最大容量大小（KB） S0C 当前新生代中SO的容量大小（KB） S1CMX 新生代中S1的最大容量大小（KB） S1C 当前新生代中S1的容量大小（KB） ECMX 新生代中Eden的最大容量大小（KB） EC 当前新生代中Eden的容量大小（KB） YGC 从应用程序启动到采样时发生 Young GC 的次数 FGC 从应用程序启动到采样时发生 Full GC 的次数 gcold老生代及持久代发生GC的情况 列名 说明 PC 当前持久代容量的大小（KB） PU 持久代使用容量的大小（KB） OC 当前老年代容量的大小（KB） OU 老年代使用容量的大小（KB） YGC 从应用程序启动到采样时发生 Young GC 的次数 FGC 从应用程序启动到采样时发生 Full GC 的次数 FGCT 从应用程序启动到采样时 Full GC 所用的时间(单位秒) GCT 从应用程序启动到采样时用于垃圾回收的总时间(单位秒)，它的值等于YGC+FGC gcoldcapacity老生代的存储容量情况 列名 说明 OGCMN 老生代的最小容量大小（KB） OGCMX 老生代的最大容量大小（KB） OGC 当前老生代的容量大小（KB） OC 当前新生代的空间容量大小（KB） YGC 从应用程序启动到采样时发生 Young GC 的次数 FGC 从应用程序启动到采样时发生 Full GC 的次数 FGCT 从应用程序启动到采样时 Full GC 所用的时间(单位秒) GCT 从应用程序启动到采样时用于垃圾回收的总时间(单位秒)，它的值等于YGC+FGC gcpermcapacity持久代的存储容量情况 列名 说明 PGCMN 持久代的最小容量大小（KB） PGCMX 持久代的最大容量大小（KB） PGC 当前持久代的容量大小（KB） PC 当前持久代的空间容量大小（KB） YGC 从应用程序启动到采样时发生 Young GC 的次数 FGC FGCT 从应用程序启动到采样时 Full GC 所用的时间(单位秒) GCT 从应用程序启动到采样时用于垃圾回收的总时间(单位秒)，它的值等于YGC+FGC gcutil新生代、老生代及持代垃圾收集的情况 列名 说明 S0 Heap上的 Survivor space 0 区已使用空间的百分比 S1 Heap上的 Survivor space 1 区已使用空间的百分比 E Heap上的 Eden space 区已使用空间的百分比 O Heap上的 Old space 区已使用空间的百分比 P Perm space 区已使用空间的百分比 YGC 从应用程序启动到采样时发生 Young GC 的次数 YGCT 从应用程序启动到采样时 Young GC 所用的时间(单位秒) FGC 从应用程序启动到采样时发生 Full GC 的次数 FGCT 从应用程序启动到采样时 Full GC 所用的时间(单位秒) GCT 从应用程序启动到采样时用于垃圾回收的总时间(单位秒)，它的值等于YGC+FGC printcompilation HotSpot编译方法的统计 列名 说明 Compiled 编译任务执行的次数 Size 方法的字节码所占的字节数 Type 编译类型 Method 指定确定被编译方法的类名及方法名，类名中使名“/”而不是“.”做为命名分隔符，方法名是被指定的类中的方法，这两个字段的格式是由HotSpot中的“-XX:+PrintComplation”选项确定的。 3 Jmap命令jmap的用途是为了展示java进程的内存映射信息，或者堆内存详情。一般使用jps命令，jps用来查看基于HotSpot的JVM里面中，所有具有访问权限的Java进程的具体状态，包括进程id，进程启动的路径及启动参数等等，与unix上的ps类似，只不过jps是用来显示Java进程，可以把JPS理解为ps的一个子集。使用jps时，如果没有指定hostid，它只会显示本地环境中所有的Java进程；如果指定了hostid，它就会显示指定hostid上面的java进程，不过这需要远程服务上开启了jstatd服务，可以参看前面的jstatd章节来启动jstad服务。jmap常用的参数如下。 histo展示class的内存情况，展示的信息为编号，实例数，字节，类名（存活的对象）。 命令jmap -histo pid 注意JVM会先触发gc，然后再统计信息。 heap展示pid的整体堆信息。根据jps命令，获取JMAP类的执行进程。 命令jmap -heap pid执行jmap命令：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051C:\\Users\\Administrator&gt;jmap -heap 3400Attaching to process ID 3400, please wait...Debugger attached successfully.Server compiler detected.JVM version is 24.76-b04using thread-local object allocation.Parallel GC with 4 thread(s) //GC线程Heap Configuration: //堆内存初始化配置 MinHeapFreeRatio = 0 //设置JVM堆最小空闲比率 MaxHeapFreeRatio = 100 //设置JVM堆最大空闲比率 MaxHeapSize = 2122317824 (2024.0MB) //-XX:MaxHeapSize=设置JVM堆的最大大小 NewSize = 1310720 (1.25MB) //-XX:NewSize=设置JVM堆的‘年轻代’的默认大小 MaxNewSize = 17592186044415 MB //-XX:MaxNewSize=设置JVM堆的‘年轻代’的最大大小 OldSize = 5439488 (5.1875MB) //-XX:OldSize=设置JVM堆的‘老年代’的大小 NewRatio = 2 //-XX:NewRatio=:‘年轻代’和‘老年代’的大小比率 SurvivorRatio = 8 //-XX:SurvivorRatio=设置年轻代中Eden区与Survivor区的大小比值 PermSize = 21757952 (20.75MB) //-XX:PermSize=&lt;value&gt;:设置JVM堆的‘永生代’的初始大小 MaxPermSize = 85983232 (82.0MB) //-XX:MaxPermSize=&lt;value&gt;:设置JVM堆的‘永生代’的最大大小 G1HeapRegionSize = 0 (0.0MB)Heap Usage:PS Young GenerationEden Space: //Eden区 capacity = 34078720 (32.5MB) used = 31388544 (29.9344482421875MB) free = 2690176 (2.5655517578125MB) 92.10599459134616% usedFrom Space: //一个Survivor区的内存分布 capacity = 5242880 (5.0MB) used = 565280 (0.539093017578125MB) free = 4677600 (4.460906982421875MB) 10.7818603515625% usedTo Space: //另一个Survivor区的内存分布 capacity = 5242880 (5.0MB) used = 0 (0.0MB) free = 5242880 (5.0MB) 0.0% usedPS Old Generation //当前的老年代区内存分布 capacity = 88080384 (84.0MB) used = 8192 (0.0078125MB) free = 88072192 (83.9921875MB) 0.009300595238095238% usedPS Perm Generation //当前的方法区内存分布 capacity = 22020096 (21.0MB) used = 2648384 (2.52569580078125MB) free = 19371712 (18.47430419921875MB) 12.027122860863095% used1541 interned Strings occupying 141688 bytes. dump导出的文件可以供分析用，比如jhat或者mat，以便查找内存溢出原因。 命令jmap -dump:live,format=b,file=m.bin pid 注意JVM会将整个heap的信息dump写入到一个文件，heap如果比较大的话，就会导致这个过程比较耗时，并且执行的过程中为了保证dump的信息是可靠的，所以会暂停应用。 permstat打印（方法区）永久代中classloader的相关信息。 命令jmap -permstat pid 注意JVM会去统计perm区的状况，这整个过程也会比较的耗时，并且同样也会暂停应用。 4 内存分析工具（Memory Analyzer Tool，MAT）修改参数配置MAT软件版本解压后目录内有个MemoryAnalyzer.ini文件，该文件里面有个Xmx参数，该参数表示最大内存占用量，默认为1024m，根据堆转储文件大小修改该参数即可。 MemoryAnalyzer.ini中的参数一般默认为-vmargs– Xmx1024m，这就够用了。假如你机器的内存不大，改大该参数的值，会导致MemoryAnalyzer启动时，报错:Failed to create the Java Virtual Machine。 当你导出的dump文件的大小大于你配置的1024m（说明1中，提到的配置：-vmargs– Xmx1024m），MAT输出分析报告的时候，会报错：An internal error occurred during: &quot;Parsing heap dump from XXX”。适当调大说明1中的参数即可。 分析文件在实际操作过程中采用的是jmap获取堆转储文件，然后导入到本地，然后MAT软件加载。加载后首页如下图，在首页上比较有用的是Histogram和Leak Suspects。 Histogram可以列出内存中的对象，对象的个数以及大小。 Dominator Tree可以列出那个线程，以及线程下面的那些对象占用的空间。 Top consumers通过图形列出最大的object。 Leak Suspects通过MA自动分析泄漏的原因。 点击Leak Suspects会在堆转储文件同目录内生成一个Leak Suspects.zip文件，同时也会从首页跳转到Leak Suspects页面。解压该文件后可以通过浏览器打开分析结果。 在Leak Suspects页面会给出可能的内存泄露，如上图所示有三个可能的内存泄露，但是只有第一个是我程序里的，另外两个是jar包或jdk里面的，这个可以不用管。点击Details进入详情页面。在详情页面Shortest Paths To the Accumulation Point表示GC root到内存消耗聚集点的最短路径，如果某个内存消耗聚集点有路径到达GC root，则该内存消耗聚集点不会被当做垃圾被回收。在All Accumulated Objects by Class列举了该对象所存储的所有内容。假如发现对象有可能会溢出，然后我们打开OQL窗口执行如下OQL语句也就是说这个是null，但是仍然有强引用存在，GC的时候是不能回收的，这样就会出现内存的溢出问题。为了找到内存泄露，我获取了两个堆转储文件，两个文件获取时间间隔是一天（因为内存只是小幅度增长，短时间很难发现问题）。对比两个文件的对象，通过对比后的结果可以很方便定位内存泄露。MAT同时打开两个堆转储文件，分别打开Histogram，如下图。在下图中方框1按钮用于对比两个Histogram，对比后在方框2处选择Group By package，然后对比各对象的变化。不难发现heap3.hprof比heap6.hprof少了64个eventInfo对象，如果对代码比较熟悉的话想必这样一个结果是能够给程序员一定的启示的。而我也是根据这个启示差找到了最终内存泄露的位置。","link":"/JDK7-Self-Tool/"},{"title":"JDK1.6 ScheduledThreadPoolExecutor","text":"1 介绍 优点 2 源码分析 ScheduledExecutorService() ScheduledThreadPoolExecutor#属性 ScheduledThreadPoolExecutor() ScheduledThreadPoolExecutor#DelayedWorkQueue() ScheduledThreadPoolExecutor#schedule() ScheduledThreadPoolExecutor#triggerTime() ScheduledThreadPoolExecutor#overflowFree() ScheduledThreadPoolExecutor#decorateTask() ScheduledThreadPoolExecutor#ScheduledFutureTask RunnableScheduledFuture ScheduledThreadPoolExecutor#ScheduledFutureTask#getDelay() ScheduledThreadPoolExecutor#ScheduledFutureTask#compareTo() ScheduledThreadPoolExecutor#getQueue() ScheduledThreadPoolExecutor#delayedExecute() ScheduledThreadPoolExecutor#ScheduledFutureTask#delayedExecute() ScheduledThreadPoolExecutor#ScheduledFutureTask#run() ScheduledThreadPoolExecutor#ScheduledFutureTask#runPeriodic() ScheduledThreadPoolExecutor#scheduleAtFixedRate() ScheduledThreadPoolExecutor#scheduleWithFixedDelay() ScheduledThreadPoolExecutor#setContinueExistingPeriodicTasksAfterShutdownPolicy() ScheduledThreadPoolExecutor#setExecuteExistingDelayedTasksAfterShutdownPolicy() ScheduledThreadPoolExecutor#shutdown() ScheduledThreadPoolExecutor#cancelUnwantedTasks() 4 总结 1 介绍ScheduledThreadPoolExecutor是一种类似Timer的定时器或者说是调度器。 优点 多线程的定时调度，timer是单线程的，每个timer实例只有一个工作线程。 由于继承自ThreadPoolExecutor，更具有灵活性和伸缩性。 没有timer那种线程泄露问题，timer调度的任务如果异常终止，那么整个timer都会被取消，无法执行其他任务。 2 源码分析ScheduledExecutorService()123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117/** * An {@link ExecutorService} that can schedule commands to run after a given * delay, or to execute periodically. * * &lt;p&gt; The &lt;tt&gt;schedule&lt;/tt&gt; methods create tasks with various delays * and return a task object that can be used to cancel or check * execution. The &lt;tt&gt;scheduleAtFixedRate&lt;/tt&gt; and * &lt;tt&gt;scheduleWithFixedDelay&lt;/tt&gt; methods create and execute tasks * that run periodically until cancelled. * * &lt;p&gt; Commands submitted using the {@link Executor#execute} and * {@link ExecutorService} &lt;tt&gt;submit&lt;/tt&gt; methods are scheduled with * a requested delay of zero. Zero and negative delays (but not * periods) are also allowed in &lt;tt&gt;schedule&lt;/tt&gt; methods, and are * treated as requests for immediate execution. * * ..... * * @since 1.5 * @author Doug Lea */public interface ScheduledExecutorService extends ExecutorService { /** * Creates and executes a one-shot action that becomes enabled * after the given delay. * * @param command the task to execute * @param delay the time from now to delay execution * @param unit the time unit of the delay parameter * @return a ScheduledFuture representing pending completion of * the task and whose &lt;tt&gt;get()&lt;/tt&gt; method will return * &lt;tt&gt;null&lt;/tt&gt; upon completion * @throws RejectedExecutionException if the task cannot be * scheduled for execution * @throws NullPointerException if command is null */ // 1 public ScheduledFuture&lt;?&gt; schedule(Runnable command, long delay, TimeUnit unit); /** * Creates and executes a ScheduledFuture that becomes enabled after the * given delay. * * @param callable the function to execute * @param delay the time from now to delay execution * @param unit the time unit of the delay parameter * @return a ScheduledFuture that can be used to extract result or cancel * @throws RejectedExecutionException if the task cannot be * scheduled for execution * @throws NullPointerException if callable is null */ // 2 public &lt;V&gt; ScheduledFuture&lt;V&gt; schedule(Callable&lt;V&gt; callable, long delay, TimeUnit unit); /** * Creates and executes a periodic action that becomes enabled first * after the given initial delay, and subsequently with the given * period; that is executions will commence after * &lt;tt&gt;initialDelay&lt;/tt&gt; then &lt;tt&gt;initialDelay+period&lt;/tt&gt;, then * &lt;tt&gt;initialDelay + 2 * period&lt;/tt&gt;, and so on. * If any execution of the task * encounters an exception, subsequent executions are suppressed. * Otherwise, the task will only terminate via cancellation or * termination of the executor. If any execution of this task * takes longer than its period, then subsequent executions * may start late, but will not concurrently execute. * * @param command the task to execute * @param initialDelay the time to delay first execution * @param period the period between successive executions * @param unit the time unit of the initialDelay and period parameters * @return a ScheduledFuture representing pending completion of * the task, and whose &lt;tt&gt;get()&lt;/tt&gt; method will throw an * exception upon cancellation * @throws RejectedExecutionException if the task cannot be * scheduled for execution * @throws NullPointerException if command is null * @throws IllegalArgumentException if period less than or equal to zero */ // 3 public ScheduledFuture&lt;?&gt; scheduleAtFixedRate(Runnable command, long initialDelay, long period, TimeUnit unit); /** * Creates and executes a periodic action that becomes enabled first * after the given initial delay, and subsequently with the * given delay between the termination of one execution and the * commencement of the next. If any execution of the task * encounters an exception, subsequent executions are suppressed. * Otherwise, the task will only terminate via cancellation or * termination of the executor. * * @param command the task to execute * @param initialDelay the time to delay first execution * @param delay the delay between the termination of one * execution and the commencement of the next * @param unit the time unit of the initialDelay and delay parameters * @return a ScheduledFuture representing pending completion of * the task, and whose &lt;tt&gt;get()&lt;/tt&gt; method will throw an * exception upon cancellation * @throws RejectedExecutionException if the task cannot be * scheduled for execution * @throws NullPointerException if command is null * @throws IllegalArgumentException if delay less than or equal to zero */ // 4 public ScheduledFuture&lt;?&gt; scheduleWithFixedDelay(Runnable command, long initialDelay, long delay, TimeUnit unit);} 标注代码分析 创建并执行一个一次性任务，这个任务过了延迟时间就会被执行。 同上。Runnable变成callable。 创建并执行一个周期性任务，当任务过了给定的初始延迟时间，会第一次被执行，然后会以给定的周期时间执行。如果某次执行过程中发生异常，那么任务就停止了(不会执行下一次任务了)。如果某次执行时长超过了周期时间，那么下一次任务会延迟启动，不会和当前任务并行执行。 创建并执行一个周期性任务，当任务过了给定的初始延迟时间，会第一次被执行，接下来的任务会在上次任务执行完毕后，延迟给定的时间，然后再继续执行。如果某次执行过程中发生了异常，那么任务就停止了(不会执行下一次任务了)。 ScheduledThreadPoolExecutor#属性1234567891011121314151617181920212223242526public class ScheduledThreadPoolExecutor extends ThreadPoolExecutor implements ScheduledExecutorService { /** * False if should cancel/suppress periodic tasks on shutdown. */ // 1 private volatile boolean continueExistingPeriodicTasksAfterShutdown; /** * False if should cancel non-periodic tasks on shutdown. */ // 2 private volatile boolean executeExistingDelayedTasksAfterShutdown = true; /** * Sequence number to break scheduling ties, and in turn to * guarantee FIFO order among tied entries. */ // 3 private static final AtomicLong sequencer = new AtomicLong(0); /** Base of nanosecond timings, to avoid wrapping */ private static final long NANO_ORIGIN = System.nanoTime(); .... 标注代码分析 是否应该在关闭时取消或者终止周期性任务。 是否应该在关闭时取消非周期性任务。 在并列调度(延迟值一样)的情况下保证先入先出的关系。 ScheduledThreadPoolExecutor()123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566/** * Creates a new ScheduledThreadPoolExecutor with the given core * pool size. * * @param corePoolSize the number of threads to keep in the pool, * even if they are idle * @throws IllegalArgumentException if &lt;tt&gt;corePoolSize &amp;lt; 0&lt;/tt&gt; */ public ScheduledThreadPoolExecutor(int corePoolSize) { super(corePoolSize, Integer.MAX_VALUE, 0, TimeUnit.NANOSECONDS, new DelayedWorkQueue()); } /** * Creates a new ScheduledThreadPoolExecutor with the given * initial parameters. * * @param corePoolSize the number of threads to keep in the pool, * even if they are idle * @param threadFactory the factory to use when the executor * creates a new thread * @throws IllegalArgumentException if &lt;tt&gt;corePoolSize &amp;lt; 0&lt;/tt&gt; * @throws NullPointerException if threadFactory is null */ public ScheduledThreadPoolExecutor(int corePoolSize, ThreadFactory threadFactory) { super(corePoolSize, Integer.MAX_VALUE, 0, TimeUnit.NANOSECONDS, new DelayedWorkQueue(), threadFactory); } /** * Creates a new ScheduledThreadPoolExecutor with the given * initial parameters. * * @param corePoolSize the number of threads to keep in the pool, * even if they are idle * @param handler the handler to use when execution is blocked * because the thread bounds and queue capacities are reached * @throws IllegalArgumentException if &lt;tt&gt;corePoolSize &amp;lt; 0&lt;/tt&gt; * @throws NullPointerException if handler is null */ public ScheduledThreadPoolExecutor(int corePoolSize, RejectedExecutionHandler handler) { super(corePoolSize, Integer.MAX_VALUE, 0, TimeUnit.NANOSECONDS, new DelayedWorkQueue(), handler); } /** * Creates a new ScheduledThreadPoolExecutor with the given * initial parameters. * * @param corePoolSize the number of threads to keep in the pool, * even if they are idle * @param threadFactory the factory to use when the executor * creates a new thread * @param handler the handler to use when execution is blocked * because the thread bounds and queue capacities are reached. * @throws IllegalArgumentException if &lt;tt&gt;corePoolSize &amp;lt; 0&lt;/tt&gt; * @throws NullPointerException if threadFactory or handler is null */ public ScheduledThreadPoolExecutor(int corePoolSize, ThreadFactory threadFactory, RejectedExecutionHandler handler) { super(corePoolSize, Integer.MAX_VALUE, 0, TimeUnit.NANOSECONDS, new DelayedWorkQueue(), threadFactory, handler); } 从构造方法可以看出，ScheduledThreadPoolExecutor内部固定使用DelayedWorkQueue做为任务队列。 ScheduledThreadPoolExecutor#DelayedWorkQueue()1234567891011121314151617181920212223242526272829/** * An annoying wrapper class to convince javac to use a * DelayQueue&lt;RunnableScheduledFuture&gt; as a BlockingQueue&lt;Runnable&gt; */ private static class DelayedWorkQueue extends AbstractCollection&lt;Runnable&gt; implements BlockingQueue&lt;Runnable&gt; { private final DelayQueue&lt;RunnableScheduledFuture&gt; dq = new DelayQueue&lt;RunnableScheduledFuture&gt;(); public Runnable poll() { return dq.poll(); } public Runnable peek() { return dq.peek(); } public Runnable take() throws InterruptedException { return dq.take(); } public Runnable poll(long timeout, TimeUnit unit) throws InterruptedException { return dq.poll(timeout, unit); } public boolean add(Runnable x) { return dq.add((RunnableScheduledFuture)x);} public boolean offer(Runnable x) { return dq.offer((RunnableScheduledFuture)x);} public void put(Runnable x) { dq.put((RunnableScheduledFuture)x); } public boolean offer(Runnable x, long timeout, TimeUnit unit) { return dq.offer((RunnableScheduledFuture)x, timeout, unit); } .... DelayedWorkQueue内部就是一个DelayQueue，所有方法都由内部的DelayQueue来代理实现，唯一要注意的是进入队列的任务必须是RunnableScheduledFuture。再回头看ScheduledThreadPoolExecutor，因为延迟队列是无界的，所以最大线程数量也就没意义了。（ScheduledThreadPoolExecutor的最大线程数量是Integer.MAX_VALUE） ScheduledThreadPoolExecutor#schedule()1234567891011121314151617181920212223242526public ScheduledFuture&lt;?&gt; schedule(Runnable command, long delay, TimeUnit unit) { if (command == null || unit == null) throw new NullPointerException(); // 1 RunnableScheduledFuture&lt;?&gt; t = decorateTask(command, new ScheduledFutureTask&lt;Void&gt;(command, null, triggerTime(delay, unit))); // 2 delayedExecute(t); return t; } public &lt;V&gt; ScheduledFuture&lt;V&gt; schedule(Callable&lt;V&gt; callable, long delay, TimeUnit unit) { if (callable == null || unit == null) throw new NullPointerException(); RunnableScheduledFuture&lt;V&gt; t = decorateTask(callable, new ScheduledFutureTask&lt;V&gt;(callable, triggerTime(delay, unit))); delayedExecute(t); return t; } 标注代码分析 将任务包装成一个RunnableScheduledFuture。 然后延迟执行这个RunnableScheduledFuture。 ScheduledThreadPoolExecutor#triggerTime()12345678910111213141516/** * Returns the trigger time of a delayed action. */ // 1 private long triggerTime(long delay, TimeUnit unit) { return triggerTime(unit.toNanos((delay &lt; 0) ? 0 : delay)); } /** * Returns the trigger time of a delayed action. */ long triggerTime(long delay) { // 2 return now() + ((delay &lt; (Long.MAX_VALUE &gt;&gt; 1)) ? delay : overflowFree(delay)); } 标注代码分析 返回一个延迟动作的触发时间。 如果当前delay很大的话，要调用overflowFree来防止溢出。 ScheduledThreadPoolExecutor#overflowFree()12345678910111213141516/** * Constrains the values of all delays in the queue to be within * Long.MAX_VALUE of each other, to avoid overflow in compareTo. * This may occur if a task is eligible to be dequeued, but has * not yet been, while some other task is added with a delay of * Long.MAX_VALUE. */private long overflowFree(long delay) { Delayed head = (Delayed) super.getQueue().peek(); if (head != null) { long headDelay = head.getDelay(TimeUnit.NANOSECONDS); if (headDelay &lt; 0 &amp;&amp; (delay - headDelay &lt; 0)) delay = Long.MAX_VALUE + headDelay; } return delay;} 将队列中所有元素的延迟值彼此的和控制在Long.MAX_VALUE以内，避免在互相比较时溢出。这种情况是可能发生的，比如一个满足条件的任务即将出队，这时来一个延迟值是Long.MAX_VALUE的任务。 ScheduledThreadPoolExecutor#decorateTask()12345678910111213141516171819202122232425262728293031/** * Modifies or replaces the task used to execute a runnable. * This method can be used to override the concrete * class used for managing internal tasks. * The default implementation simply returns the given task. * * @param runnable the submitted Runnable * @param task the task created to execute the runnable * @return a task that can execute the runnable * @since 1.6 */ protected &lt;V&gt; RunnableScheduledFuture&lt;V&gt; decorateTask( Runnable runnable, RunnableScheduledFuture&lt;V&gt; task) { return task; } /** * Modifies or replaces the task used to execute a callable. * This method can be used to override the concrete * class used for managing internal tasks. * The default implementation simply returns the given task. * * @param callable the submitted Callable * @param task the task created to execute the callable * @return a task that can execute the callable * @since 1.6 */ protected &lt;V&gt; RunnableScheduledFuture&lt;V&gt; decorateTask( Callable&lt;V&gt; callable, RunnableScheduledFuture&lt;V&gt; task) { return task; } 两个方法只是简单的实现，可作为钩子方法由子类实现。 ScheduledThreadPoolExecutor#ScheduledFutureTask123456789101112131415161718192021222324252627282930313233343536373839404142434445464748private class ScheduledFutureTask&lt;V&gt; extends FutureTask&lt;V&gt; implements RunnableScheduledFuture&lt;V&gt; { /** Sequence number to break ties FIFO */ // 1 private final long sequenceNumber; /** The time the task is enabled to execute in nanoTime units */ // 2 private long time; /** * Period in nanoseconds for repeating tasks. A positive * value indicates fixed-rate execution. A negative value * indicates fixed-delay execution. A value of 0 indicates a * non-repeating task. */ // 3 private final long period; /** * Creates a one-shot action with given nanoTime-based trigger time. */ ScheduledFutureTask(Runnable r, V result, long ns) { super(r, result); this.time = ns; this.period = 0; this.sequenceNumber = sequencer.getAndIncrement(); } /** * Creates a periodic action with given nano time and period. */ ScheduledFutureTask(Runnable r, V result, long ns, long period) { super(r, result); this.time = ns; this.period = period; this.sequenceNumber = sequencer.getAndIncrement(); } /** * Creates a one-shot action with given nanoTime-based trigger. */ ScheduledFutureTask(Callable&lt;V&gt; callable, long ns) { super(callable); this.time = ns; this.period = 0; this.sequenceNumber = sequencer.getAndIncrement(); } .... ScheduledFutureTask实现RunnableScheduledFuture。标注代码分析 任务序列号 任务可以执行的时间，单位纳秒 周期性任务的周期时间，单位纳秒。正数表示固定频率执行，负数表示固定延迟执行，0表示一次性任务。 RunnableScheduledFuture12345678910111213141516171819202122/** * A {@link ScheduledFuture} that is {@link Runnable}. Successful * execution of the &lt;tt&gt;run&lt;/tt&gt; method causes completion of the * &lt;tt&gt;Future&lt;/tt&gt; and allows access to its results. * @see FutureTask * @see Executor * @since 1.6 * @author Doug Lea * @param &lt;V&gt; The result type returned by this Future's &lt;tt&gt;get&lt;/tt&gt; method */public interface RunnableScheduledFuture&lt;V&gt; extends RunnableFuture&lt;V&gt;, ScheduledFuture&lt;V&gt; { /** * Returns true if this is a periodic task. A periodic task may * re-run according to some schedule. A non-periodic task can be * run only once. * * @return true if this task is periodic */ // 1 boolean isPeriodic();} 标注代码分析 是否为周期性任务。 ScheduledThreadPoolExecutor#ScheduledFutureTask#getDelay()1234// 1public long getDelay(TimeUnit unit) { return unit.convert(time - now(), TimeUnit.NANOSECONDS); } 标注代码分析 延迟值都是按照纳秒时间单位来算的。这里减去了now()，还记得之前算触发时间时候加上now()。ScheduledThreadPoolExecutor#ScheduledFutureTask#compareTo()1234567891011121314151617181920public int compareTo(Delayed other) { if (other == this) // compare zero ONLY if same object return 0; if (other instanceof ScheduledFutureTask) { ScheduledFutureTask&lt;?&gt; x = (ScheduledFutureTask&lt;?&gt;)other; long diff = time - x.time; if (diff &lt; 0) return -1; else if (diff &gt; 0) return 1; else if (sequenceNumber &lt; x.sequenceNumber)// 1 return -1; else return 1; } // 2 long d = (getDelay(TimeUnit.NANOSECONDS) - other.getDelay(TimeUnit.NANOSECONDS)); return (d == 0)? 0 : ((d &lt; 0)? -1 : 1); } 标注代码分析 如果触发时间相等，那么比较序列号，从而保证顺序。 如果要比较的对象不是ScheduledFutureTask，那么按照延迟值进行比较。 ScheduledThreadPoolExecutor#getQueue()1234567891011121314/** * Returns the task queue used by this executor. Each element of * this queue is a {@link ScheduledFuture}, including those * tasks submitted using &lt;tt&gt;execute&lt;/tt&gt; which are for scheduling * purposes used as the basis of a zero-delay * &lt;tt&gt;ScheduledFuture&lt;/tt&gt;. Iteration over this queue is * &lt;em&gt;not&lt;/em&gt; guaranteed to traverse tasks in the order in * which they will execute. * * @return the task queue */ public BlockingQueue&lt;Runnable&gt; getQueue() { return super.getQueue(); } 通过getDelay()实现延迟计算。overflowFree()通过Delayed head = (Delayed) super.getQueue().peek();获取延迟对象。getQueue()新增是runnable对象。 ScheduledThreadPoolExecutor#delayedExecute()123456789101112131415161718/** * Specialized variant of ThreadPoolExecutor.execute for delayed tasks. */ private void delayedExecute(Runnable command) { if (isShutdown()) { // 1 reject(command); return; } // Prestart a thread if necessary. We cannot prestart it // running the task because the task (probably) shouldn't be // run yet, so thread will just idle until delay elapses. // 2 if (getPoolSize() &lt; getCorePoolSize()) prestartCoreThread(); // 3 super.getQueue().add(command); } 标注代码分析 如果当前ScheduledThreadPoolExecutor已关闭，拒绝任务。 如果当前线程数量小于核心线程数量，那么预启动一个核心线程。 将任务加入任务队列。 ScheduledThreadPoolExecutor#ScheduledFutureTask#delayedExecute()12345678910111213141516171819202122/** * Runs a periodic task. */private void runPeriodic() { boolean ok = ScheduledFutureTask.super.runAndReset(); boolean down = isShutdown(); // Reschedule if not cancelled and not shutdown or policy allows if (ok &amp;&amp; (!down || (getContinueExistingPeriodicTasksAfterShutdownPolicy() &amp;&amp; !isStopped()))) { long p = period; if (p &gt; 0) time += p; else time = triggerTime(-p); ScheduledThreadPoolExecutor.super.getQueue().add(this); } // This might have been the final executed delayed // task. Wake up threads to check. else if (down) interruptIdleWorkers();} 由ScheduledThreadPoolExecutor#delayedExecute()、ScheduledThreadPoolExecutor#delayedExecute()可以知道，getQueue()队列里添加的是ScheduledFutureTask对象。根据ScheduledFutureTask实现RunnableScheduledFuture,RunnableScheduledFuture继承ScheduledFuture，ScheduledFuture继承Delayed(延迟)，我们知道ScheduledThreadPoolExecutor内部使用延迟队列。如下图。 ScheduledThreadPoolExecutor#ScheduledFutureTask#run()123456789101112/** * Overrides FutureTask version so as to reset/requeue if periodic. */public void run() { // 1 if (isPeriodic()) // 2 runPeriodic(); else // 3 ScheduledFutureTask.super.run();} 标注代码分析 判断下当前任务是否为周期任务。 如果是周期任务，按照周期任务方式运行。 一次性任务的话，就直接执行run方法。 ScheduledThreadPoolExecutor#ScheduledFutureTask#runPeriodic()123456789101112131415161718192021222324252627282930/** * Runs a periodic task. */ private void runPeriodic() { // 1 boolean ok = ScheduledFutureTask.super.runAndReset(); // 2 boolean down = isShutdown(); // Reschedule if not cancelled and not shutdown or policy allows // 3 if (ok &amp;&amp; (!down || (getContinueExistingPeriodicTasksAfterShutdownPolicy() &amp;&amp; !isStopped()))) { // 4 long p = period; if (p &gt; 0) // 5 time += p; else // 6 time = triggerTime(-p); // 7 ScheduledThreadPoolExecutor.super.getQueue().add(this); } // This might have been the final executed delayed // task. Wake up threads to check. // 8 else if (down) interruptIdleWorkers(); } 标注代码分析 这里执行任务并重置异步任务。 判断当前ScheduledThreadPoolExecutor是否关闭。 如果任务执行成功，并且ScheduledThreadPoolExecutor没有关闭或者策略允许关闭后继续执行周期任务，并且ScheduledThreadPoolExecutor没有停止，那么重新调度任务。 重新计算下次触发时间。 如果是固定频率，在原有触发时间上加上周期时间。 如果是固定延迟，直接指定延迟后的触发时间。 算好下次触发时间后，再将任务本身重新加入任务队列。 这可能是最后执行的延迟任务。执行完毕后，如果当前ScheduledThreadPoolExecutor已关闭，那么中断空闲的工作线程。 ScheduledThreadPoolExecutor#scheduleAtFixedRate()12345678910111213141516public ScheduledFuture&lt;?&gt; scheduleAtFixedRate(Runnable command, long initialDelay, long period, TimeUnit unit) { if (command == null || unit == null) throw new NullPointerException(); if (period &lt;= 0) throw new IllegalArgumentException(); RunnableScheduledFuture&lt;?&gt; t = decorateTask(command, new ScheduledFutureTask&lt;Object&gt;(command, null, triggerTime(initialDelay, unit), unit.toNanos(period))); delayedExecute(t); return t; } ScheduledThreadPoolExecutor#scheduleWithFixedDelay()12345678910111213141516public ScheduledFuture&lt;?&gt; scheduleWithFixedDelay(Runnable command, long initialDelay, long delay, TimeUnit unit) { if (command == null || unit == null) throw new NullPointerException(); if (delay &lt;= 0) throw new IllegalArgumentException(); RunnableScheduledFuture&lt;?&gt; t = decorateTask(command, new ScheduledFutureTask&lt;Boolean&gt;(command, null, triggerTime(initialDelay, unit), unit.toNanos(-delay))); delayedExecute(t); return t;} 通过包装ScheduledFutureTask对象生成RunnableScheduledFuture对象。然后再执行任务。2个方法区别在第4个参数。unit.toNanos(-delay)和TimeUnit unit。负数表示固定延迟周期性任务。 ScheduledThreadPoolExecutor#setContinueExistingPeriodicTasksAfterShutdownPolicy()12345678910111213141516/** * Sets the policy on whether to continue executing existing periodic * tasks even when this executor has been &lt;tt&gt;shutdown&lt;/tt&gt;. In * this case, these tasks will only terminate upon * &lt;tt&gt;shutdownNow&lt;/tt&gt;, or after setting the policy to * &lt;tt&gt;false&lt;/tt&gt; when already shutdown. This value is by default * false. * * @param value if true, continue after shutdown, else don't. * @see #getContinueExistingPeriodicTasksAfterShutdownPolicy */ public void setContinueExistingPeriodicTasksAfterShutdownPolicy(boolean value) { continueExistingPeriodicTasksAfterShutdown = value; if (!value &amp;&amp; isShutdown()) cancelUnwantedTasks(); } ScheduledThreadPoolExecutor#setExecuteExistingDelayedTasksAfterShutdownPolicy()12345678910111213141516/** * Sets the policy on whether to execute existing delayed * tasks even when this executor has been &lt;tt&gt;shutdown&lt;/tt&gt;. In * this case, these tasks will only terminate upon * &lt;tt&gt;shutdownNow&lt;/tt&gt;, or after setting the policy to * &lt;tt&gt;false&lt;/tt&gt; when already shutdown. This value is by default * true. * * @param value if true, execute after shutdown, else don't. * @see #getExecuteExistingDelayedTasksAfterShutdownPolicy */ public void setExecuteExistingDelayedTasksAfterShutdownPolicy(boolean value) { executeExistingDelayedTasksAfterShutdown = value; if (!value &amp;&amp; isShutdown()) cancelUnwantedTasks(); } ScheduledThreadPoolExecutor#shutdown()1234567891011121314/** * Initiates an orderly shutdown in which previously submitted * tasks are executed, but no new tasks will be accepted. If the * &lt;tt&gt;ExecuteExistingDelayedTasksAfterShutdownPolicy&lt;/tt&gt; has * been set &lt;tt&gt;false&lt;/tt&gt;, existing delayed tasks whose delays * have not yet elapsed are cancelled. And unless the * &lt;tt&gt;ContinueExistingPeriodicTasksAfterShutdownPolicy&lt;/tt&gt; has * been set &lt;tt&gt;true&lt;/tt&gt;, future executions of existing periodic * tasks will be cancelled. */public void shutdown() { cancelUnwantedTasks(); super.shutdown();} ScheduledThreadPoolExecutor#cancelUnwantedTasks()12345678910111213141516171819202122232425262728/** * Cancels and clears the queue of all tasks that should not be run * due to shutdown policy. */ private void cancelUnwantedTasks() { // 1 boolean keepDelayed = getExecuteExistingDelayedTasksAfterShutdownPolicy(); // 2 boolean keepPeriodic = getContinueExistingPeriodicTasksAfterShutdownPolicy(); if (!keepDelayed &amp;&amp; !keepPeriodic) // 3 super.getQueue().clear(); else if (keepDelayed || keepPeriodic) { // 4 Object[] entries = super.getQueue().toArray(); for (int i = 0; i &lt; entries.length; ++i) { Object e = entries[i]; if (e instanceof RunnableScheduledFuture) { RunnableScheduledFuture&lt;?&gt; t = (RunnableScheduledFuture&lt;?&gt;)e; if (t.isPeriodic()? !keepPeriodic : !keepDelayed) t.cancel(false); } } entries = null; // 5 purge(); } } 标注代码分析 关闭后是否继续执行延迟的任务。 关闭后是否继续执行周期性的任务。 如果都不继续，那么直接清空任务队列。 否则会按照相应的策略来取消相应类型的任务。 最后清理一把任务队列里面被取消的任务。 可以看到在设置关闭后任务处理策略和关闭当前ScheduledThreadPoolExecutor时，都会(按需)调用一下cancelUnwantedTasks方法来清理不需要的任务。 4 总结 ScheduledFutureTask表示可调度的异步任务，提交到ScheduledThreadPoolExecutor的任务都会被包装成这个类。 ScheduledThreadPoolExecutor调度任务时会按照延迟时间来，延迟时间最先到期的任务会被首先调度，如果两个任务延迟时间相同，那么还有内部序列号来保证先入先出的顺序。 ScheduledFutureTask被调度后，具体执行时，会判断自己是否是周期性任务。如果不是，任务执行一次；如果时，先执行任务，执行成功后，会算出下次触发事件(延迟时间)，然后被再次放入ScheduledThreadPoolExecutor的任务队列中，等待下次被调度执行。","link":"/JDK1.6-ScheduledThreadPoolExecutor/"},{"title":"JDK1.6 SynchronousQueue","text":"1 介绍 2 源码分析 SynchronousQueue#Transferer SynchronousQueue#TransferStack 伪栈实现 SynchronousQueue#TransferStack#transfer() SynchronousQueue#TransferStack#snode() SynchronousQueue#TransferStack#awaitFulfill() SynchronousQueue#TransferStack#shouldSpin() SynchronousQueue自选参数 SynchronousQueue#TransferStack#clean() SynchronousQueue#TransferQueue 伪队列 SynchronousQueue#TransferQueue#transfer() SynchronousQueue#TransferQueue#advanceHead() SynchronousQueue#TransferQueue#advanceTail() SynchronousQueue#TransferQueue#awaitFulfill() SynchronousQueue#TransferQueue#clean() SynchronousQueue SynchronousQueue 序列化 总结 1 介绍 SynchronousQueue是一种特殊的阻塞队列，它本身没有容量，只有当一个线程从队列取数据的同时，另一个线程才能放一个数据到队列中，反之亦然。存取过程相当于一个线程把数据(安全的)交给另一个线程的过程。 SynchronousQueue也支持公平和非公平模式。 2 源码分析SynchronousQueue内部采用伪栈和伪队列来实现，分别对应非公平模式和公平模式。 SynchronousQueue#Transferer123456789101112131415161718192021/** * Shared internal API for dual stacks and queues. */// 1static abstract class Transferer { /** * Performs a put or take. * * @param e if non-null, the item to be handed to a consumer; * if null, requests that transfer return an item * offered by producer. // 2 * @param timed if this operation should timeout * @param nanos the timeout, in nanoseconds * @return if non-null, the item provided or received; if null, * the operation failed due to timeout or interrupt -- * the caller can distinguish which of these occurred * by checking Thread.interrupted. */ abstract Object transfer(Object e, boolean timed, long nanos);} 伪栈和伪队列的公共基类。标注代码分析 转移数据的方法，用来实现put或者take。 如果不为null，相当于将一个数据交给消费者；如果为null，相当于从一个生产者接收一个消费者交出的数据。 SynchronousQueue#TransferStack 伪栈实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103/** Dual stack */ static final class TransferStack extends Transferer { /* * This extends Scherer-Scott dual stack algorithm, differing, * among other ways, by using \"covering\" nodes rather than * bit-marked pointers: Fulfilling operations push on marker * nodes (with FULFILLING bit set in mode) to reserve a spot * to match a waiting node. */ /* Modes for SNodes, ORed together in node fields */ /** Node represents an unfulfilled consumer */ // 1 static final int REQUEST = 0; /** Node represents an unfulfilled producer */ // 2 static final int DATA = 1; /** Node is fulfilling another unfulfilled DATA or REQUEST */ // 3 static final int FULFILLING = 2; /** Return true if m has fulfilling bit set */ // 4 static boolean isFulfilling(int m) { return (m &amp; FULFILLING) != 0; } /** Node class for TransferStacks. */ static final class SNode { // 5 volatile SNode next; // next node in stack // 6 volatile SNode match; // the node matched to this volatile Thread waiter; // to control park/unpark Object item; // data; or null for REQUESTs int mode; // Note: item and mode fields don't need to be volatile // since they are always written before, and read after, // other volatile/atomic operations. // 7 SNode(Object item) { this.item = item; } static final AtomicReferenceFieldUpdater&lt;SNode, SNode&gt; nextUpdater = AtomicReferenceFieldUpdater.newUpdater (SNode.class, SNode.class, \"next\"); boolean casNext(SNode cmp, SNode val) { return (cmp == next &amp;&amp; nextUpdater.compareAndSet(this, cmp, val)); } static final AtomicReferenceFieldUpdater&lt;SNode, SNode&gt; matchUpdater = AtomicReferenceFieldUpdater.newUpdater (SNode.class, SNode.class, \"match\"); /** * Tries to match node s to this node, if so, waking up thread. * Fulfillers call tryMatch to identify their waiters. * Waiters block until they have been matched. * * @param s the node to match * @return true if successfully matched to s */ // 8 boolean tryMatch(SNode s) { if (match == null &amp;&amp; matchUpdater.compareAndSet(this, null, s)) { // 9 Thread w = waiter; if (w != null) { // waiters need at most one unpark waiter = null; LockSupport.unpark(w); } return true; } // 10 return match == s; } /** * Tries to cancel a wait by matching node to itself. */ // 11 void tryCancel() { matchUpdater.compareAndSet(this, null, this); } boolean isCancelled() { return match == this; } } /** The head (top) of the stack */ volatile SNode head; static final AtomicReferenceFieldUpdater&lt;TransferStack, SNode&gt; headUpdater = AtomicReferenceFieldUpdater.newUpdater (TransferStack.class, SNode.class, \"head\"); boolean casHead(SNode h, SNode nh) { return h == head &amp;&amp; headUpdater.compareAndSet(this, h, nh); } .... TransferStack是伪栈实现。标注代码分析 一个没有得到数据的消费者。 一个没有交出数据的生产者。 匹配另一个生产者或者消费者。 判断是否包含正在匹配(FULFILLING)的标记。 栈中的下一个节点。 和当前节点完成匹配的节点。 item和mode不需要volatile修饰；是因为它们在其他的volatile/atomic操作之前写，之后读。（HB关系） 尝试匹配节点s和当前节点，如果匹配成功，唤醒等待线程。(向消费者传递数据或向生产者获取数据)调用tryMatch()来确定它们的等待线程，然后唤醒这个等待线程。 如果当前节点的match为空，那么CAS设置s为match，然后唤醒waiter。 如果match不为null，或者CAS设置match失败，那么比较match和s是否为相同对象。如果相同，说明已经完成匹配，匹配成功。 尝试取消当前节点(有线程等待)，通过将match设置为自身。 SynchronousQueue#TransferStack#transfer()123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105/** * Puts or takes an item. */ Object transfer(Object e, boolean timed, long nanos) { /* * Basic algorithm is to loop trying one of three actions: * * 1. If apparently empty or already containing nodes of same * mode, try to push node on stack and wait for a match, * returning it, or null if cancelled. * * 2. If apparently containing node of complementary mode, * try to push a fulfilling node on to stack, match * with corresponding waiting node, pop both from * stack, and return matched item. The matching or * unlinking might not actually be necessary because of * other threads performing action 3: * * 3. If top of stack already holds another fulfilling node, * help it out by doing its match and/or pop * operations, and then continue. The code for helping * is essentially the same as for fulfilling, except * that it doesn't return the item. */ // 1 SNode s = null; // constructed/reused as needed int mode = (e == null)? REQUEST : DATA; for (;;) { SNode h = head; // 2 if (h == null || h.mode == mode) { // empty or same-mode // 3 if (timed &amp;&amp; nanos &lt;= 0) { // can't wait if (h != null &amp;&amp; h.isCancelled()) // 4 casHead(h, h.next); // pop cancelled node else return null; } else if (casHead(h, s = snode(s, e, h, mode))) {// 5 // 6 SNode m = awaitFulfill(s, timed, nanos); // 7 if (m == s) { // wait was cancelled // 8 clean(s); return null; } // 9 if ((h = head) != null &amp;&amp; h.next == s) // 10 casHead(h, s.next); // help s's fulfiller return mode == REQUEST? m.item : s.item; } } else if (!isFulfilling(h.mode)) { // try to fulfill // 11 // 12 if (h.isCancelled()) // already cancelled // 13 casHead(h, h.next); // pop and retry else if (casHead(h, s=snode(s, e, h, FULFILLING|mode))) {// 14 for (;;) { // loop until matched or waiters disappear // 15 SNode m = s.next; // m is s's match // 16 if (m == null) { // all waiters are gone // 17 casHead(s, null); // pop fulfill node // 18 s = null; // use new node next time break; // restart main loop } // 19 SNode mn = m.next; // 20 if (m.tryMatch(s)) { // 21 casHead(s, mn); // pop both s and m return (mode == REQUEST)? m.item : s.item; } else // lost match // 22 // 23 s.casNext(m, mn); // help unlink } } } else { // 24 // help a fulfiller // 25 SNode m = h.next; // m is h's match // 26 if (m == null) // waiter is gone casHead(h, null); // pop fulfilling node else { // 27 SNode mn = m.next; // 28 if (m.tryMatch(h)) // help match // 29 casHead(h, mn); // pop both h and m else //30 // lost match // 31 h.casNext(m, mn); // help unlink } } } } 标注代码分析 基本算法是在一个无限循环中尝试下面三种情况里面的一种： 如果当前栈为空或者包含与给定节点模式相同的节点，尝试将节点压入栈内，并等待一个匹配节点，最后返回匹配节点或者null(如果被取消)。 如果当前栈包含于给定节点模式互补的节点，尝试将这个节点打上FULFILLING标记，然后压入栈中，和相应的节点进行匹配，然后将两个节点(当前节点和互补节点)弹出栈，并返回匹配节点的数据。匹配和删除动作不是必须要做的，因为其他线程会执行动作3。 如果栈顶已经存在一个FULFILLING(正在满足其他节点)的节点，帮助这个节点完成匹配和移除(出栈)的操作。然后继续执行(主循环)。这部分代码基本和动作2的代码一样，只是不会返回节点的数据。 head为null或者head和e的mode相同。 超时。 如果h不为null且被取消，弹出h。 创建一个SNode，赋给s，将原本的head节点做为其next节点，并尝试将其设置为新的head。 等待其他线程来满足当前线程。 awaitFulfill方法返回后，判断下是否被取消。 如果取消，清理一下s节点。 因为上面已经将s设置为head，如果满足这个条件说明有其他节点t插入到s前面，变成了head，而且这个t就是和s匹配的节点，他们已经完成匹配。 将s的next节点设置为head。相当于把s和t一起移除了。 如果栈中存在头节点，且和当前节点不是相同模式，那么说明它们是一对儿对等的节点，尝试用当前节点s来满足h节点。 如果h节点已经被取消。 将h节点弹出，并将h节点的next节点设置为栈的head。 尝试将当前节点打上”正在匹配”的标记，并设置为head。 s是当前节点，m是s的next节点，它们是正在匹配的两个节点。 如果m为空，可能其他节点把m匹配走了。 将s弹出。 将s置空，下轮循环的时候还会新建。 获取m的next节点，如果s和m匹配成功，mn就得补上head的位置了。 尝试匹配一下，匹配成功的话会把m上等待的线程唤醒。 如果匹配成功，把s和m弹出。 没匹配成功的话，说明m可能被其他节点满足了。 说明m已经被其他节点匹配了，那就把m移除掉。 说明栈顶的h正在匹配过程中。 m是h的配对儿，h正在和m匹配。 如果m为空，其他节点把m匹配走了。 获取m的next节点，如果m和h匹配成功，mn就得补上head的位置了。 匹配一下m和h。 匹配成功的话，把h和m弹出。 没匹配成功的话，说明m可能被其他节点满足了。 没成功的话，说明m已经被其他节点匹配了，那就把m移除掉。 SynchronousQueue#TransferStack#snode()12345678910111213/** * Creates or resets fields of a node. Called only from transfer * where the node to push on stack is lazily created and * reused when possible to help reduce intervals between reads * and CASes of head and to avoid surges of garbage when CASes * to push nodes fail due to contention. */static SNode snode(SNode s, Object e, SNode next, int mode) { if (s == null) s = new SNode(e); s.mode = mode; s.next = next; return s;} SynchronousQueue#TransferStack#awaitFulfill()1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768/** * Spins/blocks until node s is matched by a fulfill operation. * * @param s the waiting node * @param timed true if timed wait * @param nanos timeout value * @return matched node, or s if cancelled */ // 1SNode awaitFulfill(SNode s, boolean timed, long nanos) { /* * When a node/thread is about to block, it sets its waiter * field and then rechecks state at least one more time * before actually parking, thus covering race vs * fulfiller noticing that waiter is non-null so should be * woken. * * When invoked by nodes that appear at the point of call * to be at the head of the stack, calls to park are * preceded by spins to avoid blocking when producers and * consumers are arriving very close in time. This can * happen enough to bother only on multiprocessors. * * The order of checks for returning out of main loop * reflects fact that interrupts have precedence over * normal returns, which have precedence over * timeouts. (So, on timeout, one last check for match is * done before giving up.) Except that calls from untimed * SynchronousQueue.{poll/offer} don't check interrupts * and don't wait at all, so are trapped in transfer * method rather than calling awaitFulfill. */ long lastTime = (timed)? System.nanoTime() : 0; Thread w = Thread.currentThread(); SNode h = head; int spins = (shouldSpin(s)? (timed? maxTimedSpins : maxUntimedSpins) : 0); for (;;) { if (w.isInterrupted()) // 2 s.tryCancel(); SNode m = s.match; if (m != null) // 3 return m; if (timed) { long now = System.nanoTime(); nanos -= now - lastTime; lastTime = now; if (nanos &lt;= 0) { // 4 s.tryCancel(); continue; } } if (spins &gt; 0) // 5 spins = shouldSpin(s)? (spins-1) : 0; else if (s.waiter == null) // 6 s.waiter = w; // establish waiter so can park next iter else if (!timed) LockSupport.park(this); else if (nanos &gt; spinForTimeoutThreshold) // 7 LockSupport.parkNanos(this, nanos); }} 标注代码分析 自旋/阻塞直到节点被匹配。 如果当前线程被中断了，那么取消当前节点。 如果已经匹配成功，就返回匹配的节点。 如果超时，也取消当前节点。 自旋控制，每次循环都检测是否满足自旋条件，满足的话，自旋值就减去1，然后进入下次循环(一直减到0) 第一次循环时，会将当前线程设置到s上。 有超时条件下，会检测超时时间是否大于超时阀值(这应该是一个经验值)，大于就阻塞，小于就自旋。 在s节点真正阻塞之前，将当前线程设置到s上面，然后检查中断状态(不少于一次)，以确保后续和s匹配的节点来唤醒当前线程。当执行此方法时，如果执行节点恰好在栈顶，阻塞之前会做一些自旋，为的是如果有生产者或消费者马上到来，就不需要执行节点阻塞了。这种优化在多核下是有意义的。 SynchronousQueue#TransferStack#shouldSpin()123456789/** * Returns true if node s is at head or there is an active * fulfiller. */// 1boolean shouldSpin(SNode s) { SNode h = head; return (h == s || h == null || isFulfilling(h.mode));} 标注代码分析 如果s节点就是当前栈中头节点，或者头节点正在匹配过程中，那么可以自旋一下。 SynchronousQueue自选参数123456789101112131415161718192021222324/** The number of CPUs, for spin control */ static final int NCPUS = Runtime.getRuntime().availableProcessors(); /** * The number of times to spin before blocking in timed waits. * The value is empirically derived -- it works well across a * variety of processors and OSes. Empirically, the best value * seems not to vary with number of CPUs (beyond 2) so is just * a constant. */ static final int maxTimedSpins = (NCPUS &lt; 2)? 0 : 32; /** * The number of times to spin before blocking in untimed waits. * This is greater than timed value because untimed waits spin * faster since they don't need to check times on each spin. */ static final int maxUntimedSpins = maxTimedSpins * 16; /** * The number of nanoseconds for which it is faster to spin * rather than to use timed park. A rough estimate suffices. */ static final long spinForTimeoutThreshold = 1000L; SynchronousQueue#TransferStack#clean()123456789101112131415161718192021222324252627282930313233343536373839/** * Unlinks s from the stack. */// 1void clean(SNode s) { s.item = null; // forget item s.waiter = null; // forget thread /* * At worst we may need to traverse entire stack to unlink * s. If there are multiple concurrent calls to clean, we * might not see s if another thread has already removed * it. But we can stop when we see any node known to * follow s. We use s.next unless it too is cancelled, in * which case we try the node one past. We don't check any * further because we don't want to doubly traverse just to * find sentinel. */ SNode past = s.next; if (past != null &amp;&amp; past.isCancelled()) past = past.next; // Absorb cancelled nodes at head // 2 SNode p; while ((p = head) != null &amp;&amp; p != past &amp;&amp; p.isCancelled()) casHead(p, p.next); // Unsplice embedded nodes // 3 while (p != null &amp;&amp; p != past) { SNode n = p.next; if (n != null &amp;&amp; n.isCancelled()) p.casNext(n, n.next); else p = n; }} 标注代码分析 当s节点被取消时，才会调用这个方法。 将从栈顶节点开始到past的连续的取消节点移除。 如果p本身未取消(上面的while碰到一个未取消的节点就会退出，但这个节点和past节点之间可能还有取消节点)，再把p到past之间的取消节点都移除。 SynchronousQueue#TransferQueue 伪队列123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384/** Dual Queue */ static final class TransferQueue extends Transferer { /* * This extends Scherer-Scott dual queue algorithm, differing, * among other ways, by using modes within nodes rather than * marked pointers. The algorithm is a little simpler than * that for stacks because fulfillers do not need explicit * nodes, and matching is done by CAS'ing QNode.item field * from non-null to null (for put) or vice versa (for take). */ /** Node class for TransferQueue. */ static final class QNode { volatile QNode next; // next node in queue volatile Object item; // CAS'ed to or from null volatile Thread waiter; // to control park/unpark final boolean isData; QNode(Object item, boolean isData) { this.item = item; this.isData = isData; } static final AtomicReferenceFieldUpdater&lt;QNode, QNode&gt; nextUpdater = AtomicReferenceFieldUpdater.newUpdater (QNode.class, QNode.class, \"next\"); boolean casNext(QNode cmp, QNode val) { return (next == cmp &amp;&amp; nextUpdater.compareAndSet(this, cmp, val)); } static final AtomicReferenceFieldUpdater&lt;QNode, Object&gt; itemUpdater = AtomicReferenceFieldUpdater.newUpdater (QNode.class, Object.class, \"item\"); boolean casItem(Object cmp, Object val) { return (item == cmp &amp;&amp; itemUpdater.compareAndSet(this, cmp, val)); } /** * Tries to cancel by CAS'ing ref to this as item. */ // 1 void tryCancel(Object cmp) { itemUpdater.compareAndSet(this, cmp, this); } boolean isCancelled() { return item == this; } /** * Returns true if this node is known to be off the queue * because its next pointer has been forgotten due to * an advanceHead operation. */ // 2 boolean isOffList() { return next == this; } } /** Head of queue */ // 3 transient volatile QNode head; /** Tail of queue */ // 4 transient volatile QNode tail; /** * Reference to a cancelled node that might not yet have been * unlinked from queue because it was the last inserted node * when it cancelled. */ // 5 transient volatile QNode cleanMe; TransferQueue() { // 6 QNode h = new QNode(null, false); // initialize to dummy node. head = h; tail = h; } 标注代码分析 尝试取消节点。取消就是将节点的item域指向自身。 判断节点是否离开了队列。 队列头节点。 队列尾节点。 指向一个被取消的节点，如果取消这个节点时，它是最后一个进入队列的节点，那么这个节点可能还没有离开队列。 初始化一个哨兵节点。 SynchronousQueue#TransferQueue#transfer()123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102/** * Puts or takes an item. */ Object transfer(Object e, boolean timed, long nanos) { /* Basic algorithm is to loop trying to take either of * two actions: * * 1. If queue apparently empty or holding same-mode nodes, * try to add node to queue of waiters, wait to be * fulfilled (or cancelled) and return matching item. * * 2. If queue apparently contains waiting items, and this * call is of complementary mode, try to fulfill by CAS'ing * item field of waiting node and dequeuing it, and then * returning matching item. * * In each case, along the way, check for and try to help * advance head and tail on behalf of other stalled/slow * threads. * * The loop starts off with a null check guarding against * seeing uninitialized head or tail values. This never * happens in current SynchronousQueue, but could if * callers held non-volatile/final ref to the * transferer. The check is here anyway because it places * null checks at top of loop, which is usually faster * than having them implicitly interspersed. */ QNode s = null; // constructed/reused as needed boolean isData = (e != null); for (;;) { QNode t = tail; QNode h = head; // 1 if (t == null || h == null) // saw uninitialized value continue; // spin // 2 if (h == t || t.isData == isData) { // empty or same-mode QNode tn = t.next; // 3 if (t != tail) // inconsistent read continue; // 4 if (tn != null) { // lagging tail // 5 advanceTail(t, tn); continue; } // 6 if (timed &amp;&amp; nanos &lt;= 0) // can't wait return null; if (s == null) // 7 s = new QNode(e, isData); // 8 if (!t.casNext(null, s)) // failed to link in continue; // 9 advanceTail(t, s); // swing tail and wait // 10 Object x = awaitFulfill(s, e, timed, nanos); // 11 if (x == s) { // wait was cancelled // 12 clean(t, s); return null; } // 13 if (!s.isOffList()) { // not already unlinked // 14 advanceHead(t, s); // unlink if head if (x != null) // and forget fields s.item = s; s.waiter = null; } return (x != null)? x : e; } else { // complementary-mode // 15 QNode m = h.next; // node to fulfill // 16 if (t != tail || m == null || h != head) continue; // inconsistent read Object x = m.item; // 17 if (isData == (x != null) || // m already fulfilled x == m || // m cancelled !m.casItem(x, e)) { // lost CAS // 18 advanceHead(h, m); // dequeue and retry continue; } // 19 advanceHead(h, m); // successfully fulfilled // 20 LockSupport.unpark(m.waiter); return (x != null)? x : e; } } } 标注代码分析 如果看到未初始化的头尾节点。 队列为空或者当前节点和队列中节点模式相同。 读取到不一致的结果，说明同时有其他线程修改了tail。 说明其他线程已经添加了新节点tn，但还没将其设置为tail。 当前线程帮忙推进尾节点，就是尝试将tn设置为尾节点。 超时。 初始化s。 尝试将当前节点s拼接到t后面。 尝试将s设置为队列尾节点。 然后等着被匹配。 如果被取消。 清理s节点。 如果s节点还没有离开队列。 尝试将s设置为头节点，移除t。 找到能匹配的节点。 读取到不一致的结果，进入下一轮循环。 如果m已经被匹配；或者m被取消；如果尝试将数据e设置到m上失败。 将h出队，m设置为头结点，然后重试。 成功匹配，推进头节点。 唤醒m上的等待线程。 基本算法是在一个无限循环中尝试下面两种动作里面的一种： 如果队列为空，或者包含相同模式(存或者取)的节点。 尝试将节点加入等待的队列，直到被匹配(或被取消)， 同时返回匹配节点的数据。 如果队列中包含等待的节点，并且当前节点和这个等待节点能相互匹配，那么尝试匹配等待节点并将这个节点出队，然后返回匹配节点的数据。 在每个动作里面，都会检测并帮助其他线程来完成节点推进。在循环开始的时候会做一个非空检测，以避免当前线程看到未初始化的头尾节点。这种情况在当前SynchronousQueue中永远不会发生，但如果调用者持有一个非volatile/final域的话，就有可能会发生。在循环开始的时间做这个非空检测要比在内部(分支里)做性能好一些。 SynchronousQueue#TransferQueue#advanceHead()12345678/** * Tries to cas nh as new head; if successful, unlink * old head's next node to avoid garbage retention. */void advanceHead(QNode h, QNode nh) { if (h == head &amp;&amp; headUpdater.compareAndSet(this, h, nh)) h.next = h; // forget old next} SynchronousQueue#TransferQueue#advanceTail()1234567/** * Tries to cas nt as new tail. */ void advanceTail(QNode t, QNode nt) { if (tail == t) tailUpdater.compareAndSet(this, t, nt); } SynchronousQueue#TransferQueue#awaitFulfill()12345678910111213141516171819202122232425262728293031323334353637383940/** * Spins/blocks until node s is fulfilled. * * @param s the waiting node * @param e the comparison value for checking match * @param timed true if timed wait * @param nanos timeout value * @return matched item, or s if cancelled */ Object awaitFulfill(QNode s, Object e, boolean timed, long nanos) { /* Same idea as TransferStack.awaitFulfill */ long lastTime = (timed)? System.nanoTime() : 0; Thread w = Thread.currentThread(); int spins = ((head.next == s) ? (timed? maxTimedSpins : maxUntimedSpins) : 0); for (;;) { if (w.isInterrupted()) s.tryCancel(e); Object x = s.item; if (x != e) return x; if (timed) { long now = System.nanoTime(); nanos -= now - lastTime; lastTime = now; if (nanos &lt;= 0) { s.tryCancel(e); continue; } } if (spins &gt; 0) --spins; else if (s.waiter == null) s.waiter = w; else if (!timed) LockSupport.park(this); else if (nanos &gt; spinForTimeoutThreshold) LockSupport.parkNanos(this, nanos); } } SynchronousQueue#TransferQueue#clean()12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364 /** * Gets rid of cancelled node s with original predecessor pred. */ void clean(QNode pred, QNode s) { s.waiter = null; // forget thread /* * At any given time, exactly one node on list cannot be * deleted -- the last inserted node. To accommodate this, * if we cannot delete s, we save its predecessor as * \"cleanMe\", deleting the previously saved version * first. At least one of node s or the node previously * saved can always be deleted, so this always terminates. */ // 1 while (pred.next == s) { // Return early if already unlinked QNode h = head; QNode hn = h.next; // Absorb cancelled first node as head if (hn != null &amp;&amp; hn.isCancelled()) { // 2 advanceHead(h, hn); continue; }QNode t = tail; // Ensure consistent read for tail // 3 if (t == h) return;QNode tn = t.next; // 4if (t != tail) continue; if (tn != null) { // 5 advanceTail(t, tn); continue; } // 6 if (s != t) { // If not tail, try to unsplice QNode sn = s.next; // 7 if (sn == s || pred.casNext(s, sn)) return; } // 8 QNode dp = cleanMe; // 9 if (dp != null) { // Try unlinking previous cancelled node QNode d = dp.next; QNode dn; if (d == null || // d is gone or d == dp || // d is off list or !d.isCancelled() || // d not cancelled or (d != t &amp;&amp; // d not tail and (dn = d.next) != null &amp;&amp; // has successor dn != d &amp;&amp; // that is on list dp.casNext(d, dn)))// 10 // d unspliced casCleanMe(dp, null); // 11 if (dp == pred) return; // s is already saved node } else if (casCleanMe(null, pred)) // 12 return; // Postpone cleaning s } } 标注代码分析 在任意给定的时间点，能删除的节点一定是最后入队的节点。为了满足这个条件，如果当前无法删除s，就将其前驱节点保存为”cleanMe”，先删除之前保存的版本。至少节点s和之前保存的节点里面有一个能被删除，所以方法一定会结束。 如果head节点的next节点被取消，那么推进一下head节点。 如果队列为空。 出现不一致读，重试。 帮助推进尾节点。 如果s不是尾节点，移除s。 如果s已经被移除退出循环，否则尝试断开s。 下面要做的事情大体就是：如果s是位节点，那么不会马上删除s，而是将s的前驱节点设置为cleanMe，下次清理其他取消节点的时候会顺便把s移除。 如果dp不为null，说明是前一个被取消节点，将其移除。 把之前标记为cleanMe节点的next节点d移除。 说明s的前驱已经是cleanMe了(后续会被删掉)。 如果当前cleanMe为null，那么将s前驱节点设置为cleanMe，并退出。 SynchronousQueue123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121/** * The transferer. Set only in constructor, but cannot be declared * as final without further complicating serialization. Since * this is accessed only at most once per public method, there * isn't a noticeable performance penalty for using volatile * instead of final here. */ private transient volatile Transferer transferer; /** * Creates a &lt;tt&gt;SynchronousQueue&lt;/tt&gt; with nonfair access policy. */ public SynchronousQueue() { this(false); } /** * Creates a &lt;tt&gt;SynchronousQueue&lt;/tt&gt; with the specified fairness policy. * * @param fair if true, waiting threads contend in FIFO order for * access; otherwise the order is unspecified. */ public SynchronousQueue(boolean fair) { transferer = (fair)? new TransferQueue() : new TransferStack(); } /** * Adds the specified element to this queue, waiting if necessary for * another thread to receive it. * * @throws InterruptedException {@inheritDoc} * @throws NullPointerException {@inheritDoc} */ // 1 public void put(E o) throws InterruptedException { if (o == null) throw new NullPointerException(); if (transferer.transfer(o, false, 0) == null) { Thread.interrupted(); throw new InterruptedException(); } } /** * Inserts the specified element into this queue, waiting if necessary * up to the specified wait time for another thread to receive it. * * @return &lt;tt&gt;true&lt;/tt&gt; if successful, or &lt;tt&gt;false&lt;/tt&gt; if the * specified waiting time elapses before a consumer appears. * @throws InterruptedException {@inheritDoc} * @throws NullPointerException {@inheritDoc} */ // 2 public boolean offer(E o, long timeout, TimeUnit unit) throws InterruptedException { if (o == null) throw new NullPointerException(); if (transferer.transfer(o, true, unit.toNanos(timeout)) != null) return true; if (!Thread.interrupted()) return false; throw new InterruptedException(); } /** * Inserts the specified element into this queue, if another thread is * waiting to receive it. * * @param e the element to add * @return &lt;tt&gt;true&lt;/tt&gt; if the element was added to this queue, else * &lt;tt&gt;false&lt;/tt&gt; * @throws NullPointerException if the specified element is null */ // 3 public boolean offer(E e) { if (e == null) throw new NullPointerException(); return transferer.transfer(e, true, 0) != null; } /** * Retrieves and removes the head of this queue, waiting if necessary * for another thread to insert it. * * @return the head of this queue * @throws InterruptedException {@inheritDoc} */ // 4 public E take() throws InterruptedException { Object e = transferer.transfer(null, false, 0); if (e != null) return (E)e; Thread.interrupted(); throw new InterruptedException(); } /** * Retrieves and removes the head of this queue, waiting * if necessary up to the specified wait time, for another thread * to insert it. * * @return the head of this queue, or &lt;tt&gt;null&lt;/tt&gt; if the * specified waiting time elapses before an element is present. * @throws InterruptedException {@inheritDoc} */ // 5 public E poll(long timeout, TimeUnit unit) throws InterruptedException { Object e = transferer.transfer(null, true, unit.toNanos(timeout)); if (e != null || !Thread.interrupted()) return (E)e; throw new InterruptedException(); } /** * Retrieves and removes the head of this queue, if another thread * is currently making an element available. * * @return the head of this queue, or &lt;tt&gt;null&lt;/tt&gt; if no * element is available. */ // 6 public E poll() { return (E)transferer.transfer(null, true, 0); } 标注代码分析 添加一个数据到队列，等到其他线程接收这个数据。 添加一个数据到队列，等到其他线程接收这个数据或者超时。 添加一个数据到队列，如果有其他线程正等待接收这个数据且接收成功，返回true；否则返回false。这个方法不阻塞。 获取并移除队列前端的数据，如果队列中没有数据，就等待其他线程添加一个数据。 获取并移除队列前端的数据，如果队列中没有数据，就等待其他线程添加一个数据或者超时。 如果其他线程正在添加数据到队列，那么尝试获取并移除这个数据。这个方法不阻塞。 SynchronousQueue 序列化序列化比较特别，因为transferer域本身不需要序列化，但需要记住transferer是内部伪栈和伪队列。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849/* * To cope with serialization strategy in the 1.5 version of * SynchronousQueue, we declare some unused classes and fields * that exist solely to enable serializability across versions. * These fields are never used, so are initialized only if this * object is ever serialized or deserialized. */ static class WaitQueue implements java.io.Serializable { } static class LifoWaitQueue extends WaitQueue { private static final long serialVersionUID = -3633113410248163686L; } static class FifoWaitQueue extends WaitQueue { private static final long serialVersionUID = -3623113410248163686L; } private ReentrantLock qlock; private WaitQueue waitingProducers; private WaitQueue waitingConsumers; /** * Save the state to a stream (that is, serialize it). * * @param s the stream */ private void writeObject(java.io.ObjectOutputStream s) throws java.io.IOException { // 1 boolean fair = transferer instanceof TransferQueue; if (fair) { qlock = new ReentrantLock(true); waitingProducers = new FifoWaitQueue(); waitingConsumers = new FifoWaitQueue(); } else { qlock = new ReentrantLock(); waitingProducers = new LifoWaitQueue(); waitingConsumers = new LifoWaitQueue(); } s.defaultWriteObject(); } private void readObject(final java.io.ObjectInputStream s) throws java.io.IOException, ClassNotFoundException { s.defaultReadObject(); if (waitingProducers instanceof FifoWaitQueue) transferer = new TransferQueue(); else transferer = new TransferStack(); } 标注代码分析 序列化时根据TransferQueue类型来创建WaitQueue实例。 总结伪栈的结构下，新来的线程会作为栈顶节点或者优先和栈顶的等待节点进行匹配，并不是公平的；但伪队列的结构下，新来的线程会在队尾，或者和队头的等待节点(最前到的)进行匹配，能够保证一定的公平性。","link":"/JDK1.6-SynchronousQueue/"},{"title":"JDK1.6 ThreadPoolExecutor","text":"1 介绍 2 源码分析 Executor ExecutorService AbstractExecutorService#newTaskFor AbstractExecutorService#submit AbstractExecutorService#doInvokeAny() AbstractExecutorService#invokeAny() AbstractExecutorService#invokeAll() ThreadPoolExecutor ThreadPoolExecutor 构造函数 Executors#defaultThreadFactory() Executors#DefaultThreadFactory ThreadPoolExecutor#execute() ThreadPoolExecutor#addIfUnderCorePoolSize() ThreadPoolExecutor#addThread() ThreadPoolExecutor#Worker ThreadPoolExecutor#beforeExecute() ThreadPoolExecutor#afterExecute() ThreadPoolExecutor#getTask() ThreadPoolExecutor#workerCanExit() ThreadPoolExecutor#interruptIdleWorkers() ThreadPoolExecutor#workerDone() ThreadPoolExecutor#tryTerminate() ThreadPoolExecutor#ensureQueuedTaskHandled() ThreadPoolExecutor#addIfUnderMaximumPoolSize() ThreadPoolExecutor#shutdown() ThreadPoolExecutor#shutdownNow() ThreadPoolExecutor#drainQueue() ThreadPoolExecutor#awaitTermination() ThreadPoolExecutor#finalize() ThreadPoolExecutor#prestartCoreThread() ThreadPoolExecutor#prestartAllCoreThreads() ThreadPoolExecutor#setCorePoolSize() ThreadPoolExecutor#setMaximumPoolSize() 实现RejectedExecutionHandler接口 ThreadPoolExecutor#AbortPolicy ThreadPoolExecutor#CallerRunsPolicy ThreadPoolExecutor#DiscardPolicy ThreadPoolExecutor#DiscardOldestPolicy 3 总结 1 介绍ThreadPoolExecutor是JUC包中提供的线程池，使用ThreadPoolExecutor的好处一方面是能重用线程资源，避免重复创建线程带来的开销；另一方面是ThreadPoolExecutor提供了内部资源(线程、任务)的管理功能，方便我们监控线程池工作状态。 2 源码分析ThreadPoolExecutor类结构图 Executor123456789101112131415public interface Executor { /** * Executes the given command at some time in the future. The command * may execute in a new thread, in a pooled thread, or in the calling * thread, at the discretion of the &lt;tt&gt;Executor&lt;/tt&gt; implementation. * * @param command the runnable task * @throws RejectedExecutionException if this task cannot be * accepted for execution. * @throws NullPointerException if command is null */ // 1 void execute(Runnable command);} 标注代码分析 根据注释很好理解。command可以在新线程里执行，可以在线程池里执行，可以被调用线程执行等等。 ExecutorService12345678910111213141516171819202122232425262728293031// 1 void shutdown();// 2List&lt;Runnable&gt; shutdownNow();// 3boolean isShutdown();// 4boolean isTerminated();// 5boolean awaitTermination(long timeout, TimeUnit unit) throws InterruptedException;// 6&lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task);&lt;T&gt; Future&lt;T&gt; submit(Runnable task, T result);Future&lt;?&gt; submit(Runnable task);// 7&lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks) throws InterruptedException;&lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, long timeout, TimeUnit unit) throws InterruptedException;// 8&lt;T&gt; T invokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks) throws InterruptedException, ExecutionException;&lt;T&gt; T invokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException; 标注代码分析 关闭之前，已经提交的任务会被执行。新任务被拒绝。服务被关闭，则调用这个方法没有影响。 尝试停止所有正在执行的任务，停止处理正在等待的任务，并返回等待执行任务列表。并不能确保一定可以停止正在执行的任务。比如，通常的实现方式是中断执行任务的线程，但如果任务执行过程中并不响应中断，那就无法停止这个任务。 是否已经关闭。 关闭后，是否所有的任务都执行完毕。 在关闭、超时、任务中断后，任务执行完毕前，都阻塞。 提交任务。 执行任务集合。 执行一批任务，如果其中有一个任务完成，就返回结果。其他没有完成的任务会被取消。 AbstractExecutorService#newTaskFor1234567891011121314151617181920212223242526272829/** * Returns a &lt;tt&gt;RunnableFuture&lt;/tt&gt; for the given runnable and default * value. * * @param runnable the runnable task being wrapped * @param value the default value for the returned future * @return a &lt;tt&gt;RunnableFuture&lt;/tt&gt; which when run will run the * underlying runnable and which, as a &lt;tt&gt;Future&lt;/tt&gt;, will yield * the given value as its result and provide for cancellation of * the underlying task. * @since 1.6 */ protected &lt;T&gt; RunnableFuture&lt;T&gt; newTaskFor(Runnable runnable, T value) { return new FutureTask&lt;T&gt;(runnable, value); } /** * Returns a &lt;tt&gt;RunnableFuture&lt;/tt&gt; for the given callable task. * * @param callable the callable task being wrapped * @return a &lt;tt&gt;RunnableFuture&lt;/tt&gt; which when run will call the * underlying callable and which, as a &lt;tt&gt;Future&lt;/tt&gt;, will yield * the callable's result as its result and provide for * cancellation of the underlying task. * @since 1.6 */ protected &lt;T&gt; RunnableFuture&lt;T&gt; newTaskFor(Callable&lt;T&gt; callable) { return new FutureTask&lt;T&gt;(callable); } 将runnable、callable转换成FutureTask。 AbstractExecutorService#submit1234567891011121314151617181920public Future&lt;?&gt; submit(Runnable task) { if (task == null) throw new NullPointerException(); RunnableFuture&lt;Object&gt; ftask = newTaskFor(task, null); execute(ftask); return ftask;}public &lt;T&gt; Future&lt;T&gt; submit(Runnable task, T result) { if (task == null) throw new NullPointerException(); RunnableFuture&lt;T&gt; ftask = newTaskFor(task, result); execute(ftask); return ftask;}public &lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task) { if (task == null) throw new NullPointerException(); RunnableFuture&lt;T&gt; ftask = newTaskFor(task); execute(ftask); return ftask;} 先转成RunnableFuture，然后提交到Executor，然后返回RunnableFuture(异步任务)。 AbstractExecutorService#doInvokeAny()1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283/** * the main mechanics of invokeAny. */ private &lt;T&gt; T doInvokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, boolean timed, long nanos) throws InterruptedException, ExecutionException, TimeoutException { if (tasks == null) throw new NullPointerException(); int ntasks = tasks.size(); if (ntasks == 0) throw new IllegalArgumentException(); List&lt;Future&lt;T&gt;&gt; futures= new ArrayList&lt;Future&lt;T&gt;&gt;(ntasks); ExecutorCompletionService&lt;T&gt; ecs = new ExecutorCompletionService&lt;T&gt;(this); // For efficiency, especially in executors with limited // parallelism, check to see if previously submitted tasks are // done before submitting more of them. This interleaving // plus the exception mechanics account for messiness of main // loop. try { // Record exceptions so that if we fail to obtain any // result, we can throw the last exception we got. ExecutionException ee = null; long lastTime = (timed)? System.nanoTime() : 0; Iterator&lt;? extends Callable&lt;T&gt;&gt; it = tasks.iterator(); // Start one task for sure; the rest incrementally // 1 futures.add(ecs.submit(it.next())); --ntasks; int active = 1; // 2 for (;;) { // 3 Future&lt;T&gt; f = ecs.poll(); if (f == null) { // 4 if (ntasks &gt; 0) { --ntasks; futures.add(ecs.submit(it.next())); ++active; } // 5 else if (active == 0) break; // 6 else if (timed) { f = ecs.poll(nanos, TimeUnit.NANOSECONDS); if (f == null) throw new TimeoutException(); long now = System.nanoTime(); nanos -= now - lastTime; lastTime = now; } else // 7 f = ecs.take(); }// 8 if (f != null) { --active; try { return f.get(); } catch (InterruptedException ie) { throw ie; } catch (ExecutionException eex) { ee = eex; } catch (RuntimeException rex) { ee = new ExecutionException(rex); } } } if (ee == null) ee = new ExecutionException(); throw ee; } finally { // 9 for (Future&lt;T&gt; f : futures) f.cancel(true); } } 标注代码分析 首先提交1个任务，任务数量-1。 轮询。 ExecutorCompletionService中获取任务。 如果Future f=null，还有剩余任务(ntasks &gt; 0),提交任务到ExecutorCompletionService里，active+1。 没有在提交的任务，执行任务数量。(active = 0) 超时处理。 可能ExecutorCompletionService中的任务执行完毕，赋值给Future f。 f!=null，说明任务执行完成，active-1，返回Future#f#get() 没执行完的任务取消掉。 AbstractExecutorService#invokeAny()123456789101112131415public &lt;T&gt; T invokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks) throws InterruptedException, ExecutionException { try { return doInvokeAny(tasks, false, 0); } catch (TimeoutException cannotHappen) { assert false; return null; } } public &lt;T&gt; T invokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException { return doInvokeAny(tasks, true, unit.toNanos(timeout)); } AbstractExecutorService#invokeAll()123456789101112131415161718192021222324252627282930313233public &lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks) throws InterruptedException { if (tasks == null) throw new NullPointerException(); List&lt;Future&lt;T&gt;&gt; futures = new ArrayList&lt;Future&lt;T&gt;&gt;(tasks.size()); boolean done = false; try { // 1 for (Callable&lt;T&gt; t : tasks) { RunnableFuture&lt;T&gt; f = newTaskFor(t); futures.add(f); execute(f); } // 2 for (Future&lt;T&gt; f : futures) { if (!f.isDone()) { try { f.get(); } catch (CancellationException ignore) { } catch (ExecutionException ignore) { } } } // 3 done = true; return futures; } finally { // 4 if (!done) for (Future&lt;T&gt; f : futures) f.cancel(true); } } 标注代码分析 添加任务，执行任务 等待所有的任务都执行完成。 done判断任务执行完成。 done=false，所有任务并没有执行完成，取消没有完成的任务。 ThreadPoolExecutor123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148public class ThreadPoolExecutor extends AbstractExecutorService { /** * Permission for checking shutdown */ private static final RuntimePermission shutdownPerm = new RuntimePermission(\"modifyThread\"); /** * runState provides the main lifecyle control, taking on values: * * RUNNING: Accept new tasks and process queued tasks * SHUTDOWN: Don't accept new tasks, but process queued tasks * STOP: Don't accept new tasks, don't process queued tasks, * and interrupt in-progress tasks * TERMINATED: Same as STOP, plus all threads have terminated * * RUNNING -&gt; SHUTDOWN * On invocation of shutdown(), perhaps implicitly in finalize() * (RUNNING or SHUTDOWN) -&gt; STOP * On invocation of shutdownNow() * SHUTDOWN -&gt; TERMINATED * When both queue and pool are empty * STOP -&gt; TERMINATED * When pool is empty */ // 1 volatile int runState; // 2 static final int RUNNING = 0; // 3 static final int SHUTDOWN = 1; // 4 static final int STOP = 2; // 5 static final int TERMINATED = 3; /** * The queue used for holding tasks and handing off to worker * threads. Note that when using this queue, we do not require * that workQueue.poll() returning null necessarily means that * workQueue.isEmpty(), so must sometimes check both. This * accommodates special-purpose queues such as DelayQueues for * which poll() is allowed to return null even if it may later * return non-null when delays expire. */ // 6 private final BlockingQueue&lt;Runnable&gt; workQueue; /** * Lock held on updates to poolSize, corePoolSize, * maximumPoolSize, runState, and workers set. */ // 7 private final ReentrantLock mainLock = new ReentrantLock(); /** * Wait condition to support awaitTermination */ // 8 private final Condition termination = mainLock.newCondition(); /** * Set containing all worker threads in pool. Accessed only when * holding mainLock. */ // 9 private final HashSet&lt;Worker&gt; workers = new HashSet&lt;Worker&gt;(); /** * Timeout in nanoseconds for idle threads waiting for work. * Threads use this timeout when there are more than corePoolSize * present or if allowCoreThreadTimeOut. Otherwise they wait * forever for new work. */ // 10 private volatile long keepAliveTime; /** * If false (default) core threads stay alive even when idle. If * true, core threads use keepAliveTime to time out waiting for * work. */ // 11 private volatile boolean allowCoreThreadTimeOut; /** * Core pool size, updated only while holding mainLock, but * volatile to allow concurrent readability even during updates. */ // 12 private volatile int corePoolSize; /** * Maximum pool size, updated only while holding mainLock but * volatile to allow concurrent readability even during updates. */ // 13 private volatile int maximumPoolSize; /** * Current pool size, updated only while holding mainLock but * volatile to allow concurrent readability even during updates. */ // 14 private volatile int poolSize; /** * Handler called when saturated or shutdown in execute. */ // 15 private volatile RejectedExecutionHandler handler; /** * Factory for new threads. All threads are created using this * factory (via method addThread). All callers must be prepared * for addThread to fail by returning null, which may reflect a * system or user's policy limiting the number of threads. Even * though it is not treated as an error, failure to create threads * may result in new tasks being rejected or existing ones * remaining stuck in the queue. On the other hand, no special * precautions exist to handle OutOfMemoryErrors that might be * thrown while trying to create threads, since there is generally * no recourse from within this class. */ // 16 private volatile ThreadFactory threadFactory; /** * Tracks largest attained pool size. */ // 17 private int largestPoolSize; /** * Counter for completed tasks. Updated only on termination of * worker threads. */ // 18 private long completedTaskCount; /** * The default rejected execution handler */ // 19 private static final RejectedExecutionHandler defaultHandler = new AbortPolicy(); 标注代码分析 线程池运行状态。 正在运行。会接受新任务，并会处理任务队列中的任务。 已经关闭。不接受新任务，但仍然会处理任务队列中的任务。 已经停止。不接受新任务，不处理任务队列中的任务，会中断正在执行的任务。 STOP的基础上，在加上所有的任务都已经结束。 任务队列，将任务交给工作线程处理。 在更新内部数据(如：线程数量，运行状态，工作线程集等)时要使用的锁。 用于支持awaitTermination的等待条件。 包含所有工作类的集合。只能在持有mainLock的情况下使用。 空闲工作线程等待任务的超时时间，单位：纳秒。当前线程数大于核心线程数时，超出的线程会使用这个超时时间。如果设置了allowCoreThreadTimeOut，核心线程数也会使用这个超时时间。否则，线程会一直等待新任务，不会超时。 如果为false(默认情况下)，核心线程就算空闲也会一直存活。如果为true，等待任务的核心线程会使用keepAliveTime作为超时时间，如果超时，线程被回收。 核心线程数量，只能在持有mainLock的情况下修改。volatile可以保证可见性。 最大线程数量，只能在持有mainLock的情况下修改。 当前线程数量，只能在持有mainLock的情况下修改。 当线程池饱和或者关闭时，负责处理新来任务的处理，称为拒绝任务处理器。 线程工厂。用于创建新线程。 最大的线程数量记录。 统计任务完成数量的计数器。在工作线程终止(termination)的时候才会更新。 默认的拒绝任务处理。 ThreadPoolExecutor 构造函数123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue) { this(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue, Executors.defaultThreadFactory(), defaultHandler);}public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory) { this(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue, threadFactory, defaultHandler);}public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, RejectedExecutionHandler handler) { this(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue, Executors.defaultThreadFactory(), handler);}public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) { if (corePoolSize &lt; 0 || maximumPoolSize &lt;= 0 || maximumPoolSize &lt; corePoolSize || keepAliveTime &lt; 0) throw new IllegalArgumentException(); if (workQueue == null || threadFactory == null || handler == null) throw new NullPointerException(); this.corePoolSize = corePoolSize; this.maximumPoolSize = maximumPoolSize; this.workQueue = workQueue; this.keepAliveTime = unit.toNanos(keepAliveTime); this.threadFactory = threadFactory; this.handler = handler;} 内部的keepAliveTime都使用纳秒，所以构造方法中会有1个时间转换。 不指定线程工厂，会使用Executors.defaultThreadFactory()。 Executors#defaultThreadFactory()123public static ThreadFactory defaultThreadFactory(){ return new DefaultThreadFactory();} Executors#DefaultThreadFactory1234567891011121314151617181920212223242526272829/** * The default thread factory */ static class DefaultThreadFactory implements ThreadFactory { static final AtomicInteger poolNumber = new AtomicInteger(1); final ThreadGroup group; final AtomicInteger threadNumber = new AtomicInteger(1); final String namePrefix; DefaultThreadFactory() { SecurityManager s = System.getSecurityManager(); group = (s != null)? s.getThreadGroup() : Thread.currentThread().getThreadGroup(); namePrefix = \"pool-\" + poolNumber.getAndIncrement() + \"-thread-\"; } public Thread newThread(Runnable r) { Thread t = new Thread(group, r, namePrefix + threadNumber.getAndIncrement(), 0); if (t.isDaemon()) t.setDaemon(false); if (t.getPriority() != Thread.NORM_PRIORITY) t.setPriority(Thread.NORM_PRIORITY); return t; } } 通过DefaultThreadFactory创建Thread Name，Thread Group的Thread，由poolNumber.getAndIncrement() 知道线程序号是递增的。 ThreadPoolExecutor#execute()1234567891011121314151617181920212223242526272829303132/** * Executes the given task sometime in the future. The task * may execute in a new thread or in an existing pooled thread. * * If the task cannot be submitted for execution, either because this * executor has been shutdown or because its capacity has been reached, * the task is handled by the current &lt;tt&gt;RejectedExecutionHandler&lt;/tt&gt;. * * @param command the task to execute * @throws RejectedExecutionException at discretion of * &lt;tt&gt;RejectedExecutionHandler&lt;/tt&gt;, if task cannot be accepted * for execution * @throws NullPointerException if command is null */public void execute(Runnable command) { if (command == null) throw new NullPointerException(); // 1 if (poolSize &gt;= corePoolSize || !addIfUnderCorePoolSize(command)) { // 2 if (runState == RUNNING &amp;&amp; workQueue.offer(command)) { // 3 if (runState != RUNNING || poolSize == 0) // 4 ensureQueuedTaskHandled(command); } // 5 else if (!addIfUnderMaximumPoolSize(command)) // 6 reject(command); // is shutdown or saturated }} 标注代码分析 如果当前线程数量大于等于核心线程数量(poolSize &gt;= corePoolSize)，执行#2。如果当前线程数量小于核心线程数量(poolSize &lt; corePoolSize)，那么尝试添加1个工作线程(addIfUnderCorePoolSize)，同时让这个工作线程处理当前提交的任务，提交任务流程结束；如果添加工作线程失败，那么进入#2。 首先判断当前线程池状态是否为正在运行，如果正在运行，就将当前任务放入任务队列中。 如果当前线程池状态不是正在运行，或者workQueue.offer(command)操作失败，所以任务队列 == 0。 x 添加一个工作线程，同时让这个工作线程处理当前提交的任务，但不能超时最大工作线程数。 addIfUnderMaximumPoolSize(command)如果添加成功，提交任务流程结束；如果添加失败，使用拒绝任务处理器来处理任务。 ThreadPoolExecutor#addIfUnderCorePoolSize()1234567891011121314151617181920212223242526/** * Creates and starts a new thread running firstTask as its first * task, only if fewer than corePoolSize threads are running * and the pool is not shut down. * @param firstTask the task the new thread should run first (or * null if none) * @return true if successful */private boolean addIfUnderCorePoolSize(Runnable firstTask) { Thread t = null; final ReentrantLock mainLock = this.mainLock; // 1 mainLock.lock(); try { // 2 if (poolSize &lt; corePoolSize &amp;&amp; runState == RUNNING) t = addThread(firstTask); } finally { mainLock.unlock(); } if (t == null) return false; // 3 t.start(); return true;} 标注代码分析 新增线程需要加锁。 当前线程数量小于核心线程数量，当前线程池处于运行状态，那么添加1个工作线程。 任务执行。 ThreadPoolExecutor#addThread()1234567891011121314151617181920212223242526/** * Creates and returns a new thread running firstTask as its first * task. Call only while holding mainLock. * * @param firstTask the task the new thread should run first (or * null if none) * @return the new thread, or null if threadFactory fails to create thread */private Thread addThread(Runnable firstTask) { // 1 Worker w = new Worker(firstTask); // 2 Thread t = threadFactory.newThread(w); if (t != null) { // 3 w.thread = t; // 4 workers.add(w); // 5 int nt = ++poolSize; // 6 if (nt &gt; largestPoolSize) largestPoolSize = nt; } return t;} 标注代码分析 创建1个worker任务。 根据threadFactory创建1个Thread。 新建的Thread赋值给worker#thread。 worker集合添加worker对象。 线程池中线程数量+1。 线程池最大值重设值为nt。 ThreadPoolExecutor#Worker123456...When starting to run a task, unless the pool is stopped, eachworker thread ensures that it is not interrupted, and usesrunLock to prevent the pool from interrupting it in the midstof execution. ... 根据注释可以知道，Worker是Runnable，Worker用到ReentrantLock防止pool在运行中中断，worker thread确保不会被中断，除非pool停止。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123private final class Worker implements Runnable { /** * The runLock is acquired and released surrounding each task * execution. It mainly protects against interrupts that are * intended to cancel the worker thread from instead * interrupting the task being run. */ // 1 private final ReentrantLock runLock = new ReentrantLock(); /** * Initial task to run before entering run loop. Possibly null. */ // 2 private Runnable firstTask; /** * Per thread completed task counter; accumulated * into completedTaskCount upon termination. */ // 3 volatile long completedTasks; /** * Thread this worker is running in. Acts as a final field, * but cannot be set until thread is created. */ // 4 Thread thread; Worker(Runnable firstTask) { this.firstTask = firstTask; } // 5 boolean isActive() { return runLock.isLocked(); } /** * Interrupts thread if not running a task. */ // 6 void interruptIfIdle() { final ReentrantLock runLock = this.runLock; if (runLock.tryLock()) { try { if (thread != Thread.currentThread()) thread.interrupt(); } finally { runLock.unlock(); } } } /** * Interrupts thread even if running a task. */ // 7 void interruptNow() { thread.interrupt(); } /** * Runs a single task between before/after methods. */ private void runTask(Runnable task) { final ReentrantLock runLock = this.runLock; runLock.lock(); try { /* * Ensure that unless pool is stopping, this thread * does not have its interrupt set. This requires a * double-check of state in case the interrupt was * cleared concurrently with a shutdownNow -- if so, * the interrupt is re-enabled. */ // 8 if (runState &lt; STOP &amp;&amp; Thread.interrupted() &amp;&amp; runState &gt;= STOP) thread.interrupt(); /* * Track execution state to ensure that afterExecute * is called only if task completed or threw * exception. Otherwise, the caught runtime exception * will have been thrown by afterExecute itself, in * which case we don't want to call it again. */ // 9 boolean ran = false; beforeExecute(thread, task); try { task.run(); ran = true; afterExecute(task, null); ++completedTasks; } catch (RuntimeException ex) { if (!ran) afterExecute(task, ex); throw ex; } } finally { runLock.unlock(); } } /** * Main run loop */ public void run() { try { Runnable task = firstTask; firstTask = null; // 10 while (task != null || (task = getTask()) != null) { runTask(task); task = null; } } finally { workerDone(this); } } } 标注代码分析 防止中断线程，取消worker线程 初始任务，可能是null 线程完成任务数量 worker运行在这Thread上 调用ReentrantLock#isLocked()，作为监控Thread状态，非sync操作。Thread hold this lock，true表示当前线程持有这锁，Thread活跃状态。 如果worker是闲置，中断当前worker#thread 任务运行中，中断thread 当pool是停止，中断当前thread。 ran=false，执行task#run()后出现异常，则会调用afterExecute(task, ex),如果task#run()出现异常，则不会调用afterExecute(task, ex)。ThreadPoolExecutor#beforeExecute()和ThreadPoolExecutor#afterExecute()作为子类实现。 检查firstTask不为空，ThreadPoolExecutor#getTask()赋值task，运行task。 ThreadPoolExecutor#beforeExecute()123456789101112131415/** * Method invoked prior to executing the given Runnable in the * given thread. This method is invoked by thread &lt;tt&gt;t&lt;/tt&gt; that * will execute task &lt;tt&gt;r&lt;/tt&gt;, and may be used to re-initialize * ThreadLocals, or to perform logging. * * &lt;p&gt;This implementation does nothing, but may be customized in * subclasses. Note: To properly nest multiple overridings, subclasses * should generally invoke &lt;tt&gt;super.beforeExecute&lt;/tt&gt; at the end of * this method. * * @param t the thread that will run task r. * @param r the task that will be executed. */protected void beforeExecute(Thread t, Runnable r) { } ThreadPoolExecutor#afterExecute()1234567891011121314151617181920212223/** * Method invoked upon completion of execution of the given Runnable. * This method is invoked by the thread that executed the task. If * non-null, the Throwable is the uncaught &lt;tt&gt;RuntimeException&lt;/tt&gt; * or &lt;tt&gt;Error&lt;/tt&gt; that caused execution to terminate abruptly. * * &lt;p&gt;&lt;b&gt;Note:&lt;/b&gt; When actions are enclosed in tasks (such as * {@link FutureTask}) either explicitly or via methods such as * &lt;tt&gt;submit&lt;/tt&gt;, these task objects catch and maintain * computational exceptions, and so they do not cause abrupt * termination, and the internal exceptions are &lt;em&gt;not&lt;/em&gt; * passed to this method. * * &lt;p&gt;This implementation does nothing, but may be customized in * subclasses. Note: To properly nest multiple overridings, subclasses * should generally invoke &lt;tt&gt;super.afterExecute&lt;/tt&gt; at the * beginning of this method. * * @param r the runnable that has completed. * @param t the exception that caused termination, or null if * execution completed normally. */protected void afterExecute(Runnable r, Throwable t) { } ThreadPoolExecutor#getTask()12345678910111213141516171819202122232425262728293031323334353637383940414243444546/** * Gets the next task for a worker thread to run. The general * approach is similar to execute() in that worker threads trying * to get a task to run do so on the basis of prevailing state * accessed outside of locks. This may cause them to choose the * \"wrong\" action, such as trying to exit because no tasks * appear to be available, or entering a take when the pool is in * the process of being shut down. These potential problems are * countered by (1) rechecking pool state (in workerCanExit) * before giving up, and (2) interrupting other workers upon * shutdown, so they can recheck state. All other user-based state * changes (to allowCoreThreadTimeOut etc) are OK even when * performed asynchronously wrt getTask. * * @return the task */Runnable getTask() { for (;;) { try { int state = runState; // 1 if (state &gt; SHUTDOWN) return null; Runnable r; // 2 if (state == SHUTDOWN) // Help drain queue r = workQueue.poll(); else if (poolSize &gt; corePoolSize || allowCoreThreadTimeOut)// 3 r = workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS); else // 4 r = workQueue.take(); if (r != null) return r; // 5 if (workerCanExit()) { // 6 if (runState &gt;= SHUTDOWN) // Wake up others interruptIdleWorkers(); return null; } // Else retry } catch (InterruptedException ie) { // On interruption, re-check runState } }} 标注代码分析 线程池停止、终端，则返回null。 线程池关闭，获取队列里的任务。 如果设置超时获取队列中的任务，通过超时poll(long)获取。 阻塞等待获取任务。 检测是否可以退出这for循环。ThreadPoolExecutor#workerCanExit()代码，可以知道线程池中断、workQueue是空、设置超时时间都可以作为退出条件。 如果线程池中断、关闭，workers集合中可能还有空闲Thread，中断workers集合中的任务。 ThreadPoolExecutor#workerCanExit()123456789101112131415161718192021/** * Check whether a worker thread that fails to get a task can * exit. We allow a worker thread to die if the pool is stopping, * or the queue is empty, or there is at least one thread to * handle possibly non-empty queue, even if core timeouts are * allowed. */ private boolean workerCanExit() { final ReentrantLock mainLock = this.mainLock; mainLock.lock(); boolean canExit; try { canExit = runState &gt;= STOP || workQueue.isEmpty() || (allowCoreThreadTimeOut &amp;&amp; poolSize &gt; Math.max(1, corePoolSize)); } finally { mainLock.unlock(); } return canExit; } ThreadPoolExecutor#interruptIdleWorkers()123456789101112131415/** * Wakes up all threads that might be waiting for tasks so they * can check for termination. Note: this method is also called by * ScheduledThreadPoolExecutor. */void interruptIdleWorkers() { final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try { for (Worker w : workers) w.interruptIfIdle(); } finally { mainLock.unlock(); }} ThreadPoolExecutor#workerDone()123456789101112131415161718/** * Performs bookkeeping for an exiting worker thread. * @param w the worker */void workerDone(Worker w) { final ReentrantLock mainLock = this.mainLock; // 1 mainLock.lock(); try { completedTaskCount += w.completedTasks; workers.remove(w); // 2 if (--poolSize == 0) tryTerminate(); } finally { mainLock.unlock(); }} 标注代码分析 加锁，线程任务完成记录+1，从worker集合中移除当前work。 如果线程池当前数量=0；如果线程状态是停止、关闭，中断线程池。如果线程状态是运行且workQueue阻塞队列有任务，则至少1个活线程。 ThreadPoolExecutor#tryTerminate()12345678910111213141516171819202122232425262728293031/** * Transitions to TERMINATED state if either (SHUTDOWN and pool * and queue empty) or (STOP and pool empty), otherwise unless * stopped, ensuring that there is at least one live thread to * handle queued tasks. * * This method is called from the three places in which * termination can occur: in workerDone on exit of the last thread * after pool has been shut down, or directly within calls to * shutdown or shutdownNow, if there are no live threads. */private void tryTerminate() { // 1 if (poolSize == 0) { // 2 int state = runState; // 3 if (state &lt; STOP &amp;&amp; !workQueue.isEmpty()) { state = RUNNING; // disable termination check below Thread t = addThread(null); if (t != null) t.start(); } // 4 if (state == STOP || state == SHUTDOWN) { runState = TERMINATED; termination.signalAll(); terminated(); } }} 标注代码分析 线程池数量为0。 当前线程池状态赋值为局部变量state。 当线程池是RUNNING或者SHUTDOWN状态，且workQueue不为空。新建1个null的线程，修改线程池状态为RUNNING。 线程池是STOP，设置当前线程池状态是TERMINATED。同时唤醒1条等待线程。 ThreadPoolExecutor#ensureQueuedTaskHandled()12345678910111213141516171819202122232425262728293031323334/** * Rechecks state after queuing a task. Called from execute when * pool state has been observed to change after queuing a task. If * the task was queued concurrently with a call to shutdownNow, * and is still present in the queue, this task must be removed * and rejected to preserve shutdownNow guarantees. Otherwise, * this method ensures (unless addThread fails) that there is at * least one live thread to handle this task * @param command the task */ private void ensureQueuedTaskHandled(Runnable command) { final ReentrantLock mainLock = this.mainLock; mainLock.lock(); // 1 boolean reject = false; Thread t = null; try { int state = runState; // 2 if (state != RUNNING &amp;&amp; workQueue.remove(command)) reject = true; else if (state &lt; STOP &amp;&amp; poolSize &lt; Math.max(corePoolSize, 1) &amp;&amp; !workQueue.isEmpty())// 3 t = addThread(null); } finally { mainLock.unlock(); } // 4 if (reject) reject(command); else if (t != null) t.start(); } 标注代码分析 拒绝标志符变量。 线程池不是RUNNING，则从阻塞队列workQueue删除当前任务。设置拒绝标识符。 线程池状态不是STOP，workQueue非空，ThreadPoolExecutor#execute()中的runState != RUNNING ，可以知道线程池状态是SHUTDOWN。和ensureQueuedTaskHandled#tryTerminate()一样，必需有1个活线程执行任务。 执行拒绝方法RejectedExecutionHandler#rejectedExecution，或者运行null runnable。 ThreadPoolExecutor#addIfUnderMaximumPoolSize()123456789101112131415161718192021222324/** * Creates and starts a new thread running firstTask as its first * task, only if fewer than maximumPoolSize threads are running * and pool is not shut down. * @param firstTask the task the new thread should run first (or * null if none) * @return true if successful */ private boolean addIfUnderMaximumPoolSize(Runnable firstTask) { Thread t = null; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try { // if (poolSize &lt; maximumPoolSize &amp;&amp; runState == RUNNING) t = addThread(firstTask); } finally { mainLock.unlock(); } if (t == null) return false; t.start(); return true; } 标注代码分析 线程池中线程数量&lt;最大线程池线程数量，线程池状态RUNNING，添加1个worker任务。创建thread，赋值给worker#thread。 ThreadPoolExecutor#shutdown()123456789101112131415161718192021222324252627282930313233343536public void shutdown() { // 1SecurityManager security = System.getSecurityManager();if (security != null) security.checkPermission(shutdownPerm); final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try { // 2 if (security != null) { // Check if caller can modify our threads // 3 for (Worker w : workers) security.checkAccess(w.thread); } // 4 int state = runState; if (state &lt; SHUTDOWN) runState = SHUTDOWN; try { // 5 for (Worker w : workers) { w.interruptIfIdle(); } } catch (SecurityException se) { // Try to back out runState = state; // tryTerminate() here would be a no-op throw se; } // 6 tryTerminate(); // Terminate now if pool and queue empty } finally { mainLock.unlock(); } } 标注代码分析 检测是否允许关闭。 是否有些线程允许被修改。 设置线程运行被修改。 设置线程池状态SHUTDOWN。 worker阻塞队列终端线程。 根据注释Some workers may have been killed but we remain in non-shutdown state (which may entail tryTerminate from workerDone starting a new worker to maintain liveness.知道保留1个null的thread。 ThreadPoolExecutor#shutdownNow()12345678910111213141516171819202122232425262728293031323334353637383940public List&lt;Runnable&gt; shutdownNow() { /* * shutdownNow differs from shutdown only in that * 1. runState is set to STOP, * 2. all worker threads are interrupted, not just the idle ones, and * 3. the queue is drained and returned. */ SecurityManager security = System.getSecurityManager(); if (security != null) security.checkPermission(shutdownPerm); final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try { if (security != null) { // Check if caller can modify our threads for (Worker w : workers) security.checkAccess(w.thread); } int state = runState; if (state &lt; STOP) runState = STOP; try { for (Worker w : workers) { w.interruptNow(); } } catch (SecurityException se) { // Try to back out runState = state; // tryTerminate() here would be a no-op throw se; } // 1 List&lt;Runnable&gt; tasks = drainQueue(); tryTerminate(); // Terminate now if pool and queue empty return tasks; } finally { mainLock.unlock(); } } 标注代码分析 情况worker阻塞队列，返回阻塞队列任务集合。 shutdownNow()相对shutdown()多1个drainQueue()。 ThreadPoolExecutor#drainQueue()1234567891011121314151617181920212223/** * Drains the task queue into a new list. Used by shutdownNow. * Call only while holding main lock. */ private List&lt;Runnable&gt; drainQueue() { List&lt;Runnable&gt; taskList = new ArrayList&lt;Runnable&gt;(); // 1 workQueue.drainTo(taskList); // 2 while (!workQueue.isEmpty()) { // 3 Iterator&lt;Runnable&gt; it = workQueue.iterator(); try { if (it.hasNext()) { Runnable r = it.next(); if (workQueue.remove(r)) taskList.add(r); } } catch (ConcurrentModificationException ignore) { } } return taskList; } 标注代码分析 清空workQueue阻塞队列，并把workQueue阻塞队列数据放到新建list集合。 根据注释If the queue is a DelayQueue or any other kind of queue for which poll or drainTo may fail to remove some elementsdrainTo()可能会失败，所以需要遍历workQueue阻塞队列，再次清除1遍。 根据注释guarantee atomicity wrt other threads using this queue, we need to create a new iterator for each element removed.保证原子性。每次循环都创建新的iterator对象。 ThreadPoolExecutor#awaitTermination()123456789101112131415161718public boolean awaitTermination(long timeout, TimeUnit unit) throws InterruptedException { long nanos = unit.toNanos(timeout); final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try { for (;;) { // 1 if (runState == TERMINATED) return true; if (nanos &lt;= 0) return false; nanos = termination.awaitNanos(nanos); } } finally { mainLock.unlock(); } } 标注代码分析 线程状态TERMINATED，直接返回true。 时间负数，线程中断失败。 等待(或等待超时)，等待线程被唤醒或者中断。 ThreadPoolExecutor#finalize()1234567/** * Invokes &lt;tt&gt;shutdown&lt;/tt&gt; when this executor is no longer * referenced. */protected void finalize() { shutdown();} 覆写finalize()，根据注释executor没有强引用的时候，可以执行shutdown()。可以参考finalize章节。 ThreadPoolExecutor#prestartCoreThread()12345678910/** * Starts a core thread, causing it to idly wait for work. This * overrides the default policy of starting core threads only when * new tasks are executed. This method will return &lt;tt&gt;false&lt;/tt&gt; * if all core threads have already been started. * @return true if a thread was started */public boolean prestartCoreThread() { return addIfUnderCorePoolSize(null);} 如果poolSize &lt; corePoolSize，创建1个thread，返回true。根据注释知道，poolSize &gt;= corePoolSize，线程池里线程都启动，所以返回false。 ThreadPoolExecutor#prestartAllCoreThreads()123456789101112/** * Starts all core threads, causing them to idly wait for work. This * overrides the default policy of starting core threads only when * new tasks are executed. * @return the number of threads started */public int prestartAllCoreThreads() { int n = 0; while (addIfUnderCorePoolSize(null)) ++n; return n;} prestartAllCoreThreads()相对prestartCoreThread()多while循环。在poolSize &lt; corePoolSize时候，不断创建runnable = null的线程。 ThreadPoolExecutor#setCorePoolSize()1234567891011121314151617181920212223242526272829303132333435public void setCorePoolSize(int corePoolSize) { if (corePoolSize &lt; 0) throw new IllegalArgumentException(); final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try { int extra = this.corePoolSize - corePoolSize; this.corePoolSize = corePoolSize; // 1 if (extra &lt; 0) { int n = workQueue.size(); // don't add more threads than tasks while (extra++ &lt; 0 &amp;&amp; n-- &gt; 0 &amp;&amp; poolSize &lt; corePoolSize) { Thread t = addThread(null); if (t != null) t.start(); else break; } } else if (extra &gt; 0 &amp;&amp; poolSize &gt; corePoolSize) { // 2 try { Iterator&lt;Worker&gt; it = workers.iterator(); while (it.hasNext() &amp;&amp; extra-- &gt; 0 &amp;&amp; poolSize &gt; corePoolSize &amp;&amp; workQueue.remainingCapacity() == 0) it.next().interruptIfIdle(); } catch (SecurityException ignore) { // Not an error; it is OK if the threads stay live } } } finally { mainLock.unlock(); } } 标注代码分析 new corePoolSize &gt; corePoolSize，新增extra数量的runnable = null的Thread。 new corePoolSize &lt; corePoolSize，中断worker阻塞队列中闲置的线程。 ThreadPoolExecutor#setMaximumPoolSize()1234567891011121314151617181920212223242526public void setMaximumPoolSize(int maximumPoolSize) { if (maximumPoolSize &lt;= 0 || maximumPoolSize &lt; corePoolSize) throw new IllegalArgumentException(); final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try { int extra = this.maximumPoolSize - maximumPoolSize; this.maximumPoolSize = maximumPoolSize; // 1 if (extra &gt; 0 &amp;&amp; poolSize &gt; maximumPoolSize) { try { Iterator&lt;Worker&gt; it = workers.iterator(); while (it.hasNext() &amp;&amp; extra &gt; 0 &amp;&amp; poolSize &gt; maximumPoolSize) { it.next().interruptIfIdle(); --extra; } } catch (SecurityException ignore) { // Not an error; it is OK if the threads stay live } } } finally { mainLock.unlock(); } } 标注代码分析 根据注释可以理解，如果new maximumPoolSize &gt; maximumPoolSize，则直接设值。如果new maximumPoolSize &lt; maximumPoolSize，中断workers阻塞队列中的闲置Thread。实现RejectedExecutionHandler接口ThreadPoolExecutor#AbortPolicy拒绝当前任务，抛出RejectedExecutionException。ThreadPoolExecutor#CallerRunsPolicy线程池未关闭，直接运行当前任务。ThreadPoolExecutor#DiscardPolicy丢弃当前任务，什么都不操作。ThreadPoolExecutor#DiscardOldestPolicy丢弃Queue的第1个任务，也就是最早添加的Runnable，运行当前任务。3 总结","link":"/JDK1.6-ThreadPoolExecutor/"},{"title":"JVM体系结构(一)","text":"1 JVM体系结构 2 JVM体系结构图 Class Loader Execution Engine 执行引擎 Java Native Interface(JNI)本地接口 Runtime Date Area 运行时数据区 本系列基于JDK7 1 JVM体系结构主要包含两个子系统和两个组件。 Class Loader（类加载器）子系统， Execution Engine（执行引擎）子系统。 Runtim Data Area（运行时数据区域）组件，Native Interface（本地接口）组件。2 JVM体系结构图 Class Loader类加载器负责加载Java类的字节代码到Java虚拟机中，可以根据指定的类名(如java.lang.Object)来装载class文件的内容到Runtime Data Area中的Method Area(方法区域)。Java程序员可以extends java.lang.ClassLoader类来写自己的Class Loader。Execution Engine 执行引擎执行引擎是JVM最核心的组成部分之一，其主要是执行class中的指令，任何JVM实现的核心是Execution Engine。执行引擎可以把Java字节码转为机器能识别的字节码，并调用机器的指令进行计算等，不同JVM的执行效率很大程度决定于他们各自实现的Execution Engine的好坏。“虚拟机”的执行引擎与“物理机”的执行引擎是比较类似的，这两种机器都有执行代码能力，其区别是物理机的执行引擎是直接建立在处理器、硬件、指令集和操作系统层面上的，而虚拟机的执行引擎是自己实现的，因此虚拟机可以自行制定指令集与执行引擎的结构体系，并且能够执行那些不被硬件直接支持的指令。Java Native Interface(JNI)本地接口Java本地接口（Java Native Interface，JNI）是一个标准的Java API，它支持将Java代码与使用其他编程语言编写的代码相集成，例如可以调用Native语言函数C\\C++等。JNI是java与其它编程语言交互的接口。Runtime Date Area 运行时数据区这个组件就是JVM的内存区域，下面对这部分进行详细介绍。这是了解JVM内存模型的重要部分。","link":"/JVM-1/"},{"title":"JVM运行数据区(三)","text":"1 虚拟机栈 VM stack 2 本地方法栈 Native Method stack 3 程序计数器 Program Counter Register 4 方法区 Method Area 方法区内的常量池 - 运行时常量池（Runtime Constant Pool） 5 堆空间 Heap Young（年轻代） 伊甸园（ Eden space） 幸存者0区（ Survivor 0 space）和幸存者1区（ Survivor1 space） Tenured（老年代） Runtime Data Area主要包括五个部分： Heap（堆） Method Area（方法区域） VM Stack（虚拟机栈） Native Method Stack（本地方法栈）（ 在Sun的HotSpot虚拟机中VM Stack和Native method stack是合并到一起的） Program Counter（程序计数器） Heap和Method Area是被所有线程的共享使用的，而Vm Stack, Program Counter和Native Method Stack是以线程为粒度的，每个线程独自拥有。 1 虚拟机栈 VM stackJava虚拟机栈也是线程私有的（每个线程都会拥有的），它的生命周期与线程相同。虚拟机栈描述的是Java方法执行的内存模型：每个方法被执行时都会同时创建一个栈帧（Stack Frame）用于存储局部变量表（基本类型）、操作栈、动态链接（引用对象）、方法出口等信息。每一个方法被调用直至执行完成的过程，就对应着一个栈帧（栈中的每一个元素就被称为栈帧）在虚拟机栈中从入到出栈的过程，每当线程调用一个方法的时候就会向方法栈压入一个新帧。栈存取速度比堆要快，仅次于寄存器。但缺点是，存在栈中的数据大小与生存期必须是确定的，缺乏灵活性。 2 本地方法栈 Native Method stack本地方法栈与虚拟机栈所发挥的作用是非常相似的，其区别不过是虚拟机栈为虚拟机执行Java方法服务的，而本地方法栈则是为虚拟机使用到的本地方法服务。虚拟机规范中对本地方法栈中的方法使用的语言、使用方式与数据结构并没有强制规定，因此具体的虚拟机可以自由实现它。例如Sun HotSpot虚拟机直接把本地方法栈和虚拟机栈合二为一。 3 程序计数器 Program Counter Register程序计数器是是一块较小的内存空间，它的作用可以看做是当前线程所执行的字节码的行号指示器。在虚拟机的概念模型里，字节码解释器工作时就是通过改变这个计数器的选取下一条需要执行的字节码指令，分支、循环、跳转、异常处理、线程恢复等基础功能都需要依赖这个计数器完成。Java虚拟机的多线程是通过线程轮流切换并分配处理器执行时间的方式来实现的，在任何一个确定的时刻，一个处理器（对于多核处理器来说是一个内核）只会执行一条线程中的指令。因此，为了线程切换后能恢复到正确的执行位置，每条线程都需要有一个独立的程序计数器，各条线程之间的计数器互不影响，独立存储，我们称这类内存区域为“线程”私有的内存。 4 方法区 Method Area方法区域存放了所加载的类的信息（名称、修饰符等）、类中的静态变量、类中定义为final类型的常量、类中的Field信息、类中的方法信息等。当开发人员在程序中通过Class对象中的getName等方法来获取信息时，这些数据都来源于方法区域。方法区域也是全局共享的，因此会涉及到多线种访问的同步问题，方法区在一定的条件下它也会被GC，当方法区域需要使用的内存超过其允许的大小时，会抛出JAVA.lang.OutOfMemoryError:PermGen full的错误信息。在Sun JVM中这块区域对应的为Permanet Generation，又称为持久代，Permanet Generation实际上并不等同于方法区，只不过是Hotspot JVM用Permanet Generation来实现方法区而已，有些虚拟机也没有PermSpace而是用其他机制来实现方法区。 方法区内的常量池 - 运行时常量池（Runtime Constant Pool）运行时常量池是方法区（永久代）的一部分。Class文件中除了有类的版本，字段、方法、接口等描述信息外，还有一项信息是常量池（Class文件的常量池），用于存放编译期生成的各种字面量和符号引用，这部分内容将在类加载后存放到方法区的运行时常量池中。运行时常量池相对于Class文件常量池的另外一个重要特征是具备动态性，Java语言并不要求常量一定只能在编译期产生，也就是并非预置入Class文件中常量池的内容才能进入方法区运行时常量池，运行期间也可能将新的常量放入方法区运行时常量池中。这种特性被开发人员利用得比较多的便是String类的intern()。运行时常量池既然是方法区的一部分，自然也会受到方法区内存的限制，当常量池无池再申请到内存时会抛OutOfMenmoryError异常。 5 堆空间 Heap堆空间是Java对象生死存亡的地区，Java对象的出生，成长，死亡都在这个区域完成。 Java程序在运行时创建的所有类实例或数组都放在堆中。堆中的变量所需的存储空间只有在运行时创建了对象之后才能确定。Java的垃圾收集器会自动收走这些不再使用的数据。但缺点是，由于要在运行时动态分配内存，存取速度较慢。每一个Java程序独占一个JVM实例，一个JVM实例只存在一个堆空间，因些每个Java程序都有它自己的堆空间，它们不会彼此干扰。同一个Java程序的多个线程都共享着同一个堆空间，所以就需要考虑多线程访问对象（堆数据）的同步问题。Sun的HotSpot虚拟机对于堆内存共划分为二大部分：年轻代/新生代（Young Generation）、老年代（Old Generation）。 Young（年轻代）JVM规范中的Heap的一部份， 年轻代又分三个区：一个Eden区，两个Survivor区。 伊甸园（ Eden space）Java堆空间中的大部分对象在此出生，该区的名字因此而得名。也即是说当你的Java程序运行时，需要创建新的对象时，JVM都将在该区为你创建一个指定的对象供程序使用。 幸存者0区（ Survivor 0 space）和幸存者1区（ Survivor1 space）当伊甸园的空间用完时，程序又需要创建对象；此时JVM的垃圾回收器将对伊甸园区进行垃圾回收，将伊甸园区中的还存活的对象移动到幸存者0区或1区。幸存者两个区就是用于存放伊甸园垃圾回收时所幸存下来的Java对象。Survivor的两个区是对称的，没先后关系，所以同一个区中可能同时存在从Eden复制过来对象，和从前一个Survivor复制过来的对象，而复制到年老区的只有从第一个Survivor去过来的对象。而且，Survivor区总有一个是空的。（总有1个是空，和另一个Survivor复制到此Survivor意思并不冲突） Tenured（老年代）在年轻代中经历了多次垃圾回收后仍然存活的对象，就会被放到老年代中。因此，可以认为老年代中存放的都是一些生命周期较长的对象。另外一些大对象也会直接进入老年代，可以通过设置JVM参数来指定多大对象直接进入老年代（参数为-XX:PretenureSizeThreshold=1024，单位为字节）。","link":"/JVM-3/"},{"title":"JVM类加载器(二)","text":"1 类加载器的模型 类加载器双亲委派模型 双亲委派模型的优点 2 类加载器的类型 Bootstrap ClassLoader 启动类加载器 Extension ClassLoader 扩展类加载器 Application ClassLoader 应用程序类加载器 User-Defined ClassLoader 用户自定义类加载器 3 类的加载的过程 加载 连接 验证 准备 解析 初始化 类加载器负责加载Java类的字节代码到Java虚拟机中，可以根据指定的类名(如java.lang.Object)来装载class文件的内容到Runtime Data Area中的Method Area(方法区域)。Java程序员可以extends java.lang.ClassLoader类来写自己的Class loader。 1 类加载器的模型类加载器双亲委派模型如果一个类加载器接收到了类加载的请求，它首先把这个请求委托给他的父类加载器去完成，每个层次的类加载器都是如此，因此所有的加载请求都应该传送到顶层的启动类加载器中，只有当父加载器反馈自己无法完成这个加载请求（它在搜索范围中没有找到所需的类）时，子加载器才会尝试自己去加载。 双亲委派模型的优点Java类随着它的类加载器一起具备了一种带有优先级的层次关系。例如类java.lang.Object，它存放在tools.jar中，无论哪个类加载器要加载这个类，最终都会委派给启动类加载器进行加载，因此Object类在程序的各种类加载器环境中都是同一个类。相反，如果用户自己写了一个名为java.lang.Object的类，并放在程序的Classpath中，那系统中将会出现多个不同的Object类，Java类型体系中最基础的行为也无法保证，应用程序也会变得一片混乱。 2 类加载器的类型站在JVM的角度讲，主要有两种类型加载器：启动类加载器和其它的类加载器。启动类加载器是JVM实现的一部分，使用C++语言实现，其它类加载器都由Java语言实现 ，独立于虚拟机外部，并且全部继承抽象类java.lang.ClassLoader。 Bootstrap ClassLoader 启动类加载器这是JVM的根ClassLoader，它是用C++实现的，JVM启动时初始化此ClassLoader，并由此ClassLoader完成$JAVA_HOME$中jre\\lib\\rt.jar（Sun JDK的实现）中所有class文件的加载，这个jar中包含了Java规范定义的所有接口以及实现（加载可信的类，包括Java的API）。启动类加载器无法被Java程序直接引用，Java程序在它开始运行之前并非被完全加载，其各个部分是在必需时才加载。 Extension ClassLoader 扩展类加载器扩展类加载器负责加载&lt;JAVA＿HOME&gt;\\lib\\ext目录中或者java.ext.dirs系统变量所指定的所有类库，开发者可以直接使用扩展类加载器。 Application ClassLoader 应用程序类加载器JVM用此classloader来加载用户类路径 (Classpath)上所指定的类库，包含指定的jar包以及目录，该加载器有时也称为系统类加载器。开发者可以直接使用这个类加载器，如果应用程序中没有自定义过自己的类加载器，一般情况下这个就是程序中默认的类加载器。 User-Defined ClassLoader 用户自定义类加载器User-DefinedClassLoader是Java开发人员继承ClassLoader抽象类自行实现的ClassLoader，基于自定义的ClassLoader可用于加载非Classpath中的jar以及目录。 3 类的加载的过程类的加载过程：加载，链接，初始化。 加载加载过程负责找到二进制字节码并加载至JVM中，JVM通过类名、类所在的包名通过ClassLoader来完成类的加载。 连接链接过程负责对二进制字节码的格式进行校验、初始化装载类中的静态变量以及解析类中调用的接口、类。 验证确保被导入类的正确性。 准备为类变量分配内存，并将其初始化为默认值。 解析解析这个类创建的对其他类的所有引用。 初始化初始化过程即为有父类的情况，对父类初始化，或者执行类中的静态初始化代码、构造器代码以及静态属性的初始化，在四种情况下初始化过程会被触发执行：调用new；反射调用类中的方法；子类调用了初始化；JVM启动过程中指定的初始化类。所有的类都是在对其第一次使用时候，动态加载到JVM中。当程序创建第一个对类的静态成员引用时，就会加载这个类。这个证明构造方法也是静态方法，即使构造方法没有static关键字。因此new操作符创建类的新对象也会被当做对类的静态成员的引用。","link":"/JVM-2/"},{"title":"JVM内存调整(五)","text":"JVM运行时数据区的内存大小可以通过参数来设置，通常能设置的两块区域为堆空间和持久代（方法区），设置方法是以参数的形式来指定，Sun的HotSpot需要在JVM启动前设置这些参数，启动JVM后不能动态改变其大小。JVM参数说明：不同的Java程序设置参数的地方不一样，但参数名称是一样的。例： 启动一般Java程序可以使用以下方式设置启动时的JVM参数： 123456JAVA -Xms2g -Xmx2g -Xmn512M -Xss128K -XX:PermSize=128M-XX:MaxPermSize=128M-XX:NewRatio=4-XX:SurivorRatio=4-XX:MaxTenuringThreshold=1 设置eclipse的JVM参数一般是在eclipse安装目录下的eclipse.ini文件中。 设置tomcat的JVM参数是在tomcat的bin目录下的catalina.bat文件中。 如果是启动main()，则直接在启动命令上添加JVM参数设置。","link":"/JVM-5/"},{"title":"JVM堆内存,堆外内存","text":"1、概念 堆内存 堆外内存 堆外内存优点 堆外内存缺点 2、堆外内存释放 2.1 ByteBuffer ByteBuffer释放堆外内存，源码查看 2.2 Unsafe 1、概念JVM可以使用的内存分外2种：堆内存和堆外内存。 堆内存由JVM负责分配和释放，如果程序没有缺陷代码导致内存泄露，那么就不会遇到java.lang.OutOfMemoryError（OOM）这个错误。 堆外内存直接分配和释放内存，提高效率。堆外内存意味着把内存对象分配在Java虚拟机的堆以外的内存，这些内存直接受操作系统管理（而不是虚拟机）。这样做的结果就是能保持一个较小的堆，以减少垃圾收集对应用的影响。JDK5.0之后，代码中能直接操作本地内存的方式有2种：使用未公开的Unsafe和NIO的ByteBuffer。存储对象生命周期比较长，对象数据结构比较单一。 堆外内存优点 可以扩展至更大的内存空间。 理论上能减少GC暂停时间。因为垃圾回收会暂停其他的工作。 可以在进程间共享，减少JVM间的对象复制，使得JVM的分割部署更容易实现。因为堆内在flush到远程时，会先复制到直接内存（非堆内存），然后在发送；而堆外内存相当于省略掉了这个工作。 它的持久化存储可以支持快速重启，同时还能够在测试环境中重现生产数据。堆外内存缺点 堆外内存难以控制，如果内存泄漏，那么很难排查。 数据结构不能复杂化，结构单一，最好是基础类型。使用序列化和反序列化，性能比堆内对象还差。 使用堆外内存，不用考虑JVM内存限制，但需要考虑磁盘系统。（HDD或者SSD） 2、堆外内存释放2.1 ByteBufferByteBuffer.allocateDirect分配的堆外内存不需要我们手动释放，GC会自己执行，而且ByteBuffer中也没有提供手动释放的API。也即是说，使用ByteBuffer不用担心堆外内存的释放问题，除非堆内存中的ByteBuffer对象由于错误编码而出现内存泄露。ByteBuffer#allocateDirect()12345678910111213141516171819/** * Allocates a new direct byte buffer. * * &lt;p&gt; The new buffer's position will be zero, its limit will be its * capacity, its mark will be undefined, and each of its elements will be * initialized to zero. Whether or not it has a * {@link #hasArray &lt;/code&gt;backing array&lt;code&gt;} is unspecified. * * @param capacity * The new buffer's capacity, in bytes * * @return The new byte buffer * * @throws IllegalArgumentException * If the &lt;tt&gt;capacity&lt;/tt&gt; is a negative integer */ public static ByteBuffer allocateDirect(int capacity) { return new DirectByteBuffer(capacity); } 测试程序12345public static void main(String[] args) throws Exception { while (true) { ByteBuffer buffer = ByteBuffer.allocateDirect(10 * 1024 * 1024); }} 在Eclipse里设置 打印GC日志：-verbose:gc -XX:+PrintGCDetails 设置堆外内存：-XX:MaxDirectMemorySize=40M 禁止调用GC：-XX:+DisableExplicitGC 1-verbose:gc -XX:+PrintGCDetails -XX:MaxDirectMemorySize=40M ByteBuffer释放堆外内存，源码查看ByteBuffer.allocateDirect(10 * 1024 * 1024)分配内存，进入 DirectByteBuffer(int cap) ，此方法里有调用这个方法 Bits.reserveMemory(size, cap)，这个方法是分配内存和释放垃圾对象。该方法里先执行内存分配，然后释放垃圾对象，进行GC；这个方法后面有段代码cleaner = Cleaner.create(this, new Deallocator(base, size, cap))，这个是创建清理外部内存线程的方法，new Deallocator(base, size, cap)是一个任务实例。DirectByteBuffer#DirectByteBuffer123456789101112131415161718192021222324DirectByteBuffer(int cap) { // package-private super(-1, 0, cap, cap); boolean pa = VM.isDirectMemoryPageAligned(); int ps = Bits.pageSize(); long size = Math.max(1L, (long)cap + (pa ? ps : 0)); Bits.reserveMemory(size, cap); long base = 0; try { base = unsafe.allocateMemory(size); } catch (OutOfMemoryError x) { Bits.unreserveMemory(size, cap); throw x; } unsafe.setMemory(base, size, (byte) 0); if (pa &amp;&amp; (base % ps != 0)) { // Round up to page boundary address = base + ps - (base &amp; (ps - 1)); } else { address = base; } cleaner = Cleaner.create(this, new Deallocator(base, size, cap)); att = null;} DirectByteBuffer#Deallocator123456789101112131415161718192021222324252627private static class Deallocator implements Runnable{ private static Unsafe unsafe = Unsafe.getUnsafe(); private long address; private long size; private int capacity; private Deallocator(long address, long size, int capacity) { assert (address != 0); this.address = address; this.size = size; this.capacity = capacity; } public void run() { if (address == 0) { // Paranoia return; } unsafe.freeMemory(address); address = 0; Bits.unreserveMemory(size, capacity); }} DirectByteBuffer#reserveMemory123456789101112131415161718192021222324252627282930313233static void reserveMemory(long size, int cap) { synchronized (Bits.class) { if (!memoryLimitSet &amp;&amp; VM.isBooted()) { maxMemory = VM.maxDirectMemory(); memoryLimitSet = true; } // -XX:MaxDirectMemorySize limits the total capacity rather than the // actual memory usage, which will differ when buffers are page // aligned. if (cap &lt;= maxMemory - totalCapacity) { reservedMemory += size; totalCapacity += cap; count++; return; } } System.gc(); try { Thread.sleep(100); } catch (InterruptedException x) { // Restore interrupt status Thread.currentThread().interrupt(); } synchronized (Bits.class) { if (totalCapacity + cap &gt; maxMemory) throw new OutOfMemoryError(\"Direct buffer memory\"); reservedMemory += size; totalCapacity += cap; count++; }} 2.2 UnsafeUnsafe分配内存，需要手动去释放内存，不然会报OOM错。使用Unsafe是有风险的，很容易导致内存泄露。12345678910111213public static void main(String[] args) throws NoSuchFieldException, SecurityException, IllegalArgumentException, IllegalAccessException { // 通过反射获取rt.jar下的Unsafe类 Field field = Unsafe.class.getDeclaredField(\"theUnsafe\"); field.setAccessible(true); // 实例化对象 Unsafe unsafe = (Unsafe) field.get(null); while (true) { long pointer = unsafe.allocateMemory(1024 * 1024 * 20); System.out.println(unsafe.getByte(pointer + 1)); // 如果不释放内存,运行一段时间会报错java.lang.OutOfMemoryError // unsafe.freeMemory(pointer); } }","link":"/JVM-Stack-Memory/"},{"title":"深入理解Java内存模型(Final)","text":"1 写final域的重排序规则 2 读final域的重排序规则 3 final域是引用类型 4 为什么final引用不能从构造函数内”溢出” 5 final语义在处理器中的实现 6 JSR-133为什么要增强final的语义 7 参考 与前面介绍的锁和volatile相比较，对final域的读和写更像是普通的变量访问。对于final域，编译器和处理器要遵守两个重排序规则。 在构造函数内对一个final域的写入，与随后把这个被构造对象的引用赋值给一个引用变量，这两个操作之间不能重排序。 初次读一个包含final域的对象的引用，与随后初次读这个final域，这两个操作之间不能重排序。 下面，我们通过一些示例性的代码来分别说明这两个规则。1234567891011121314151617181920public class FinalExample { int i; //普通变量 final int j; //final变量 static FinalExample obj; public void FinalExample () { //构造函数 i = 1; //写普通域 j = 2; //写final域 } public static void writer () { //写线程A执行 obj = new FinalExample (); } public static void reader () { //读线程B执行 FinalExample object = obj; //读对象引用 int a = object.i; //读普通域 int b = object.j; //读final域 }} 这里假设一个线程A执行writer()，随后另一个线程B执行reader()。下面我们通过这两个线程的交互来说明这两个规则。 1 写final域的重排序规则写final域的重排序规则禁止把final域的写重排序到构造函数之外。这个规则的实现包含下面2个方面。 JMM禁止编译器把final域的写重排序到构造函数之外。 编译器会在final域的写之后，构造函数return之前，插入一个StoreStore屏障。这个屏障禁止处理器把final域的写重排序到构造函数之外。 现在让我们分析writer()。writer()只包含一行代码：finalExample = new FinalExample()。这行代码包含两个步骤。 构造一个FinalExample类型的对象； 把这个对象的引用赋值给引用变量obj。 假设线程B读对象引用与读对象的成员域之间没有重排序（马上会说明为什么需要这个假设），下图是一种可能的执行时序。在上图中，写普通域的操作被编译器重排序到了构造函数之外，读线程B错误的读取了普通变量i初始化之前的值。而写final域的操作，被写final域的重排序规则“限定”在了构造函数之内，读线程B正确的读取了final变量初始化之后的值。写final域的重排序规则可以确保：在对象引用为任意线程可见之前，对象的final域已经被正确初始化过了，而普通域不具有这个保障。以上图为例，在读线程B“看到”对象引用obj时，很可能obj对象还没有构造完成（对普通域i的写操作被重排序到构造函数外，此时初始值2还没有写入普通域i）。 2 读final域的重排序规则读final域的重排序规则如下。在一个线程中，初次读对象引用与初次读该对象包含的final域，JMM禁止处理器重排序这两个操作（注意，这个规则仅仅针对处理器）。编译器会在读final域操作的前面插入一个LoadLoad屏障。初次读对象引用与初次读该对象包含的final域，这两个操作之间存在间接依赖关系。由于编译器遵守间接依赖关系，因此编译器不会重排序这两个操作。大多数处理器也会遵守间接依赖，大多数处理器也不会重排序这两个操作。但有少数处理器允许对存在间接依赖关系的操作做重排序（比如alpha处理器），这个规则就是专门用来针对这种少部分处理器（会重排序间接依赖关系的处理器）。reader()包含三个操作。 初次读引用变量obj。 初次读引用变量obj指向对象的普通域j。 初次读引用变量obj指向对象的final域i。 现在我们假设写线程A没有发生任何重排序，同时程序在不遵守间接依赖的处理器上执行，下面是一种可能的执行时序。在上图中，读对象的普通域的操作被处理器重排序到读对象引用之前。读普通域时，该域还没有被写线程A写入，这是一个错误的读取操作。而读final域的重排序规则会把读对象final域的操作“限定”在读对象引用之后，此时该final域已经被A线程初始化过了，这是一个正确的读取操作。读final域的重排序规则可以确保：在读一个对象的final域之前，一定会先读包含这个final域的对象的引用。在这个示例程序中，如果该引用不为null，那么引用对象的final域一定已经被A线程初始化过了。 3 final域是引用类型上面我们看到的final域是基础数据类型，下面让我们看看如果final域是引用类型，将会有什么效果？请看下列示例代码。1234567891011121314151617181920212223public class FinalReferenceExample { final int[] intArray; //final是引用类型 static FinalReferenceExample obj; public FinalReferenceExample () { //构造函数 intArray = new int[1]; //1 intArray[0] = 1; //2 } public static void writerOne () { //写线程A执行 obj = new FinalReferenceExample (); //3 } public static void writerTwo () { //写线程B执行 obj.intArray[0] = 2; //4 } public static void reader () { //读线程C执行 if (obj != null) { //5 int temp1 = obj.intArray[0]; //6 } }} 这里final域为一个引用类型，它引用一个int型的数组对象。对于引用类型，写final域的重排序规则对编译器和处理器增加了如下约束。 在构造函数内对一个final引用的对象的成员域的写入，与随后在构造函数外把这个被构造对象的引用赋值给一个引用变量，这两个操作之间不能重排序。 对上面的示例程序，我们假设首先线程A执行writerOne()，执行完后线程B执行writerTwo()，执行完后线程C执行reader()。下面是一种可能的线程执行时序。在上图中，1是对final域的写入，2是对这个final域引用的对象的成员域的写入，3是把被构造的对象的引用赋值给某个引用变量。这里除了前面提到的1不能和3重排序外，2和3也不能重排序。JMM可以确保读线程C至少能看到写线程A在构造函数中对final引用对象的成员域的写入。即C至少能看到数组下标0的值为1。而写线程B对数组元素的写入，读线程C可能看的到，也可能看不到。JMM不保证线程B的写入对读线程C可见，因为写线程B和读线程C之间存在数据竞争，此时的执行结果不可预知。如果想要确保读线程C看到写线程B对数组元素的写入，写线程B和读线程C之间需要使用同步原语（lock或volatile）来确保内存可见性。 4 为什么final引用不能从构造函数内”溢出”前面我们提到过，写final域的重排序规则可以确保：在引用变量为任意线程可见之前，该引用变量指向的对象的final域已经在构造函数中被正确初始化过了。其实要得到这个效果，还需要一个保证：在构造函数内部，不能让这个被构造对象的引用为其他线程可见，也就是对象引用不能在构造函数中“溢出”。为了说明问题，让我们来看下面示例代码。12345678910111213141516171819public class FinalReferenceEscapeExample { final int i; static FinalReferenceEscapeExample obj; public FinalReferenceEscapeExample () { i = 1; //1写final域 obj = this; //2 this引用在此“逸出”，被其他线程所看见 } public static void writer() { new FinalReferenceEscapeExample (); } public static void reader { if (obj != null) { //3 int temp = obj.i; //4 } }} 假设一个线程A执行writer()，另一个线程B执行reader()。这里的操作2使得对象还未完成构造前就为线程B可见。即使这里的操作2是构造函数的最后一步，且即使在程序中操作2排在操作1后面，执行read()的线程仍然可能无法看到final域被初始化后的值，因为这里的操作1和操作2之间可能被重排序。实际的执行时序可能如下图所示。从上图我们可以看出：在构造函数返回前，被构造对象的引用不能为其他线程可见，因为此时的final域可能还没有被初始化。在构造函数返回后，任意线程都将保证能看到final域正确初始化之后的值。 5 final语义在处理器中的实现现在我们以x86处理器为例，说明final语义在处理器中的具体实现。上面我们提到，写final域的重排序规则会要求译编器在final域的写之后，构造函数return之前，插入一个StoreStore障屏。读final域的重排序规则要求编译器在读final域的操作前面插入一个LoadLoad屏障。由于x86处理器不会对写-写操作做重排序，所以在x86处理器中，写final域需要的StoreStore障屏会被省略掉。同样，由于x86处理器不会对存在间接依赖关系的操作做重排序，所以在x86处理器中，读final域需要的LoadLoad屏障也会被省略掉。也就是说在x86处理器中，final域的读/写不会插入任何内存屏障！ 6 JSR-133为什么要增强final的语义在旧的Java内存模型中 ，最严重的一个缺陷就是线程可能看到final域的值会改变。比如，一个线程当前看到一个整形final域的值为0（还未初始化之前的默认值），过一段时间之后这个线程再去读这个final域的值时，却发现值变为了1（被某个线程初始化之后的值）。最常见的例子就是在旧的Java内存模型中，String的值可能会改变（参考文献2中有一个具体的例子，感兴趣的读者可以自行参考，这里就不赘述了）。为了修补这个漏洞，JSR-133专家组增强了final的语义。通过为final域增加写和读重排序规则，可以为java程序员提供初始化安全保证：只要对象是正确构造的（被构造对象的引用在构造函数中没有“逸出”），那么不需要使用同步（指lock和volatile的使用），就可以保证任意线程都能看到这个final域在构造函数中被初始化之后的值。 7 参考 深入理解Java内存模型","link":"/JMM-6/"},{"title":"深入理解Java内存模型(总结)","text":"1 处理器内存模型 2 JMM，处理器内存模型与顺序一致性内存模型之间的关系 3 JMM的设计 4 JMM的内存可见性保证 5 JSR-133对旧内存模型的修补 6 参考 1 处理器内存模型顺序一致性内存模型是一个理论参考模型，JMM和处理器内存模型在设计时通常会把顺序一致性内存模型作为参照。JMM和处理器内存模型在设计时会对顺序一致性模型做一些放松，因为如果完全按照顺序一致性模型来实现处理器和JMM，那么很多的处理器和编译器优化都要被禁止，这对执行性能将会有很大的影响。根据对不同类型读/写操作组合的执行顺序的放松，可以把常见处理器的内存模型划分为下面几种类型。 放松程序中写-读操作的顺序，由此产生了total store ordering内存模型（简称为TSO）。 在前面1的基础上，继续放松程序中写-写操作的顺序，由此产生了partial store order内存模型（简称为PSO）。 在前面1和2的基础上，继续放松程序中读-写和读-读操作的顺序，由此产生了relaxed memory order内存模型（简称为RMO）和PowerPC内存模型。 注意，这里处理器对读/写操作的放松，是以两个操作之间不存在数据依赖性为前提的（因为处理器要遵守as-if-serial语义，处理器不会对存在数据依赖性的两个内存操作做重排序）。下面的表格展示了常见处理器内存模型的细节特征。在这个表格中，我们可以看到所有处理器内存模型都允许写-读重排序，原因在第一章以说明过：它们都使用了写缓存区，写缓存区可能导致写-读操作重排序（处理器执行的内存操作和实际内存执行的不一样）。同时，我们可以看到这些处理器内存模型都允许更早读到当前处理器的写，原因同样是因为写缓存区：由于写缓存区仅对当前处理器可见，这个特性导致当前处理器可以比其他处理器先看到临时保存在自己的写缓存区中的写。上面表格中的各种处理器内存模型，从上到下，模型由强变弱。越是追求性能的处理器，内存模型设计的会越弱。因为这些处理器希望内存模型对它们的束缚越少越好，这样它们就可以做尽可能多的优化来提高性能。由于常见的处理器内存模型比JMM要弱，Java编译器在生成字节码时，会在执行指令序列的适当位置插入内存屏障来限制处理器的重排序。同时，由于各种处理器内存模型的强弱并不相同，为了在不同的处理器平台向程序员展示一个一致的内存模型，JMM在不同的处理器中需要插入的内存屏障的数量和种类也不相同。下图展示了JMM在不同处理器内存模型中需要插入的内存屏障的示意图。 2 JMM，处理器内存模型与顺序一致性内存模型之间的关系JMM是一个语言级的内存模型，处理器内存模型是硬件级的内存模型，顺序一致性内存模型是一个理论参考模型。下面是语言内存模型，处理器内存模型和顺序一致性内存模型的强弱对比示意图。从上图我们可以看出：相对于易编程性，常见的4种处理器内存模型比常用的3中语言内存模型要弱，处理器内存模型和语言内存模型都比顺序一致性内存模型要弱。同处理器内存模型一样，越是追求执行性能的语言，内存模型设计的会越弱。 3 JMM的设计从JMM设计者的角度来说，在设计JMM时，需要考虑两个关键因素。 程序员对内存模型的使用。程序员希望内存模型易于理解，易于编程。程序员希望基于一个强内存模型来编写代码。 编译器和处理器对内存模型的实现。编译器和处理器希望内存模型对它们的束缚越少越好，这样它们就可以做尽可能多的优化来提高性能。编译器和处理器希望实现一个弱内存模型。 由于这两个因素互相矛盾，所以JSR-133专家组在设计JMM时的核心目标就是找到一个好的平衡点：一方面要为程序员提供足够强的内存可见性保证；另一方面，对编译器和处理器的限制要尽可能的放松。下面让我们看看JSR-133是如何实现这一目标的。为了具体说明，请看前面提到过的计算圆面积的示例代码。123double pi = 3.14; //Adouble r = 1.0; //Bdouble area = pi * r * r; //C 上面计算圆的面积的示例代码存在三个happens- before关系。 A happens-before B B happens-before C A happens-before C 由于A happens-before B，happens-before的定义会要求：A操作执行的结果要对B可见，且A操作的执行顺序排在B操作之前。 但是从程序语义的角度来说，对A和B做重排序即不会改变程序的执行结果，也还能提高程序的执行性能（允许这种重排序减少了对编译器和处理器优化的束缚）。也就是说，上面这3个happens-before关系中，虽然2和3是必需要的，但1是不必要的。因此，JMM把happens-before要求禁止的重排序分为了下面两类。 会改变程序执行结果的重排序。 不会改变程序执行结果的重排序。 JMM对这两种不同性质的重排序，采取了不同的策略。 对于会改变程序执行结果的重排序，JMM要求编译器和处理器必须禁止这种重排序。 对于不会改变程序执行结果的重排序，JMM对编译器和处理器不作要求（JMM允许这种重排序）。 下面是JMM的设计示意图。从上图可以看出两点。 JMM向程序员提供的happens-before规则能满足程序员的需求。JMM的happens-before规则不但简单易懂，而且也向程序员提供了足够强的内存可见性保证（有些内存可见性保证其实并不一定真实存在，比如上面的A happens-before B）。 JMM对编译器和处理器的束缚已经尽可能的少。从上面的分析我们可以看出，JMM其实是在遵循一个基本原则：只要不改变程序的执行结果（指的是单线程程序和正确同步的多线程程序），编译器和处理器怎么优化都行。比如，如果编译器经过细致的分析后，认定一个锁只会被单个线程访问，那么这个锁可以被消除。再比如，如果编译器经过细致的分析后，认定一个volatile变量仅仅只会被单个线程访问，那么编译器可以把这个volatile变量当作一个普通变量来对待。这些优化既不会改变程序的执行结果，又能提高程序的执行效率。 4 JMM的内存可见性保证Java程序的内存可见性保证按程序类型可以分为下列三类。 单线程程序。单线程程序不会出现内存可见性问题。编译器，runtime和处理器会共同确保单线程程序的执行结果与该程序在顺序一致性模型中的执行结果相同。 正确同步的多线程程序。正确同步的多线程程序的执行将具有顺序一致性（程序的执行结果与该程序在顺序一致性内存模型中的执行结果相同）。这是JMM关注的重点，JMM通过限制编译器和处理器的重排序来为程序员提供内存可见性保证。 未同步/未正确同步的多线程程序。JMM为它们提供了最小安全性保障：线程执行时读取到的值，要么是之前某个线程写入的值，要么是默认值(0,null,false)。 下图展示了这三类程序在JMM中与在顺序一致性内存模型中的执行结果的异同。只要多线程程序是正确同步的，JMM保证该程序在任意的处理器平台上的执行结果，与该程序在顺序一致性内存模型中的执行结果一致。 5 JSR-133对旧内存模型的修补JSR-133对JDK5之前的旧内存模型的修补主要有两个。 增强volatile的内存语义。旧内存模型允许volatile变量与普通变量重排序。JSR-133严格限制volatile变量与普通变量的重排序，使volatile的写-读和锁的释放-获取具有相同的内存语义。 增强final的内存语义。在旧内存模型中，多次读取同一个final变量的值可能会不相同。为此，JSR-133为final增加了两个重排序规则。现在，final具有了初始化安全性。6 参考 深入理解Java内存模型","link":"/JMM-7/"},{"title":"JVM垃圾回收(四)","text":"1 垃圾回收概念 什么是垃圾回收 GC的基本原理 为什么要垃圾回收 哪些区域会被GC 2 垃圾收集算法 标记-清除算法 复制算法 标记-整理算法 分代收集算法 3 垃圾收集器 串行收集器（Serial Collector） 吞吐量优先的并行收集器（Throughput Collector） 策略 年轻代暂停应用程序 年老代暂停应用程序 暂停时间优先的并发收集器(Concurrent Low Pause Collector-CMS) 策略 年轻代同样是暂停应用程序 年老代则只有两次短暂停 并行(Parallel)与并发(Concurrent)区别 老年代 年轻代 垃圾回收类型 4 HotSpot垃圾回收机制 垃圾收集简易流程图 伊甸园区 Eden 幸存者0区和幸存者1区 Survivor0 Survivor1 老年代 Tenured Generation 方法区（持久代） Perm Generation 1 垃圾回收概念什么是垃圾回收JVM中自动检测并移除不再使用的数据对象的这种机制称为：垃圾回收（Garbage Collection），简称GC。 GC的基本原理JVM通过使用垃圾收集器及使用相应的垃圾回收算法将内存中不再被使用的对象进行回收。 为什么要垃圾回收由于不同Java对象存活时间是不一定的，因此，在程序运行一段时间以后，如果不进行垃圾回收，整个程序会因内存耗尽导致整个程序崩溃。垃圾回收还会整理那些零散的内存碎片，碎片过多最直接的问题就是会导致无法分配大块的内存空间以及降低程序的运行效率。 哪些区域会被GCVM栈、本地方法栈以及程序计数器会随方法或线程的结束而自然被回收，所以这些区域不需要考虑回收问题。堆空间和持久代（方法区）是GC回收的重点区域，不同区域对象的收集叫法不一样。 对年轻代的对象的收集称为minor GC（eden：minor gc，整个新生代：major gc）。 对老年代的对象的收集称为Full GC。程序中主动调用System.gc()强制执行的GC为Full GC。Full GC基本都是整个堆空间及持久代发生了垃圾回收，通常优化的目标之一是尽量减少GC和Full GC的频率。 持久代的垃圾回收和老年代的垃圾回收是绑定的，一旦其中一个区域被占满，这两个区都要进行垃圾回收（Full GC）。 2 垃圾收集算法标记-清除算法最基础的收集算法，如它的名字一样，算法分为“标记”和“清除”两个阶段：首先标记出所有需要回收的对象，在标记完成后统一回收掉所有被标记的对象，之所以说它是最基础的收集算法，是因为很多收集算法都是基于这种思路并对其缺点进行改进而的。它的主要缺点有两个：一个是效率问题，标记和清楚的效率都不高；另一个是空间问题，标记清除后会产生大量不连续的内存碎片，空间碎片太多可能导致，当程序在以后运行过程中需要分配较大对象是无法找到足够的连续内存而不得不提前触发一次垃圾收集动作。 复制算法为了解决效率问题，一种称为“复制”的收集算法出现了，它将可用内存按容量划分为大小相等的两块，每次只使用其中的一块。当这一块的内存用完了，就将还存活着的对象复制到另外一块上面，然后再把已使用过的内存空间一次清理掉。这样使得每次都是对其中一块进行内存回收，内存分配时也就不用考虑内存碎片等复杂情况，只要移动堆顶指针，按顺序分配内存即可，实现简单，运行高效。只是这种算法内存会缩小为原来的一半，太浪费空间。 标记-整理算法由于复制收集算法在对象存活率较高时就要执行较多的复制操作，效率将会变低，更关键的是，如果不想浪费50%的空间，就需要有额外的空间进行分配担保，以应对被使用的内存中所有对象都100%存活的极端情况，所以在老年代一般不能直接选用这种算法（如果100%存活，老年代没有内存空间了，就没有办法按照复制算法来回收）。根据老年代的特点，有人提出了另外一种“标记-整理”算法，标记过程仍然与“标记-清楚”算法一样，但后续步骤不是直接对可回收对象进行清理，而是让所有存活的对象都向一端移动，然后直接清理掉端边界以外的内存。 分代收集算法当前商业虚拟机的垃圾收集都采用“分代收集”算法，这种算法并没有什么新的思想，只是根据对象的存活周期的不同将内存划分为几块。一般是把Java堆分为新生代和老年代，这样就可以根据各个年代的特点采用最适当的收集算法。在新生代中，每次垃圾收集时都发现在大批对象死去，只有少量存活，那就选用复制算法，只需要付出少量存活对象的复制成本就可以完成收集。而老年代中因为对象存活率高、没有额外空间对它进行分配担保，就必须使用“标记-清理”或“标记-整理”算法来进行回收。如果说收集算法是内存回收的方法论，垃圾收集器就是内存回收的具体实现，不同的垃圾收集器有不同的内存回收算法（引用计数、标记-清除算法、复制算法、标记-整理算法等）。 JVM规范中对垃圾收集器应该如何实现并没有任何规定，因此不同的厂商、不同版本的JVM所提供的垃圾收集器都可能会有很大的差别，并且一般都会提供参数供用户根据自己的应用特点和要求组合出各个年代所使用的收集器。 3 垃圾收集器串行收集器（Serial Collector）使用单线程处理所有垃圾回收工作，因为无需多线程交互，所以效率比较高。但是它在进行垃圾收集时，必须暂停其它所有的工作线程，直到它收集结束，这对很多应用都是难以接受的，并且也无法使用多处理器的优势，所以此收集器比较适合用在单处理器机器上。这类收集器有：Serial、Serial Old等。使用-XX:+UseSerialGC，策略为年轻代串行复制，老年代串行标记整理。垃圾回收简易图。 吞吐量优先的并行收集器（Throughput Collector）并行收集器可以使用多条线程进行垃圾收集。常用于对年轻代或老年代进行并行垃圾回收，能显著减少垃圾回收时间，一般会在多线程多处理器机器上使用。这类收集器有：ParNew，Parallel Scavenge，Parallel Old等。使用-XX:+UseParallelGC，也是JDK5 -server的默认值。已默认无需配置的参数：-XX:+UseAdaptiveSizePolicy(动态调整新生代大小)。垃圾回收简易图。 策略年轻代暂停应用程序多个垃圾收集线程并行的复制收集，线程数默认为CPU个数，CPU很多时，可用–XX:ParallelGCThreads=减少线程数。 年老代暂停应用程序与串行收集器一样，单垃圾收集线程标记整理。所以需要2+的CPU时才会优于串行收集器，适用于后台处理，科学计算。可以使用-XX:MaxGCPauseMillis=和-XX:GCTimeRatio来调整GC的时间。 暂停时间优先的并发收集器(Concurrent Low Pause Collector-CMS)并发收集器主要以保证大部分工作都并发进行（应用不停止），垃圾回收只暂停很少的时间，可以提高服务的响应速度，减少系统停顿的时间，以给用户带来较好的体验，此收集器适合对响应时间要求比较高的中、大规模应用。这类收集器有：CMS等。采用CMS时候，新生代必须使用Serial GC或者ParNew GC两种。CMS共有七个步骤，只有Initial Marking和Final Marking两个阶段是stop-the-world（暂停应用）的，其他步骤均和应用并行进行。持久代的GC也采用CMS，通过-XX：CMSPermGenSweepingEnabled -XX：CMSClassUnloadingEnabled来制定。在采用CMS GC的情况下，Young Generation变慢的原因通常是由于Old Generation出现了大量的碎片。老年代GC慢了，会影响年轻代。使用-XX:+UseConcMarkSweepGC，已默认无需配置的参数：-XX:+UseParNewGC(Parallel收集新生代)，-XX:+CMSPermGenSweepingEnabled(CMS收集持久代) ，-XX:UseCMSCompactAtFullCollection(Full GC时压缩年老代)。 策略年轻代同样是暂停应用程序多个垃圾收集线程并行的复制收集。此时年轻代的CMS垃圾收集算法和Serial/Parallel GC一样，需要暂停应用，进行垃圾收集。 年老代则只有两次短暂停其他时间应用程序与收集线程并发的清除，来回收以减少应用暂停时间。注：以上提到的这些垃圾收集器都可以通过jvm参数配置来指定该jvm使用那一种垃圾收集器，例如使用-XX:+UseSerialGC可以打开使用Serial作为垃圾收集器进行内存回收。 并行(Parallel)与并发(Concurrent)区别 并行：指多条垃圾收集线程并行。 并发：指用户线程与垃圾收集线程并发，程序在继续运行，而垃圾收集程序运行于另一个个CPU上。老年代并发收集一开始会很短暂的停止一次所有线程来开始初始标记根对象，然后标记线程与应用线程一起并发运行，最后又很短的暂停一次，多线程并行的重新标记之前可能因为并发而漏掉的对象，然后就开始与应用程序并发的清除过程。可见，最长的两个遍历过程都是与应用程序并发执行的，比以前的串行算法改进太多太多了！这就是CMS算法的核心流程。串行标记清除是等年老代满了再开始收集的，而并发收集因为要与应用程序一起运行，如果满了才收集，应用程序就无内存可用，所以系统默认68%满的时候就开始收集。内存已设得较大，吃内存又没有这么快的时候，可以用-XX:CMSInitiatingOccupancyFraction=恰当增大该比率。年轻代年轻代的复制收集，依然必须停止所有应用程序线程，原理如此，只能靠多CPU，多收集线程并发来提高收集速度，但除非你的Server独占整台服务器，否则如果服务器上本身还有很多其他线程时，切换起来速度就….. 所以，搞到最后，暂停时间的瓶颈就落在了年轻代的复制算法上。因此Young的大小设置挺重要的，大点就不用频繁GC，而且增大GC的间隔后，可以让多点对象自己死掉而不用复制了。但Young增大时，GC造成的停顿时间攀升得非常恐怖，比如在我的机器上，默认8M的Young，只需要几毫秒的时间，64M就升到90毫秒，而升到256M时，就要到300毫秒了，峰值还会攀到恐怖的800ms。谁叫复制算法，要等Young满了才开始收集，开始收集就要停止所有线程呢。垃圾回收类型 Minor GC：Young Generation当新创建对象，内存空间不够的时候，就会执行这个垃圾回收。由于执行最频繁，因此一般采用复制回收机制。 Major GC：清理Old Generation的内存，这里一般采用的是标记清除+标记整理机制。 Full GC：全面的垃圾回收。4 HotSpot垃圾回收机制垃圾收集简易流程图垃圾收集器：Young-&gt;Old简易流程图伊甸园区 Eden启动Java程序时，JVM随之启动，并将JDK的类和接口以及Java程序运行时需要的类和接口及编译后的Class文件或JAR包中的Class文件装载到JVM的方法区，在Eden中创建JVM、程序运行时必须的Java对象，当Eden的空间不足以用来创建新Java对象的时候，JVM的垃圾回收器执行对Eden区的垃圾回收工作，销毁那些不再被其他对象引用的Java对象，并将那些被其他对象所引用的Java对象（未被回收的对象）移动到幸存者0区。幸存者0区和幸存者1区 Survivor0 Survivor1如果幸存者0区有足够空间存放则直接放到幸存者0区；如果幸存者0区没有足够空间存放，则JVM的垃圾回收器执行对幸存者0区的垃圾回收工作，销毁那些不再被其他对象引用的Java对象，并将那些被其他对象所引用的Java对象移动到幸存者1区。 如果幸存者1区有足够空间存放则直接放到幸存者1区；如果幸存者1区没有足够空间存放，则JVM的垃圾回收器执行对幸存者1区的垃圾回收工作，销毁那些不再被其他对象引用的Java对象，并将那些被其他对象所引用的Java对象移动到年老区。老年代 Tenured Generation如果年老区有足够空间存放则直接放到年老区；如果年老区没有足够空间存放，则JVM的垃圾回收器执行对年老区的垃圾回收工作，销毁那些不再被其他对象引用的Java对象，并保留那些被其他对象所引用的Java对象。如果到最后年老区，幸存者1区，幸存者0区和伊甸园区都没有空间的话，则JVM会报告：“JVM堆空间溢出（java.lang.OutOfMemoryError:javaheap space）”，也即是在堆空间没有空间来创建对象。方法区（持久代） Perm GenerationJVM的规范中没有规定必须实现永久代的垃圾收集。也就是说，不一定必须实现。而且永久代的垃圾回收”性价比”很低，新生代进行一次gc，一般可以回收70%-95%，但是永久代远低于此。永久代的垃圾收集主要分两个部分：废弃常量和无用的类。如果一个应用装载的class类比较多，永久代分配内存小的话，也会出现”永久存储区溢出（java.lang.OutOfMemoryError:java Permanent Space）”。","link":"/JVM-4/"},{"title":"JVM调优案例分析-Eclipse启动","text":"1 为什么要进行JVM调优 2 如何JVM调优 JVM调优参数配置 3 Eclipse启动调优 系统环境 调优示例 初始化加载 分析 第1次调优 分析 第2次调优 分析 第3次调优 分析 1 为什么要进行JVM调优运行在JVM上的程序都会进行内存分配以及垃圾回收，在这个过程中设置合理的内存大小及垃圾回收算法能显著提高应用的响应速度及运行效率，相反不合理的JVM参数设置会造成应用程序响应不稳定并导致整个应用程序挂掉。 2 如何JVM调优不同类型应用程序的JVM参数设置都不一样，如何设置最优的JVM参数不仅需要对GC机制有一定的了解，而且还要反复的试验才能得出最合适的JVM参数值。例如：某些系统要求运行稳定、并且响应速度高，这类应用就需要通过调整其JVM参数来减少内存大小调整及垃圾回收所占用的时间，以尽量的提高响应速度。报表类及容易产生大对象对响应速度要求不是很高的系统，可以把堆空间设置较大些。除了了解GC的机制外等一些基本调优方法外，往往还需要借助一些监控工具来进行JVM参数调优，例：Jprofiler 、VisualVM、Jconsole等，通过这些工具可以监控JVM运行时内存分配情况，线程状态、数量，堆空间类、对象数量类型信息等，此外还可以借助分析垃圾回收日志对JVM进行优化。 JVM调优参数配置1234567891011121314-verbose:gc （开启打印垃圾回收日志）-Xloggc:eclipse_gc.log （设置垃圾回收日志打印的文件，文件名称可以自定义）-XX:+PrintGCTimeStamps （打印垃圾回收时间信息时的时间格式）-XX:+PrintGCDetails （打印垃圾回收详情）-Xms50m（堆最小值） –Xmx200m -XX:PermSize=30m（JDK8 = -XX:MetaspaceSize=256m）-XX:MaxPermSize=60m//添加JVM监控参数-Djava.rmi.server.hostname=127.0.0.1 -Dcom.sun.management.jmxremote.port=6688 -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.authenticate=false 3 Eclipse启动调优系统环境12345CPU：Intel I5-4590 @3.30GHz内存：8G系统：win7 @64位Eclipse：Luna Service Release 1 (4.4.1)JDK：8 调优示例初始化加载eclipse.ini配置123456789101112131415161718192021222324-startupplugins/org.eclipse.equinox.launcher_1.3.0.v20140415-2008.jar--launcher.libraryplugins/org.eclipse.equinox.launcher.win32.win32.x86_64_1.1.200.v20140603-1326-productorg.eclipse.epp.package.jee.product--launcher.defaultActionopenFile--launcher.XXMaxPermSize256M-showsplashorg.eclipse.platform--launcher.XXMaxPermSize512m--launcher.defaultActionopenFile--launcher.appendVmargs-vmargs-Dosgi.requiredJavaVersion=1.6 -javaagent:lombok.jar-verbose:gc-Xloggc:eclipse_test_gc.log-XX:+PrintGCTimeStamps-XX:+PrintGCDetails gc.log12345678910111213141516170.755: [GC (Allocation Failure) [PSYoungGen: 131584K-&gt;3908K(153088K)] 131584K-&gt;3916K(502784K), 0.0061911 secs] [Times: user=0.03 sys=0.00, real=0.01 secs] 1.450: [GC (Allocation Failure) [PSYoungGen: 135492K-&gt;20964K(153088K)] 135500K-&gt;20988K(502784K), 0.0218611 secs] [Times: user=0.06 sys=0.00, real=0.02 secs] 2.027: [GC (Metadata GC Threshold) [PSYoungGen: 130012K-&gt;21489K(153088K)] 130036K-&gt;25430K(502784K), 0.0221815 secs] [Times: user=0.06 sys=0.00, real=0.02 secs]2.049: [Full GC (Metadata GC Threshold) [PSYoungGen: 21489K-&gt;0K(153088K)] [ParOldGen: 3940K-&gt;25211K(349696K)] 25430K-&gt;25211K(502784K), [Metaspace: 19524K-&gt;19524K(1069056K)], 0.0830986 secs] [Times: user=0.27 sys=0.00, real=0.08 secs] 3.775: [GC (Allocation Failure) [PSYoungGen: 131584K-&gt;10997K(190464K)] 156795K-&gt;36217K(540160K), 0.0247439 secs] [Times: user=0.05 sys=0.00, real=0.02 secs] 4.839: [GC (Metadata GC Threshold) [PSYoungGen: 186429K-&gt;20045K(261632K)] 211648K-&gt;45272K(611328K), 0.0179861 secs] [Times: user=0.03 sys=0.02, real=0.02 secs] 4.857: [Full GC (Metadata GC Threshold) [PSYoungGen: 20045K-&gt;0K(261632K)] [ParOldGen: 25227K-&gt;41383K(399360K)] 45272K-&gt;41383K(660992K), [Metaspace: 32389K-&gt;32389K(1081344K)], 0.1242518 secs] [Times: user=0.36 sys=0.00, real=0.12 secs] 6.307: [GC (Allocation Failure) [PSYoungGen: 241152K-&gt;18220K(274432K)] 282535K-&gt;59611K(673792K), 0.0172074 secs] [Times: user=0.06 sys=0.00, real=0.02 secs] 7.997: [GC (Allocation Failure) [PSYoungGen: 261420K-&gt;25680K(273408K)] 302811K-&gt;67079K(672768K), 0.0185006 secs] [Times: user=0.08 sys=0.00, real=0.02 secs] 8.268: [GC (Metadata GC Threshold) [PSYoungGen: 82395K-&gt;20501K(347136K)] 123794K-&gt;61908K(746496K), 0.0151410 secs] [Times: user=0.01 sys=0.00, real=0.02 secs] 8.284: [Full GC (Metadata GC Threshold) [PSYoungGen: 20501K-&gt;0K(347136K)] [ParOldGen: 41407K-&gt;56860K(558592K)] 61908K-&gt;56860K(905728K), [Metaspace: 53496K-&gt;53496K(1099776K)], 0.2932783 secs] [Times: user=0.75 sys=0.00, real=0.29 secs] 10.175: [GC (Allocation Failure) [PSYoungGen: 313856K-&gt;17170K(346112K)] 370716K-&gt;74039K(904704K), 0.0169520 secs] [Times: user=0.01 sys=0.00, real=0.02 secs] 12.128: [GC (Allocation Failure) [PSYoungGen: 331026K-&gt;26531K(394240K)] 387895K-&gt;83408K(952832K), 0.0273926 secs] [Times: user=0.06 sys=0.01, real=0.03 secs] 13.499: [GC (Allocation Failure) [PSYoungGen: 390563K-&gt;32749K(396800K)] 447440K-&gt;93985K(955392K), 0.0303289 secs] [Times: user=0.06 sys=0.02, real=0.03 secs] 14.154: [GC (Metadata GC Threshold) [PSYoungGen: 192786K-&gt;34344K(458752K)] 254022K-&gt;95587K(1017344K), 0.0309133 secs] [Times: user=0.06 sys=0.02, real=0.03 secs] 14.185: [Full GC (Metadata GC Threshold) [PSYoungGen: 34344K-&gt;0K(458752K)] [ParOldGen: 61243K-&gt;88940K(785920K)] 95587K-&gt;88940K(1244672K), [Metaspace: 89904K-&gt;89904K(1134592K)], 0.1934725 secs] [Times: user=0.42 sys=0.00, real=0.19 secs] 启动时间14s，GC=16，其中Full GC=4，PSYoungGen GC=12。 分析 GC次数太多。 real-time=0.94s 。 每次Full GC的时候，ParOldGen（老年代）值没有GC操作，说明ParOldGen（老年代）内存足够；Metaspace值也没有GC操作，Metaspace的内存也足够。 0.755s，YoungGen（年轻代）GC前占130m，GC后占3.9m，销毁对象127m，总内存150。从这里可以看出GC操作销毁无用对象占用总内存比例比较高。解决方式：提高YoungGen（年轻代）内存 第1次调优eclipse.ini配置1234567891011121314151617181920212223242526272829303132-startupplugins/org.eclipse.equinox.launcher_1.3.0.v20140415-2008.jar--launcher.libraryplugins/org.eclipse.equinox.launcher.win32.win32.x86_64_1.1.200.v20140603-1326-productorg.eclipse.epp.package.jee.product--launcher.defaultActionopenFile--launcher.XXMaxPermSize256M-showsplashorg.eclipse.platform--launcher.XXMaxPermSize512m--launcher.defaultActionopenFile--launcher.appendVmargs-vmargs-Dosgi.requiredJavaVersion=1.6 -javaagent:lombok.jar-verbose:gc-Xloggc:eclipse_test_gc.log-XX:+PrintGCTimeStamps-XX:+PrintGCDetails-Xms512m–Xmx512m -Xmn300m-XX:MetaspaceSize=512m-Djava.rmi.server.hostname=127.0.0.1 -Dcom.sun.management.jmxremote.port=6688 -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.authenticate=false 初始化堆：512m，最大堆：512m，年轻代：300，survivor0:150m，survivor1=150m，tenured Generation：212m，metaspace=512mgc.log123456789101.475: [GC (Allocation Failure) [PSYoungGen: 269312K-&gt;20675K(313856K)] 269312K-&gt;20699K(479744K), 0.0258210 secs] [Times: user=0.06 sys=0.01, real=0.03 secs] 4.139: [GC (Allocation Failure) [PSYoungGen: 289987K-&gt;36912K(313856K)] 290011K-&gt;36944K(479744K), 0.0751285 secs] [Times: user=0.20 sys=0.01, real=0.08 secs] 5.792: [GC (Allocation Failure) [PSYoungGen: 306224K-&gt;44540K(313856K)] 306256K-&gt;48936K(479744K), 0.0568584 secs] [Times: user=0.17 sys=0.02, real=0.06 secs] 7.648: [GC (Allocation Failure) [PSYoungGen: 313852K-&gt;44523K(313856K)] 318248K-&gt;62079K(479744K), 0.0543820 secs] [Times: user=0.14 sys=0.00, real=0.05 secs] 9.127: [GC (Allocation Failure) [PSYoungGen: 313835K-&gt;44531K(313856K)] 331391K-&gt;79425K(479744K), 0.0544645 secs] [Times: user=0.13 sys=0.00, real=0.05 secs] 10.753: [GC (Allocation Failure) [PSYoungGen: 313843K-&gt;44533K(242176K)] 348737K-&gt;93038K(408064K), 0.0475107 secs] [Times: user=0.16 sys=0.00, real=0.05 secs] 12.530: [GC (Allocation Failure) [PSYoungGen: 242165K-&gt;39059K(278016K)] 290670K-&gt;106623K(443904K), 0.0549795 secs] [Times: user=0.17 sys=0.00, real=0.06 secs] 13.380: [GC (Allocation Failure) [PSYoungGen: 236691K-&gt;30476K(281600K)] 304255K-&gt;113511K(447488K), 0.0335930 secs] [Times: user=0.13 sys=0.00, real=0.03 secs] 14.123: [GC (Allocation Failure) [PSYoungGen: 234252K-&gt;26140K(280576K)] 317287K-&gt;118931K(446464K), 0.0381255 secs] [Times: user=0.09 sys=0.00, real=0.04 secs] 15.143: [GC (Allocation Failure) [PSYoungGen: 229916K-&gt;14606K(279552K)] 322707K-&gt;123709K(445440K), 0.0284687 secs] [Times: user=0.08 sys=0.00, real=0.03 secs] 启动时间15s，GC=10，其中Full GC=0，PSYoungGen GC=10。 分析 real-time=0.48s，时间已经比初始化时减少50%。 Full GC已经没有了，说明堆内存变大。 PSYoungGen内存依然不够大，GC次数高达10次。 解决方式：继续提高堆内存，提高PSYoungGen内存。 第2次调优eclipse.ini配置1234567891011121314151617181920212223242526272829-startupplugins/org.eclipse.equinox.launcher_1.3.0.v20140415-2008.jar--launcher.libraryplugins/org.eclipse.equinox.launcher.win32.win32.x86_64_1.1.200.v20140603-1326-productorg.eclipse.epp.package.jee.product--launcher.defaultActionopenFile--launcher.XXMaxPermSize256M-showsplashorg.eclipse.platform--launcher.XXMaxPermSize512m--launcher.defaultActionopenFile--launcher.appendVmargs-vmargs-Dosgi.requiredJavaVersion=1.6 -javaagent:lombok.jar-verbose:gc-Xloggc:eclipse_test_gc.log-XX:+PrintGCTimeStamps-XX:+PrintGCDetails-Xms1024m–Xmx1024m -Xmn768m-XX:MetaspaceSize=512m-XX:+UseConcMarkSweepGC 初始化堆：1024m，最大堆：1024m，年轻代：768，survivor0:384m，survivor1=384m，tenured Generation：256m，metaspace=512mgc.log1234567891011123.590: [GC (Allocation Failure) 3.590: [ParNew: 629248K-&gt;41257K(707840K), 0.0421096 secs] 629248K-&gt;41257K(969984K), 0.0423289 secs] [Times: user=0.11 sys=0.02, real=0.04 secs] 9.514: [GC (Allocation Failure) 9.514: [ParNew: 670505K-&gt;51460K(707840K), 0.1455994 secs] 670505K-&gt;84357K(969984K), 0.1457105 secs] [Times: user=0.47 sys=0.02, real=0.14 secs] 15.587: [GC (Allocation Failure) 15.587: [ParNew: 680708K-&gt;43195K(707840K), 0.0751499 secs] 713605K-&gt;99746K(969984K), 0.0755409 secs] [Times: user=0.20 sys=0.02, real=0.08 secs] 18.992: [GC (Allocation Failure) 18.992: [ParNew: 672443K-&gt;64909K(707840K), 0.0494642 secs] 728994K-&gt;121459K(969984K), 0.0496048 secs] [Times: user=0.16 sys=0.00, real=0.05 secs] Heap par new generation total 707840K, used 373763K [0x0000000081800000, 0x00000000b1800000, 0x00000000b1800000) eden space 629248K, 49% used [0x0000000081800000, 0x000000009459d7b0, 0x00000000a7e80000) from space 78592K, 82% used [0x00000000a7e80000, 0x00000000abde3518, 0x00000000acb40000) to space 78592K, 0% used [0x00000000acb40000, 0x00000000acb40000, 0x00000000b1800000) concurrent mark-sweep generation total 262144K, used 56550K [0x00000000b1800000, 0x00000000c1800000, 0x0000000100000000) Metaspace used 97509K, capacity 106568K, committed 106752K, reserved 1140736K class space used 11967K, capacity 14761K, committed 14848K, reserved 1048576K 启动时间18s，GC=4，其中Full GC=0，PSYoungGen GC=4。 分析 real-time=0.31s，时间已经比第1次优化时减少30%。 user-time=0.94s，GC时间达到近1s。 PSYoungGen内存足够大了，但是GC时间太长和GC的算法有关，第1次调优使用的是：并行收集算法（多线程处理）。根据第1次调优-年轻代：Parallel Scavenge（PS），第2次调优-年轻代：ParNew。 UseConcMarkSweepGC配置CMS算法，可能没有启用年轻代的收集。 解决方式：Eclipse.ini加上配置：1-XX:CMSInitiatingOccupancyFraction=85 第3次调优eclipse.ini配置12345678910111213141516171819202122232425262728293031323334-startupplugins/org.eclipse.equinox.launcher_1.3.0.v20140415-2008.jar--launcher.libraryplugins/org.eclipse.equinox.launcher.win32.win32.x86_64_1.1.200.v20140603-1326-productorg.eclipse.epp.package.jee.product--launcher.defaultActionopenFile--launcher.XXMaxPermSize256M-showsplashorg.eclipse.platform--launcher.XXMaxPermSize512m--launcher.defaultActionopenFile--launcher.appendVmargs-vmargs-Dosgi.requiredJavaVersion=1.6 -javaagent:lombok.jar-verbose:gc-Xloggc:eclipse_test_gc.log-XX:+PrintGCTimeStamps-XX:+PrintGCDetails-Xms1024m–Xmx1024m -Xmn768m-XX:MetaspaceSize=512m-XX:+UseConcMarkSweepGC-XX:CMSInitiatingOccupancyFraction=85-Djava.rmi.server.hostname=127.0.0.1 -Dcom.sun.management.jmxremote.port=6688 -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.authenticate=false 初始化堆：1024m，最大堆：1024m，年轻代：768，survivor0:384m，survivor1=384m，tenured Generation：256m，metaspace=512mgc.log123456789101112134.104: [GC (Allocation Failure) 4.104: [ParNew: 629248K-&gt;41260K(707840K), 0.0346760 secs] 629248K-&gt;41260K(969984K), 0.0348408 secs] [Times: user=0.09 sys=0.00, real=0.04 secs] 8.236: [GC (Allocation Failure) 8.236: [ParNew: 670508K-&gt;51831K(707840K), 0.1331332 secs] 670508K-&gt;84728K(969984K), 0.1332595 secs] [Times: user=0.36 sys=0.01, real=0.13 secs] 12.319: [GC (Allocation Failure) 12.319: [ParNew: 681079K-&gt;42928K(707840K), 0.0565921 secs] 713976K-&gt;99627K(969984K), 0.0566873 secs] [Times: user=0.14 sys=0.00, real=0.06 secs] 14.646: [GC (Allocation Failure) 14.646: [ParNew: 672176K-&gt;56551K(707840K), 0.0357001 secs] 728875K-&gt;113251K(969984K), 0.0357838 secs] [Times: user=0.09 sys=0.00, real=0.04 secs] Heap par new generation total 707840K, used 391215K [0x0000000081800000, 0x00000000b1800000, 0x00000000b1800000) eden space 629248K, 53% used [0x0000000081800000, 0x0000000095ed1db0, 0x00000000a7e80000) from space 78592K, 71% used [0x00000000a7e80000, 0x00000000ab5b9f88, 0x00000000acb40000) to space 78592K, 0% used [0x00000000acb40000, 0x00000000acb40000, 0x00000000b1800000) concurrent mark-sweep generation total 262144K, used 56699K [0x00000000b1800000, 0x00000000c1800000, 0x0000000100000000) Metaspace used 97640K, capacity 106658K, committed 107008K, reserved 1140736K class space used 11969K, capacity 14727K, committed 14848K, reserved 1048576K Console Log：启动时间14s，GC=4，其中Full GC=0，PSYoungGen GC=4。 分析 real-time=0.27s，时间已经比第2次调优时减少0.04s。 user-time=0.68s，GC比第3次调优时减少0.3s。 采用CMS并发垃圾收集算法。","link":"/JVM-Eclipse/"},{"title":"(转载)字符串匹配（KMP）","text":"1 引言 思想 程序 2 概念 3 思想 部分匹配表 如何计算Next[] k值定义 Next的核心思想 4 优化 4 计算 5 程序代码 Java版本 1 引言简单匹配模式算法的效率不高，原因在于匹配过程中有回溯。示例：从左到右一个个匹配，如果这个过程中有某个字符不匹配，就跳回去，将模式串向右移动一位。我们只需要比较i指针指向的字符和j指针指向的字符是否一致。如果一致就都向后移动，如果不一致，如下图：A和E不相等，那就把i指针移回第1位（假设下标从0开始），j移动到模式串的第0位，然后又重新开始这个步骤： 思想在S[i]!=P[j]达到失配点，主串S要回到原来的i+1的位置（回溯），模式串P要回到第一个字符的位置，然后继续比较。每次到达失配点时，串S和串P的指针i，j都要回溯，因此效率比较低。 程序12345678910111213141516171819202122232425262728293031323334353637383940package baoli;public class A { public static void main(String[] args) { System.out.println(bf(\"ab1cs\", \"cs\")); } /** * * 暴力破解法 * @param ts * 主串 * @param ps * 模式串 * @return 如果找到，返回在主串中第一个字符出现的下标，否则为-1 */ public static int bf(String ts, String ps) { char[] t = ts.toCharArray(); char[] p = ps.toCharArray(); int i = 0; // 主串的位置 int j = 0; // 模式串的位置 while (i &lt; t.length &amp;&amp; j &lt; p.length) { if (t[i] == p[j]) { // 当两个字符相同，就比较下一个 i++; j++; } else { i = i - j + 1; // 一旦不匹配，i后退 j = 0; // j归0 } } if (j == p.length) { return i - j; } else { return -1; } }} KMP算法到达失配点时，串S不需要回溯，串P也不一定要回溯到第1个字符的位置。求Next[]函数的时间复杂度为O(m)，m是模式串的长度。则KMP算法的时间复杂度为O(m+n)，其中n是主串的长度。KMP 算法的主要特点是： 需要对模式字符串做预处理。 预处理阶段需要额外的O(m)空间和复杂度。 匹配阶段与字符集的大小无关。 匹配阶段至多执行2n - 1次字符比较。 对模式中字符的比较顺序时从左到右。2 概念字符串匹配是计算机的基本任务之一。举例来说，有一个字符串”BBC ABCDAB ABCDABCDABDE”，我想知道，里面是否包含另一个字符串”ABCDABD”？许多算法可以完成这个任务，Knuth-Morris-Pratt算法（简称KMP）是最常用的之一。它以三个发明者命名，起头的那个K就是著名科学家Donald Knuth。这种算法不太容易理解，网上有很多解释，但读起来都很费劲。直到读到Jake Boxer的文章，我才真正理解这种算法。下面，试图写一篇比较好懂的KMP算法解释。首先，字符串”BBC ABCDAB ABCDABCDABDE”的第一个字符与搜索词”ABCDABD”的第一个字符，进行比较。因为B与A不匹配，所以搜索词后移一位。因为B与A不匹配，搜索词再往后移。就这样，直到字符串有一个字符，与搜索词的第一个字符相同为止。接着比较字符串和搜索词的下一个字符，还是相同。直到字符串有一个字符，与搜索词对应的字符不相同为止。这时，最自然的反应是，将搜索词整个后移一位，再从头逐个比较。这样做虽然可行，但是效率很差，因为你要把”搜索位置”移到已经比较过的位置，重比一遍。一个基本事实是，当空格与D不匹配时，你其实知道前面六个字符是”ABCDAB”。KMP算法的想法是，设法利用这个已知信息，不要把”搜索位置”移回已经比较过的位置，继续把它向后移，这样就提高了效率。怎么做到这一点呢？可以针对搜索词，算出一张《部分匹配表》（Partial Match Table）。这张表是如何产生的，后面再介绍，这里只要会用就可以了。已知空格与D不匹配时，前面六个字符”ABCDAB”是匹配的。查表可知，最后一个匹配字符B对应的”部分匹配值”为2，因此按照下面的公式算出向后移动的位数： 1移动位数 = 已匹配的字符数 - 对应的部分匹配值 因为 6 - 2 等于4，所以将搜索词向后移动4位。因为空格与Ｃ不匹配，搜索词还要继续往后移。这时，已匹配的字符数为2（”AB”），对应的”部分匹配值”为0。所以，移动位数 = 2 - 0，结果为2，于是将搜索词向后移2位。因为空格与A不匹配，继续后移一位。逐位比较，直到发现C与D不匹配。于是，移动位数 = 6 - 2，继续将搜索词向后移动4位。逐位比较，直到搜索词的最后一位，发现完全匹配，于是搜索完成。如果还要继续搜索（即找出全部匹配），移动位数 = 7 - 0，再将搜索词向后移动7位，这里就不再重复了。下面介绍《部分匹配表》是如何产生的。首先，要了解两个概念：”前缀”和”后缀”。”前缀”指除了最后一个字符以外，一个字符串的全部头部组合；”后缀”指除了第一个字符以外，一个字符串的全部尾部组合。“部分匹配值”就是”前缀”和”后缀”的最长的共有元素的长度。以”ABCDABD”为例，1234567- &quot;A&quot;的前缀和后缀都为空集，共有元素的长度为0。- &quot;AB&quot;的前缀为[A]，后缀为[B]，共有元素的长度为0。- &quot;ABC&quot;的前缀为[A, AB]，后缀为[BC, C]，共有元素的长度0。- &quot;ABCD&quot;的前缀为[A, AB, ABC]，后缀为[BCD, CD, D]，共有元素的长度为0。- &quot;ABCDA&quot;的前缀为[A, AB, ABC, ABCD]，后缀为[BCDA, CDA, DA, A]，共有元素为&quot;A&quot;，长度为1。- &quot;ABCDAB&quot;的前缀为[A, AB, ABC, ABCD, ABCDA]，后缀为[BCDAB, CDAB, DAB, AB, B]，共有元素为&quot;AB&quot;，长度为2。- &quot;ABCDABD&quot;的前缀为[A, AB, ABC, ABCD, ABCDA, ABCDAB]，后缀为[BCDABD, CDABD, DABD, ABD, BD, D]，共有元素的长度为0。 “部分匹配”的实质是，有时候，字符串头部和尾部会有重复。比如，”ABCDAB”之中有两个”AB”，那么它的”部分匹配值”就是2（”AB”的长度）。搜索词移动的时候，第一个”AB”向后移动4位（字符串长度-部分匹配值），就可以来到第二个”AB”的位置。 3 思想部分匹配表部分匹配表就是程序代码里的next[]，next[]里存的是模式串（搜索词）P的每个字符的最大k值。k值是字符串匹配失败时，字符需要回到什么位置的值。（回溯的值）k值部分匹配表的值既然是部分匹配表的数据，那next中的k值也满足“前缀”和“后缀”共有元素的长度：P[0 ~ k-1] == P[j-k ~ j-1]（头部k长度的字符与尾部k长度的字符是相等的）比如：ABCDAB的前缀为[A, AB, ABC, ABCD, ABCDA]，后缀为[BCDAB, CDAB, DAB, AB, B]，共有元素为”AB”，长度为2；既k的值是2。如图：因为：当T[i] != P[j]时，有T[i-j ~ i-1] == P[0 ~ j-1]（表示：在失配点，之前的j个字符都是匹配的），由P[0 ~ k-1] == P[j-k ~ j-1]（在k点失配，前缀和后缀的长度相等）必然：T[i-k ~ i-1] == P[0 ~ k-1]，下一趟匹配过程可以从T串的i、P串的k开始。这里通过数学公式推导出来T[i-k ~ i-1] == P[0 ~ k-1]，这就是模式串（搜索词）移动到k点，而不需要比较k之前的字符串了。 如何计算Next[]如何计算next[]？因为在P的每一个位置都可能发生不匹配，也就是说我们要计算每一个位置j对应的k，所以用一个next[]来保存，next[j] = k，表示当T[i] != P[j]时，j指针的下一个位置。 k值定义k值被定义为：字符串失配时，字符串相同的前、后缀子串长的最大值。公式的含义：当匹配在S[i]和P[j]失效时，j应该回溯的位置k（next[j]）。next[j]&gt;=0表示下一趟从S[i]和P[k]（P[next[j]]）开始；next[j]=-1，下一趟从S[i]和P[0]开始。 Next的核心思想j=0,next[k]=-1现在要始终记住一点，next[j]的值（也就是k）表示，当P[j] != T[i]时，j指针的下一步移动位置。先来看第一个：当j为0时，如果这时候不匹配，怎么办？j=1，根据第3个公式，k=0。S串中的i不回溯，j回溯到k（next[1]=0），则又是不匹配；j=0,next[0]=-1,k=-1，相当于P的0位置之前有个-1，这个-1位置与S串的i肯定不会匹配（-1位置实际上是不存在），则S串和P串分别+1重新开始（如第3图所示）。next[0] = -1。这也是一种特殊情况。j=0,next[k]=-1对于next[1]，请看灰色部分，在第二组中，因为W[1]（图中的a）前面只有一个字符（b），所以只要W[1]不匹配，不管W[0]是不是蓝色，W总是会滑到开头的。所以next[1] == 0总是成立的，这是一种特殊情况。你可以顺着灰色条看上去（注意是灰色部分哦），图1中c对应W的位置1在图2是不是变成对应0了。j指针一定是后移到0位置的。因为它前面也就只有这一个位置next[j+1] == next[j] + 1我们发现一个规律：当P[k] == P[j]时，有next[j+1] == next[j] + 1（j+1的回溯点k1和k+1是一个点，因为P[k]=P[j]）代码里就是这句：next[j] = k;其实这个是可以证明的：因为在P[j]之前已经有P[0 ~ k-1] == p[j-k ~ j-1]。（next[j] == k）这时候现有P[k] == P[j]，我们是不是可以得到P[0 ~ k-1] + P[k] == p[j-k ~ j-1] + P[j]。即：P[0 ~ k] == P[j-k ~ j]，即next[j+1] == k + 1 == next[j] + 1。P[k] != P[j]像这种情况，如果你从代码上看应该是这一句：k = next[k]；p[j]和p[k]不匹配，这时j回溯到k位置，没有意义了，因为本身就不匹配了，那么在k位置再往前回溯，k=next[k]。注：另一种图解（图片挺好解释的，文字比较难理解）对于长度为k的头部子字符串，他可能有图中蓝色部分的前缀和后缀。注意，如果图中头部的黄色表示的字符与下标j表示的字符相等，那么，下标j找到了他的最长前缀了头部黄色表示的字符的下标就是next[k]。因为next[k]表示的就是字符串长度为k的头部字符串的最长前缀和后缀。 4 优化求next[]函数可以通过改进之后，进一步提高效率。显然，当我们上边的算法得到的next[]应该是[ -1，0，0，1 ]，所以下一步我们应该是把j移动到第1个元素：这一步是完全没有意义的。因为后面的B(j=3)已经不匹配了，那前面的B(j=1)也一定是不匹配的。显然，发生问题的原因在于P[j] == P[next[j]]。加上一个判断条件就可以，当P[j]=P[k]的时候，需要跳过P[k]，回溯到k的上一个回溯点next[k]，即：next[j] = next[k]; 4 计算 j 0 1 2 3 4 5 6 7 P a b c a b c a b next[j]=k -1 0 0 0 1 2 3 4 模式串（abcabcab）求f(4)=next[4]，应该在其前串（abca）找到k。abca的前缀：{a,ab,abc}；后缀：{bca,ca,a}。前后缀相同的最大长度是1，即f(4)=next[4]的k值是1。 5 程序代码Java版本12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364package kmp;public class A { public static void main(String[] args) { System.out.println(KMP(\"1221yu12\", \"yu\")); } public static int KMP(String ts, String ps) { char[] t = ts.toCharArray(); char[] p = ps.toCharArray(); // 主串的位置 int i = 0; // 模式串的位置 int j = 0; //j回溯的位置 int[] next = getNext(ps); while (i &lt; t.length &amp;&amp; j &lt; p.length) { // 当j为-1时，要移动的是i，当然j也要归0 //2个字符串相匹配时，i++，j++ if (j == -1 || t[i] == p[j]) { i++; j++; } else { //2个字符串不匹配时候， i不需要回溯了， j回到指定位置 j = next[j]; } } //模式串完全匹配，返回S串前j的开始位置 if (j == p.length) { return i - j; } else { return -1; } } // 获取next数组（部分匹配表） public static int[] getNext(String ps) { //P字符数组 char[] p = ps.toCharArray(); int[] next = new int[p.length];//部分匹配表 //j=0，k=-1，因为j=0，左边没有数字，现在假设左边有个-1，j回到-1，对应S串中的i，相当于P串的j=j+1，相当于P串的j=j+，也相当于++j和++i next[0] = -1; //初始化P串的j int j = 0; //初始化k int k = -1; //循环匹配P串 while (j &lt; p.length - 1) { //P串的k前缀和后缀相同时 if (k == -1 || p[j] == p[k]) { // if (p[++j] == p[++k]) { next[j] = next[k]; } else {//不相同，当两个字符相等时要跳过k，因为P[++j]不匹配S串，P[++k]也同样不匹配S串，这回溯到k的下一个点，重新匹配 next[j] = k;//不相同，j回溯到k位置,比如2个B的例子 } } else {//p[j]和p[k]不匹配，这时j回溯到k位置，没有意义了，因为本身就不匹配了，那么在k位置再往前回溯，k=next[k] k = next[k]; } } return next; }}","link":"/KMP/"},{"title":"JVM垃圾回收算法-CMS(Concurrent Low Pause Collector)","text":"1 介绍 2 配置 3 实战 1 介绍CMS，全称Concurrent Low Pause Collector，是jdk1.4后期版本开始引入的新gc算法，在jdk5和jdk6中得到了进一步改进，它的主要适合场景是对响应时间的重要性需求 大于对吞吐量的要求，能够承受垃圾回收线程和应用线程共享处理器资源，并且应用中存在比较多的长生命周期的对象的应用。CMS是用于对Tenured Generation的回收，也就是年老代的回收，目标是尽量减少应用的暂停时间，减少Full GC发生的几率，利用和应用程序线程并发的垃圾回收线程来标记清除年老代。在我们的应用中，因为有缓存的存在，并且对于响应时间也有比较高的要求，因此希望能尝试使用CMS来替代默认的server型JVM使用的并行收集器，以便获得更短的垃圾回收的暂停时间，提高程序的响应性。CMS并非没有暂停，而是用两次短暂停来替代串行标记整理算法的长暂停，它的收集周期是这样。 初始标记(CMS-initial-mark) 并发标记(CMS-concurrent-mark) 重新标记(CMS-remark) 并发清除(CMS-concurrent-sweep) 并发重设状态等待下次CMS的触发(CMS-concurrent-reset)。 其中的1，3两个步骤需要暂停所有的应用程序线程的。第一次暂停从root对象开始标记存活的对象，这个阶段称为初始标记；第二次暂停是在并发标记之后， 暂停所有应用程序线程，重新标记并发标记阶段遗漏的对象（在并发标记阶段结束后对象状态的更新导致）。第一次暂停会比较短，第二次暂停通常会比较长，并且remark这个阶段可以并行标记。而并发标记、并发清除、并发重设阶段的所谓并发，是指一个或者多个垃圾回收线程和应用程序线程并发地运行，垃圾回收线程不会暂停应用程序的执行，如果你有多于一个处理器，那么并发收集线程将与应用线程在不同的处理器上运行，显然，这样的开销就是会降低应用的吞吐量。remark阶段的并行，是指暂停了所有应用程序后，启动一定数目的垃圾回收进程进行并行标记，此时的应用线程是暂停的。CMS的Young Generation的回收采用的仍然是并行复制收集器，这个跟Paralle GC算法是一致的。 2 配置 启用CMS:-XX:+UseConcMarkSweepGC CMS默认启动的回收线程数目是(ParallelGCThreads + 3)/4) ，如果你需要明确设定，可以通过：-XX:ParallelCMSThreads=20，其中ParallelGCThreads是年轻代的并行收集线程数 CMS是不会整理堆碎片的，因此为了防止堆碎片引起Full GC，通过会开启CMS阶段进行合并碎片选项：-XX:+UseCMSCompactAtFullCollection，开启这个选项一定程度上会影响性能。 为了减少第二次暂停的时间，开启并行remark: -XX:+CMSParallelRemarkEnabled。如果remark还是过长的话，可以开启-XX:+CMSScavengeBeforeRemark选项，强制remark之前开始一次minor gc，减少remark的暂停时间，但是在remark之后也将立即开始又一次minor gc。 为了避免Perm区满引起的Full GC，建议开启CMS回收Perm区选项：+CMSPermGenSweepingEnabled -XX:+CMSClassUnloadingEnabled 默认CMS是在Tenured Generation沾满68%的时候开始进行CMS收集，如果你的年老代增长不是那么快，并且希望降低CMS次数的话，可以适当调高此值：-XX:CMSInitiatingOccupancyFraction=80,这里修改成80%占满的时候才开始CMS回收。 年轻代的并行收集线程数默认是：(cpu &lt;= 8) ? cpu : 3 + ((cpu * 5) / 8)，如果你希望降低这个线程数，可以通过-XX:ParallelGCThreads=N来调整。3 实战1234-server -Xms1536m -Xmx1536m -XX:NewSize=256m -XX:MaxNewSize=256m -XX:PermSize=64m -XX:MaxPermSize=64m -XX:-UseConcMarkSweepGC -XX:+UseCMSCompactAtFullCollection -XX:CMSInitiatingOccupancyFraction=80 -XX:+CMSParallelRemarkEnabled -XX:SoftRefLRUPolicyMSPerMB=0 需要在生产环境或者压测环境中测量这些参数下系统的表现，这时候需要打开GC日志查看具体的信息，因此加上参数。1-verbose:gc -XX:+PrintGCTimeStamps -XX:+PrintGCDetails -Xloggc:/home/test/logs/gc.log 在运行相当长一段时间内查看CMS的表现情况，CMS的日志输出类似这样。1234567891011124391.322: [GC [1 CMS-initial-mark: 655374K(1310720K)] 662197K(1546688K), 0.0303050 secs] [Times: user=0.02 sys=0.02, real=0.03 secs]4391.352: [CMS-concurrent-mark-start]4391.779: [CMS-concurrent-mark: 0.427/0.427 secs] [Times: user=1.24 sys=0.31, real=0.42 secs]4391.779: [CMS-concurrent-preclean-start]4391.821: [CMS-concurrent-preclean: 0.040/0.042 secs] [Times: user=0.13 sys=0.03, real=0.05 secs]4391.821: [CMS-concurrent-abortable-preclean-start]4392.511: [CMS-concurrent-abortable-preclean: 0.349/0.690 secs] [Times: user=2.02 sys=0.51, real=0.69 secs]4392.516: [GC[YG occupancy: 111001 K (235968 K)]4392.516: [Rescan (parallel) , 0.0309960 secs]4392.547: [weak refs processing, 0.0417710 secs] [1 CMS-remark: 655734K(1310720K)] 766736K(1546688K), 0.0932010 secs] [Times: user=0.17 sys=0.00, real=0.09 secs]4392.609: [CMS-concurrent-sweep-start]4394.310: [CMS-concurrent-sweep: 1.595/1.701 secs] [Times: user=4.78 sys=1.05, real=1.70 secs]4394.310: [CMS-concurrent-reset-start]4394.364: [CMS-concurrent-reset: 0.054/0.054 secs] [Times: user=0.14 sys=0.06, real=0.06 secs] 其中可以看到CMS-initial-mark阶段暂停了0.0303050秒，而CMS-remark阶段暂停了0.0932010秒，因此两次暂停的总共时间是0.123506秒，也就是123毫秒左右。两次短暂停的时间之和在200以下可以称为正常现象。但是你很可能遇到两种fail引起full gc：Prommotion failed和Concurrent mode failed。Prommotion failed的日志输出大概是这样。12[ParNew (promotion failed): 320138K-&gt;320138K(353920K), 0.2365970 secs]42576.951: [CMS: 1139969K-&gt;1120688K( 166784K), 9.2214860 secs] 1458785K-&gt;1120688K(2520704K), 9.4584090 secs] Prommotion failed这个问题的产生是由于Survivor空间不够，从而向年老代转移对象，年老代没有足够的空间来容纳这些对象，导致一次Full GC的产生。解决这个问题的办法有两种完全相反的倾向：增大救助空间、增大年老代或者去掉救助空间。增大Survivor空间就是调整-XX:SurvivorRatio参数，这个参数是Eden区和Survivor区的大小比值，默认是32，也就是说Eden区是Survivor区的32倍大小，要注意Survivor是有两个区的，因此Surivivor其实占整个Young Genertation的1/34。调小这个参数将增大Survivor区，让对象尽量在Surivivor区呆长一点，减少进入年老代的对象。去掉Survivor空间的想法是让大部分不能马上回收的数据尽快进入年老代，加快年老代的回收频率，减少年老代暴涨的可能性，这个是通过将-XX:SurvivorRatio设置成比较大的值（比如65536)来做到。在我们的应用中，将Young Generation设置成256M，这个值相对来说比较大了，而救助空间设置成默认大小(1/34)，从压测情况来看，没有出现prommotion failed的现象，年轻代比较大，从GC日志来看，minor gc的时间也在5-20毫秒内，还可以接受，因此暂不调整。Concurrent mode failed的产生是由于CMS回收年老代的速度太慢，导致年老代在CMS完成前就被沾满，引起Full GC，避免这个现象的产生就是调小-XX:CMSInitiatingOccupancyFraction参数的值，让CMS更早更频繁的触发，降低年老代被沾满的可能。我们的应用暂时负载比较低，在生产环境上年老代的增长非常缓慢，因此暂时设置此参数为80。在压测环境下，这个参数的表现还可以，没有出现过Concurrent mode failed。","link":"/JVM-CMS/"},{"title":"深入理解Java内存模型(Volatile-Happens before)","text":"1 volatile特性 2 volatile写-读建立的happens-before关系 happens-before在JSR-133中的规则 3 volatile写-读的内存语义 volatile写的内存语义如下 volatile读的内存语义如下 4 volatile内存语义的实现 volatile写插入内存屏障 volatile读插入内存屏障 编译器对内存屏障进行优化 5 JSR-133为什么要增强volatile的内存语义 6 参考 1 volatile特性当我们声明共享变量为volatile后，对这个变量的读/写将会很特别。理解volatile特性的一个好方法，把对volatile变量的单个读/写，看成是使用同一个监视器锁对这些单个读/写操作做了同步。下面我们通过具体的示例来说明，请看下面的示例代码：12345678910111213141516class VolatileFeaturesExample { volatile long vl = 0L; //使用volatile声明64位的long型变量 public void set(long l) { vl = l; //单个volatile变量的写 } public void getAndIncrement () { vl++; //复合（多个）volatile变量的读/写 } public long get() { return vl; //单个volatile变量的读 }} 假设有多个线程分别调用上面程序的三个方法，这个程序在语意上和下面程序等价：123456789101112131415161718class VolatileFeaturesExample { long vl = 0L; // 64位的long型普通变量 public synchronized void set(long l) { //对单个的普通 变量的写用同一个监视器同步 vl = l; } public void getAndIncrement () { //普通方法调用 long temp = get(); //调用已同步的读方法 temp += 1L; //普通写操作 set(temp); //调用已同步的写方法 } public synchronized long get() { //对单个的普通变量的读用同一个监视器同步 return vl; }} 如上面示例程序所示，对一个volatile变量的单个读/写操作，与对一个普通变量的读/写操作使用同一个监视器锁来同步，它们之间的执行效果相同。监视器锁的happens-before规则保证释放监视器和获取监视器的两个线程之间的内存可见性，这意味着对一个volatile变量的读，总是能看到（任意线程）对这个volatile变量最后的写入。监视器锁的语义决定了临界区代码的执行具有原子性。这意味着即使是64位的long型和double型变量，只要它是volatile变量，对该变量的读写就将具有原子性。如果是多个volatile操作或类似于volatile++这种复合操作，这些操作整体上不具有原子性。简而言之，volatile变量自身具有下列特性： 可见性。对一个volatile变量的读，总是能看到（任意线程）对这个volatile变量最后的写入。 原子性。对任意单个volatile变量的读/写具有原子性，但类似于volatile++这种复合操作不具有原子性。 volatile的简单变量如果当前值由该变量以前的值相关，那么volatile关键字不起作用，也就是说如下的表达式都不是原子操作。12n=n+1 ;n++; 只有当变量的值和自身上一个值无关时对该变量的操作才是原子级别的，如n = m + 1，这个就是原子级别的。 2 volatile写-读建立的happens-before关系上面讲的是volatile变量自身的特性，对程序员来说，volatile对线程的内存可见性的影响比volatile自身的特性更为重要，也更需要我们去关注。从JSR-133开始，volatile变量的写-读可以实现线程之间的通信。 happens-before在JSR-133中的规则123451：Each action in a thread happens before every action in that thread that comes later in the program&apos;s order.2：An unlock on a monitor happens before every subsequent lock on that same monitor.3：A write to a volatile field happens before every subsequent read of that same volatile.4：A call to start() on a thread happens before any actions in the started thread.5：All actions in a thread happen before any other thread successfully returns from a join() on that thread. 规则解释： 可以理解为对于单个线程来说，前面的写操作对后面都是可见的，这里肯定有人问那指令重排序之后怎么保证这点呢，我也有这个疑问，所以我理解的是如果这个写是同步的，那么对单线程来说，所有同步的写都是按照program order的，这个也是顺序一致性的第一层含义。要理解的是，Java在使用了同步手段之后，被同步保护的点都是保证顺序一致性的。因为同步的底层实现比如内存屏障/lock都有防止重排序的含义。 可以理解为一个锁的释放后它前面的写操作对后续进入同一个锁的线程可见，对锁来说这个太肯定了，释放时会lock cmpxchg一次，进入时会lock cmpxchg一次，两次都保证了可见性。 可以理解为volatile的写操作对后续的读可见，也是lock addl操作保证了写volatile的可见性。 可以理解为线程start()写线程开始状态对后续线程的其他动作可见，JVM内部处理了，实际实现肯定也是用了lock/内存屏障来实现的，其实在聊聊JVM（九）理解进入safepoint时如何让Java线程全部阻塞中我们提到了线程状态的改变，在JVM里面是对一个线程状态变量进行原子的修改，这个状态的改变是原子的，并且可见的，当然就具备了Happens-before的能力。 可以理解为一个被join的线程中所有的写操作在它join结束后回到原来的线程时，对原来的线程可见。这个和上面的原理差不多，就是JVM在修改线程状态的时候是一次原子操作，并且保证了可见性(估计是一次CAS)，所以连带着修改状态前面的修改也都对后续的操作可见了。 从内存语义的角度来说，volatile与监视器锁有相同的效果：volatile写和监视器的释放有相同的内存语义；volatile读与监视器的获取有相同的内存语义。请看下面使用volatile变量的示例代码：12345678910111213141516class VolatileExample { int a = 0; volatile boolean flag = false; public void writer() { a = 1; //1 flag = true; //2 } public void reader() { if (flag) { //3 int i = a; //4 …… } }} 假设线程A执行writer()之后，线程B执行reader()。根据happens-before规则，这个过程建立的happens-before关系可以分为两类： 根据程序次序规则，1 happens-before 2；3 happens-before 4。 根据volatile规则，2 happens-before 3。 根据happens-before的传递性规则，1 happens-before 4。（lock/内存屏障不仅仅把当前的地址的数据原子的写到缓存和内存，肯定也把这之前CPU缓存/write buffer的脏数据写回到主内存了，这样就实现了Happens-before的传递性）。 上述happens-before关系的图形化表现形式如下：在上图中，每一个箭头链接的两个节点，代表了一个happens-before关系。黑色箭头表示程序顺序规则；橙色箭头表示volatile规则；蓝色箭头表示组合这些规则后提供的happens-before保证。这里A线程写一个volatile变量后，B线程读同一个volatile变量。A线程在写volatile变量之前所有可见的共享变量，在B线程读同一个volatile变量后，将立即变得对B线程可见。 3 volatile写-读的内存语义volatile写的内存语义如下当写一个volatile变量时，JMM会把该线程对应的本地内存中的共享变量刷新到主内存。以上面示例程序VolatileExample为例，假设线程A首先执行writer()，随后线程B执行reader()，初始时两个线程的本地内存中的flag和a都是初始状态。下图是线程A执行volatile写后，共享变量的状态示意图：如上图所示，线程A在写flag变量后，本地内存A中被线程A更新过的两个共享变量的值被刷新到主内存中。此时，本地内存A和主内存中的共享变量的值是一致的。 volatile读的内存语义如下当读一个volatile变量时，JMM会把该线程对应的本地内存置为无效。线程接下来将从主内存中读取共享变量。下面是线程B读同一个volatile变量后，共享变量的状态示意图：如上图所示，在读flag变量后，本地内存B已经被置为无效。此时，线程B必须从主内存中读取共享变量。线程B的读取操作将导致本地内存B与主内存中的共享变量的值也变成一致的了。如果我们把volatile写和volatile读这两个步骤综合起来看的话，在读线程B读一个volatile变量后，写线程A在写这个volatile变量之前所有可见的共享变量的值都将立即变得对读线程B可见。下面对volatile写和volatile读的内存语义做个总结： 线程A写一个volatile变量，实质上是线程A向接下来将要读这个volatile变量的某个线程发出了（其对共享变量所在修改的）消息。 线程B读一个volatile变量，实质上是线程B接收了之前某个线程发出的（在写这个volatile变量之前对共享变量所做修改的）消息。 线程A写一个volatile变量，随后线程B读这个volatile变量，这个过程实质上是线程A通过主内存向线程B发送消息。4 volatile内存语义的实现下面，让我们来看看JMM如何实现volatile写/读的内存语义。前文我们提到过重排序分为编译器重排序和处理器重排序。为了实现volatile内存语义，JMM会分别限制这两种类型的重排序类型。下面是JMM针对编译器制定的volatile重排序规则表：举例来说，第三行最后一个单元格的意思是：在程序顺序中，当第一个操作为普通变量的读或写时，如果第二个操作为volatile写，则编译器不能重排序这两个操作。从上表我们可以看出： 当第二个操作是volatile写时，不管第一个操作是什么，都不能重排序。这个规则确保volatile写之前的操作不会被编译器重排序到volatile写之后。 当第一个操作是volatile读时，不管第二个操作是什么，都不能重排序。这个规则确保volatile读之后的操作不会被编译器重排序到volatile读之前。 当第一个操作是volatile写，第二个操作是volatile读时，不能重排序。 为了实现volatile的内存语义，编译器在生成字节码时，会在指令序列中插入内存屏障来禁止特定类型的处理器重排序。对于编译器来说，发现一个最优布置来最小化插入屏障的总数几乎不可能，为此，JMM采取保守策略。下面是基于保守策略的JMM内存屏障插入策略： 在每个volatile写操作的前面插入一个StoreStore屏障。 在每个volatile写操作的后面插入一个StoreLoad屏障。 在每个volatile读操作的后面插入一个LoadLoad屏障。 在每个volatile读操作的后面插入一个LoadStore屏障。 上述内存屏障插入策略非常保守，但它可以保证在任意处理器平台，任意的程序中都能得到正确的volatile内存语义。 volatile写插入内存屏障volatile写插入内存屏障后生成的指令序列示意图：上图中的StoreStore屏障可以保证在volatile写之前，其前面的所有普通写操作已经对任意处理器可见了（刷新到主内存）。这是因为StoreStore屏障将保障上面所有的普通写在volatile写之前刷新到主内存。这里比较有意思的是volatile写后面的StoreLoad屏障。这个屏障的作用是避免volatile写与后面可能有的volatile读/写操作重排序。因为编译器常常无法准确判断在一个volatile写的后面，是否需要插入一个StoreLoad屏障（比如，一个volatile写之后方法立即return）。为了保证能正确实现volatile的内存语义，JMM在这里采取了保守策略：在每个volatile写的后面或在每个volatile读的前面插入一个StoreLoad屏障。从整体执行效率的角度考虑，JMM选择了在每个volatile写的后面插入一个StoreLoad屏障。因为volatile写-读内存语义的常见使用模式是：一个写线程写volatile变量，多个读线程读同一个volatile变量。当读线程的数量大大超过写线程时，选择在volatile写之后插入StoreLoad屏障将带来可观的执行效率的提升。从这里我们可以看到JMM在实现上的一个特点：首先确保正确性，然后再去追求执行效率。 volatile读插入内存屏障volatile读插入内存屏障后生成的指令序列示意图：上图中的LoadLoad屏障用来禁止处理器把上面的volatile读与下面的普通读重排序。LoadStore屏障用来禁止处理器把上面的volatile读与下面的普通写重排序。 编译器对内存屏障进行优化volatile写和volatile读的内存屏障插入策略非常保守。在实际执行时，只要不改变volatile写-读的内存语义（执行结果不改变），编译器可以根据具体情况省略不必要的屏障。下面我们通过具体的示例代码来说明：123456789101112131415class VolatileBarrierExample { int a; volatile int v1 = 1; volatile int v2 = 2; void readAndWrite() { int i = v1; //第一个volatile读 int j = v2; // 第二个volatile读 a = i + j; //普通写 v1 = i + 1; // 第一个volatile写 v2 = j * 2; //第二个 volatile写 } … //其他方法} 针对readAndWrite()，编译器在生成字节码时可以做如下的优化：注意，最后的StoreLoad屏障不能省略。因为第二个volatile写之后，方法立即return。此时编译器可能无法准确断定后面是否会有volatile读或写，为了安全起见，编译器常常会在这里插入一个StoreLoad屏障。上面的优化是针对任意处理器平台，由于不同的处理器有不同“松紧度”的处理器内存模型，内存屏障的插入还可以根据具体的处理器内存模型继续优化。以x86处理器为例，上图中除最后的StoreLoad屏障外，其它的屏障都会被省略。前面保守策略下的volatile读和写，在x86处理器平台可以优化成：前文提到过，x86处理器仅会对写-读操作做重排序。X86不会对读-读，读-写和写-写操作做重排序，因此在x86处理器中会省略掉这三种操作类型对应的内存屏障。在x86中，JMM仅需在volatile写后面插入一个StoreLoad屏障即可正确实现volatile写-读的内存语义。这意味着在x86处理器中，volatile写的开销比volatile读的开销会大很多（因为执行StoreLoad屏障开销会比较大）。 5 JSR-133为什么要增强volatile的内存语义在JSR-133之前的旧Java内存模型中，虽然不允许volatile变量之间重排序，但旧的Java内存模型允许volatile变量与普通变量之间重排序。在旧的内存模型中，VolatileExample示例程序可能被重排序成下列时序来执行：在旧的内存模型中，当1和2之间没有数据依赖关系时，1和2之间就可能被重排序（3和4类似）。其结果就是：读线程B执行4时，不一定能看到写线程A在执行1时对共享变量的修改。因此在旧的内存模型中，volatile的写-读没有监视器的释放-获所具有的内存语义。为了提供一种比监视器锁更轻量级的线程之间通信的机制，JSR-133专家组决定增强volatile的内存语义：严格限制编译器和处理器对volatile变量与普通变量的重排序，确保volatile的写-读和监视器的释放-获取一样，具有相同的内存语义。从编译器重排序规则和处理器内存屏障插入策略来看，只要volatile变量与普通变量之间的重排序可能会破坏volatile的内存语意，这种重排序就会被编译器重排序规则和处理器内存屏障插入策略禁止。由于volatile仅仅保证对单个volatile变量的读/写具有原子性（volatile保证可见性，不能保证一定的原子性），而监视器锁的互斥执行的特性可以确保对整个临界区代码的执行具有原子性。在功能上，监视器锁比volatile更强大；在可伸缩性和执行性能上，volatile更有优势。如果读者想在程序中用volatile代替监视器锁，请一定谨慎。 6 参考 深入理解Java内存模型","link":"/JMM-5/"},{"title":"JVM内存泄漏分析","text":"1 问题 2 编写对GC友好，不会泄露的代码 使用更多生命周期短的、小的、不改变指向(immutable)的对象，编写清晰的代码 将用完的对象设为NULL其实没什么作用 避免显式GC(System.gc()) finalize() 内存泄漏 3 Java内存回收机制 静态集合类引起内存泄露 覆写hashcode 例1 结果 监听器 各种连接 内部类和外部模块等的引用 单例模式 本地变量 1 问题Java线程是JVM基础的一部分。你的Java堆空间内存占用不仅仅是由于静态对象和长生命的对象导致，还有可能因为短生命对象。OutOfMemoryError问题经常被误认为是内存泄露引起。我们经常忽略错误的线程执行模型和它们持有的JVM里的短生命对象，直到它们的执行完成我们才发现。在这种问题情形下： 程序中短生命/无状态对象（XML,JSON数据负载等）被线程持有的时间会变得很长(线程锁争用，大量数据负载，远程系统的慢响应时间等)。 这种短生命对象会因为垃圾收集而晋升到长生命空间，比如老年代空间。 副作用是会导致老年代空间很快被占满，增加了Full GC(major收集)的频率。 由于这种严重的情况，它将导致更多的GC垃圾收集，增加JVM暂停时间和最终的OutOfMemoryError:Java堆空间。 你的应用此时被停掉，你很疑惑到底怎么回事。最后，你考虑增加Java堆空间或者寻找哪里有内存泄露，你真的找对路了么？避免在线程栈大小（虚拟机栈）和Java堆内存占用之间产生混淆是非常重要的。线程栈（虚拟机栈）大小是一种特殊的内存空间，它被JVM用于存储每个方法调用。当一个线程调用方法A，它将这个调用入栈。如果方法A调用方法B，同样也会入栈。一旦方法执行完毕，这个调用便从栈里出栈。这种线程方法调用会导致Java对象产生，并分配在Java堆里。增加线程栈的大小是没有任何效果的（对象最终在堆得年轻代（Eden）产生）。而调整线程栈大小通常是要处理java.lang.stackoverflowerror错误或者OutOfMemoryError: unable to create new native thread错误的时候才会需要。 2 编写对GC友好，不会泄露的代码使用更多生命周期短的、小的、不改变指向(immutable)的对象，编写清晰的代码出于懒惰也好，朴素的节俭意识也好，我们都习惯对一个变量重用再重用。但是，Java的垃圾收集器喜欢短生命周期的对象，对象如果在新生代内，在垃圾收集发生前就死掉了，垃圾收集器就什么都不用做了。现代JVM构建一个新对象只需要10个本地CPU指令，并不弱于C/C++。但垃圾收集没有压缩算法时会稍慢，更频繁的New对象也导致更频繁的GC。大对象的分配效率更低，而且对非压缩算法的垃圾收集器，更容易造成碎片。对象重用增加了代码的复杂度，降低了可读性。 将用完的对象设为NULL其实没什么作用把对象主动设为Null的”好习惯”其实没什么用，JIT Compiler会自动分析local变量的生命周期。只有一个例外情况，就是String[1024] foo这种赤裸裸的数组，你需要主动的foo[100]=null释放第100号元素，所以最好还是直接用ArrayList这些标准库算了。 避免显式GC(System.gc())大家都知道System.gc()不好，full-gc浪费巨大，GC的时机把握不一定对等等，甚至有-XX:+DisableExplicitGC的JVM参数来禁止它。但我还不会用System.gc()呢，不怕不怕。真的不怕吗？先用FindBugs查一下所用到的全部第三方类库吧。至少RMI 就会老实不客气的执行System.gc()来实现分布式GC算法。但我也不会用RMI啊。那EJB呢，EJB可是建在RMI上的。如果无可避免，用-Dsun.rmi.dgc.client.gcInterval=3600000，-Dsun.rmi.dgc.server.gcInterval=3600000 (单位为微妙) 增大大GC的间隔(原默认值为1分钟)，-XX:+ExplicitGCInvokesConcurrent让System.gc()也CMS并发执行。 finalize()大家也都知道finalize()不好，分配代价昂贵，释放代价更昂贵(要多走一个循环，而且他们死得慢，和他们相关联的对象也跟着死得慢了)，又不确定能否被调用(JVM开始关闭时，就不会再进行垃圾收集)，又不确定何时被调用(GC时间不定，即使system.gc()也只是提醒而不是强迫GC，又不确定以什么样的顺序调用，所以finalize不是C++的析构函数，也不像C++的析构函数。我们都知道啊，所以我从来都没使用。都是在显式的维护那些外部资源，比如在finally{}里释放。 内存泄漏Java 不是有垃圾收集器了吗？怎么还泄漏啊？此泄漏非比泄漏。C/C++的泄漏，是对象已不可到达，而内存又没有回收，真正的内存黑洞。而Java的泄漏，则是因为各种原因，对象对应用已经无用，但一直被持有，一直可到达。 被生命周期极长的集合类不当持有，号称是Java内存泄漏的首因。 这些集合类的生命周期通常极长，而且是一个辅助管理性质的对象，在一个业务事务运行完后，如果没有将某个业务对象主动的从中清除的话，这个集合就会吃越来越多内存，可以用WeakReference，如WeakHashMap，使得它持有的对象不增加对象的引用数。 Scope定义不对，这个很简单了，方法的局部变量定义成类的变量，类的静态变量等。 异常时没有加finally{}来释放某些资源，JDBC时代也是很普遍的事情。 另外一些我了解不深的原因，如：Swing里的Listener没有显式remove；内部类持有外部对象的隐式引用；Finalizers造成关联对象没有被及时清空等。3 Java内存回收机制不论哪种语言的内存分配方式，都需要返回所分配内存的真实地址，也就是返回一个指针到内存块的首地址。Java中对象是采用new或者反射的方法创建的，这些对象的创建都是在堆（Heap）中分配的，所有对象的回收都是由Java虚拟机通过垃圾回收机制完成的。Java中对内存对象的访问，使用的是引用的方式。在Java代码中我们维护一个内存对象的引用变量，通过这个引用变量的值，我们可以访问到对应的内存地址中的内存对象空间。在Java程序中，这个引用变量本身既可以存放堆内存中，又可以放在代码栈的内存中（与基本数据类型相同）。GC线程会从代码栈中的引用变量开始跟踪，从而判定哪些内存是正在使用的。如果GC线程通过这种方式，无法跟踪到某一块堆内存，那么GC就认为这块内存将不再使用了（因为代码中已经无法访问这块内存了）。GC为了能够正确释放对象，会监控每个对象的运行状况，对他们的申请、引用、被引用、赋值等状况进行监控，Java会使用有向图的方法进行管理内存，实时监控对象是否可以达到，如果不可到达，则就将其回收，这样也可以消除引用循环的问题。在Java语言中，判断一个内存空间是否符合垃圾收集标准有两个：一个是给对象赋予了空值null，以下再没有调用过，另一个是给对象赋予了新值，这样重新分配了内存空间。内存泄露是指无用对象（不再使用的对象）持续占有内存或无用对象的内存得不到及时释放，从而造成的内存空间的浪费称为内存泄露。内存泄露有时不严重且不易察觉，这样开发者就不知道存在内存泄露，但有时也会很严重，会提示Out of memory。那么，Java内存泄露根本原因是什么呢？长生命周期的对象持有短生命周期对象的引用就很可能发生内存泄露，尽管短生命周期对象已经不再需要，但是因为长生命周期对象持有它的引用而导致不能被回收，这就是java中内存泄露的发生场景。具体主要有如下几大类： 静态集合类引起内存泄露像HashMap、Vector等的使用最容易出现内存泄露，这些静态变量的生命周期和应用程序一致，他们所引用的所有的对象Object也不能被释放，因为他们也将一直被Vector等引用着。例:1234567Static Vector v = new Vector(10); for (int i = 1; i&lt;100; i++) { Object o = new Object(); v.add(o); o = null; //只是当前引用被赋予null，对象o依然是有值}// 在这个例子中，循环申请Object对象，并将所申请的对象放入一个Vector中，如果仅仅释放引用本身（o=null），那么Vector仍然引用该对象，所以这个对象对GC来说是不可回收的。因为，GC在跟踪代码栈中的引用时，会发现v引用，而继续往下跟踪，就会发现v引用指向的内存空间中又存在指向Object对象的引用。也就是说尽管o引用已经被置空，但是Object对象仍然存在其他的引用，是可以被访问到的，所以GC无法将其释放掉。因此，如果对象加入到Vector后，还必须从Vector中删除，最简单的方法就是将Vector对象设置为null。 覆写hashcode当集合里面的对象属性被修改后，再调用remove()方法时不起作用。（这需要覆写hashcode()，此hashcode()必需包含被修改的属性） 例1实体对象，覆写hashcode方法1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071package memory; public class Person { private String username; private String password; private int age; public Person(String username, String password, int age) { this.username = username; this.password = password; this.age = age; } public String getUsername() { return username; } public void setUsername(String username) { this.username = username; } public String getPassword() { return password; } public void setPassword(String password) { this.password = password; } public int getAge() { return age; } public void setAge(int age) { this.age = age; } public int hashCode() { final int prime = 31; int result = 1; result = prime * result + age; result = prime * result + ((password == null) ? 0 : password.hashCode()); result = prime * result + ((username == null) ? 0 : username.hashCode()); return result; } public boolean equals(Object obj) { if (this == obj) return true; if (obj == null) return false; if (getClass() != obj.getClass()) return false; Person other = (Person) obj; if (age != other.age) return false; if (password == null) { if (other.password != null) return false; } else if (!password.equals(other.password)) return false; if (username == null) { if (other.username != null) return false; } else if (!username.equals(other.username)) return false; return true; }} 123456789101112131415161718192021222324public static void main(String[] args) { Set&lt;Person&gt; set = new HashSet&lt;Person&gt;(); Person p1 = new Person(\"唐僧\", \"pwd1\", 25); Person p2 = new Person(\"孙悟空\", \"pwd2\", 26); Person p3 = new Person(\"猪八戒\", \"pwd3\", 27); set.add(p1); set.add(p2); set.add(p3); System.out.println(\"p1：\" + p1.hashCode()); System.out.println(\"p2：\" + p2.hashCode()); System.out.println(\"p3：\" + p3.hashCode()); System.out.println(\"修改前包含p3对象：\" + set.contains(p3) + \"；hasecode =\" + p3.hashCode()); // System.out.println(\"总共有:\" + set.size() + \" 个元素!\"); // 结果：总共有:3 个元素! p3.setAge(2); // 修改p3的年龄,此时p3元素对应的hashcode值发生改变 System.out.println(\"修改后包含p3对象：\" + set.contains(p3) + \"；hasecode =\" + p3.hashCode()); System.out.println(\"是否删除成功：\" + set.remove(p3)); // 此时remove不掉，造成内存泄漏 set.add(p3); // 重新添加，居然添加成功 System.out.println(\"-------------------------------新增p3后\"); for (Person person : set) { System.out.println(person + \"；\" + person.getUsername()); }} 结果1234567891011p1：107826683p2：130403032p3：136136341修改前包含p3对象：true；hasecode =136136341修改后包含p3对象：false；hasecode =136112316是否删除成功：false-------------------------------新增p3后memory.Person@81ce8bc；猪八戒memory.Person@7c5cad8；孙悟空memory.Person@66d4dfb；唐僧memory.Person@81ce8bc；猪八戒 总结：set是不能重复的。set的内部是一个HashMap，set#add()就是map#add()，map里是按照entry#table来存储对象的，add里是按照对象的hashcode的值计算table的位置。 未修改：根据hashcode计算的值，把对象引用存放在table的某个位置。 修改：根据新的hashcode的值，把对象引用存放在table的新位置。 修改前和修改后，实际上在table中存放了，2个地址。但是2个地址都是指向同一个引用。 hashcode是计算对象存储的地址，对象没有改变，改变的是hashcode，也就是存储的地址。所以有2个引用指向一个对象地址。contain = false，也是定位不到旧的hashcode计算值的table位置。这个hashcode被重新设置，所以并不存在table中。查看hashMap#add()，就可以知道新旧2个table位置，实际上存的都是对象的引用。旧的hashcode计算值的table位置是3，新的hashcode计算值的位置是15。 监听器在Java编程中，我们都需要和监听器打交道，通常一个应用当中会用到很多监听器，我们会调用一个控件的诸如addXXXListener()等方法来增加监听器，但往往在释放对象的时候却没有记住去删除这些监听器，从而增加了内存泄漏的机会。 各种连接比如数据库连接(dataSourse.getConnection())，网络连接(socket)和io连接，除非其显式的调用了其close()将其连接关闭，否则是不会自动被GC回收的。对于Resultset和Statement对象可以不进行显式回收，但Connection一定要显式回收，因为Connection在任何时候都无法自动回收，而Connection一旦回收，Resultset和Statement对象就会立即为NULL。但是如果使用连接池，情况就不一样了，除了要显式地关闭连接，还必须显式地关闭Resultset、Statement对象（关闭其中一个，另外一个也会关闭），否则就会造成大量的Statement对象无法释放，从而引起内存泄漏。这种情况下一般都会在try里面去的连接，在finally里面释放连接。 内部类和外部模块等的引用内部类的引用是比较容易遗忘的一种，而且一旦没释放可能导致一系列的后继类对象没有释放。此外程序员还要小心外部模块不经意的引用，例如程序员A负责A模块，调用了B模块的一个方法如:1public void registerMsg(Object b); 这种调用就要非常小心了，传入了一个对象，很可能模块B就保持了对该对象的引用，这时候就需要注意模块B是否提供相应的操作去除引用。 单例模式不正确使用单例模式是引起内存泄露的一个常见问题，单例对象在被初始化后将在JVM的整个生命周期中存在（以静态变量的方式），如果单例对象持有外部对象的引用，那么这个外部对象将不能被jvm正常回收，导致内存泄露。例子：12345678910111213141516171819class A{ public A(){ B.getInstance().setA(this); } .... } //B类采用单例模式 class B{ private A a; private static B instance=new B(); public B(){} public static B getInstance(){ return instance; } public void setA(A a){ this.a=a; } //getter... } 显然B采用singleton模式，它持有一个A对象的引用，而这个A类的对象将不能被回收。想象下如果A是个比较复杂的对象或者集合类型会发生什么情况。 本地变量在不涉及复杂数据结构的一般情况下，Java的内存泄露表现为一个内存对象的生命周期超出了程序需要它的时间长度。我们有时也将其称为“对象游离”。123456789101112131415161718public class FileSearch{ private byte[] content; private File mFile; public FileSearch(File file){ mFile = file; } public boolean hasString(String str){ int size = getFileSize(mFile); content = new byte[size]; loadFile(mFile, content); String s = new String(content); return s.contains(str); }} 在这段代码中，FileSearch类中有一个函数hasString，用来判断文档中是否含有指定的字符串。流程是先将mFile加载到内存中，然后进行判断。但是，这里的问题是，将content声明为了实例变量，而不是本地变量（局部变量）。于是，在此函数返回之后，内存中仍然存在整个文件的数据。而很明显，这些数据我们后续是不再需要的，这就造成了内存的无故浪费。要避免这种情况下的内存泄露，要求我们以C/C++的内存管理思维来管理自己分配的内存。 是在声明对象引用之前，明确内存对象的有效作用域。在一个函数内有效的内存对象，应该声明为local变量，与类实例生命周期相同的要声明为实例变量以此类推。 在内存对象不再需要时，记得手动将其引用置空。","link":"/JVM-JMM-JDK7/"},{"title":"深入理解Finalize","text":"1 基础 2 对象销毁和对象重生 unfinalized finalizable finalized reachable finalizer-reachable unreachable 2.2 对象再生 2.2.1 例子1 2.2.2 例子2 3 Finalize执行顺序 4 何时及如何使用finalize 5 finalize的安全性 5.1 Finalizer类属性结构 5.2 Finalizer.class 5.3 总结 1 基础Java技术允许使用finalize()在垃圾收集器将对象从内存中清除出去之前做必要的清理工作。这个方法是由垃圾收集器在确定这个对象没有被引用时，对这个对象调用的。它是在Object类中定义的，因此所有的类都继承了它。子类覆盖finalize()以整理系统资源或者执行其他清理工作（要不然会引起资源泄露，有可能导致程序崩溃）。finalize()是在垃圾收集器删除对象之前被自动调用的。垃圾收集器只知道释放那些由new分配的内存，所以不知道如何释放对象的“特殊”内存。为解决这个问题，Java提供了一个名为finalize()，它的工作原理应该是这样的：一旦垃圾收集器准备好释放对象占用的存储空间，它首先调用finalize()，而且只有在下一次垃圾收集过程中，才会真正回收对象的内存（垃圾回收需要2次）。所以如果使用finalize()，就可以在垃圾收集期间进行一些重要的清除或清扫工作(如关闭流等操作)。但JVM(Java虚拟机)不保证此方法总被调用。finalize()抛出的未捕获异常只会导致该对象的finalize()执行退出。用户可以自己调用对象的finalize()，但是这种调用是正常的方法调用，和对象的销毁过程无关。 2 对象销毁和对象重生一个简单的对象生命周期为，Unfinalized、Finalizable、Finalized、Reclaimed。在对象的销毁过程中，按照对象的finalize()的执行情况，可以分为以下几种，系统会记录对象的对应状态。 unfinalized没有执行finalize()，系统也不准备执行。 finalizable可以执行finalize()了，系统会在随后的某个时间执行finalize。 finalized该对象的finalize()已经被执行了。GC怎么来保持对finalizable()的对象的追踪呢。GC有一个Queue，叫做F-Queue，所有对象在变为finalizable的时候会加入到该Queue，然后等待GC执行它的finalize()。这时我们引入了对对象的另外一种记录分类，系统可以检查到一个对象属于哪一种： reachable从活动的对象引用链可以到达的对象。包括所有线程当前栈的局部变量，所有的静态变量等等。 finalizer-reachable除了reachable外，从F-Queue可以通过引用到达的对象。 unreachable其它的对象，不可达对象。 首先，所有的对象都是从Reachable+Unfinalized（没有执行finalize()，对象可达）走向死亡之路的。 从当前活动集到对象不可达时，对象可以从Reachable状态变到F-Reachable（进入F-Queue，对象变成finalizable状态）或者Unreachable状态。 当对象为非Reachable+Unfinalized时，GC会把它移入F-Queue，状态变为F-Reachable+Finalizable（进入F-Queue，可达，finalizable状态）。 任何时候，GC都可以从F-Queue中拿到一个Finalizable的对象，标记它为Finalized，然后执行它的finalize()，由于该对象在这个线程中又可达了，于是该对象变成Reachable了（并且Finalized）。而finalize()执行时，又有可能把其它的F-Reachable（进入F-Queue，finalizable状态）的对象变为一个Reachable的，这个叫做对象再生。 当一个对象在Unreachable+Unfinalized时，如果该对象使用的是默认的Object的finalize，或者虽然重写了，但是新的实现什么也不干（子类覆写一个空方法）。为了性能，GC可以把该对象之间变到Reclaimed状态直接销毁，而不用加入到F-Queue等待GC做进一步处理。（不可达，不执行finalize()） 从状态图看出，不管怎么折腾，任意一个对象的finalize只至多执行一次，一旦对象变为Finalized（执行过finalized()），就怎么也不会在回到F-Queue（finalizable状态）去了。当然没有机会再执行finalize了。 当对象处于Unreachable+Finalized时，该对象离真正的死亡不远了。GC可以安全的回收该对象的内存了。进入Reclaimed。 2.2 对象再生2.2.1 例子1123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354package demo1; class C { static A a;}class A { B b; public A(B b) { this.b = b; } @Override public void finalize() { System.out.println(\"A finalize\"); //C实例化a引用 C.a = this; }}class B { String name; int age; public B(String name, int age) { this.name = name; this.age = age; } @Override public void finalize() { System.out.println(\"B finalize\"); } @Override public String toString() { return name + \" is \" + age; }}public class Main { public static void main(String[] args) throws Exception { A a = new A(new B(\"allen\", 20)); //强制销毁 a = null; System.gc(); Thread.sleep(5000); //销毁之后，可能会重生 System.out.println(C.a.b); }} 控制台123A finalizeB finalizeallen is 20 A类中持有B类的引用，A对象=null，强制销毁，执行finalize()，这个方法里，有重新赋值。这个对象从finalizer-reachable状态 -&gt; reachable-finalized，这个对象又重新创建了。但是，对象只能复活一次；在垃圾回收过程中，不能对复活对象调用finalize()，因为复活的对象第一次finalize运行过后，该对象的finalizable置为false了（状态已经变成finalized），该对象即使以后被GC运行，也不会执行finalize()了，所以对象只能复活1次。 2.2.2 例子21234567891011package demo3;public class B { static B b; public void finalize() { System.out.println(\"method B.finalize\"); b = this; } } 123456789101112131415package demo3;public class M { public static void main(String[] args) { B b = new B(); b = null; //第1次GC，b再生 System.gc(); //赋值为空，再次GC，b被销毁，但是已经被标注为执行过finalize B.b = null; System.gc(); }} 打印1method B.finalize 3 Finalize执行顺序所有finalizable状态的对象的finalize()的执行是不确定的，既不确定由哪个线程执行，也不确定执行的顺序。考虑以下情况就明白为什么了，实例a，b，c是一组相互循环引用的finalizable对象。finalize()操作具有下列限制：垃圾回收过程中执行准确时间是不确定的。不保证资源在任何特定的时间都能释放，除非调用Close()或Dispose()。即使一个对象引用另一个对象，也不能保证两个对象的finalize()以任何特定的顺序运行。即，如果对象A具有对对象B的引用，并且两者都有finalize()，则当对象A的finalize()启动时，对象B可能已经运行结束了。 4 何时及如何使用finalize 最重要的，尽量不要用finalize，太复杂了，还是让系统照管比较好。可以定义其它的方法来释放非内存资源。 如果用，尽量简单。 如果用，避免对象再生，这个是自己给自己找麻烦。 可以用来保护非内存资源被释放。即使定义了其它的方法来释放非内存资源，但是其它人未必会调用该方法来释放。在finalize里面可以检查一下，如果没有释放就释放好了，晚释放总比不释放好。 即使对象的finalize已经运行了，不能保证该对象被销毁。要实现一些保证对象彻底被销毁时的动作，只能依赖于java.lang.ref里面的类和GC交互了。 5 finalize的安全性一个类覆写finalize()，通过jmap命令查看，创建很多finalize实例对象。12345678910111213141516package demo3;public class P { public static void main(String[] args) { while (true) { P heap = new P(); System.out.println(\"memory address=\" + heap); } } @Override public void finalize(){ System.out.println(\"finalize.\"); }} 创建Finalizer类的实例有12923个。 5.1 Finalizer类属性结构 ReferenceQueue queue：引用队列。 Finalizer unfinalized：Finalizer类实现内部链表。 Object lock：同步监视器对象。 通过断点分析Finalizer源码来了解Finalizer创建实例过程。 5.2 Finalizer.class123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197.....final class Finalizer extends FinalReference { /* Package-private; must be in same package as the Reference class */ private static ReferenceQueue queue = new ReferenceQueue(); private static Finalizer unfinalized = null; private static final Object lock = new Object(); private Finalizer next = null, prev = null; private boolean hasBeenFinalized() { return (next == this); } private void add() { synchronized (lock) { if (unfinalized != null) { this.next = unfinalized; unfinalized.prev = this; } unfinalized = this; } } private void remove() { synchronized (lock) { if (unfinalized == this) { if (this.next != null) { unfinalized = this.next; } else { unfinalized = this.prev; } } if (this.next != null) { this.next.prev = this.prev; } if (this.prev != null) { this.prev.next = this.next; } this.next = this; /* Indicates that this has been finalized */ this.prev = this; } } private Finalizer(Object finalizee) { super(finalizee, queue); add(); } /* Invoked by VM */ static void register(Object finalizee) { new Finalizer(finalizee); } private void runFinalizer(JavaLangAccess jla) { synchronized (this) { if (hasBeenFinalized()) return; remove(); } try { Object finalizee = this.get(); if (finalizee != null &amp;&amp; !(finalizee instanceof java.lang.Enum)) { jla.invokeFinalize(finalizee); /* Clear stack slot containing this variable, to decrease the chances of false retention with a conservative GC */ finalizee = null; } } catch (Throwable x) { } super.clear(); } /* Create a privileged secondary finalizer thread in the system thread group for the given Runnable, and wait for it to complete. This method is used by both runFinalization and runFinalizersOnExit. The former method invokes all pending finalizers, while the latter invokes all uninvoked finalizers if on-exit finalization has been enabled. These two methods could have been implemented by offloading their work to the regular finalizer thread and waiting for that thread to finish. The advantage of creating a fresh thread, however, is that it insulates invokers of these methods from a stalled or deadlocked finalizer thread. */ private static void forkSecondaryFinalizer(final Runnable proc) { AccessController.doPrivileged( new PrivilegedAction&lt;Void&gt;() { public Void run() { ThreadGroup tg = Thread.currentThread().getThreadGroup(); for (ThreadGroup tgn = tg; tgn != null; tg = tgn, tgn = tg.getParent()); Thread sft = new Thread(tg, proc, \"Secondary finalizer\"); sft.start(); try { sft.join(); } catch (InterruptedException x) { /* Ignore */ } return null; }}); } /* Called by Runtime.runFinalization() */ static void runFinalization() { if (!VM.isBooted()) { return; } forkSecondaryFinalizer(new Runnable() { private volatile boolean running; public void run() { if (running) return; final JavaLangAccess jla = SharedSecrets.getJavaLangAccess(); running = true; for (;;) { Finalizer f = (Finalizer)queue.poll(); if (f == null) break; f.runFinalizer(jla); } } }); } /* Invoked by java.lang.Shutdown */ static void runAllFinalizers() { if (!VM.isBooted()) { return; } forkSecondaryFinalizer(new Runnable() { private volatile boolean running; public void run() { if (running) return; final JavaLangAccess jla = SharedSecrets.getJavaLangAccess(); running = true; for (;;) { Finalizer f; synchronized (lock) { f = unfinalized; if (f == null) break; unfinalized = f.next; } f.runFinalizer(jla); }}}); } private static class FinalizerThread extends Thread { private volatile boolean running; FinalizerThread(ThreadGroup g) { super(g, \"Finalizer\"); } public void run() { if (running) return; // Finalizer thread starts before System.initializeSystemClass // is called. Wait until JavaLangAccess is available while (!VM.isBooted()) { // delay until VM completes initialization try { VM.awaitBooted(); } catch (InterruptedException x) { // ignore and continue } } final JavaLangAccess jla = SharedSecrets.getJavaLangAccess(); running = true; for (;;) { try { Finalizer f = (Finalizer)queue.remove(); f.runFinalizer(jla); } catch (InterruptedException x) { // ignore and continue } } } } static { ThreadGroup tg = Thread.currentThread().getThreadGroup(); for (ThreadGroup tgn = tg; tgn != null; tg = tgn, tgn = tg.getParent()); Thread finalizer = new FinalizerThread(tg); finalizer.setPriority(Thread.MAX_PRIORITY - 2); finalizer.setDaemon(true); finalizer.start(); }} VM创建一个覆写finalize()的JavaBean，会执行register()，这个方法会创建一个新的Finalizer类的实例化对象。1new Finalizer(finalizee); Finalizer()，会把覆写finalizer()的类实例对象添加到ReferenceQueue（引用队列中），然后执行add()。12super(finalizee, queue);add(); add()添加当前覆写finalizer()的类实例对象（父类的referent指向覆写finalizer()的类实例对象）到unfinalized链表中，这样这个覆写finalize()的类实例，第1次不会被GC回收，因为有链表引用。123456789private void add() { synchronized (lock) { if (unfinalized != null) { this.next = unfinalized; unfinalized.prev = this; } unfinalized = this; }} FinalizerThread是JVM内部的守护线程，优先级很低，是个单一职责的线程。12345678910111213141516171819202122232425262728293031private static class FinalizerThread extends Thread { private volatile boolean running; FinalizerThread(ThreadGroup g) { super(g, \"Finalizer\"); } public void run() { if (running) return; // Finalizer thread starts before System.initializeSystemClass // is called. Wait until JavaLangAccess is available while (!VM.isBooted()) { // delay until VM completes initialization try { VM.awaitBooted(); } catch (InterruptedException x) { // ignore and continue } } final JavaLangAccess jla = SharedSecrets.getJavaLangAccess(); running = true; for (;;) { try { Finalizer f = (Finalizer)queue.remove(); f.runFinalizer(jla); } catch (InterruptedException x) { // ignore and continue } } }} 该线程从引用队列中删除并获取finalizer对象，finalizer对象执行runFinalizer()。12Finalizer f = (Finalizer)queue.remove();f.runFinalizer(jla); runFinalizer()是删除finalizer链表中的finalizer对象，并且执行该对象的finalize()，删除finalizer链表中的对象，这样Finalizer的链表就没有指向覆写finalizer()的类实例（父类的referent指向覆写finalizer()的类实例对象），则该实例就会在下一次GC被回收。1234567891011121314151617private void runFinalizer(JavaLangAccess jla) { synchronized (this) { if (hasBeenFinalized()) return; remove(); } try { Object finalizee = this.get(); if (finalizee != null &amp;&amp; !(finalizee instanceof java.lang.Enum)) { jla.invokeFinalize(finalizee); /* Clear stack slot containing this variable, to decrease the chances of false retention with a conservative GC */ finalizee = null; } } catch (Throwable x) { } super.clear();} 5.3 总结 如果一个类A实现了finalize()，那么每次创建A类对象的时候，都会多创建一个Finalizer对象(Finalizer父类的referent指向覆写finalizer()的类实例对象）；如果类没有实现finalize()，那么不会创建额外的Finalizer对象。 Finalizer内部维护了一个unfinalized链表，每次创建的Finalizer对象都会插入到该链表中。 如果类没有实现finalize()，那么进行垃圾回收的时候，可以直接从堆内存中释放该对象。这是速度最快，效率最高的方式。 如果类实现了finalize()，进行GC的时候，如果发现某个对象只被Finalizer对象引用（父类的referent属性引用），那么会将该Finalizer对象加入到Finalizer类的引用队列（ReferenceQueue）中，并添加到unfinalized链表中。 runFinalizer是JVM内部的守护线程，优先级很低。Finalizer线程是个单一职责的线程。这个线程会不停的循环等待java.lang.ref.Finalizer.ReferenceQueue中的新增对象。一旦Finalizer线程发现队列中出现了新的对象，它会弹出该对象，将该引用从Finalizer类链表中移除，调用它的finalize()，因此下次GC再执行的时候，这个Finalizer实例以及它引用的那个对象（覆写finalizer()的类实例对象）就可以回垃圾回收掉了。 使用finalize()容易导致OOM，因为如果创建对象的速度很快，那么Finalizer线程的回收速度赶不上创建速度，就会导致内存垃圾越来越多，这些对象从Eden移动到Survivor区，如果拷贝溢出，就将溢出的数据晋升到Old（老年代），进行Full GC。 注意:覆写finalize()，不能够证明GC执行了2次。实际上是1个线程执行：添加对象到Finalizer链表中；另一个线程执行从链表中删除这个对象，执行finalizer()。","link":"/JVM-Finalize/"},{"title":"锁粒度的控制","text":"update数据库的时候，数据库控制并发的方式，基本分为2种：乐观锁、悲观锁。 悲观锁锁记录我们一般的操作就是SELECT … FOR UPDATE，行级锁。这个SQL在读取完数据后，就能把这行数据锁住，防止其它SESSION对行数据进行修改。这就是我们所说的悲观锁。为什么叫悲观锁呢，因为它会让其它SESSION阻塞，等待锁定行记录的那条SESSION将修改COMMIT掉后才能获得对行数据的操作资源。我们通常不提倡用悲观锁，为什么呢？因为我们通常公司里的服务都是访问量挺高的，所以占用数据池资源是挺大的，如果用悲观锁，就会导致很多的资源阻塞而无法使用，这样我们的系统便会变得很慢，老是在等资源。个人觉得悲观锁的使用场景得看业务和实际情况，如果这个模块本身访问量就很低，那就可以用悲观锁。 乐观锁在表中加入版本号字段，更新时将版本号同时更新。在表中加入字段，每次UPDATE前会先去读取该版本号（可以是一个整数），更新的时候将之前读取版本号加1再和实际那行的版本号比较，如果大于实际版本号便更新，其他则失败。举个例子，比如表中的字段LOCK_ST = 0。2个SEESION同时去更新它，a SESSION和b SESSION同时会读取0这个值，然后a比较快，更新了这条数据，并把版本字段LOCK_ST更新成1，这个时候b再去更新，b会把读到的LOCK_ST加1，也就是0+1，然后提交更新的时候比较版本号，发现1=1，所以更新不了，于是b就失败了。这就是我们所说的乐观锁。不锁定资源，任由所有SESSION都去更新，但是更新会失败。通常我们的系统中比较提倡乐观锁，原因和悲观锁正好相反。","link":"/Lock-Control/"},{"title":"第45条-将局部变量的作用域最小化","text":"优点 优化思路 优点增强代码的可读性，可维护性，并降低错误的可能性。 优化思路 要使局部变量的作用域最小化，最有力的方法就是在第一次使用它的地方声明，这样有便于读者集中注意力，不容易分散；如果在之前申明，阅读者很容易忘记变量的类型和变量的意义。 过早的声明变量，使得变量的作用域过早的扩展（作用域扩大），变量销毁的时间过于晚。 变量的作用域从申明点开始，到这个方法的结束。 局部变量声明的时候，都应该要先初始化变量。比如，A a;写成A a=null;相对更好，更直观的看到a = null。 循环的使用，for和while；for比while好用。for变量定义在for的作用域内部，while则在外部。这样容易造成变量使用错误，而不会报异常。for更简短，增强可读性。 将局部变量的作用域最小化。如果一个方法有2个操作（不只是业务），可以拆分成2个方法，变量不会冲突，耦合度低。（平时开发也是这样，耦合度低，扩展性好，可读性强，好维护）","link":"/Minimize-The-Scope-Of-Local-Variables/"},{"title":"MySQL基本命令","text":"表状态SHOW TABLE STATUS LIKE 't_b_poc_notice_line%'; 删除进程123select * from information_schema.innodb_trx kill 3511909 查看表锁show OPEN TABLES where In_use &gt; 0; 查看进程号show processlist; 删除进程kill 1085850;","link":"/MySQL-Command/"},{"title":"MyBatis SQL日志源码分析","text":"1 源码 BaseJdbcLogger PreparedStatementLogger ResultSetLogger 2 打印debug的日志 3 字符串前缀 1 源码BaseJdbcLogger打印日志的抽象类。 PreparedStatementLoggerPreparedStatement的日志。 ResultSetLoggerResultSet的日志。 2 打印debug的日志12345protected void debug(String text, boolean input) { if (statementLog.isDebugEnabled()) { statementLog.debug(prefix(input) + text); }} 3 字符串前缀1234567891011private String prefix(boolean isInput) { char[] buffer = new char[queryStack * 2 + 2]; Arrays.fill(buffer, '='); buffer[queryStack * 2 + 1] = ' '; if (isInput) { buffer[queryStack * 2] = '&gt;'; } else { buffer[0] = '&lt;'; } return new String(buffer); }","link":"/MyBatis-SQL-Log/"},{"title":"MongoDB如何选择片键","text":"shard key需要有高的散列程度（应该包含不同的值）。也就是shard key需要拥有很多不同的值。便于数据的切分和迁移。 尽量与应用程序融合。让mongos面对查询时可以直接定位到某个shard。 具有随机性。这是为了不会让某段时间内的insert请求全部集中到某个单独的分片上，造成单片的写速度成为整个集群的瓶颈。用ObjectId作为shard key时会发生随机性差情况。ObjectId实际上由进程ID+TIMESTAMP + 其他因素，所以一段时间内的timestamp会相对集中。不过随机性高会有一个副作用，就是查询性比较差。可用hash key（散列值）增加随机性。 如果片键变化少，又想它作为片键，可以选择使用组合片键。 片键数量有限，这种片键称为：小基数片键。这种片键，到数据量变多的时候，会造成数据无法分隔，磁盘逐渐耗尽的情况。 片键无法修改。 组合片键：｛”值映射多个数据块”，”搜索字段”｝","link":"/MongoDB-Select-Sharding/"},{"title":"最佳调度问题(回溯算法)","text":"1 概述 2 解题思路 3 程序代码 1 概述掌握调度问题的处理方法，实现最佳调度问题的回溯解决。 2 解题思路一个深度为N的M叉树。基本思路： 搜索从开始结点（根结点）出发，以DFS搜索整个解空间。 每搜索完一条路径则记录下besttime和bestx[]序列 开始结点就成为一个活结点，同时也成为当前的扩展结点。在当前的扩展结点处向纵深方向移至一个新结点，并成为一个新的活结点，也成为当前扩展结点。 如果在当前的扩展结点处不能再向纵深方向扩展，则当前扩展结点就成为死结点。 此时，应往回移动（回溯）至最近的一个活结点处，并使这个活结点成为当前的扩展结点；直至找到一个解或全部解。 3 程序代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140package demo4;import java.util.Random;/** * 最佳调度问题 */public class BestSchedule { /** * 任务数 */ int N; /** * 机器数 */ int M; /** * 最优值=最优时间 */ int best; /** * 每个任务所需的时间序列 */ int[] t; /** * 每台机器所需时间序列 */ int[] len; /** * 当前路径=机器编号 * x[i]=j：i任务，j机子编号 */ int[] x; /** * 最优调度：其中bestx[i]=m表示把第i项任务分配给第m台机器 */ int[] bestx; public static void main(String[] args) { BestSchedule bs = new BestSchedule(); bs.showTest(); } void showTest() { N = 10; // 任务数 M = 7; // 机器数目 Random r = new Random(); // 每个任务的时间 t = new int[N]; //随机分配每个任务所需要的时间 for (int i = 0; i &lt; N; i++) { t[i] = r.nextInt(5 * N); } // 记录每台机器所需要的时间 len = new int[M]; best = Integer.MAX_VALUE; // N个任务分配第几台机子 bestx = new int[N]; x = new int[N]; Long startTime = System.nanoTime(); backtrack(0); Long endTime = System.nanoTime(); System.out.println(\"总耗时： \" + (endTime - startTime) + \" ns\"); System.out.print(\"最优时间：\"); System.out.println(best); System.out.print(\"每个任务所需要时间：\"); for (int i = 0; i &lt; N; i++){ System.out.print(t[i] + \" \"); } System.out.println(); System.out.print(\"最优调度：\"); for (int i = 0; i &lt; N; i++){ System.out.print(bestx[i] + \" \"); } } /** * 回溯搜索 * @param dep 任务编号 */ void backtrack(int dep) { //打印最优解数据，打印i个任务由那个机子执行效率高 if (dep == N) { //时间 int tmp = comp(); //比最优解时间都小 if (tmp &lt; best) { //最优时间 best = tmp; //遍历N个任务 for (int i = 0; i &lt; N; i++) { //第i任务分配给x[i]个机器 bestx[i] = x[i]; } } return; } //遍历机器 // for (int i = 0; i &lt; M; i++) { //第i台机子执行任务所需时间+dep任务所需要的时间 len[i] += t[dep]; //机子下标从1开始 //当前任务dep由i机子执行 x[dep] = i + 1; //i台机子执行完当前dep任务的时间比最优解小，执行下一个任务 //下一个任务继续循环遍历机子 //会在最优解时间内执行完任务，那么此任务符合条件 //问题：导致每台机子执行，都有可能是最优解，每个任务都被所有机子执行 if (len[i] &lt; best) { backtrack(dep + 1); } //当前机子i执行任务dep，不比最优解小，减去当前dep任务执行的时间 //继续下一个机子i+1执行dep任务 len[i] -= t[dep]; } } /** * 计算完成任务的时间 * @return 机器执行任务时间 */ int comp() { //机器完成任务时间 int tmp = 0; //遍历机器 for (int i = 0; i &lt; M; i++) { //当前机器执行任务时间&gt;之前机器执行任务时间 if (len[i] &gt; tmp) { tmp = len[i]; } } return tmp; }} 结果:1234总耗时： 6291008 ns最优时间：45每个任务所需要时间：11 7 45 44 14 15 2 20 41 39 最优调度：1 1 2 3 1 4 1 4 5 6","link":"/Optimal-Scheduling-Problem/"},{"title":"Python2切换Python3","text":"Ubuntu自带python2，有时候需要使用pytho3。使用 update-alternatives 建立链接1sudo update-alternatives --install /usr/bin/python python /usr/local/lib/python2.7 100 1sudo update-alternatives --install /usr/bin/python python /usr/local/lib/python3.2 150 如果要切换到Python21sudo update-alternatives --config python","link":"/Python2ToPython3/"},{"title":"最优装载问题(分支界限算法)","text":"1 概述 2 解题思路 3 程序代码 C++代码 Java代码 活动队列 1 概述有一批共n个集装箱要装上2艘载重量分别为c1，c2的轮船，其中集装箱i的重量为wi，且要求确定是否有一个合理的装载方案可将这n个集装箱装上这2艘轮船。可证明，采用如下策略可以得到一个最优装载方案：先尽可能的将第一艘船装满，其次将剩余的集装箱装到第二艘船上。 2 解题思路 首先将第一艘轮船尽可能装满。 将剩余的集装箱装上第二艘轮船。 在算法的while循环中，首先检测当前扩展结点的左儿子结点是否为可行结点。如果是则将其加入到活结点队列中。然后将其右儿子结点加入到活结点队列中(右儿子结点一定是可行结点)。2个儿子结点都产生后，当前扩展结点被舍弃。活结点队列中的队首元素被取出作为当前扩展结点，由于队列中每一层结点之后都有一个尾部标记-1，故在取队首元素时，活结点队列一定不空。当取出的元素是-1时，再判断当前队列是否为空。如果队列非空，则将尾部标记-1加入活结点队列，算法开始处理下一层的活结点。节点的左子树表示将此集装箱装上船，右子树表示不将此集装箱装上船。设bestw是当前最优解；ew是当前扩展结点所相应的重量；r是剩余集装箱的重量。则当ew+r&lt;bestw时，可将其右子树剪去，因为此时若要船装最多集装箱，就应该把此箱装上船。另外，为了确保右子树成功剪枝，应该在算法每一次进入左子树的时候更新bestw的值。为了在算法结束后能方便地构造出与最优值相应的最优解，算法必须存储相应子集树中从活结点到根结点的路径。为此目的，可在每个结点处设置指向其父结点的指针，并设置左、右儿子标志。找到最优值后，可以根据parent回溯到根节点，找到最优解。123456789101112131415161718192021222324变量含义： Ew: 扩展节点的载重量 W: 重量数组 Q: 活节点队列 bestw: 当前最优载重量 i: 当前处理到的层数 n: 总货物数 while (true) { // 检查左儿子结点 if (Ew + w[i] &lt;= c) //x[i] = 1 EnQueue(Q, Ew + w[i], bestw, i, n); // 右儿子结点总是可行的 EnQueue(Q, Ew, bestw, i, n); //x[i] = 0 Q.Delete(Ew); // 取下一扩展结点 if (Ew == -1) { // 同层结点尾部 if (Q.IsEmpty()) return bestw; Q.Add(-1); // 同层结点尾部标志 Q.Delete(Ew); // 取下一扩展结点 i++; // 进入下一层 }} 3 程序代码备注：C++和Java版本并没有实现最优解。 C++代码12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455#include&lt;iostream&gt;#include&lt;queue&gt;using namespace std;//Q为队列，wt为当前扩展结点所对应的载重量，bestw最优载重量，//i当前层数，n为总层数void enqueue(queue&lt;int&gt; &amp;Q,int wt,int &amp;bestw,int i,int n){ if(i==n) { if(wt&gt;bestw) bestw=wt; }else Q.push(wt);//非叶子结点则加入队列中}int MaxLoading(int w[],int c,int n){ //初始化 queue&lt;int&gt; q; q.push(-1); int i=1; int EW=0,bestw=0; while(true) { if(w[i]+EW&lt;=c) { enqueue(q,w[i]+EW,bestw,i,n); } enqueue(q,EW,bestw,i,n); EW=q.front(); q.pop(); if(EW==-1) { if(q.empty()) return bestw; q.push(-1); EW=q.front(); q.pop(); i++; } }}void main(){ //物品的个数 int n=3; //背包的容量 int c =50; //物品的重量 int w[100]={10,40,50}; int bestw = MaxLoading(w,c,n); cout&lt;&lt;\"做大装载量为\"&lt;&lt;bestw&lt;&lt;endl; cout&lt;&lt;\"end\";} Java代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182package demo1;/** * 分支限界FIFO * */public class BranchLimitFIFOSearch { public static void main(String[] args) { // n个货箱 int n = 3; // 第一艘船的载重量 float c1 = 50; // 第二艘船的载重量 float c2 = 50; // 货箱质量数组 float[] w = { 0, 10, 40, 40 }; // 初始化 BranchLimitFIFOSearch bfis = new BranchLimitFIFOSearch(n, c1, c2, w); // 所有货箱的重量之和 float s = bfis.getS(); if (s &lt;= c1 || s &lt;= c2) { System.out.println(\"只需要1首船！\"); } if (s &gt; c1 + c2) { System.out.println(\"2首船不能解决问题！\"); return; } // 获取最大装载 bfis.maxLoading(c1); // 第一艘船的最大装载 float bestw = bfis.getBestw(); if (s - bestw &lt;= c2) { System.out.println(\"第1首船装载： \" + bestw); System.out.println(\"第2首船装载： \" + (s - bestw)); } else { System.out.println(\"不能解决问题\"); } } private int n; // n个货箱 private float c1; // 第一艘船的载重量 private float c2; // 第二艘船的载重量 private float bestw; // 第一艘船的最大装载 private float ew = 0; // 当前船的装载量 private float[] w; // 货箱质量数组 private float s = 0; // 所有货箱的重量之和 private MyQueue mq = new MyQueue(); // FIFO队列，活动队列 /** * 构造方法 * * @param _n * @param _c1 * @param _c2 * @param _w */ public BranchLimitFIFOSearch(int _n, float _c1, float _c2, float[] _w) { n = _n; c1 = _c1; c2 = _c2; w = _w; for (float f : _w) { s += f; } } /** * 最优装载值 * * @param c * 第1首船的载重量 */ public float maxLoading(float c) { // 初始化结点队列，标记分层 // -1：每一层处理完，都以-1为标记 mq.put(new Float(-1)); // A结点的层 int i = 1; // 当前船的装载量 ew = 0; // 目前的最优值 bestw = 0; // 搜索子集空间树 while (!mq.empty()) { // 检查A结点的左孩子，货箱i是否可以装载 // ew船目前载重量 // 符合条件放到活动队列中 if (ew + w[i] &lt;= c) { // 货箱i可以装载 addLiveNode(ew + w[i], i); } // 右孩子总是可行的，不装载货物i addLiveNode(ew, i); // 获取活动队列 ew = (Float) mq.get(); // 到达层的尾部，每层的结束 if (ew == -1) { // 活动队列没有数据，则返回最优解 if (mq.empty()) { return bestw; } // 处理完当前层，标记-1 mq.put(new Float(-1)); // 获取活动队列的下一个节点，表示船的载重量 ew = (Float) mq.get(); i++; // ew的层 } } return bestw; } /** * 入队 * * @param wt * @param i */ public void addLiveNode(float wt, int i) { if (i == n) { // 是叶子 // 最大重量 if (wt &gt; bestw) { bestw = wt; } } else { // 不是叶子 // 添加到队列中 mq.put(new Float(wt)); } } public int getN() { return n; } public void setN(int n) { this.n = n; } public float getC1() { return c1; } public void setC1(float c1) { this.c1 = c1; } public float getC2() { return c2; } public void setC2(float c2) { this.c2 = c2; } public float getBestw() { return bestw; } public void setBestw(float bestw) { this.bestw = bestw; } public float getEw() { return ew; } public void setEw(float ew) { this.ew = ew; } public float getS() { return s; } public void setS(float s) { this.s = s; }} 活动队列12345678910111213141516171819202122232425262728293031323334353637383940414243package demo1;import java.util.LinkedList;/** * 自定义活动队列 * * @since jdk1.6 * @author 毛正吉 * @version 1.0 * @date 2010.05.25 * */public class MyQueue { private LinkedList ll = new LinkedList(); /** * 入队 * * @param o */ public void put(Object o) { ll.addLast(o); } /** * 出队 * * @return */ public Object get() { return ll.removeFirst(); } /** * 队是否为空 * * @return */ public boolean empty() { return ll.isEmpty(); }}","link":"/Optimal-Loading-Problem/"},{"title":"推荐算法初步学习","text":"推荐算法","link":"/Recommended-Algorithm-Preliminary-Learning/"},{"title":"旋转交换(编程珠玑)","text":"1 问题 2 解决思路 方法1 方法2 3 程序代码 方法2的代码 1 问题请将一个具有n个元素的一维向量向左旋转i个位置。例如，假设n=8,i=3，那么向量abcdefgh旋转之后得到向量defghabc。简单编码使用一个具有n个元素的中间向量分n步即可完成此作业。你可以仅使用几十字节的微小内存，花费与n成比例的时间来旋转该向量吗？ 2 解决思路方法1将向量x中的前i个元素复制到一个临时数组中，接着将余下的n-i个元素左移i个位置，然后再将前i个元素从临时数组中复制回x中的后面位置。该方案使用i个额外的位置，如i足够大，过于浪费空间。 方法2将这个问题看作是把数组ab转换成数组ba吧，但同时也假定我们具有在数组中转置指定部分元素的函数。我们先从ab开始，转置a得到$a^rb$，再转置b得到$a^rb^r$，然后再转置整个$a^rb^r$得到$(a^rb^r)^r$，实际上就是ba。 reverse(0, i-1) reverse(i, n-1) reverse(0, n-1) 该转置代码在时间和空间上都很有效，并且是这么简短和简单，想出错都很难。 3 程序代码方法2的代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354#include &lt;stdio.h&gt;void swap(int *p, int *q);void reverse(int *vector, int index_begin, int index_end);void revrot(int *vector, int len, int step);int main(int argc, char **argv){ int step = 3; int i = 0; int vector[1024] = {1,2,3,4,5,6,7,8}; revrot(vector, 8, step); printf(\"after revolve: \"); for(i = 0; i &lt; 8; i++) { printf(\"%d \", vector[i]); } printf(\"\\n\");}//交换位置void swap(int *p, int *q){ int temp; temp = *p; *p = *q; *q = temp;}//@vector：数组//@index_begin：开始位置//@index_end：结束位置void reverse(int *vector, int index_begin, int index_end){ while(index_begin &lt; index_end) { swap(vector + index_begin, vector + index_end); index_begin++; index_end--; }}//@vector：数组//@len：数组长度//@step：反转位置void revrot(int *vector, int len, int step){ reverse(vector, 0, step - 1); reverse(vector, step, len - 1); reverse(vector, 0, len - 1);}","link":"/Rotary-Exchange/"},{"title":"QPS,PV,RT线程之间的关系","text":"1 QPS是什么 2 QPS如何统计 3 根据QPS推算PV 4 根据QPS,PV推算服务器数量 4.1 峰值QPS和机器计算公式 峰值时间每秒请求数(QPS) 峰值机器数量 4.2 例子 5 最佳线程数 5.1 为什么要找最佳线程数 5.2 最佳线程数的获取 5.3 影响最佳线程数的主要因素 IO CPU 6 QPS和线程数的关系 1 QPS是什么单个进程每秒请求服务器的成功次数QPS = req/sec = 请求数/秒 2 QPS如何统计QPS统计方式 [一般使用 http_load 进行统计]QPS = 总请求数 / ( 进程总数 * 请求时间 ) 3 根据QPS推算PV单台服务器每天PV计算: 公式1：每天总PV = QPS * 3600 * 6 公式2：每天总PV = QPS * 3600 * 8 4 根据QPS,PV推算服务器数量服务器数量 = 每天总PV / 单台服务器每天总PV 4.1 峰值QPS和机器计算公式每天80%的访问集中在20%的时间里，这20%时间叫做峰值时间 峰值时间每秒请求数(QPS)( 总PV数 * 80% ) / ( 每天秒数 * 20% ) 峰值机器数量峰值时间QPS / 单台机器的QPS 4.2 例子 每天300w PV 的在单台机器上，这台机器需要多少QPS？( 3000000 * 0.8 ) / (86400 * 0.2 ) = 139 (QPS) 如果一台机器的QPS是58，需要几台机器来支持？139 / 58 = 3 5 最佳线程数性能压测的情况下，起初随着用户数的增加，QPS会上升，当到了一定的阀值之后，用户数量增加QPS并不会增加，或者增加不明显，同时请求的响应时间却大幅增加。这个阀值我们认为是最佳线程数。 5.1 为什么要找最佳线程数 过多的线程只会造成，更多的内存开销，更多的CPU开销，但是对提升QPS确毫无帮助。 找到最佳线程数后通过简单的设置，可以让web系统更加稳定，得到最高，最稳定的QPS输出。5.2 最佳线程数的获取 通过用户慢慢递增来进行性能压测，观察QPS，响应时间。 根据公式计算:服务器端最佳线程数量=((线程等待时间+线程cpu时间)/线程cpu时间) * cpu数量。 单用户压测，查看CPU的消耗，然后直接乘以百分比，再进行压测，一般这个值的附近应该就是最佳线程数量。5.3 影响最佳线程数的主要因素IOIO开销较多的应用其CPU线程等待时间会比较长，所以线程数量可以开的多一些，相反则线程数量要少一些，其实有两种极端，纯IO的应用，比如proxy，则线程数量可以开到非常大（实在太大了则需要考虑线程切换的开销），这种应用基本上后端（比如这个proxy是代理搜索的）的QPS能有多少，proxy就有多少。CPU对于耗CPU的计算，这种情况一般来讲只能开到CPU个数的线程数量。但是并不是说这种应用的QPS就不高，往往这种应用的QPS可以很高，因为耗CPU计算的应用，往往处理单次请求的时间会很短。6 QPS和线程数的关系 在最佳线程数量之前，QPS和线程是互相递增的关系，线程数量到了最佳线程之后，QPS持平，不在上升，甚至略有下降，同时响应时间持续上升。 同一个系统而言，最佳线程数越多，QPS越高。","link":"/QPSPVRT/"},{"title":"SDCard文件读写权限","text":"1234&lt;!-- SDCard中创建与删除文件权限 --&gt; &lt;uses-permission android:name=\"android.permission.MOUNT_UNMOUNT_FILESYSTEMS\"/&gt; &lt;!-- 向SDCard写入数据权限 --&gt; &lt;uses-permission android:name=\"android.permission.WRITE_EXTERNAL_STORAGE\"/&gt;","link":"/SDCard-Read-Write/"},{"title":"最大值段和(分治法，动态规划)","text":"1 问题 2 解题 分治法 思路 三种情况 C版本 Java版本 1 2 动态规划法 C版本 Java版本 1 2 1 问题概念：给定n个整数（可能为负数）组成的序列a[1],a[2],a[3],…,a[n]，求该序列如a[i]+a[i+1]+…+a[j]的子段和的最大值。当所给的整均为负数时定义子段和为0，依此定义，所求的最优值为：Max{0,a[i]+a[i+1]+…+a[j]},1&lt;=i&lt;=j&lt;=n。一个数组a[]：需要求最大子段和的数组；一个数组b[]：数组a子段和的数组，{a[0]，a[0]+a[1]，a[0]+a[1]+a[2]...........}；例如，当(a[1],a[2],a[3],a[4],a[5],a[6])=(-2,11,-4,13,-5,-2)时，最大子段和为20。 2 解题分治法思路如果将所给的序列a[1:n]分为长度相等的两段a[1:n/2]和a[n/2+1:n],分别求出这两段的最大子段和，则a[1:n]的最大子段和：a[]:1..........................n分段处理:1..........n/2........n 三种情况 a[1:n]的最大子段和与a[1:n/2]的最大子段和相同（左边的子段和） a[1:n]的最大子段和与a[n/2+1:n]的最大子段和相同（右边的子段和） a[1:n]的最大子段和为a[i]+…+a[j]，并且1&lt;=i&lt;=n/2,n/2+1&lt;=j&lt;=n。（子段和=左边子段和+右边子段和） 对于（1）和（2）两种情况可递归求得，但是对于情况（3），容易看出a[n/2],a[n/2+1]在最大子段中。第3种情况：我们可以在a[1:n/2]中计算出s1=max(a[n/2]+a[n/2-1]+…+a[i]),0&lt;=i&lt;=n/2，并在a[n/2+1:n]中计算出s2= max(a[n/2+1]+a[n/2+2]+…+a[i]),n/2+1&lt;=i&lt;=n。则s1+s2为出现情况（3）的最大子段和。 C版本123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960#include&lt;stdio.h&gt;#define MAX100int maxsub(int left,int right);int a[MAX];int main(){ int i; int count; scanf(\"%d\",&amp;count); for(i=0;i&lt;count;i++) { scanf(\"%d\",&amp;a[i]); } printf(\"%d/n\",maxsub(0,count-1)); return 0; } // int maxsub(int left,int right) { int center,i; int sum,left_sum,right_sum; int left_max,right_max; center=(left+right)/2; //只有1位 if(left==right) return a[left]; else { left_sum=maxsub(left,center); right_sum=maxsub(center+1,right); sum=0; left_max=0; //遍历左边 //获取左边的最大子段和 for(i=center;i&gt;=left;i--) { sum+=a[i]; if(sum&gt;left_max) left_max=sum; } sum=0; right_max=0; //遍历右边，获取最大子段和 for(i=center+1;i&lt;=right;i++) { sum+=a[i]; if(sum&gt;right_max) right_max=sum; } // 第三种情况，最大子段和， //最大字段和=左边子段和+右边子段和 sum=right_max+left_max; if(sum&lt;left_sum) sum=left_sum; if(sum&lt;right_sum) sum=right_sum; } return sum;} Java版本112345678910111213141516171819202122232425262728293031323334353637383940414243444546474849package max.number;public class FenZhi { /** * 获取左边最大的字段和（连续的） * @param a * @return */ public static int getLeft(int[] a) { int left = 0, sum = 0, left_max = 0; int center = (a.length - 1) / 2; // 遍历左边 // 获取左边的最大子段和 for (int i = center; i &gt;= left; i--) { sum += a[i]; if (sum &gt; left_max) left_max = sum; } return left_max; } /** * 获取右边的子段和（连续） * @param a * @return */ public static int getRight(int[] a) { int right = a.length - 1, sum = 0, right_max = 0; int center = (a.length - 1) / 2; for (int i = center + 1; i &lt;= right; i++) { sum += a[i]; if (sum &gt; right_max) right_max = sum; } return right_max; } public static void main(String[] args) { int[] a = { -2, 11, -4, 13, -5, -2 }; int left_max = getLeft(a); int right_max = getRight(a); int sum = left_max + right_max; System.out.println(\"第一种情况：left_max：\" + left_max); System.out.println(\"第二种情况：right_max：\" + right_max); System.out.println(\"第三种情况：sum：\" + sum); }} 21234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162package max.number.demo3;/** * 分治法 */public class FenZhiFa { /** * * @param a * 数组 * @param left * 最左边 * @param right * 最右边 * @return */ public static int MaxSum(int a[], int left, int right) { int sum = 0; if (left == right) {// 如果序列长度为1，则可以直接求解 if (a[left] &gt; 0) { sum = a[left]; } else { sum = 0; } } else { int center = (left + right) / 2; // 划分 int leftSum = MaxSum(a, left, center);// 对应情况1，即最大子段和为左边的一段，递归求解， 这里递归获取最大值，和总和的值进行比较 int rightSum = MaxSum(a, center + 1, right);// 对应情况2，即最大子段和为右边的一段，递归求解 int s1 = 0, lefts = 0;// 对应情况3，即最大子段和为左右两段之间的某段，先求解s1 for (int i = center; i &gt;= left; i--) { lefts += a[i]; if (lefts &gt; s1) { s1 = lefts; } } int s2 = 0, rights = 0;// 再求解s2 for (int j = center + 1; j &lt;= right; j++) { rights += a[j]; if (rights &gt; s2) { s2 = rights; } } sum = s1 + s2;// 计算第3种情况的最大子段和 if (sum &lt; leftSum) { sum = leftSum; } if (sum &lt; rightSum) { sum = rightSum; }// 在这三种情况中选择较大者 } return sum; } public static void main(String[] args) { int[] a = { -2, 11, -4, 13, -5, -2 }; int SUM = MaxSum(a, 0, a.length - 1); System.out.println(\"最大子段和为：\" + SUM); }} 动态规划法概念：记b[j]=max(a[i]+a[i+1]+..+a[j])，其中1&lt;=i&lt;=j，并且1&lt;=j&lt;=n。则所求的最大子段和为max b[j],1&lt;=j&lt;=n。b[]：最大字段和的数组由b[j]的定义可易知，当b[j-1]&gt;0时，b[j]=b[j-1]+a[j]，否则b[j]=a[j]。（先初始化b[0]的数据）1&lt;=i&lt;=j&lt;=na[]:{20，30，-10，20}b[]:{0，0，0，0}，默认a[]一样的长度b[]={a[0]，a[0]+a[1]，a[0]+a[1]+a[2]}= {a[0]，b[0]+a[1]，b[1]+a[2]}:b[0]=a[0]，b[1]=a[0]+a[1].............................=b[j-1]+a[j]=b[j]计算时候：a，b数组从1开始计算 C版本1234567891011121314151617181920212223242526272829#include&lt;stdio.h&gt;int main(){ int count; int a[100]; int b[100]; int i; int max; scanf(\"%d\",&amp;count); for(i=0;i&lt;count;i++) { scanf(\"%d\",&amp;a[i]); } b[0]=a[0]; max=b[0]; for(i=1;i&lt;count;i++) { if(b[i-1]&gt;0){ b[i]=b[i-1]+a[i]; }else{ b[i]=a[i]; } if(b[i]&gt;max){ max=b[i]; } } printf(\"%d/n\",max); return 0;} Java版本11234567891011121314151617181920212223242526272829package max.number;/** * 简单的最大子段和 */public class Max { public static void main(String[] args) { // int[] a = { -2, 11, -4, 13, -5, -2 }; // 待确定的数组 int[] a = { 1, 2, -1, 1, 3, 2, -2, 3, -1, 5, -7, 3, 2, -2, 4 - 5 }; // 子段和的数组，选出最大的那个值 int[] b = new int[a.length]; b[0] = a[0]; int max = b[0]; for (int i = 1; i &lt; a.length; i++) { if (b[i - 1] &gt; 0) { b[i] = b[i - 1] + a[i]; } else { b[i] = a[i]; } if (max &lt; b[i]) { max = b[i]; } } System.out.println(max); }} 2123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135package max.number;/** * 最大子段和 * * 动态规划方法： 若记b[j]=max(a[i]+a[i+1]+..+a[j]),其中1&lt;=i&lt;=j,并且1&lt;=j&lt;=n。则所求的最大子段和为max * b[j]，1&lt;=j&lt;=n。 由b[j]的定义可易知，当b[j-1]&gt;0时b[j]=b[j-1]+a[j]，否则b[j]=a[j]。 * 故b[j]的动态规划递归式为: b[j]=max(b[j-1]+a[j],a[j])，1&lt;=j&lt;=n。 * * 主要有打印：最大子段数组 * * 写的不是很好 * */public class MaxArray { /** * 输出数组 * * @param a */ public static void prtArray(int[] a) { for (int i = 0; i &lt; a.length; i++) { System.out.print(a[i] + \" \"); } System.out.print(\"\\n\"); } /** * 2个数字最大值 返回最大值 * * @param a1 * @param a2 * @return */ public static int max(int a1, int a2) { if (a1 &gt;= a2 || a1 == a2) return a1; return a2; } /** * 设置最大B：最大字段和 * * a,b,beg数组长度相同 * * @param n * 长度，数组位置下标 * @param b * @param a * @param beg */ public static void setB(int n, int[] b, int[] a, int[] beg) { // 下标是0 if (n == 0) { b[n] = a[n]; beg[n] = n; } else { // n递减 setB(n - 1, b, a, beg); // 最大值b[n] b[n] = max(b[n - 1] + a[n], a[n]); if (b[n - 1] + a[n] &gt; a[n]) beg[n] = beg[n - 1]; else beg[n] = n; } } /** * 最大子数组 b[] 最大子段数组 * * @param a */ public static void maxChildArry(int[] a) { // 新建a长度的b数组 int b[] = new int[a.length]; // 新建最大子段和的开始的位置 int beg[] = new int[a.length]; // a，b数组第一位相同 b[0] = a[0]; // 遍历数组 for (int n = 0; n &lt; b.length; n++) setB(n, b, a, beg); // 最大的数字 int maxsum = b[getMaxElementIndex(b)]; System.out.println(\"MaxSum: \" + maxsum); PrtMaxChildArry(a, beg[getMaxElementIndex(b)], getMaxElementIndex(b)); } /** * 打印最大子段合的子数组 * * @param aa * @param beg * @param end */ public static void PrtMaxChildArry(int aa[], int beg, int end) { System.out.print(\"The Maxmium Child-Array is: { \"); for (int i = beg; i &lt;= end; i++) { System.out.print(aa[i] + \" \"); } System.out.println(\"}\\n\"); } /** * 获取最大值子段合的最大节点下标 * * @param b * @return */ public static int getMaxElementIndex(int[] b) { int maxele = 0; int i; for (i = 1; i &lt; b.length; i++) { if (b[maxele] &lt; b[i]) { maxele = i; } } return maxele; } /** * @param args */ public static void main(String[] args) { // int[] a = { 1, 2, -1, 1, 3, 2, -2, 3, -1, 5, -7, 3, 2, -2, 4 - 5 }; // prtArray(a); int[] a = { -2, 11, -4, 13, -5, -2 }; maxChildArry(a); }}","link":"/Maximum-Segment-Sum/"},{"title":"迷宫(回溯算法)","text":"1 概述 2 解题思路 3 程序代码 代码1 代码2 1 概述以一个M×N的长方阵表示迷宫，0和1分别表示迷宫中的通路和障碍。 2 解题思路可使用回溯方法，即从入口出发，顺着某一个方向进行探索，若能走通，则继续往前进；否则沿着原路退回，换一个方向继续探索，直至出口位置，求得一条通路。假如所有可能的通路都探索到而未能到达出口，则所设定的迷宫没有通路。探索迷宫的四个方向：RIGHT为向右，DOWN向下，LEFT向左，UP向上，输出从入口到出口的行走路径。 3 程序代码代码1代码：采用循环方式，进行回溯计算。1234567891011121314151617181920212223package demo2;/** * 位置 * * @author Administrator */class Position { int row;// 行 int col;// 列 public Position() { } public Position(int row, int col) { this.col = col; this.row = row; } public String toString() { return \"(\" + row + \" ,\" + col + \")\"; }} 迷宫代码主类:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159package demo2;import java.util.Stack;/** * 回溯方法-解题迷宫 */class Maze { //迷宫地图 int[][] maze = {{0, 0, 1, 0, 0, 0, 1 ,0}, {0, 0, 1, 0, 0, 0, 1, 0}, {0, 0, 1, 0, 1, 1, 0, 1}, {0, 1, 1, 1, 0, 0, 1, 0}, {0, 0, 0, 1, 0, 0, 0, 0}, {0, 1, 0, 0, 0, 1, 0, 1}, {0, 1, 1, 1, 1, 0, 0, 1}, {1, 1, 0, 0, 0, 1, 0, 1}, {1, 1, 0, 0, 0, 0, 0, 0}}; private int row = 9; private int col = 8; //存储迷宫路线 Stack&lt;Position&gt; stack; //坐标点的是否通路 //true：通路，false：不通 boolean p[][] = null; public Maze() { //maze = new int[15][15]; stack = new Stack&lt;Position&gt;(); p = new boolean[15][15]; } /* * 构造迷宫 */ public void init() { /*Scanner scanner = new Scanner(System.in); System.out.println(\"请输入迷宫的行数\"); row = scanner.nextInt(); System.out.println(\"请输入迷宫的列数\"); col = scanner.nextInt(); */ //System.out.println(\"请输入\" + row + \"行\" + col + \"列的迷宫\"); //int temp = 0; //初始化路线都不通 for (int i = 0; i &lt; row; ++i) { for (int j = 0; j &lt; col; ++j) { //temp = scanner.nextInt(); //maze[i][j] = temp; p[i][j] = false; } } } /* * 回溯迷宫，查看是否有出路 * * 1：围墙 * 0：通的路 */ public void findPath() { // 给原始迷宫的周围家一圈围墙 int[][] temp = new int[row + 2][col + 2]; for (int i = 0; i &lt; row + 2; ++i) { for (int j = 0; j &lt; col + 2; ++j) { //第一行 temp[0][j] = 1; //最后一行 temp[row + 1][j] = 1; //第一列，最后一列 temp[i][0] = temp[i][col + 1] = 1; } } // 将原始迷宫复制到新的迷宫中 for (int i = 0; i &lt; row; ++i) { for (int j = 0; j &lt; col; ++j) { temp[i + 1][j + 1] = maze[i][j]; } } // 从左上角开始按照顺时针开始查询 int i = 1; int j = 1; //第1个点被访问 p[i][j] = true; //存储迷宫路线 stack.push(new Position(i, j)); //探索迷宫的四个方向：向右，向下，向左，向上，输出从入口到出口的行走路径。 while (!stack.empty() &amp;&amp; (!(i == (row) &amp;&amp; (j == col)))) { //列右 if ((temp[i][j + 1] == 0) &amp;&amp; (p[i][j + 1] == false)) { p[i][j + 1] = true; stack.push(new Position(i, j + 1)); j++; } else if ((temp[i + 1][j] == 0) &amp;&amp; (p[i + 1][j] == false)) {//行右 p[i + 1][j] = true; stack.push(new Position(i + 1, j)); i++; } else if ((temp[i][j - 1] == 0) &amp;&amp; (p[i][j - 1] == false)) {//列左 p[i][j - 1] = true; stack.push(new Position(i, j - 1)); j--; } else if ((temp[i - 1][j] == 0) &amp;&amp; (p[i - 1][j] == false)) {//行左 p[i - 1][j] = true; stack.push(new Position(i - 1, j)); i--; } else { //删除栈顶部元素 stack.pop(); //没有路线，退出循环 if (stack.empty()) { break; } //获取栈顶行值 i = stack.peek().row; //获取栈顶列值 j = stack.peek().col; } } //存储新位置 Stack&lt;Position&gt; newPos = new Stack&lt;Position&gt;(); if (stack.empty()) { System.out.println(\"没有路径\"); } else { System.out.println(\"有路径\"); System.out.println(\"路径如下：\"); while (!stack.empty()) { Position pos = new Position(); pos = stack.pop(); newPos.push(pos); } } /* * 图形化输出路径 */ String resault[][] = new String[row + 1][col + 1]; for (int k = 0; k &lt; row; ++k) { for (int t = 0; t &lt; col; ++t) { resault[k][t] = (maze[k][t]) + \"\"; } } //迷宫路线值 while (!newPos.empty()) { Position p1 = newPos.pop(); resault[p1.row - 1][p1.col - 1] = \"#\"; } //打印迷宫数据 for (int k = 0; k &lt; row; ++k) { for (int t = 0; t &lt; col; ++t) { System.out.print(resault[k][t] + \"\\t\"); } System.out.println(); } }} 123456789101112package demo2;class Hello { public static void main(String[] args) { long s1 = System.currentTimeMillis(); Maze demo = new Maze(); demo.init(); demo.findPath(); long s2 = System.currentTimeMillis(); System.out.println(\"耗时【\" + (s2 - s1) + \"豪秒】 .............................\"); }} 结果:123456789101112有路径路径如下：# # 1 0 0 0 1 0 0 # 1 0 0 0 1 0 # # 1 0 1 1 0 1 # 1 1 1 0 0 1 0 # # # 1 # # # 0 0 1 # # # 1 # 1 0 1 1 1 1 0 # 1 1 1 0 0 0 1 # 1 1 1 0 0 0 0 # # 耗时【0豪秒】 ............................. 代码2代码：经典的回溯算法，此代码采用递归的方式，每当执行1次打印迷宫日志完，会回到上1次递归处，继续执行判断。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115package demo3;/** *回溯方法-解题迷宫2 */public class MiGong { /** * 定义迷宫数组 */ private int[][] array = { { 0, 0, 1, 0, 0, 0, 1, 0 }, { 0, 0, 1, 0, 0, 0, 1, 0 }, { 0, 0, 1, 0, 1, 1, 0, 1 }, { 0, 1, 1, 1, 0, 0, 1, 0 }, { 0, 0, 0, 1, 0, 0, 0, 0 }, { 0, 1, 0, 0, 0, 1, 0, 1 }, { 0, 1, 1, 1, 1, 0, 0, 1 }, { 1, 1, 0, 0, 0, 1, 0, 1 }, { 1, 1, 0, 0, 0, 0, 0, 0 } }; private int maxLine = 8; private int maxRow = 9; public static void main(String[] args) { long s1 = System.currentTimeMillis(); new MiGong().check(0, 0); long s2 = System.currentTimeMillis(); System.out.println(\"耗时【\" + (s2 - s1) + \"豪秒】 .............................\"); } /** * * @param i * 行 * @param j * 列 */ private void check(int i, int j) { // 如果到达右下角出口 // 循环到最后一行 if (i == maxRow - 1 &amp;&amp; j == maxLine - 1) { //打印 print(); return; } // 向右走 //同行，列+1 if (canMove(i, j, i, j + 1)) { //标记当前位置已经走过 array[i][j] = 5; check(i, j + 1); //位置不通 array[i][j] = 0; } // 向左走 //同行，列-1 if (canMove(i, j, i, j - 1)) { array[i][j] = 5; check(i, j - 1); array[i][j] = 0; } // 向下走 //同列，行+1 if (canMove(i, j, i + 1, j)) { array[i][j] = 5; check(i + 1, j); array[i][j] = 0; } // 向上走 //同行，列-1 if (canMove(i, j, i - 1, j)) { array[i][j] = 5; check(i - 1, j); array[i][j] = 0; } } /** * * @param i 当前行 * @param j 当前列 * @param targetI 下一行 * @param targetJ 下一列 * @return */ private boolean canMove(int i, int j, int targetI, int targetJ) { // System.out.println(\"从第\" + (i + 1) + \"行第\" + (j + 1) + \"列，走到第\" + (targetI + 1) + \"行第\" + (targetJ + 1) + \"列\"); // 到迷宫的边界 if (targetI &lt; 0 || targetJ &lt; 0 || targetI &gt;= maxRow || targetJ &gt;= maxLine) { // System.out.println(\"到达最左边或最右边，失败了\"); return false; } //目标是墙，失败了 if (array[targetI][targetJ] == 1) { // System.out.println(\"目标是墙，失败了\"); return false; } // 避免在两个空格间来回走 // 已经是正确路径 if (array[targetI][targetJ] == 5) { // System.out.println(\"来回走，失败了\"); return false; } return true; } private void print() { System.out.println(\"得到一个解：\"); for (int i = 0; i &lt; maxRow; i++) { for (int j = 0; j &lt; maxLine; j++) { System.out.print(array[i][j] + \" \"); } System.out.println(); } }} 结果:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081得到一个解：5 5 1 0 0 0 1 0 5 5 1 0 0 0 1 0 5 0 1 0 1 1 0 1 5 1 1 1 0 0 1 0 5 5 5 1 5 5 5 0 0 1 5 5 5 1 5 1 0 1 1 1 1 0 5 1 1 1 0 0 0 1 5 1 1 1 0 0 0 0 5 0 得到一个解：5 5 1 0 0 0 1 0 5 5 1 0 0 0 1 0 5 0 1 0 1 1 0 1 5 1 1 1 5 5 1 0 5 5 5 1 5 5 5 0 0 1 5 5 5 1 5 1 0 1 1 1 1 0 5 1 1 1 0 0 0 1 5 1 1 1 0 0 0 0 5 0 得到一个解：5 5 1 0 0 0 1 0 0 5 1 0 0 0 1 0 5 5 1 0 1 1 0 1 5 1 1 1 0 0 1 0 5 5 5 1 5 5 5 0 0 1 5 5 5 1 5 1 0 1 1 1 1 0 5 1 1 1 0 0 0 1 5 1 1 1 0 0 0 0 5 0 得到一个解：5 5 1 0 0 0 1 0 0 5 1 0 0 0 1 0 5 5 1 0 1 1 0 1 5 1 1 1 5 5 1 0 5 5 5 1 5 5 5 0 0 1 5 5 5 1 5 1 0 1 1 1 1 0 5 1 1 1 0 0 0 1 5 1 1 1 0 0 0 0 5 0 得到一个解：5 0 1 0 0 0 1 0 5 5 1 0 0 0 1 0 5 5 1 0 1 1 0 1 5 1 1 1 0 0 1 0 5 5 5 1 5 5 5 0 0 1 5 5 5 1 5 1 0 1 1 1 1 0 5 1 1 1 0 0 0 1 5 1 1 1 0 0 0 0 5 0 得到一个解：5 0 1 0 0 0 1 0 5 5 1 0 0 0 1 0 5 5 1 0 1 1 0 1 5 1 1 1 5 5 1 0 5 5 5 1 5 5 5 0 0 1 5 5 5 1 5 1 0 1 1 1 1 0 5 1 1 1 0 0 0 1 5 1 1 1 0 0 0 0 5 0 得到一个解：5 0 1 0 0 0 1 0 5 0 1 0 0 0 1 0 5 0 1 0 1 1 0 1 5 1 1 1 0 0 1 0 5 5 5 1 5 5 5 0 0 1 5 5 5 1 5 1 0 1 1 1 1 0 5 1 1 1 0 0 0 1 5 1 1 1 0 0 0 0 5 0 得到一个解：5 0 1 0 0 0 1 0 5 0 1 0 0 0 1 0 5 0 1 0 1 1 0 1 5 1 1 1 5 5 1 0 5 5 5 1 5 5 5 0 0 1 5 5 5 1 5 1 0 1 1 1 1 0 5 1 1 1 0 0 0 1 5 1 1 1 0 0 0 0 5 0 耗时【5豪秒】 .............................","link":"/Maze-backtracking-Algorithm/"},{"title":"MyBatis基于接口编程的原理分析","text":"1 源码 UserMapper application-context.xml test 2 原理分析 MapperScannerConfigurer#Scanner#doScan MapperFactoryBean#afterPropertiesSet() MapperFactoryBean#getObject() SqlSessionTemplate#getMapper() org.apache.ibatis.session.Configuration#getMapper() org.apache.ibatis.binding.MapperRegistry#getMapper() MapperProxy#newMapperProxy() MapperProxy#invoke 3 Mybatis版本差异 MapperFactoryBean#checkDaoConfig() MapperProxy#invoke() 1 源码UserMapper1234567891011package org.denger.mapper; import org.apache.ibatis.annotations.Param; import org.apache.ibatis.annotations.Select; import org.denger.po.User; public interface UserMapper { @Select(\"select * from tab_uc_account where id=#{userId}\") User getUser(@Param(\"userId\") Long userId); } application-context.xml1234567891011121314151617181920212223242526272829303132333435&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:context=\"http://www.springframework.org/schema/context\" xmlns:aop=\"http://www.springframework.org/schema/aop\" xmlns:tx=\"http://www.springframework.org/schema/tx\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-3.0.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-3.0.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop-2.0.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx-2.0.xsd\"&gt; &lt;!-- Provided by annotation-based configuration --&gt; &lt;context:annotation-config/&gt; &lt;!--JDBC Transaction Manage --&gt; &lt;bean id=\"dataSourceProxy\" class=\"org.springframework.jdbc.datasource.TransactionAwareDataSourceProxy\"&gt; &lt;constructor-arg&gt; &lt;ref bean=\"dataSource\" /&gt; &lt;/constructor-arg&gt; &lt;/bean&gt; &lt;!-- The JDBC c3p0 dataSource bean--&gt; &lt;bean id=\"dataSource\" class=\"com.mchange.v2.c3p0.ComboPooledDataSource\" destroy-method=\"close\"&gt; &lt;property name=\"driverClass\" value=\"com.mysql.jdbc.Driver\" /&gt; &lt;property name=\"jdbcUrl\" value=\"jdbc:mysql://127.0.0.1:3306/noah\" /&gt; &lt;property name=\"user\" value=\"root\" /&gt; &lt;property name=\"password\" value=\"123456\" /&gt; &lt;/bean&gt; &lt;!--MyBatis integration with Spring as define sqlSessionFactory --&gt; &lt;bean id=\"sqlSessionFactory\" class=\"org.mybatis.spring.SqlSessionFactoryBean\"&gt; &lt;property name=\"dataSource\" ref=\"dataSource\" /&gt; &lt;/bean&gt; &lt;bean class=\"org.mybatis.spring.mapper.MapperScannerConfigurer\"&gt; &lt;property name=\"sqlSessionFactory\" ref=\"sqlSessionFactory\"/&gt; &lt;property name=\"basePackage\" value=\"org.denger.mapper\"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;/beans&gt; test12345678910111213141516171819package org.denger.mapper; import org.junit.Assert; import org.junit.Test; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.test.context.ContextConfiguration; import org.springframework.test.context.junit4.AbstractJUnit4SpringContextTests; @ContextConfiguration(locations = { \"/application-context.xml\"}) public class UserMapperTest extends AbstractJUnit4SpringContextTests{ @Autowired public UserMapper userMapper; @Test public void testGetUser(){ Assert.assertNotNull(userMapper.getUser(300L)); } } 2 原理分析对于以上极其简单代码看上去并无特殊之处，主要亮点在于 UserMapper 居然不用实现类，而且在调用 getUser 的时候，也是使用直接调用了UserMapper实现类，那么Mybatis是如何去实现 UserMapper的接口的呢？可能你马上能想到的实现机制就是通过动态代理方式，看看MyBatis整个的代理过程吧。首先在Spring的配置文件中看到下面的Bean。1234&lt;bean class=\"org.mybatis.spring.mapper.MapperScannerConfigurer\"&gt; &lt;property name=\"sqlSessionFactory\" ref=\"sqlSessionFactory\"/&gt; &lt;property name=\"basePackage\" value=\"org.denger.mapper\"&gt;&lt;/property&gt; &lt;/bean&gt; 12345/** * BeanDefinitionRegistryPostProcessor that searches recursively starting from a base package for * interfaces and registers them as {@code MapperFactoryBean}. Note that only interfaces with at * least one method will be registered; concrete classes will be ignored. * &lt;p&gt; 以上的MapperScannerConfigurer的注释中描述道。从base包中搜索所有下面所有interface，并将其注册到Spring Bean容器中，其注册的class bean是MapperFactoryBean。看看它的注册过程，从MapperScannerConfigurer#Scanner类中抽取，在初始化以上application-content.xml文件时就会进行调用。主要用于是搜索base packages下的所有mapper.class，并将其注册至spring的benfinitionHolder中。 MapperScannerConfigurer#Scanner#doScan123456789101112131415161718192021222324/** 1. Calls the parent search that will search and register all the candidates. Then the 2. registered objects are post processed to set them as MapperFactoryBeans */ @Override protected Set&lt;BeanDefinitionHolder&gt; doScan(String... basePackages) { // #1 Set&lt;BeanDefinitionHolder&gt; beanDefinitions = super.doScan(basePackages); if (beanDefinitions.isEmpty()) { logger.warn(\"No MyBatis mapper was found in '\" + MapperScannerConfigurer.this.basePackage + \"' package. Please check your configuration.\"); } else { // #2 for (BeanDefinitionHolder holder : beanDefinitions) { GenericBeanDefinition definition = (GenericBeanDefinition) holder.getBeanDefinition(); if (logger.isDebugEnabled()) { logger.debug(\"Creating MapperFactoryBean with name '\" + holder.getBeanName() + \"' and '\"+ definition.getBeanClassName() + \"' mapperInterface\"); } // #3 definition.getPropertyValues().add(\"mapperInterface\", definition.getBeanClassName()); definition.setBeanClass(MapperFactoryBean.class); } return beanDefinitions; } Spring初始化Bean过程的人可能都知道，Spring首先会将需要初始化的所有class先通过BeanDefinitionRegistry进行注册，并且将该Bean的一些属性信息(如scope、className、beanName等)保存至BeanDefinitionHolder中；MyBatis这里首先会调用Spring中的ClassPathBeanDefinitionScanner#doScan()，将所有Mapper接口的class注册至BeanDefinitionHolder实例中，然后返回一个Set&lt;BeanDefinitionHolder&gt;，包含所有搜索到的Mapper#BeanDefinitionHolder对象。 由于#1中注册的都是接口class， 可以肯定的是接口是不能直接初始化的；for循环中替换当前所有holder的className为MapperFactoryBean.class，并且将 mapper interface的class name setter 至 MapperFactoryBean 属性为 mapperInterface 中，也就是 #3代码所看到的。 再看看MapperFactoryBean，它是直接实现了Spring的FactoryBean及InitializingBean接口。其实既使不看这两个接口，当看MapperFactoryBean的classname就知道它是一个专门用于创建 Mapper 实例Bean的工厂。至此，已经完成了Spring与MyBatis的整合的初始化配置的过程。接着，在以上的Test类中，需要注入UserMapper接口实例时，由于MyBatis给所有的Mapper实例注册都是一个MapperFactory的生成，所以产生UserMapper实现仍需要MapperFactoryBean来进行创建。接下来看看 MapperFactoryBean的处理过程。先需要创建Mapper实例时，首先在 MapperFactoryBean中执行的方法。 MapperFactoryBean#afterPropertiesSet()123456789101112/** * {@inheritDoc} */ public void afterPropertiesSet() throws Exception { Assert.notNull(this.sqlSession, \"Property 'sqlSessionFactory' or 'sqlSessionTemplate' are required\"); Assert.notNull(this.mapperInterface, \"Property 'mapperInterface' is required\"); Configuration configuration = this.sqlSession.getConfiguration(); if (this.addToConfig &amp;&amp; !configuration.hasMapper(this.mapperInterface)) { configuration.addMapper(this.mapperInterface); } } 上面方法中先会检测当前需要创建的mapperInterface在全局的Configuration中是否存在，如果不存在则添加。等等再说他为什么要将 mapperInterface 添加至 Configuration中。该方法调用完成之后，就开始调用 getObject()来产生mapper实例。 MapperFactoryBean#getObject()123456/** * {@inheritDoc} */ public T getObject() throws Exception { return this.sqlSession.getMapper(this.mapperInterface); } 通过Debug可以看到 sqlSession及mapperInterface对象：到目前为止UserMapper实例实际上还并未产生，再进入org.mybatis.spring.SqlSessionTemplate#getMapper()，该方法将this及mapper interface class 作为参数传入 org.apache.ibatis.session.Configuration#getMapper() ，代码如下。 SqlSessionTemplate#getMapper()123456/** * {@inheritDoc} */ public &lt;T&gt; T getMapper(Class&lt;T&gt; type) { return getConfiguration().getMapper(type, this); } org.apache.ibatis.session.Configuration#getMapper()123public &lt;T&gt; T getMapper(Class&lt;T&gt; type, SqlSession sqlSession) { return mapperRegistry.getMapper(type, sqlSession); } mapperRegistry保存着当前所有的mapperInterface class，那么它在什么时候将 mapperinterface class 保存进入的呢？其实就是在上面的 afterPropertiesSet 中通过 configuration.addMapper(this.mapperInterface) 添加进入的。 org.apache.ibatis.binding.MapperRegistry#getMapper()1234567891011public &lt;T&gt; T getMapper(Class&lt;T&gt; type, SqlSession sqlSession) { // #1 if (!knownMappers.contains(type)) throw new BindingException(\"Type \" + type + \" is not known to the MapperRegistry.\"); try { // #2 return MapperProxy.newMapperProxy(type, sqlSession); } catch (Exception e) { throw new BindingException(\"Error getting mapper instance. Cause: \" + e, e); } } 首先判断当前knownMappers是否存在mapper interface class，因为前面说到afterPropertiesSet中已经将当前的mapper interface class添加进入了。 生成Mapper Proxy对象。MapperProxy#newMapperProxy()123456public static &lt;T&gt; T newMapperProxy(Class&lt;T&gt; mapperInterface, SqlSession sqlSession) { ClassLoader classLoader = mapperInterface.getClassLoader(); Class[] interfaces = new Class[]{mapperInterface}; MapperProxy proxy = new MapperProxy(sqlSession); return (T) Proxy.newProxyInstance(classLoader, interfaces, proxy); } JDK的动态代理就不说，至此，基本Mybatis已经完成了Mapper实例的整个创建过程，也就是在具体使用 UserMapper#getUser() 时，它实际上调用的是 MapperProxy，因为此时所返回的 MapperProxy是实现了UserMapper接口的。只不过 MapperProxy拦截了所有对userMapper中方法的调用，如下。 MapperProxy#invoke1234567891011121314151617181920public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { try { //如果调用不是 object 中默认的方法(如equals之类的) if (!OBJECT_METHODS.contains(method.getName())) { //因为当前MapperProxy代理了所有 Mapper，所以需要根据当前拦截到的方法及代理对象获取 MapperInterface class，也就是UserMapper.class final Class declaringInterface = findDeclaringInterface(proxy, method); //然后再根据UserMapper.class、及当前调用的Method(也就是getUser)及SqlSession构造一个 MapperMethod，在这里面会获取到getUser方法上的 @Select()的SQL，然后再通过sqlSession来进行执行 final MapperMethod mapperMethod = new MapperMethod(declaringInterface, method, sqlSession); //execute执行数据库操作，并返回结果集 final Object result = mapperMethod.execute(args); if (result == null &amp;&amp; method.getReturnType().isPrimitive()) { throw new BindingException(\"Mapper method '\" + method.getName() + \"' (\" + method.getDeclaringClass() + \") attempted to return null from a method with a primitive return type (\" + method.getReturnType() + \").\"); } return result; } } catch (SQLException e) { e.printStackTrace(); } return null; } 为什么说它拦截了呢？可以看到, 它并没有调用 method.invoke(object)方法，因为实际上 MapperProxy只是动态的implement UserMapper接口，但它没有真正实现 UserMapper中的任何方法。至于结果的返回，它也是通过 MapperMethod.execute 中进行数据库操作来返回结果的。就是一个实现了 MapperInterface 的 MapperProxy 实例被MapperProxy代理了，可以Debug看看 userMapper实例就是 MapperProxy。 3 Mybatis版本差异以上文章很早以前写的，现在用Mybatis3.4.0版本，2个版本存在一些差异。 MapperFactoryBean#checkDaoConfig()MapperFactoryBean#afterPropertiesSet方法，在3.4版本中不存在，3.4版本：1234567891011121314151617protected void checkDaoConfig() { super.checkDaoConfig(); notNull(this.mapperInterface, \"Property 'mapperInterface' is required\"); Configuration configuration = getSqlSession().getConfiguration(); if (this.addToConfig &amp;&amp; !configuration.hasMapper(this.mapperInterface)) { try { configuration.addMapper(this.mapperInterface); } catch (Exception e) { logger.error(\"Error while adding the mapper '\" + this.mapperInterface + \"' to configuration.\", e); throw new IllegalArgumentException(e); } finally { ErrorContext.instance().reset(); } } } MapperProxy#invoke()在3.4版本中也不一样。3.4版本：1234567891011public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { if (Object.class.equals(method.getDeclaringClass())) { try { return method.invoke(this, args); } catch (Throwable t) { throw ExceptionUtil.unwrapThrowable(t); } } final MapperMethod mapperMethod = cachedMapperMethod(method); return mapperMethod.execute(sqlSession, args); }","link":"/MyBatis-Interface-Analysis/"},{"title":"第14章-类型的信息RTTI","text":"1 介绍 2 使用方式 3 工作原理 第1种 第2种 第3种 注意 4 RTTI的限制?如何突破?一反射机制 5 RTTI与反射机制的区别 6 类的生命周期 装载 链接 初始化 以JDK6为例 1 介绍RTTI运行时类型信息使得可以在程序运行时发现和使用类型信息。 Run-Time Type Information 2 使用方式Java是如何在运行时识别对象和类的信息的，主要有两种方式（还有辅助的第三种方式，见下描述） “传统的”RTTI，它假定在编译时已经知道所有的类型，比如Shape s = (Shape)s1； “反射”机制，它运行在运行时发现和使用类的信息，即使用Class.forName()。 关键字instanceof，它返回一个bool值，它保持类型的概念，它指的是”你是这个类吗？或者你是这个类的派生类吗？”。而如果用==或equals比较实际的Class对象，就没有考虑继承它或者是这个确切的类型，或者不是。3 工作原理RTTI主要用来运行时获取对象到底是什么具体的类型。RTTI运行的时候，识别一个对象的类型。（运行的时候获取对象确切的类型）要理解RTTI在Java中的工作原理，首先必须知道类型信息在运行时是如何表示的，这项工作是由称为Class对象的特殊对象完成的，它包含与类有关的信息。Java Class对象来执行其RTTI，使用类加载器的子系统实现。类是程序的重要组成部分，每个类都有一个Class对象，每当编写并编译一个新类就会产生一个Class对象，它被保存在一个同名的.class文件中。在运行时，生成这个类的对象时，运行这个程序的Java虚拟机（JVM）会确认这个类的Class对象是否已经加载，如果尚未加载，JVM就会根据类名查找.class文件，并将其载入，一旦这个类的Class对象被载入内存，它就被用来创建这个类的所有对象。在运行时使用类型信息，就必须首先获得对恰当的Class对象的引用，获取方式有三种。 第1种如果没有持有该类型的对象，则Class.forName()就是实现此功能的便捷途，因为它不需要对象信息。第2种如果已经拥有类型的对象，那就可以通过调用getClass()方法来获取Class引用，它将返回表示该对象的实际类型的Class引用。 示例123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263package rtti;interface HasBatteries {}interface WaterProof {}interface Shoots {}class Toy { Toy() { } Toy(int i) { }}class FancyToy extends Toy implements HasBatteries, WaterProof, Shoots { FancyToy() { super(1); }}public class RTTITest { static void printInfo(Class cc) { System.out.println(\"Class name: \" + cc.getName() + \", is interface? [\" + cc.isInterface() + \"]\"); System.out.println(\"Simple name: \" + cc.getSimpleName()); System.out.println(\"Canonical name: \" + cc.getCanonicalName()); } public static void main(String[] args) { Class c = null; try { c = Class.forName(\"rtti.FancyToy\"); // 必须是全限定名（包名+类名） } catch (ClassNotFoundException e) { System.out.println(\"Can't find FancyToy\"); System.exit(1); } printInfo(c); for (Class face : c.getInterfaces()) { printInfo(face); } Class up = c.getSuperclass(); Object obj = null; try { // Requires default constructor. obj = up.newInstance(); } catch (InstantiationException e) { System.out.println(\"Can't Instantiate\"); System.exit(1); } catch (IllegalAccessException e) { System.out.println(\"Can't access\"); System.exit(1); } printInfo(obj.getClass()); }} 第3种Java还提供另一种方法来生成对Class对象的引用，即使用类字面常量。比如上面的就像这样：FancyToy.class来引用。这样做不仅更简单，而且更安全，因为它在编译时就会受到检查（因此不需要置于try语句块中），并且它根除对forName()的引用，所以也更高效。类字面常量不仅可以应用于普通的类，也可以应用于接口、数组以及基本数据类型。 注意当使用.class来创建对Class对象的引用时，不会自动地初始化该Class对象，初始化被延迟到对静态方法（构造器隐式的是静态的）或者非final静态域（注意final静态域常量值不会触发初始化类操作）进行首次引用时才执行。而使用Class.forName()时会自动的初始化类。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455package rtti;import java.util.Random;class Initable { static final int staticFinal = 47; static final int staticFinal2 = ClassInitialization.rand.nextInt(1000); static { System.out.println(\"Initializing Initable\"); }}class Initable2 { static int staticNonFinal = 147; static { System.out.println(\"Initializing Initable2\"); }}class Initable3 { static int staticNonFinal = 74; static { System.out.println(\"Initializing Initable3\"); }}public class ClassInitialization { public static Random rand = new Random(47); public static void main(String[] args) { // Does not trigger initialization Class initable = Initable.class; System.out.println(\"After creating Initable ref\"); // Does not trigger initialization System.out.println(Initable.staticFinal); // Does trigger initialization(rand() is static method) System.out.println(Initable.staticFinal2); // Does trigger initialization(not final) System.out.println(Initable2.staticNonFinal); try { Class initable3 = Class.forName(\"rtti.Initable3\"); } catch (ClassNotFoundException e) { System.out.println(\"Can't find Initable3\"); System.exit(1); } System.out.println(\"After creating Initable3 ref\"); System.out.println(Initable3.staticNonFinal); }} 输出结果：123456789After creating Initable ref47Initializing Initable258Initializing Initable2147Initializing Initable3After creating Initable3 ref74 初始化方法实现尽可能有效的”惰性”。从这个结果可以看出使用.class方式来获取类的引用不会引发类的初始化。但是，使用Class.forName()立刻就进行初始化，就像对initable3引用的例子。 static、final的值是一个编译器常量，获取这个值是不需要对类进行初始化的。如staticFinal。 static、final不是一个编译常量，比如new Random(47)，这个是一个构造方法，构造方法是隐试的静态方法，所以会对类进行初始化。 非final的static对象，在使用的时候，首先会对类进行初始化操作。如Initable2#staticNonFinal。4 RTTI的限制?如何突破?一反射机制如果不知道某个对象的确切类型，RTTI可以告诉你，但是有一个限制：这个类型在编译时必须已知，这样才能使用RTTI识别它，也就是在编译时，编译器必须知道所有要通过RTTI来处理的类。（RTTI的一种方式）可以突破这个限制吗？是的，突破它的就是反射机制。（反射机制也是RTTI的一种方式）Class类与java.lang.reflect类库一起对反射的概念进行支持，该类库包含Field、Method以及Constructor类（每个类都实现Member接口）。这些类型的对象是由JVM在运行时创建的，用以表示未知类里对应的成员。这样就可以使用Constructor创建新的对象，用get()/set()读取和修改与Field对象关联的字段，用invoke()方法调用与Method对象关联的方法。另外，还可以调用getFields()、getMethods()和getConstructors()等很便利的方法，以返回表示字段、方法以及构造器的对象的数组。这样，匿名对象的类信息就能在运行时被完全确定下来，而在编译时不需要知道任何事情。 5 RTTI与反射机制的区别当通过反射与一个未知类型的对象打交道时，JVM只是简单地检查这个对象，看它属于哪个特定的类（就像RTTI那样），在用它做其他事情之前必须先加载那个类的Class对象，因此，那个类的.class文件对于JVM来说必须是可获取的，要么在本地机器上，要么可以通过网络取得。RTTI与反射之间真正的区别只在于；对RTTI来说，编译器在编译时打开和检查.class文件（也就是可以用普通方法调用对象的所有方法）；而对于反射机制来说，.class文件在编译时是不可获取的，所以是在运行时打开和检查.class文件。RTTI和反射机制都是运行时获取类的信息。只是一个是编译的时候检查class文件，一个是运行时检查class文件。 6 类的生命周期在一个类编译完成之后，下一步就需要开始使用类，如果要使用一个类，肯定离不开JVM。创建Class对象引用时，不会自动的初始化该Class对象。在程序执行中，JVM通过装载、链接、初始化这3个步骤完成Class对象的初始化。 装载通过类加载器执行的，加载器将.class文件的二进制文件装入JVM的方法区，并且在堆区创建描述这个类的java.lang.Class对象。 （并不代表初始化） 链接把二进制数据组装为可以运行的状态，验证类中的字节码，为静态域分配存储空间，创建类对其他类的所有引用。链接分为校验，准备，解析这3个阶段： 校验：一般用来确认此二进制文件是否适合当前的JVM（版本）。 准备：为静态成员分配内存空间，并设置默认值。int=0，实际上还是分配内存。 解析（创建类对其他类的所有引用）：转换常量池中的代码作为直接引用的过程，直到所有的符号引用都可以被运行程序使用（建立完整的对应关系）。 完成之后，类型也就完成初始化，初始化之后类的对象就可以正常使用，直到一个对象不再使用之后，将被垃圾回收。释放空间。当没有任何引用指向Class对象时就会被卸载，结束类的生命周期。 初始化对父类初始化，对静态方法初始化，代码块初始化和变量初始化。","link":"/RTTI/"},{"title":"跳表SkipList","text":"1 跳表介绍 1.1 跳表核心思想 2 存储模式 2.1 性质 2.2 结构设计 3 操作 3.1 搜索 3.2 插入 K取值 高度 空间复杂度 3.3 删除 4 代码 4.1 Java 4.2 C++ 初始化 插入 删除 1 跳表介绍目前经常使用的平衡数据结构有：B树，红黑树，AVL树，Splay Tree, Treep等。跳表是一种随机化的数据结构，目前开源软件Redis和LevelDB都有用到它，它的效率和红黑树以及AVL树不相上下，但跳表的原理相当简单，只要你能熟练操作链表，就能轻松实现一个 SkipList。这是跳表的作者，上面介绍的William Pugh给出的解释。 Skip lists are a data structure that can be used in place of balanced trees. Skip lists use probabilistic balancing rather than strictly enforced balancing and as a result the algorithms for insertion and deletion in skip lists are much simpler and significantly faster than equivalent algorithms for balanced trees. 跳表是平衡树的一种替代的数据结构，但是和红黑树不相同的是，跳表对于树的平衡的实现是基于一种随机化的算法的，这样也就是说跳表的插入和删除的工作是比较简单的。 1.1 跳表核心思想从该有序表中搜索元素“23,43,59”，需要比较的次数分别为&lt;2, 4, 6&gt;，总共比较的次数为2 + 4 + 6 = 12次。有没有优化的算法吗? 链表是有序的，但不能使用二分查找。类似二叉搜索树，把一些节点提取出来，作为索引。得到如下结构。把“14,34,50,72”提取出来作为一级索引，这样搜索的时候就可以减少比较次数了。还可以再从一级索引提取一些元素出来，作为二级索引，变成如下结构。如果是说链表是排序的，并且节点中还存储指向前面第二个节点的指针的话，那么在查找一个节点时，仅仅需要遍历N/2个节点即可。这基本上就是跳表的核心思想，其实也是一种通过“空间来换取时间”的一个算法，通过在每个节点中增加了向前的指针，从而提升查找的效率。 2 存储模式-1表示INT_MIN，链表的最小值。1表示INT_MAX，链表的最大值。 2.1 性质 由很多层结构组成。 每一层都是一个有序的链表。 最底层(Level 1)的链表包含所有元素。 如果一个元素出现在Level i的链表中，则它在Level i之下的链表也都会出现。 每个节点包含两个指针，一个指向同一链表中的下一个元素，一个指向下面一层的元素。2.2 结构设计如果一个跳表的层MaxLevel义为跳表中所有节点中最大的层数。定义每个节点类型 12345678typedef struct nodeStructure *node;typedef struct nodeStructure{ keyType key; // key值 valueType value; // value值 // 向前指针数组，根据该节点层数的不同，指向不同大小的数组 node forward[1];}; 上面的每个结构体对应着图中的每个节点，如果一个节点是一层的节点的话（如7，12等节点），那么对应的forward将指向一个只含一个元素的数组，以此类推。定义跳表数据类型1234typedef struct listStructure{ int level; /* Maximum level of the list (1 more than the number of levels in the list) */ struct nodeStructure * header; /* pointer to header */} * list; 跳表数据类型中包含了维护跳表的必要信息，level表明跳表的层数，header如下所示。123456789101112131415#define MaxNumberOfLevels 16 #define MaxLevel (MaxNumberOfLevels-1) //NIL变量：node NIL;#define newNodeOfLevel(l) (node)malloc(sizeof(struct nodeStructure)+(l)*sizeof(node *)) // newNodeOfLevel生成一个nodeStructure结构体，同时生成l个node *数组指针``` # 3 操作## 3.1 搜索![](./skiplist-8.jpg)例子：查找元素 1171. 比较21，比21大，往后面找。2. 比较37，比37大，比链表最大值小，从37的下面一层开始找。3. 比较71，比71大，比链表最大值小，从71的下面一层开始找。4. 比较85，比85大，从后面找。5. 比较117，等于117，找到了节点。伪代码搜索算法如下。 /* 如果存在 x, 返回 x 所在的节点， 否则返回 x 的后继节点 */find(x){ p = top; while (1) { while (p-&gt;next-&gt;key &lt; x) p = p-&gt;next; if (p-&gt;down == NULL) return p-&gt;next; p = p-&gt;down; }} 1234567891011121314151617## 3.2 插入先确定该元素要占据的层数K（采用随机方式，这完全是随机的）。然后在`Level 1 ... Level K`各个层的链表都插入元素。 例子：插入119，K = 2 ![](./skiplist-9.jpg)如果K大于链表的层数，则要添加新的层。 例子：插入 119， K = 4 ![](./skiplist-10.jpg)### K取值插入元素的时候，元素所占有的层数完全是随机的，通过一下随机算法产生。``` c++int random_level() { K = 1; while (random(0,1)) K++; return K; } 显然随机变量K满足参数为p = 1/2的几何分布，K的期望值E[K] = 1/p = 2，各个元素的层数，期望值是2层。 高度n个元素的跳表，每个元素插入的时候都要检查，用来决定元素占据的层数K，跳表的高度等于这n次检查生成中产生的最大K。 空间复杂度根据上面的分析，每个元素的期望高度为2， 一个大小为n的跳表，其节点数目的期望值是2n。 3.3 删除在各个层中找到包含x的节点，使用标准的delete from list删除该节点。例子：删除71 4 代码4.1 Java跳表节点类型，每个跳表类型中仅仅存储左侧的节点和下面的节点。 完成初始化 插入操作：和上面介绍的插入操作是类似的，首先查找到插入的位置，生成update数组，然后随机生成一个level，然后修改指针。 删除操作：和上面介绍的删除操作是类似的，查找到需要删除的节点，如果查找不到，抛出异常，如果查找到的需要删除的节点的话，修改指针，释放删除节点的内存。 SkipNode12345678910111213141516171819202122package demo1;class SkipNode&lt;E extends Comparable&lt;? super E&gt;&gt; { public final E value; // 节点存储的数据 public final SkipNode&lt;E&gt;[] forward; // 节点的指针数组 /** * 根据节点的层级构造一个节点 * * @param level * 节点层级 * @param value * 节点存储值 */ @SuppressWarnings(\"unchecked\") public SkipNode(int level, E value) { forward = new SkipNode[level + 1];// level层的元素后面带着level+1的指针数组 this.value = value; }} SkipSet123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143package demo1;public class SkipSet&lt;E extends Comparable&lt;? super E&gt;&gt; { /** * 概率因子，实验证明p=1/e比p=0.5要好，e是个神奇的数字！ */ // public static final double P = 0.5; public static final double P = 1 / Math.E; /** * 最大层级 */ public static final int MAX_LEVEL = 6; /** * 开始节点，不存值，贯穿所有层 */ public final SkipNode&lt;E&gt; header = new SkipNode&lt;E&gt;(MAX_LEVEL, null); /** * 当前跳表的最高层级 */ public int level = 0; /** * 插入一个元素 * * @param value * 待插入值 */ @SuppressWarnings(\"unchecked\") public void insert(E value) { SkipNode&lt;E&gt; x = header; //节点所有层更新的数组 SkipNode&lt;E&gt;[] update = new SkipNode[MAX_LEVEL + 1]; for (int i = level; i &gt;= 0; i--) { while (x.forward[i] != null &amp;&amp; x.forward[i].value.compareTo(value) &lt; 0) { x = x.forward[i]; } // update[i]是比value小的数里面最大的，是value的前置节点 update[i] = x; } x = x.forward[0]; // 此处不允许插入相同元素，为一个set // 跳表中不包含所要插的元素 if (x == null || !x.value.equals(value)) { // 随机产生插入的层级 int lvl = randomLevel(); // 产生的随机层级比当前跳表的最高层级大，需要添加相应的层级，并更新最高层级 if (lvl &gt; level) { for (int i = level + 1; i &lt;= lvl; i++) { update[i] = header; } level = lvl; } // 生成新节点 x = new SkipNode&lt;E&gt;(lvl, value); // 调整节点的指针，和指向它的指针 for (int i = 0; i &lt;= lvl; i++) { x.forward[i] = update[i].forward[i]; update[i].forward[i] = x; } } } /** * 删除一个元素 * * @param value * 待删除值 */ @SuppressWarnings(\"unchecked\") public void delete(E value) { SkipNode&lt;E&gt; x = header; SkipNode&lt;E&gt;[] update = new SkipNode[MAX_LEVEL + 1]; for (int i = level; i &gt;= 0; i--) { while (x.forward[i] != null &amp;&amp; x.forward[i].value.compareTo(value) &lt; 0) { x = x.forward[i]; } update[i] = x; } x = x.forward[0]; // 删除元素，调整指针 if (x.value.equals(value)) { for (int i = 0; i &lt;= level; i++) { if (update[i].forward[i] != x) break; update[i].forward[i] = x.forward[i]; } // 如果元素为本层最后一个元素，则删除同时降低当前层级 while (level &gt; 0 &amp;&amp; header.forward[level] == null) { level--; } } } /** * 查找是否包含此元素 * * @param searchValue * 带查找值 * @return true：包含；false:不包含 */ public boolean contains(E searchValue) { SkipNode&lt;E&gt; x = header; // 从开始节点的最高层级开始查找 for (int i = level; i &gt;= 0; i--) { // 当到达本层级的NULL节点或者遇到比查找值大的节点时，转到下一层级查找 while (x.forward[i] != null &amp;&amp; x.forward[i].value.compareTo(searchValue) &lt; 0) { x = x.forward[i]; } } x = x.forward[0]; // 此时x有三种可能，1.x=null,2.x.value=searchValue,3.x.value&gt;searchValue return x != null &amp;&amp; x.value.equals(searchValue); } /** * 这里是跳表的精髓所在，通过随机概率来判断节点的层级 * * @return 节点的层级 */ public static int randomLevel() { int lvl = (int) (Math.log(1. - Math.random()) / Math.log(1. - P)); return Math.min(lvl, MAX_LEVEL); } /** * 输出跳表的所有元素 遍历最底层的元素即可 */ public String toString() { StringBuilder sb = new StringBuilder(); sb.append(\"{\"); SkipNode&lt;E&gt; x = header.forward[0]; while (x != null) { sb.append(x.value); x = x.forward[0]; if (x != null) { sb.append(\",\"); } } sb.append(\"}\"); return sb.toString(); }} Test11234567891011121314151617package demo1;public class Test1 { public static void main(String[] args) { SkipSet skipSet=new SkipSet&lt;&gt;(); skipSet.insert(1); skipSet.insert(7); skipSet.insert(14); skipSet.insert(21); skipSet.insert(32); skipSet.insert(37); skipSet.insert(71); skipSet.insert(85); skipSet.insert(117); System.out.println(skipSet.toString()); }} 1{1,7,14,21,32,37,71,85,117} 4.2 C++初始化初始化的过程很简单，仅仅是生成下图中红线区域内的部分，也就是跳表的基础结构。1234567891011121314list newList(){ list list1; int i; // 申请list类型大小的内存 list1 = (list)malloc(sizeof(struct listStructure)); // 设置跳表的层level，初始的层为0层（数组从0开始） list1-&gt;level = 0; // 生成header部分 list1-&gt;header = newNodeOfLevel(MaxNumberOfLevels); // 将header的forward数组清空 for(i=0;i&lt;MaxNumberOfLevels;i++) list1-&gt;header-&gt;forward[i] = NIL; return(list1);}; 插入由于跳表数据结构整体上是有序的，所以在插入时，需要首先查找到合适的位置，然后就是修改指针（和链表中操作类似），然后更新跳表的level变量。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051boolean insert(l,key,value) register list l;register keyType key;register valueType value;{ register int k; // 使用了update数组 node update[MaxNumberOfLevels]; register node p,q; p = l-&gt;header; k = l-&gt;level; /*******************1步*********************/ do { // 查找插入位置 while (q = p-&gt;forward[k], q-&gt;key &lt; key) p = q; // 设置update数组 update[k] = p; } while(--k&gt;=0); // 对于每一层进行遍历 // 这里已经查找到了合适的位置，并且update数组已经 // 填充好了元素 if (q-&gt;key == key) { q-&gt;value = value; return(false); }; // 随机生成一个层数 k = randomLevel(); if (k&gt;l-&gt;level) { // 如果新生成的层数比跳表的层数大的话 // 增加整个跳表的层数 k = ++l-&gt;level; // 在update数组中将新添加的层指向l-&gt;header update[k] = l-&gt;header; }; /*******************2步*********************/ // 生成层数个节点数目 q = newNodeOfLevel(k); q-&gt;key = key; q-&gt;value = value; // 更新两个指针域 do { p = update[k]; q-&gt;forward[k] = p-&gt;forward[k]; p-&gt;forward[k] = q; } while(--k&gt;=0); // 如果程序运行到这里，程序已经插入了该节点 return(true);} 删除和插入是相同的，首先查找需要删除的节点，如果找到了该节点的话，那么只需要更新指针域，如果跳表的level需要更新的话，进行更新。1234567891011121314151617181920212223242526272829303132333435363738394041boolean delete(list1,key) register list list1;register keyType key;{ register int k,m; // 生成一个辅助数组update node update[MaxNumberOfLevels]; register node p,q; p = list1-&gt;header; k = m = list1-&gt;level; // 这里和查找部分类似，最终update中包含的是： // 指向该节点对应层的前驱节点 do { while (q = p-&gt;forward[k], q-&gt;key &lt; key) p = q; update[k] = p; } while(--k&gt;=0); // 如果找到了该节点，才进行删除的动作 if (q-&gt;key == key) { // 指针运算 for(k=0; k&lt;=m &amp;&amp; (p=update[k])-&gt;forward[k] == q; k++) // 这里可能修改l-&gt;header-&gt;forward数组的值的 p-&gt;forward[k] = q-&gt;forward[k]; // 释放实际内存 free(q); // 如果删除的是最大层的节点，那么需要重新维护跳表的 // 层数level while( list1-&gt;header-&gt;forward[m] == NIL &amp;&amp; m &gt; 0 ){ m--; } list1-&gt;level = m; return(true); } else { // 没有找到该节点，不进行删除动作 return(false); }}","link":"/SkipList/"},{"title":"MongoDB分片副本集","text":"​1 环境 2 分片知识 mongos config server shard 3 副本集知识 4 分片副本集拓扑图架构 设计 图1 图2 5 安装部署（以图1） 5.1 端口 5.2 MongoDB安装命令 5.3 config部署命令 5.4 mongos部署命令 5.4.1 方法1 5.4.2 方法2 5.5 副本集部署命令 5.5.1 服务器1 启动命令 新增副本集 5.5.2 服务器2 启动命令 新增副本集 5.6 仲载部署命令 5.6.1 服务器1 启动命令 新增仲载服务器 5.6.2 服务器2 启动命令 新增仲载服务器 5.7 分片部署命令 5.7.1 服务器1 启动命令 新增分片 5.7.2 服务器2 启动命令 新增分片 单个分片 副本集分片 设置片键 5.8 设置索引 6 基本常用命令 6.1 查询分片情况 6.2 查询集合状态 6.3 指定AirMonitor分片生效 6.4 指定数据库里需要分片的集合和片键 6.5 组合片键 6.6 删除分片 7 测试 7.1 数据分片情况 7.2 查询 7.3 保存 7.4 中断机制（选举） 7.5 MapReduce 8 存在问题 9 基本命令 9.1 连接MongoDB 9.2 设置副本MongoDB，可以查询数据 9.3 查看同步状态 9.4 查看集群节点的状态 9.5 新增副本 9.6 删除副本 参考 ​1 环境jar版本比较老，存在性能问题。比如：map-reduce查询过慢，Java创建线程问题引起，有时间可以写一篇。MongoDB版本：mongodb-2.6.8 2 分片知识从图中可以看到有四个组件：mongos、config server、shard、replica set。 mongos数据库集群请求的入口，所有的请求都通过mongos进行协调，不需要在应用程序添加一个路由选择器，mongos自己就是一个请求分发中心，它负责把对应的数据请求请求转发到对应的shard服务器上。在生产环境通常有多mongos作为请求的入口，防止其中一个挂掉所有的MongoDB请求都没有办法操作。 config server顾名思义为配置服务器，存储所有数据库元信息（路由、分片）的配置。mongos本身没有物理存储分片服务器和数据路由信息，只是缓存在内存里，配置服务器则实际存储这些数据。mongos第一次启动或者关掉重启就会从config server加载配置信息，以后如果配置服务器信息变化会通知到所有的mongos更新自己的状态，这样mongos就能继续准确路由。在生产环境通常有多个config server配置服务器，因为它存储了分片路由的元数据，这个可不能丢失！就算挂掉其中一台，只要还有存货，MongoDB集群就不会挂掉。 shard这就是传说中的分片。上面提到一个机器就算能力再大也有天花板，就像军队打仗一样，一个人再厉害喝血瓶也拼不过对方的一个师。俗话说三个臭皮匠顶个诸葛亮，这个时候团队的力量就凸显出来了。在互联网也是这样，一台普通的机器做不了的多台机器来做，如下图。一台机器的一个数据表Collection1存储了1T数据，压力太大了！在分给4个机器后，每个机器都是256G，则分摊了集中在一台机器的压力。也许有人问一台机器硬盘加大一点不就可以了，为什么要分给四台机器呢？不要光想到存储空间，实际运行的数据库还有硬盘的读写、网络的IO、CPU和内存的瓶颈。在MongoDB集群只要设置好了分片规则，通过mongos操作数据库就能自动把对应的数据操作请求转发到对应的分片机器上。在生产环境中分片的片键可要好好设置，这个影响到了怎么把数据均匀分到多个分片机器上，不要出现其中一台机器分了1T，其他机器没有分到的情况，这样还不如不分片！ 3 副本集知识mongoDB官方已经不建议使用主从模式了，替代方案是采用副本集的模式。官方最新文档已经移除主从复制，采用副本集。 REMOVEDMongoDB 4.0 removes support for master-slave replication. Before you can upgrade to MongoDB 4.0, if your deployment uses master-slave replication, you must upgrade to a replica set.To convert your master-slave replication, see Convert a Master-Slave Deployment to a Replica Set. 那什么是副本集呢？打魔兽世界总说打副本，其实这两个概念差不多一个意思。游戏里的副本是指玩家集中在高峰时间去一个场景打怪，会出现玩家暴多怪物少的情况，游戏开发商为了保证玩家的体验度，就为每一批玩家单独开放一个同样的空间同样的数量的怪物，这一个复制的场景就是一个副本，不管有多少个玩家各自在各自的副本里玩不会互相影响。MongoDB的副本也是这个，主从模式其实就是一个单副本的应用，没有很好的扩展性和容错性。而副本集具有多个副本保证了容错性，就算一个副本挂掉了还有很多副本存在，并且解决了上面第一个问题“主节点挂掉了，整个集群内会自动切换”。难怪MongoDB官方推荐使用这种模式。我们来看看MongoDB副本集的架构图：由图可以看到客户端连接到整个副本集，不关心具体哪一台机器是否挂掉。主服务器负责整个副本集的读写，副本集定期同步数据备份，一但主节点挂掉，副本节点就会选举一个新的主服务器，这一切对于应用服务器不需要关心。我们看一下主服务器挂掉后的架构：副本集中的副本节点在主节点挂掉后通过心跳机制检测到后，就会在集群内发起主节点的选举机制，自动选举一位新的主服务器。 4 分片副本集拓扑图架构介绍完分片和副本集的知识，现在开始此次MongoDB分片副本集的拓扑图 设计 3个config管理分片的信息，3个mongos作为请求分发的入口，如果一个config，或者mongos断掉，依然还有其他mongos和config在运行。 图1 服务器1：分片A的增删查改。 服务器2：分片A的副本集同步数据,分片B的增删查改。 服务器3：分片B的副本集同步。图2 服务器1：分片A的增删查改。 服务器2：分片A的副本集同步数据,分片B的副本集同步。 服务器3： 分片B的增删查改。 图1和图2相比较：图2降低了分片B的压力（增删查改），3台服务器，挂掉2个服务器，实际上都是会出现问题。 5 安装部署（以图1）5.1 端口 config：1000，1001，1002 mongos：2000，2001，2002 shared：3000，3001 repliSet：4000，4001 arb：5000，50015.2 MongoDB安装命令服务器11234mongod.exe --logpath=F:\\log\\MongoDB-Shared\\A\\config\\log.txt --dbpath=F:\\db\\MongoDB-Shared\\A\\configmongod.exe --logpath=F:\\log\\MongoDB-Shared\\A\\mongos\\log.txt --dbpath=F:\\db\\MongoDB-Shared\\A\\mongosmongod.exe --logpath=F:\\log\\MongoDB-Shared\\A\\mongodb-A-shared\\log.txt --dbpath=F:\\db\\MongoDB-Shared\\A\\mongodb-A-sharedmongod.exe --logpath=F:\\log\\MongoDB-Shared\\A\\mongodb-B-arb\\log.txt --dbpath=F:\\db\\MongoDB-Shared\\A\\mongodb-B-arb 服务器21234mongod.exe --logpath=F:\\log\\MongoDB-Shared\\B\\config\\log.txt --dbpath=F:\\db\\MongoDB-Shared\\B\\configmongod.exe --logpath=F:\\log\\MongoDB-Shared\\B\\mongos\\log.txt --dbpath=F:\\db\\MongoDB-Shared\\B\\mongosmongod.exe --logpath=F:\\log\\MongoDB-Shared\\B\\mongodb-A-replset\\log.txt --dbpath=F:\\db\\MongoDB-Shared\\B\\mongodb-A-replsetmongod.exe --logpath=F:\\log\\MongoDB-Shared\\B\\mongodb-B-shared\\log.txt --dbpath=F:\\db\\MongoDB-Shared\\B\\mongodb-B-shared 服务器31234mongod.exe --logpath=F:\\log\\MongoDB-Shared\\C\\config\\log.txt --dbpath=F:\\db\\MongoDB-Shared\\C\\configmongod.exe --logpath=F:\\log\\MongoDB-Shared\\C\\mongos\\log.txt --dbpath=F:\\db\\MongoDB-Shared\\C\\mongosmongod.exe --logpath=F:\\log\\MongoDB-Shared\\C\\mongodb-A-arb\\log.txt --dbpath=F:\\db\\MongoDB-Shared\\C\\mongodb-A-arbmongod.exe --logpath=F:\\log\\MongoDB-Shared\\C\\mongodb-B-replset\\log.txt --dbpath=F:\\db\\MongoDB-Shared\\C\\mongodb-B-replset 5.3 config部署命令服务器11mongod --dbpath=F:\\db\\MongoDB-Shared\\A\\config --port 1000 服务器21mongod --dbpath=F:\\db\\MongoDB-Shared\\B\\config --port 1001 服务器31mongod --dbpath=F:\\db\\MongoDB-Shared\\C\\config --port 1002 5.4 mongos部署命令5.4.1 方法1这样配置，每个mongos只会对应本机的config。服务器11mongos --port 2000 --configdb=127.0.0.1:1000 服务器21mongos --port 2001 --configdb=127.0.0.1:1001 服务器31mongos --port 2002 --configdb=127.0.0.1:1002 5.4.2 方法2在每个服务器里配置mongos，这样mongos对应3个服务器的config。1mongos --port 2000 --configdb=127.0.0.1:1000,127.0.0.1:1001,127.0.0.1:1002 5.5 副本集部署命令5.5.1 服务器1启动命令1mongod --dbpath=F:\\db\\MongoDB-Shared\\B\\mongodb-A-replset --port 4000 --replSet MonitorA/127.0.0.1:3000 新增副本集123456db.runCommand({&quot;replSetInitiate&quot;:{&quot;_id&quot;:&quot;MonitorA&quot;,&quot;members&quot;: [ {&quot;_id&quot;:1,&quot;host&quot;:&quot;127.0.0.1:3000&quot; }, {&quot;_id&quot;:2,&quot;host&quot;:&quot;127.0.0.1:4000&quot; } ]}}) 5.5.2 服务器2启动命令1mongod --dbpath=F:\\db\\MongoDB-Shared\\C\\mongodb-B-replset --port 4001 --replSet MonitorB/127.0.0.1:3001 新增副本集123456db.runCommand({&quot;replSetInitiate&quot;:{&quot;_id&quot;:&quot;MonitorB&quot;,&quot;members&quot;: [ {&quot;_id&quot;:1,&quot;host&quot;:&quot;127.0.0.1:3001&quot; }, {&quot;_id&quot;:2,&quot;host&quot;:&quot;127.0.0.1:4001&quot; } ] }}) 5.6 仲载部署命令5.6.1 服务器1启动命令123mongod --dbpath=F:\\db\\MongoDB-Shared\\C\\mongodb-A-arb --port 5000 --replSet MonitorA/127.0.0.1:3000``` #### 新增仲载服务器 rs.addArb(“127.0.0.1:5000”)12### 5.6.2 服务器2#### 启动命令 mongod –dbpath=F:\\db\\MongoDB-Shared\\A\\mongodb-B-arb –port 5001 –replSet MonitorB/127.0.0.1:30011#### 新增仲载服务器 rs.addArb(“127.0.0.1:5001”)123## 5.7 分片部署命令### 5.7.1 服务器1#### 启动命令 mongod –dbpath=F:\\db\\MongoDB-Shared\\A\\mongodb-A-shared –port 3000 –replSet MonitorA/127.0.0.1:40001#### 新增分片 db.runCommand( { addshard : “MonitorA/127.0.0.1:3000,127.0.0.1:4000,127.0.0.1:5000”});12### 5.7.2 服务器2#### 启动命令 mongod –dbpath=F:\\db\\MongoDB-Shared\\B\\mongodb-B-shared –port 3001 –replSet MonitorB/127.0.0.1:40011#### 新增分片 db.runCommand( { addshard : “MonitorB/127.0.0.1:3001,127.0.0.1:4001,127.0.0.1:5001”});12如里shard是单台服务器，用`db.runCommand( { addshard : &quot;[: ]&quot; } )`，这样的命令加入，如果shard是副本集，用`db.runCommand( { addshard : &quot;replicaSetName/[:port][,serverhostname2[:port],…]&quot; })`，这样的格式表示 。##### 单个分片 db.runCommand({“addshard”:”127.0.0.1:3000”,allowLocal:true})12```db.runCommand({&quot;addshard&quot;:&quot;127.0.0.1:3001&quot;,allowLocal:true}) 副本集分片1db.runCommand( { addshard : &quot;MonitorA/127.0.0.1:3000,127.0.0.1:4000,127.0.0.1:5000&quot;}); 1db.runCommand( { addshard : &quot;MonitorB/127.0.0.1:3001,127.0.0.1:4001,127.0.0.1:5001&quot;}); 设置片键1db.runCommand( { shardcollection : &quot;AirMonitor.datagram&quot;,key : {rssi: 1}}) 5.8 设置索引这里设置组合索引123db.datagram.ensureIndex( {&quot;deviceMac&quot; : 1 } ); db.datagram.ensureIndex( { &quot;rssi&quot; : 1, &quot;deviceMac&quot; : 1 } ); db.datagram.ensureIndex( { &quot;deviceMac&quot; : 1, &quot;terminalMac&quot; : 1, &quot;date&quot; : 1 } ); 6 基本常用命令6.1 查询分片情况12db.printShardingStatus()db.runCommand( { listshards : 1}) 6.2 查询集合状态1db.datagram.stats() 6.3 指定AirMonitor分片生效1db.runCommand( { enablesharding :&quot;AirMonitor&quot;}); 6.4 指定数据库里需要分片的集合和片键1db.runCommand( { shardcollection : &quot;AirMonitor.datagram&quot;,key : {id: 1} } ) 6.5 组合片键1db.runCommand( { shardcollection : &quot;AirMonitor.datagram&quot;,key : {rssi: 1,deviceMac:1} } ) 6.6 删除分片123db.runCommand( { removeshard: &quot;MonitorA&quot; } )db.runCommand( { removeshard: &quot;MonitorB/127.0.0.1:3001,127.0.0.1:4001,127.0.0.1:5001&quot; } )db.runCommand( { removeshard: &quot;MonitorA/127.0.0.1:3000,127.0.0.1:4000,127.0.0.1:5000&quot; } ) 7 测试插入数据10w条：for (var i = 1; i &lt;= 100000; i++){db.datagram.save({&quot;rssi&quot; : i,&quot;deviceMac&quot;:&quot;yujie&quot;});} 7.1 数据分片情况 MonitorA：rssi的0-&gt;5900都在A分片。 MonitorB ：5900之后都在B分片。12345678AirMonitor.datagram shard key: { &quot;rssi&quot; : 1, &quot;deviceMac&quot; : 1 } chunks: MonitorB 2 MonitorA 1 { &quot;rssi&quot; : { &quot;$minKey&quot; : 1 }, &quot;deviceMac&quot; : { &quot;$minKey&quot;: 1 } } --&gt;&gt; { &quot;rssi&quot; : 1, &quot;deviceMac&quot; : &quot;yujie&quot; } on : MonitorB Timestamp(2, 0) { &quot;rssi&quot; : 1, &quot;deviceMac&quot; : &quot;yujie&quot; } --&gt;&gt; { &quot;rssi&quot; : 5900, &quot;deviceMac&quot; : &quot;yujie&quot; } on : MonitorA Timestamp(3, 1) { &quot;rssi&quot; : 5900, &quot;deviceMac&quot; : &quot;yujie&quot; } --&gt;&gt; { &quot;rssi&quot; :{ &quot;$maxKey&quot; : 1 }, &quot;deviceMac&quot; : { &quot;$maxKey&quot; : 1 } } on : MonitorB Timestamp(3,0) 7.2 查询在java里查询全部的时候，会把A，B分片同时查询出来，放在集合里，并且不会在排序。1234567812:22:32.088 [http-bio-55555-exec-3] INFO c.m.a.c.Test2Controller - 5900-yujie12:22:32.089 [http-bio-55555-exec-3] INFO c.m.a.c.Test2Controller - 1-yujie12:22:32.089 [http-bio-55555-exec-3] INFO c.m.a.c.Test2Controller - 5901-yujie12:22:32.089 [http-bio-55555-exec-3] INFO c.m.a.c.Test2Controller - 2-yujie12:22:32.089 [http-bio-55555-exec-3] INFO c.m.a.c.Test2Controller - 5902-yujie12:22:32.089 [http-bio-55555-exec-3] INFO c.m.a.c.Test2Controller - 3-yujie12:22:32.089 [http-bio-55555-exec-3] INFO c.m.a.c.Test2Controller - 5903-yujie12:22:32.089 [http-bio-55555-exec-3] INFO c.m.a.c.Test2Controller - 4-yujie 7.3 保存分片里保存数据方法较慢 ；1w条数据保存到分片B，需要10s。 7.4 中断机制（选举）没有如何问题。 7.5 MapReduce在分片副本集里不能使用MapReduce。 8 存在问题 保存方法太慢。 从多个片查询数据时，不会重新排序。 分片副本集里不能使用MapReduce。以上存在的问题，可能是jar版本较低，而造成的影响。期待后续更新jar，在进行测试。9 基本命令9.1 连接MongoDB1mongo 127.0.0.1/Monitor -u -p 9.2 设置副本MongoDB，可以查询数据1db.getMongo().setSlaveOk() 9.3 查看同步状态1db.printSlaveReplicationInfo(); 9.4 查看集群节点的状态1rs.status(); 9.5 新增副本1rs.add(&quot;ip+端口号&quot;) 注意：这个命令只能用在主库中 9.6 删除副本1rs.remove(&quot;IP+端口&quot;) 参考https://www.cnblogs.com/lanceyan/p/3497124.html","link":"/MongoDB-Sharding-Replica/"},{"title":"Mybatis一级缓存和二级缓存","text":"1 一级缓存 官方文档 2 二级缓存 3 Cache FifoCache LoggingCache LruCache ScheduledCache SerializedCache SoftCache SynchronizedCache WeakCache Cache PerpetualCache 4 缓存装饰器 LruCache最近最少使用的回收策略 LruCache#setSize LruCache#putObject LruCache#cycleKeyList ScheduledCache调度缓存装饰器 ScheduledCache#clearWhenStale() SerializedCache序列化缓存装饰器 SerializedCache#putObject() SerializedCache#getObject() SerializedCache#CustomObjectInputStream LoggingCache日志缓存装饰器 LoggingCache#getObject() LoggingCache#getHitRatio() SynchronizedCache同步的缓存装饰器 FifoCache先进先出缓存回收策略装饰器 FifoCache#FifoCache() FifoCache#putObject() FifoCache#cycleKeyList() SoftCache软引用缓存装饰器 SoftCache数据结构 SoftCache#putObject() SoftCache#removeGarbageCollectedItems() WeakCache弱引用缓存装饰器 TransactionalCache事务性缓存 TransactionalCache数据结构 1 一级缓存一级缓存，又叫本地缓存，是PerpetualCache类型的永久缓存，保存在执行器中（BaseExecutor），而执行器又在SqlSession（DefaultSqlSession）中，所以一级缓存的生命周期与SqlSession是相同的。MyBatis的一级缓存指的是在一个Session域内，Session为关闭的时候执行的查询会根据SQL为key被缓存，单独使用MyBatis而不继承Spring，使用原生的MyBatis的SqlSessionFactory来构造sqlSession查询，是可以使用以及缓存的。当参数不变的时候只进行一次查询，参数变更以后，则需要重新进行查询，而清空缓存以后，参数相同的查询过的SQL也需要重新查询，当执行SQL时两次查询中间发生增删改操作，则SqlSession的缓存清空。如果集成Spring是没有使用一级缓存。原因是一个sqlSession，但是实际上因为我们的dao继承SqlSessionDaoSupport，而SqlSessionDaoSupport内部sqlSession的实现是使用用动态代理实现的，这个动态代理sqlSessionProxy使用一个模板方法封装select()等操作，每一次select()查询都会自动先执行openSession()，执行完后调用close()方法，相当于生成一个新的session实例，所以我们无需手动的去关闭这个session()，当然也无法使用MyBatis的一级缓存，也就是说MyBatis的一级缓存在Spring中是没有作用的。 官方文档 MyBatis SqlSession provides you with specific methods to handle transactions programmatically. But when using MyBatis-Spring your beans will be injected with a Spring managed SqlSession or a Spring managed mapper. That means that Spring will always handle your transactions.You cannot call SqlSession.commit(), SqlSession.rollback() or SqlSession.close() over a Spring managed SqlSession. If you try to do so, a UnsupportedOperationException exception will be thrown. Note these methods are not exposed in injected mapper classes. 2 二级缓存二级缓存，又叫自定义缓存，实现Cache接口的类都可以作为二级缓存，所以可配置如encache等的第三方缓存。二级缓存以namespace名称空间为其唯一标识，被保存在Configuration核心配置对象中。12345public class Configuration { // ... protected final Map&lt;String, Cache&gt; caches = new StrictMap&lt;Cache&gt;(\"Caches collection\"); // ...} 每次构建SqlSessionFactory对象时都会创建新的Configuration对象，因此，二级缓存的生命周期与SqlSessionFactory是相同的。在创建每个MapperedStatement对象时，都会根据其所属的namespace名称空间，给其分配Cache缓存对象。二级缓存同样执行增删查改操作，会清空缓存。二级缓存就是global caching，它超出session范围之外，可以被所有sqlSession共享，它的实现机制和MySQL的缓存一样，开启它只需要在MyBatis的配置文件开启settings里。1&lt;setting name=\"cacheEnabled\" value=\"true\"/&gt; 在相应的Mapper文件里：123456789&lt;mapper namespace=\"dao.userdao\"&gt; ... select statement ... &lt;!-- Cache 配置 --&gt; &lt;cache eviction=\"FIFO\" flushInterval=\"60000\" size=\"512\" readOnly=\"true\" /&gt;&lt;/mapper&gt; 需要注意的是global caching的作用域是针对Mapper#Namespace而言的，也就是说只在有在这个Namespace内的查询才能共享这个cache。下面是官方文档的介绍： It’s important to remember that a cache configuration and the cache instance are bound to the namespace of the SQL Map file. Thus, all statements in the same namespace as the cache are bound by it. 注意 映射语句文件中的所有select语句将会被缓存。 映射语句文件中的所有insert，update和delete语句会刷新缓存。 缓存会使用Least Recently Used（LRU，最近最少使用的）算法来收回。 缓存会根据指定的时间间隔来刷新。 缓存会存储1024个对象。 如果二级缓存想要命中实现，则必须要将上一次sqlSession commit之后才能生效，不然将不会命中。原因：两个不同的session必须提交前面一个session才能缓存生效的，原因是因为MyBatis的缓存会被一个Transactioncache类包装住，所有的cache#putObject全部都会被暂时存到一个map里，等事务提交以后，这个map里的缓存对象才会被真正的cache类执行putObject操作。这么设计的原因是防止事务执行过程中出异常导致回滚，如果get到object后直接put进缓存，万一发生回滚，就很容易导致MyBatis缓存被脏读。 3 Cache在MyBatis中，缓存的功能由根接口Cache（org.apache.ibatis.cache.Cache）定义。整个体系采用装饰器设计模式，数据存储和缓存的基本功能由PerpetualCache（org.apache.ibatis.cache.impl.PerpetualCache）永久缓存实现，然后通过一系列的装饰器来对PerpetualCache永久缓存进行缓存策略等方便的控制。如下图。用于装饰PerpetualCache的标准装饰器共有8个（全部在org.apache.ibatis.cache.decorators包中）： FifoCache先进先出算法，缓存回收策略 LoggingCache输出缓存命中的日志信息 LruCache最近最少使用算法，缓存回收策略 ScheduledCache调度缓存，负责定时清空缓存 SerializedCache缓存序列化和反序列化存储 SoftCache基于软引用实现的缓存管理策略 SynchronizedCache同步的缓存装饰器，用于防止多线程并发访问 WeakCache基于弱引用实现的缓存管理策略另外，还有一个特殊的装饰器TransactionalCache（事务性的缓存）所有的缓存对象的操作与维护都是由Executor器执行来完成的，一级缓存由BaseExecutor（包含SimpleExecutor、ReuseExecutor、BatchExecutor三个子类）负责维护，二级缓存由CachingExecutor负责维护。因此需要注意的是，配置二级缓存不代表MyBatis就会使用二级缓存，还需要确保在创建SqlSession的过程中，MyBatis创建是CachingExecutor类型的执行器。 Cache12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364package org.apache.ibatis.cache;import java.util.concurrent.locks.ReadWriteLock;/** * 缓存接口 * 给缓存供应商的SPI（Service Provider Interface） * 一个Cache的实例将为名称空间被创建 * Cache接口的实现类必须有一个具有String类型参数的构造方法，用于接收Cache对象的id，作为其唯一标识 * * mybatis将以namespace作为id调用这个构造函数创建对象 * * */public interface Cache { /** * 获取缓存对象的唯一标识 * @return */ String getId(); /** * 保存key/value到缓存对象中 * key可以是任何对象，但一般是CacheKey对象 * value是查询结果，为List类型 * @param key * @param value */ void putObject(Object key, Object value); /** * 从缓存对象中获取key对应的value * @param key * @return */ Object getObject(Object key); /** * 可选的方法，没有被核心框架调用，移除key对应的value * @param key * @return */ Object removeObject(Object key); /** * 清空缓存 */ void clear(); /** * 获取缓存对象中存储的键/值对的数量 * 可选的方法，没有被框架核心调用 */ int getSize(); /** * 获取读写锁 * 可选的方法，从3.2.6起这个方法不再被框架核心调用 * 任何需要的锁，都必须由缓存供应商提供 * * @return A ReadWriteLock */ ReadWriteLock getReadWriteLock();} PerpetualCache12345678910111213141516171819202122package org.apache.ibatis.cache.impl;import java.util.HashMap;import java.util.Map;import java.util.concurrent.locks.ReadWriteLock;import org.apache.ibatis.cache.Cache;import org.apache.ibatis.cache.CacheException;/** * 永久缓存 Cache接口实现类 * Cache接口只有这唯一一个基础实现，其他实现类全都是装饰模式持有另一个缓存对象 * * */public class PerpetualCache implements Cache { // 缓存对象的唯一标识 private String id; // 对象内部维护的HashMap private Map&lt;Object, Object&gt; cache = new HashMap&lt;Object, Object&gt;(); ....} 在MyBatis中，PerpetualCache是唯一的Cache接口的基础实现。它内部维护一个HashMap，所有的缓存操作，其实都是对这个HashMap的操作。 4 缓存装饰器LruCache最近最少使用的回收策略12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364package org.apache.ibatis.cache.decorators;import java.util.LinkedHashMap;import java.util.Map;import java.util.concurrent.locks.ReadWriteLock;import org.apache.ibatis.cache.Cache;/** * 基于最近最少使用算法的回收策略 * * */public class LruCache implements Cache { // 代理的缓存对象 private final Cache delegate; // 此Map的key和value都是要添加的键值对的键 private Map&lt;Object, Object&gt; keyMap; // 最老的key private Object eldestKey; public LruCache(Cache delegate) { this.delegate = delegate; setSize(1024); } .... public void setSize(final int size) { keyMap = new LinkedHashMap&lt;Object, Object&gt;(size, .75F, true) { private static final long serialVersionUID = 4267176411845948333L; protected boolean removeEldestEntry(Map.Entry&lt;Object, Object&gt; eldest) { boolean tooBig = size() &gt; size; if (tooBig) { eldestKey = eldest.getKey(); } return tooBig; } }; } @Override public void putObject(Object key, Object value) { delegate.putObject(key, value); cycleKeyList(key); } .... /** * 循环keyList * @param key */ private void cycleKeyList(Object key) { keyMap.put(key, key); if (eldestKey != null) { delegate.removeObject(eldestKey); eldestKey = null; } }} LruCache内部维护一个Map1private Map&lt;Object, Object&gt; keyMap; 它的实际类型是LinkedHashMap&lt;Object,Object&gt;的匿名子类，子类重写removeEldesEntry()，用于获取在达到容量限制时被删除的key。 LruCache#setSize12345678910111213public void setSize(final int size) { keyMap = new LinkedHashMap&lt;Object, Object&gt;(size, .75F, true) { private static final long serialVersionUID = 4267176411845948333L; protected boolean removeEldestEntry(Map.Entry&lt;Object, Object&gt; eldest) { boolean tooBig = size() &gt; size; if (tooBig) { eldestKey = eldest.getKey(); } return tooBig; } };} 在每次调用setSize()，都会创建一个新的该类型的对象，同时指定其容量大小。第三个参数为true代表Map中的键值对列表要按照访问顺序排序，每次被方位的键值对都会被移动到列表尾部（值为false时按照插入顺序排序）。 LruCache#putObject1234public void putObject(Object key, Object value) { delegate.putObject(key, value); cycleKeyList(key);} 在每次给代理缓存对象添加完键值对后，都会调用cycleKeyList()进行一次检查。 LruCache#cycleKeyList1234567891011121314 /** * 循环keyList * @param key */private void cycleKeyList(Object key) { // 把刚刚给代理缓存对象中添加的key，同时添加到keyMap中 keyMap.put(key, key); // 如果eldestKey不为null，则代表keyMap内部删除eldestKey这个key if (eldestKey != null) { // 同样把代理缓存对象中key为eldestKey的键值对删除即可 delegate.removeObject(eldestKey); eldestKey = null; }} LruCache把新添加的键值对的键添加到keyMap中，如果发现keyMap内部删除一个key，则同样把代理缓存对象中相同的key删除。LruCache就是以这种方式实现最近最少访问回收算法的。 ScheduledCache调度缓存装饰器它的内部维护2个字段，clearInterval和lastClear1234// 调用clear()清空缓存的时间间隔，单位毫秒，默认1小时protected long clearInterval;// 最后一次清空缓存的时间，单位毫秒protected long lastClear; 在对代理的缓存对象进行任何操作之前，都会首先调用clearWhenStale()方法检查当前时间点是否需要清理一次缓存，如果需要则进行清理并返回true，否则返回false。 ScheduledCache#clearWhenStale()123456789101112/** * 当缓存过期时调用clear方法进行清空 * @return 如果成功进行清理则返回true，否则返回false */private boolean clearWhenStale() { // 如果当前时间-最后一次清空时间&gt;指定的时间间隔，则调用clear()进行清空 if (System.currentTimeMillis() - lastClear &gt; clearInterval) { clear(); return true; } return false;} SerializedCache序列化缓存装饰器它负责在调用putObject(key,value)方法保存key/value时，把value序列化为字节数组；在调用getObject(key)获取value时，把获取到字节数组再反序列化回来。使用此装饰器的前提是，所有要缓存的value必须实现Serializable接口，否则会抛出CacheException异常。 SerializedCache#putObject()12345678@Overridepublic void putObject(Object key, Object object) { if (object == null || object instanceof Serializable) { delegate.putObject(key, serialize((Serializable) object)); } else { throw new CacheException(\"SharedCache failed to make a copy of a non-serializable object: \" + object); }} SerializedCache#getObject()12345@Overridepublic Object getObject(Object key) { Object object = delegate.getObject(key); return object == null ? null : deserialize((byte[]) object);} 在反序列化时，SerializedCache使用内部定义的类CustomObjectInputStream，此类继承自ObjectInputStream，重写父类的resolveClass()，区别在于解析加载Class对象时使用的ClassLoader类加载器不同。 SerializedCache#CustomObjectInputStream123456789public static class CustomObjectInputStream extends ObjectInputStream { public CustomObjectInputStream(InputStream in) throws IOException { super(in); } @Override protected Class&lt;?&gt; resolveClass(ObjectStreamClass desc) throws IOException, ClassNotFoundException { return Resources.classForName(desc.getName()); }} LoggingCache日志缓存装饰器它内部维护2个字段，requests查询次数计数器和hits查询命中次数计数器12345678 // 日志记录器private Log log;// 代理的缓存对象private Cache delegate;// 每次调用getObject(key)查询时，此值+1protected int requests = 0;// 每次调用getObject(key)获取到的value不为null时，此值+1protected int hits = 0; 在每次调用getObject()从缓存对象中查询值时，都会迭代这两个计数器，并且计算实时命中率，打印到日志中。 LoggingCache#getObject()12345678910111213@Overridepublic Object getObject(Object key) { requests++; final Object value = delegate.getObject(key); if (value != null) { hits++; } // 打印当前缓存对象的命中率 if (log.isDebugEnabled()) { log.debug(\"Cache Hit Ratio [\" + getId() + \"]: \" + getHitRatio()); } return value;} LoggingCache#getHitRatio()1234567/** * 计算实时命中率 * @return*/ private double getHitRatio() { return (double) hits / (double) requests;} SynchronizedCache同步的缓存装饰器这个装饰器比较简单，只是把所有操作缓存对象的方法上都加synchronized，用来避免多线程并发访问。123456789101112131415161718192021222324 @Overridepublic synchronized int getSize() { return delegate.getSize();}@Overridepublic synchronized void putObject(Object key, Object object) { delegate.putObject(key, object);}@Overridepublic synchronized Object getObject(Object key) { return delegate.getObject(key);}@Overridepublic synchronized Object removeObject(Object key) { return delegate.removeObject(key);}@Overridepublic synchronized void clear() { delegate.clear();} FifoCache先进先出缓存回收策略装饰器它内部维护一个不限容量的LinkedList，名称为keyList，在构造方法中被创建。1private LinkedList&lt;Object&gt; keyList; FifoCache#FifoCache()12345public FifoCache(Cache delegate) { this.delegate = delegate; this.keyList = new LinkedList&lt;Object&gt;(); this.size = 1024;} 在调用putObject()添加缓存时，会在向代理的缓存对象中添加数据之前，调用cycleKeyList()进行一次验证，如果keyList超过限制长度，则进行回收。 FifoCache#putObject()12345@Overridepublic void putObject(Object key, Object value) { cycleKeyList(key); delegate.putObject(key, value);} FifoCache#cycleKeyList()12345678910private void cycleKeyList(Object key) { // 把key添加到keyList中 keyList.addLast(key); // 如果keyList超长，则移除第一个key，并获取被移除的key // 之后从代理缓存对象中，删除这个key if (keyList.size() &gt; size) { Object oldestKey = keyList.removeFirst(); delegate.removeObject(oldestKey); }} SoftCache软引用缓存装饰器它利用JDK的SoftReference软引用，借助垃圾回收器进行缓存对象的回收。通常使用的引用方式都是强引用，如：Object obj = new Object();只要引用变量obj!=null，那么Object对象永远不会被垃圾回收器回收。而软引用的引用方式是这样的。1SoftReference ref = new SoftReference(new Object()); 引用变量ref引用SoftReference对象（这属于强引用），再由SoftReference对象内部引用new Object（这属于软引用）。 SoftCache数据结构12345678910// 强引用集合，最近一此查询命中的对象，其引用会被加入此集合的头部// 集合采取先进先出策略，当长度超出指定size时，删除尾部元素private final LinkedList&lt;Object&gt; hardLinksToAvoidGarbageCollection;// 此队列保存被垃圾回收器回收的对象所在的Reference对象// 垃圾回收器在进行内存回收时，会把Reference对象内的引用变量置为null，同时将Reference对象加入队列中private final ReferenceQueue&lt;Object&gt; queueOfGarbageCollectedEntries;// 代理的缓存对象private final Cache delegate;// 强引用集合长度限制，可通过setSize方法设置，默认为256private int numberOfHardLinks; SoftCache在写缓存之前，会先调用removeGarbageCollectedItems()删除已经被垃圾回收器回收的key/value，之后想缓存对象中写入SoftEntry类型的对象（定义在SoftCache的内部，是SoftReference类的子类）。 SoftCache#putObject()12345@Overridepublic void putObject(Object key, Object value) { removeGarbageCollectedItems(); delegate.putObject(key, new SoftEntry(key, value, queueOfGarbageCollectedEntries));} SoftCache#removeGarbageCollectedItems()12345678910/** * 从缓存对象中删除已经被垃圾回收器回收的value对象对应的key */private void removeGarbageCollectedItems() { SoftEntry sv; // 弹出队列中的所有key，依次删除 while ((sv = (SoftEntry) queueOfGarbageCollectedEntries.poll()) != null) { delegate.removeObject(sv.key); }} SoftCache在读缓存时，是直接读取的。这样存在一个问题，缓存的value对象已经被垃圾回收器回收，但是该对象的软引用对象还存在，这种情况下要删除缓存对象中，软引用对象对应的key。另外，每次调用getObject()查询到缓存对象中的value还未被回收时，都会把此对象的引用临时加入强引用集合，这样确保该对象不会被回收。这种机制保证访问频次越搞的value对象，被回收的几率越小。123456789101112131415161718192021222324252627@Overridepublic Object getObject(Object key) { Object result = null; @SuppressWarnings(\"unchecked\") // assumed delegate cache is totally // managed by this cache SoftReference&lt;Object&gt; softReference = (SoftReference&lt;Object&gt;) delegate.getObject(key); // 引用变量为null，说明不存在key指定的键值对 if (softReference != null) { // 键值对存在的情况下，获取软引用变量引用的对象 result = softReference.get(); // 如果引用的value已经被回收，则删除缓存对象中的key if (result == null) { delegate.removeObject(key); } else { // See #586 (and #335) modifications need more than a read lock // 缓存的value对象没有被回收，且这次访问到了，则把此对象引用加入强引用集合 // 使其不会被回收 synchronized (hardLinksToAvoidGarbageCollection) { hardLinksToAvoidGarbageCollection.addFirst(result); if (hardLinksToAvoidGarbageCollection.size() &gt; numberOfHardLinks) { hardLinksToAvoidGarbageCollection.removeLast(); } } } } return result;} WeakCache弱引用缓存装饰器WeakCache在实现上与SoftCache几乎相同，只是把引用对象由SoftReference软引用换成WeakReference弱引用。 TransactionalCache事务性缓存TransactionalCache比其他Cache对象多出2个方法：commit()和rollback()。TransactionalCache对象内部存在暂存区，所有对缓存对象的写操作都不会直接作用于缓存对象，而是被保存在暂存区，只有调用TransactionalCache#commit()，所有的更新操作才会真正同步到缓存对象中。（二级缓存先执行commit()才能使用的原因）这样的话，就会存在一个问题，如果事务被设置为自动提交（autoCommit=true）的话，写操作会更新RDBMS（关系型数据库管理系统），但不会清空缓存对象（因为自动提交不会调用commit()），这样会产生数据库与缓存中数据不一致的情况。如果缓存没有过期失效的机制，那么问题会很严重。 TransactionalCache数据结构12345678910111213// 原始的被代理的Cache缓存对象private Cache delegate;// 调用commit()方法时是否清空缓存，初始为false// 如果此值为true，则调用commit时会进行清空缓存的操作// 只有事务中包含更新操作时，此值才会为true// 否则只需要覆盖指定key/value的更新即可，（覆盖分为删除和添加两步操作）private boolean clearOnCommit;// 在commit时需要进行的添加操作// 调用putObject方法时添加到这里private Map&lt;Object, AddEntry&gt; entriesToAddOnCommit;// 在commit时需要进行的移除操作，// 调用removeObject时添加到这里private Map&lt;Object, RemoveEntry&gt; entriesToRemoveOnCommit; 之所以把putObject操作分为删除和添加两步，可能是因为有的缓存的添加逻辑是：如果key已存在，则不允许添加，抛出异常。","link":"/MyBatis-Cache/"},{"title":"Redis持久化RDB和AOF","text":"1 Redis持久化 2 RDB持久化 执行快照场景 执行SAVE或BGSAVE命令 SAVE命令 BGSAVE命令 执行FLUSHALL命令 执行复制 优点 RDB是一个非常紧凑（compact）的文件 RDB非常适用于灾难恢复（disaster recovery） RDB可以最大化Redis的性能 缺点 RDB快照 快照的运作方式 3 AOF持久化 优点 缺点 AOF重写 AOF重写执行步骤 AOF同步 appendfsync always appendfsync no AOF文件出错 4 应该选用哪一个 5 Redis持久化磁盘IO方式及其带来的问题 1 Redis持久化Redis提供多种不同级别的持久化方式：一种是RDB，另一种是AOF。RDB会根据配置的规则定时将内存中的数据持久化到硬盘上，AOF则是在每次执行写命令之后将命令记录下来。两种持久化方式可以单独使用，但是通常会将两者结合使用。RDB持久化和AOF持久化之间的异同是非常重要的，以下几个小节将详细地介绍这这两种持久化功能，并对它们的相同和不同之处进行说明。 2 RDB持久化RDB持久化可以在指定的时间间隔内生成数据集的时间点快照（point-in-time snapshot）。RDB方式的持久化是通过快照的方式完成的。当符合某种规则时，会将内存中的数据全量生成一份副本存储到硬盘上，这个过程称作”快照”，Redis会在以下几种情况下对数据进行快照。 根据配置规则进行自动快照。 用户执行SAVE,BGSAVE命令。 执行FLUSHALL命令。 执行复制（replication）。执行快照场景根据配置自动快照，Redis允许用户自定义快照条件，当满足条件时自动执行快照，快照规则的配置方式如下。 123save 900 1save 300 10save 60 10000 每个快照条件独占一行，他们之间是或（||）关系，只要满足任何一个就进行快照。上面配置save后的第一个参数T是时间，单位是秒，第二个参数M是更改的键的个数，含义是：当时间T内被更改的键的个数大于M时，自动进行快照。比如save 900 1的含义是15分钟内(900s)被更改的键的个数大于1时，自动进行快照操作。 执行SAVE或BGSAVE命令除让Redis自动进行快照外，当我们需要重启、迁移、备份Redis时，我们也可以手动执行SAVE或BGSAVE命令主动进行快照操作。 SAVE命令当执行SAVE命令时，Redis同步进行快照操作，期间会阻塞所有来自客户端的请求，所以放数据库数据较多时，应该避免使用该命令。 BGSAVE命令从命令名字就能看出来，这个命令与SAVE命令的区别就在于该命令的快照操作是在后台异步进行的，进行快照操作的同时还能处理来自客户端的请求。执行BGSAVE命令后Redis会马上返回OK表示开始进行快照操作，如果想知道快照操作是否已经完成，可以使用LASTSAVE命令返回最近一次成功执行快照的时间，返回结果是一个Unix时间戳。 执行FLUSHALL命令当执行FLUSHALL命令时，Redis会清除数据库中的所有数据。需要注意的是：不论清空数据库的过程是否触发自动快照的条件，只要自动快照条件不为空，Redis就会执行一次快照操作，当没有定义自动快照条件时，执行FLUSHALL命令不会进行快照操作。 执行复制当设置主从模式时，Redis会在复制初始化是进行自动快照。 优点RDB是一个非常紧凑（compact）的文件它保存Redis在某个时间点上的数据集。这种文件非常适合用于进行备份。比如说，你可以在最近的24小时内，每小时备份一次RDB文件，并且在每个月的每一天，也备份一个RDB文件。这样的话，即使遇上问题，也可以随时将数据集还原到不同的版本。 RDB非常适用于灾难恢复（disaster recovery）它只有一个文件，并且内容都非常紧凑，可以（在加密后）将它传送到别的数据中心。 RDB可以最大化Redis的性能父进程在保存RDB文件时唯一要做的就是fork出一个子进程，然后这个子进程就会处理接下来的所有保存工作，父进程无须执行任何磁盘I/O操作。RDB在恢复大数据集时的速度比AOF的恢复速度要快。 缺点如果你需要尽量避免在服务器故障时丢失数据，那么RDB不适合你。虽然Redis允许你设置不同的保存点（save point）来控制保存RDB文件的频率，但是，因为RDB文件需要保存整个数据集的状态，所以它并不是一个轻松的操作。因此你可能会至少5分钟才保存一次RDB文件。在这种情况下，一旦发生故障停机，你就可能会丢失好几分钟的数据。每次保存RDB的时候，Redis都要fork()出一个子进程，并由子进程来进行实际的持久化工作。在数据集比较庞大时， fork()可能会非常耗时，造成服务器在某某毫秒内停止处理客户端；如果数据集非常巨大，并且CPU时间非常紧张的话，那么这种停止时间甚至可能会长达整整1秒。虽然AOF重写也需要进行fork()，但无论AOF重写的执行间隔有多长，数据的耐久性都不会有任何损失。 RDB快照在默认情况下，Redis将数据库快照保存在名字为dump.rdb的二进制文件中。你可以对Redis进行设置，让它在”N秒内数据集至少有M个改动”这一条件被满足时，自动保存一次数据集。你也可以通过调用SAVE或者BGSAVE，手动让Redis进行数据集保存操作。比如说，以下设置会让Redis在满足”60秒内有至少有1000个键被改动”这一条件时，自动保存一次数据集。1save 60 1000 这种持久化方式被称为快照（snapshot）。 快照的运作方式当Redis需要保存dump.rdb文件时，服务器执行以下操作。 Redis调用fork()，同时拥有父进程和子进程。 子进程将数据集写入到一个临时RDB文件中。 当子进程完成对新RDB文件的写入时，Redis用新RDB文件替换原来的RDB文件，并删除旧的RDB文件。 这种工作方式使得Redis可以从写时复制（copy-on-write）机制中获益。 只进行追加操作的文件（append-only file，AOF）。 快照功能并不是非常耐久，如果Redis因为某些原因而造成故障停机，那么服务器将丢失最近写入、且仍未保存到快照中的那些数据。尽管对于某些程序来说，数据的耐久性并不是最重要的考虑因素，但是对于那些追求完全耐久能力（full durability）的程序来说，快照功能就不太适用。从1.1版本开始，Redis增加一种完全耐久的持久化方式：AOF持久化。你可以通过修改配置文件来打开AOF功能。1appendonly yes 从现在开始，每当Redis执行一个改变数据集的命令时（比如SET），这个命令就会被追加到AOF文件的末尾。这样的话，当Redis重新启时，程序就可以通过重新执行AOF文件中的命令来达到重建数据集的目的。 3 AOF持久化AOF持久化记录服务器执行的所有写操作命令，并在服务器启动时，通过重新执行这些命令来还原数据集。AOF文件中的命令全部以Redis协议的格式来保存，新命令会被追加到文件的末尾。Redis还可以在后台对AOF文件进行重写（rewrite），使得AOF文件的体积不会超出保存数据集状态所需的实际大小。Redis还可以同时使用AOF持久化和RDB持久化。在这种情况下，当Redis重启时，它会优先使用AOF文件来还原数据集， 因为AOF文件保存的数据集通常比RDB文件所保存的数据集更完整。你甚至可以关闭持久化功能，让数据只在服务器运行时存在。默认情况下，Redis没有开启AOF（append only file）持久化功能，可以通过在配置文件中作如下配置启用。1appendonly yes 优点使用AOF持久化会让Redis变得非常耐久（much more durable），你可以设置不同的fsync策略，比如无fsync，每秒钟一次fsync，或者每次执行写入命令时fsync。AOF的默认策略为每秒钟fsync一次，在这种配置下，Redis仍然可以保持良好的性能，并且就算发生故障停机，也最多只会丢失一秒钟的数据（fsync会在后台线程执行，所以主线程可以继续努力地处理命令请求）。AOF文件是一个只进行追加操作的日志文件（append only log），因此对AOF文件的写入不需要进行seek，即使日志因为某些原因而包含未写入完整的命令（比如写入时磁盘已满，写入中途停机，等等），redis-check-aof工具也可以轻易地修复这种问题。Redis可以在AOF文件体积变得过大时，自动地在后台对AOF进行重写，重写后的新AOF文件包含恢复当前数据集所需的最小命令集合。整个重写操作是绝对安全的，因为Redis在创建新AOF文件的过程中，会继续将命令追加到现有的AOF文件里面，即使重写过程中发生停机，现有的AOF文件也不会丢失。而一旦新AOF文件创建完毕，Redis就会从旧AOF文件切换到新AOF文件，并开始对新AOF文件进行追加操作。AOF文件有序地保存对数据库执行的所有写入操作，这些写入操作以 Redis协议的格式保存，因此AOF文件的内容非常容易被人读懂，对文件进行分析（parse）也很轻松。导出（export）AOF文件也非常简单：举个例子，如果你不小心执行FLUSHALL命令，但只要AOF文件未被重写，那么只要停止服务器，移除AOF文件末尾的FLUSHALL命令，并重启Redis， 就可以将数据集恢复到FLUSHALL执行之前的状态。 缺点对于相同的数据集来说，AOF文件的体积通常要大于RDB文件的体积。根据所使用的fsync策略，AOF的速度可能会慢于RDB。在一般情况下，每秒fsync的性能依然非常高，而关闭fsync可以让AOF的速度和RDB一样快，即使在高负荷之下也是如此。不过在处理巨大的写入载入时，RDB可以提供更有保证的最大延迟时间（latency）。AOF在过去曾经发生过这样的BUG：因为个别命令的原因，导致AOF文件在重新载入时，无法将数据集恢复成保存时的原样。 （举个例子，阻塞命令BRPOPLPUSH就曾经引起过这样的BUG。）测试套件里为这种情况添加测试：它们会自动生成随机的、复杂的数据集， 并通过重新载入这些数据来确保一切正常。 虽然这种BUG在AOF文件中并不常见，但是对比来说，RDB几乎是不可能出现这种BUG的。 AOF重写因为AOF的运作方式是不断地将命令追加到文件的末尾，所以随着写入命令的不断增加，AOF文件的体积也会变得越来越大。举个例子，如果你对一个计数器调用100次INCR，那么仅仅是为保存这个计数器的当前值，AOF文件就需要使用100条记录（entry）。然而在实际上， 只使用一条SET命令已经足以保存计数器的当前值，其余99条记录实际上都是多余的。处理这种情况，Redis支持一种有趣的特性：可以在不打断服务客户端的情况下，对AOF文件进行重建（rebuild）。执行BGREWRITEAOF命令，Redis将生成一个新的AOF文件，这个文件包含重建当前数据集所需的最少命令。AOF重写可以在配置文件中做相应的配置，当满足配置的条件时，自动进行AOF重写操作。配置如下。12auto-aof-rewrite-percentage 100auto-aof-rewrite-min-size 64mb 第一行的意思是，目前的AOF文件的大小超过上一次重写时的AOF文件的百分之多少时再次进行重写，如果之前没有重写过，则以启动时AOF文件大小为依据。第二行的意思是，当AOF文件的大小大于64MB时才进行重写，因为如果AOF文件本来就很小时，有几个无效的命令也是无伤大雅的事情。这两个配置项通常一起使用。 AOF重写执行步骤Redis执行fork()，现在同时拥有父进程和子进程。子进程开始将新AOF文件的内容写入到临时文件。对于所有新执行的写入命令，父进程一边将它们累积到一个内存缓存中，一边将这些改动追加到现有AOF文件的末尾，这样即使在重写的中途发生停机，现有的AOF文件也还是安全的。当子进程完成重写工作时，它给父进程发送一个信号，父进程在接收到信号之后，将内存缓存中的所有数据追加到新AOF文件的末尾。现在Redis原子地用新文件替换旧文件，之后所有命令都会直接追加到新AOF文件的末尾。 AOF同步你可以配置Redis多久才将数据fsync到磁盘一次。有三个选项 每次有新命令追加到AOF文件时就执行一次fsync：非常慢，也非常安全。 每秒fsync一次：足够快（和使用RDB持久化差不多），并且在故障时只会丢失1秒钟的数据。 从不fsync：将数据交给操作系统来处理。更快，也更不安全的选择。123# appendfsync alwaysappendfsync everysec# appendfsync no 推荐（并且也是默认）的措施为每秒fsync一次，这种fsync策略可以兼顾速度和安全性。总是fsync的策略在实际使用中非常慢，即使在Redis 2.0对相关的程序进行改进之后仍是如此，频繁调用fsync注定这种策略不可能快得起来。 AOF文件出错服务器可能在程序正在对AOF文件进行写入时停机，如果停机造成AOF文件出错（corrupt），那么Redis在重启时会拒绝载入这个AOF文件，从而确保数据的一致性不会被破坏。 4 应该选用哪一个一般来说，如果想达到足以媲美PostgreSQL的数据安全性，你应该同时使用两种持久化功能。如果你非常关心你的数据，但仍然可以承受数分钟以内的数据丢失，那么你可以只使用RDB持久化。有很多用户都只使用AOF持久化，但我们并不推荐这种方式。因为定时生成RDB快照（snapshot）非常便于进行数据库备份，并且RDB恢复数据集的速度也要比AOF恢复的速度要快，除此之外，使用RDB还可以避免之前提到的AOF程序的BUG。因为以上提到的种种原因，未来我们可能会将AOF和RDB整合成单个持久化模型。 5 Redis持久化磁盘IO方式及其带来的问题有Redis线上运维经验的人会发现Redis在物理内存使用比较多，但还没有超过实际物理内存总容量时就会发生不稳定甚至崩溃的问题，有人认为是基于快照方式持久化的fork系统调用造成内存占用加倍而导致的，这种观点是不准确的，因为fork调用的copy-on-write机制是基于操作系统页这个单位的，也就是只有有写入的脏页会被复制，但是一般你的系统不会在短时间内所有的页都发生写入而导致复制，那么是什么原因导致Redis崩溃的呢？答案：Redis的持久化使用Buffer IO造成的，所谓Buffer IO是指Redis对持久化文件的写入和读取操作都会使用物理内存的Page Cache，而大多数数据库系统会使用Direct IO来绕过这层Page Cache并自行维护一个数据的Cache，而当Redis的持久化文件过大（尤其是快照文件），并对其进行读写时，磁盘文件中的数据都会被加载到物理内存中作为操作系统对该文件的一层Cache，而这层Cache的数据与Redis内存中管理的数据实际是重复存储的，虽然内核在物理内存紧张时会做Page Cache的剔除工作，但内核很可能认为某块Page Cache更重要，而让你的进程开始Swap，这时你的系统就会开始出现不稳定或者崩溃。我们的经验是当你的Redis物理内存使用超过内存总容量的3/5时就会开始比较危险。","link":"/Redis-RDB-AOF/"},{"title":"Kryo","text":"1 介绍 特点 2 示例 3 实现简易Pool 结构 KryoPool KryoFactory KryoCallback SoftReferenceQueue 4 源码 项目结构 包结构 序列化 1 Kryo Kryo实例属性 Kryo#kryo() Kryo#writeClassAndObject(Output output, Object object) Kryo#writeClass(Output output, Class type) Kryo#writeReferenceOrNull(Output output, Object object, boolean mayBeNull) 2 ReferenceResolver结构 3 ClassResolver 4 Registration 5 Serializer 6 MapReferenceResolver结构 7 IdentityObjectIntMap结构 IdentityObjectIntMap#put() IdentityObjectIntMap#push() IdentityObjectIntMap#putStash() IdentityObjectIntMap#get() 8 DefaultClassResolver 9 Output结构 Output#writeVarInt (int value, boolean optimizePositive) Output#require (int required) 10 JavaSerializer 11 MapSerializer 反序列化 1 Kryo 2 Kryo#readClass (Input input) 3 Kryo#readReferenceOrNull (Input input, Class type, boolean mayBeNull) 4 Kryo#reference (Object object) 5 Kryo#copy(T object) 6 Kryo#copyShallow (T object) 1 介绍Kryo是一个快速有效的对象图序列化Java库。它的目标是快速、高效、易使用。该项目适用于对象持久化到文件或数据库中或通过网络传输。Kryo还可以自动实现深浅的拷贝/克隆。 就是直接复制一个对象对象到另一个对象，而不是对象转换为字节然后转化为对象。Kryo如果设置References=true，序列化的时候会从缓存中获取之前序列化过的对象，从而提高效率。 特点 序列化、反序列化速度快。 序列化和反序列化，第1次加载类的全部信息，如果使用代码里reference=true。默认会生成和对象相对应的id值。但第2次、第N次加载类时，会根据id值去缓存中查找相对应的对象。2 示例1234567891011121314Kryo kryo = new Kryo(); //是否使用引用,默认开启，使用引用对象会和id进行关联 kryo.setReferences(false);//注册对象，使用java的原生序列化对象kryo.register(obj.getClass(), new JavaSerializer()); // 序列化 Output output = new Output(new FileOutputStream(\"file.bin\")); SomeClass someObject = ... kryo.writeObject(output, someObject); output.close(); // 反序列化 Input input = new Input(new FileInputStream(\"file.bin\")); SomeClass someObject = kryo.readObject(input, SomeClass.class); input.close(); 3 实现简易Pool结构 KryoPool1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950public interface KryoPool { .... /** Runs the provided {@link KryoCallback} with a {@link Kryo} instance from the pool (borrow/release around * {@link KryoCallback#execute(Kryo)}). */ &lt;T&gt; T run (KryoCallback&lt;T&gt; callback); // 1 /** Builder for a {@link KryoPool} instance, constructs a {@link KryoPoolQueueImpl} instance. */ public static class Builder { private final KryoFactory factory; private Queue&lt;Kryo&gt; queue = new ConcurrentLinkedQueue&lt;Kryo&gt;(); private boolean softReferences; public Builder (KryoFactory factory) { if (factory == null) { throw new IllegalArgumentException(\"factory must not be null\"); } this.factory = factory; } /** Use the given queue for pooling kryo instances (by default a {@link ConcurrentLinkedQueue} is used). */ public Builder queue (Queue&lt;Kryo&gt; queue) { if (queue == null) { throw new IllegalArgumentException(\"queue must not be null\"); } this.queue = queue; return this; } /** Use {@link SoftReference}s for pooled {@link Kryo} instances, so that instances may be garbage collected when there's * memory demand (by default disabled). */ public Builder softReferences () { softReferences = true; return this; } /** Build the pool. */ // 2 public KryoPool build () { Queue&lt;Kryo&gt; q = softReferences ? new SoftReferenceQueue(queue) : queue; return new KryoPoolQueueImpl(factory, q); } .... }} pool内部构建类。 KryoPool#Builder#build，创建pool，如果开启softReferences(软引用)，新建一个SoftReferenceQueue(软引用队列)。否则使用ConcurrentLinkedQueue。KryoFactory123456/** Factory to create new configured instances of {@link Kryo}. * * @author Martin Grotzke */public interface KryoFactory { Kryo create ();} KryoCallback12345678/** Callback to run with a provided kryo instance. * * @author Martin Grotzke * * @param &lt;T&gt; The type of the result of the interaction with kryo. */public interface KryoCallback&lt;T&gt; { T execute (Kryo kryo);} SoftReferenceQueue1234567891011121314/** Internally uses {@link SoftReference}s for queued Kryo instances, most importantly adjusts the {@link Queue#poll() poll} * behavior so that gc'ed Kryo instances are skipped. Most other methods are unsupported. * * @author Martin Grotzke */class SoftReferenceQueue implements Queue&lt;Kryo&gt; { private Queue&lt;SoftReference&lt;Kryo&gt;&gt; delegate; public SoftReferenceQueue (Queue&lt;?&gt; delegate) { this.delegate = (Queue&lt;SoftReference&lt;Kryo&gt;&gt;)delegate; } ....} 软引用队列，实现Queue。 4 源码项目结构 ClassResolver：类级别的解释器，把class注册到缓存，根据name、class从缓存中获取注册对象（Registration）。 ReferenceResolver：引用级别的解释器，把class类中的引用注册到缓存（class类中的引用就是属性），根据referenceId从缓存中获取对象。 Serializer：序列化接口。实现类通过不同的方式实现此接口。 Registration：注册类。把class注册到缓存，下次从缓存获取对象。属性：id(Class的Id)，class，serializer实现类。包结构 factories：序列化工厂 io：封装的io类.其中重要Input,Output. pool：Kryo池,通过ConcurrentLinkedQueue实现,Pool中实现构造Pool属性的内部类. serializers：序列化种类 util：自定义实现的集合类：Map，List.实现Map,List,Default的ClassResolver序列化1 KryoKryo主类，实现Write、Read、Copy。 Kryo实例属性123456789101112131415161718192021222324252627282930313233343536373839404142434445464748//id对应的对象状态 static public final byte NULL = 0; static public final byte NOT_NULL = 1; //id对应的对象类型：引用、非引用 static private final int REF = -1; static private final int NO_REF = -2; //默认的serializer private SerializerFactory defaultSerializer = new ReflectionSerializerFactory(FieldSerializer.class); private final ArrayList&lt;DefaultSerializerEntry&gt; defaultSerializers = new ArrayList(33); private final int lowPriorityDefaultSerializerCount; //类解释器接口实例 private final ClassResolver classResolver; //下一个注册id private int nextRegisterID; private ClassLoader classLoader = getClass().getClassLoader(); private InstantiatorStrategy strategy = new DefaultInstantiatorStrategy(); //必须注册 private boolean registrationRequired; private boolean warnUnregisteredClasses; //write,read操作序数 private int depth, maxDepth = Integer.MAX_VALUE; private boolean autoReset = true; //判断是否是当前线程,代码中日志级别是warn private volatile Thread thread; //存储对象的Map private ObjectMap context, graphContext; //引用解释器接口实例 private ReferenceResolver referenceResolver; //read操作referenceId的数组 private final IntArray readReferenceIds = new IntArray(0); private boolean references, copyReferences = true; //read操作返回的对象 private Object readObject; //深度复制对象 private int copyDepth; //浅度复制对象 private boolean copyShallow; //原对象to复制 private IdentityMap originalToCopy; //需要复制的引用 private Object needsCopyReference; //泛型解释器 private GenericsResolver genericsResolver = new GenericsResolver(); private FieldSerializerConfig fieldSerializerConfig = new FieldSerializerConfig(); private TaggedFieldSerializerConfig taggedFieldSerializerConfig = new TaggedFieldSerializerConfig(); private StreamFactory streamFactory; Kryo#kryo()初始化默认Serializer、注册基本类型12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667/** @param referenceResolver May be null to disable references. */ public Kryo (ClassResolver classResolver, ReferenceResolver referenceResolver, StreamFactory streamFactory) { if (classResolver == null) throw new IllegalArgumentException(\"classResolver cannot be null.\"); this.classResolver = classResolver; classResolver.setKryo(this); this.streamFactory = streamFactory; streamFactory.setKryo(this); this.referenceResolver = referenceResolver; if (referenceResolver != null) { referenceResolver.setKryo(this); references = true; } addDefaultSerializer(byte[].class, ByteArraySerializer.class); addDefaultSerializer(char[].class, CharArraySerializer.class); addDefaultSerializer(short[].class, ShortArraySerializer.class); addDefaultSerializer(int[].class, IntArraySerializer.class); addDefaultSerializer(long[].class, LongArraySerializer.class); addDefaultSerializer(float[].class, FloatArraySerializer.class); addDefaultSerializer(double[].class, DoubleArraySerializer.class); addDefaultSerializer(boolean[].class, BooleanArraySerializer.class); addDefaultSerializer(String[].class, StringArraySerializer.class); addDefaultSerializer(Object[].class, ObjectArraySerializer.class); addDefaultSerializer(KryoSerializable.class, KryoSerializableSerializer.class); addDefaultSerializer(BigInteger.class, BigIntegerSerializer.class); addDefaultSerializer(BigDecimal.class, BigDecimalSerializer.class); addDefaultSerializer(Class.class, ClassSerializer.class); addDefaultSerializer(Date.class, DateSerializer.class); addDefaultSerializer(Enum.class, EnumSerializer.class); addDefaultSerializer(EnumSet.class, EnumSetSerializer.class); addDefaultSerializer(Currency.class, CurrencySerializer.class); addDefaultSerializer(StringBuffer.class, StringBufferSerializer.class); addDefaultSerializer(StringBuilder.class, StringBuilderSerializer.class); addDefaultSerializer(Collections.EMPTY_LIST.getClass(), CollectionsEmptyListSerializer.class); addDefaultSerializer(Collections.EMPTY_MAP.getClass(), CollectionsEmptyMapSerializer.class); addDefaultSerializer(Collections.EMPTY_SET.getClass(), CollectionsEmptySetSerializer.class); addDefaultSerializer(Collections.singletonList(null).getClass(), CollectionsSingletonListSerializer.class); addDefaultSerializer(Collections.singletonMap(null, null).getClass(), CollectionsSingletonMapSerializer.class); addDefaultSerializer(Collections.singleton(null).getClass(), CollectionsSingletonSetSerializer.class); addDefaultSerializer(TreeSet.class, TreeSetSerializer.class); addDefaultSerializer(Collection.class, CollectionSerializer.class); addDefaultSerializer(TreeMap.class, TreeMapSerializer.class); addDefaultSerializer(Map.class, MapSerializer.class); addDefaultSerializer(TimeZone.class, TimeZoneSerializer.class); addDefaultSerializer(Calendar.class, CalendarSerializer.class); addDefaultSerializer(Locale.class, LocaleSerializer.class); addDefaultSerializer(Charset.class, CharsetSerializer.class); addDefaultSerializer(URL.class, URLSerializer.class); OptionalSerializers.addDefaultSerializers(this); TimeSerializers.addDefaultSerializers(this); lowPriorityDefaultSerializerCount = defaultSerializers.size(); // Primitives and string. Primitive wrappers automatically use the same registration as primitives. register(int.class, new IntSerializer()); register(String.class, new StringSerializer()); register(float.class, new FloatSerializer()); register(boolean.class, new BooleanSerializer()); register(byte.class, new ByteSerializer()); register(char.class, new CharSerializer()); register(short.class, new ShortSerializer()); register(long.class, new LongSerializer()); register(double.class, new DoubleSerializer()); register(void.class, new VoidSerializer()); } Kryo#writeClassAndObject(Output output, Object object)序列化对象1234567891011121314151617181920212223242526272829/** Writes the class and object or null using the registered serializer. * @param object May be null. */ public void writeClassAndObject (Output output, Object object) { if (output == null) throw new IllegalArgumentException(\"output cannot be null.\"); beginObject(); try { if (object == null) { writeClass(output, null); return; } //返回注册对象 Registration registration = writeClass(output, object.getClass()); //使用references方式序列化,writeReferenceOrNull 从缓存中获取,则执行下列代码,也就是不执行write操作.因为数据已经序列化到缓存了. //非第1次或者null,数据已经存在缓存中,不需要执行其他逻辑 //true：缓存中存在数据 //false：缓存中不存在数据 if (references &amp;&amp; writeReferenceOrNull(output, object, false)) { //设置泛型 registration.getSerializer().setGenerics(this, null); return; } if (TRACE || (DEBUG &amp;&amp; depth == 1)) log(\"Write\", object); //注册对象获取serializer的write方式进行序列化,相当于实时执行序列化 //基本数据类型的引用是实时write registration.getSerializer().write(this, output, object); } finally { if (--depth == 0 &amp;&amp; autoReset) reset(); } } 执行BeginObject()，depth++、判断当前是否是多线程。 object == null，执行 writeClass(output, null)，返回注册对象（Registration） writeReferenceOrNull()，引用类型第1次、基本类型 是 return false；引用类型非第1次、null 是 return true 。如果是null和非第1次（说明数据已经存在缓存中），执行if中的操作。 registration.getSerializer().write(this, output, object)，相当于实时write()数据。基本类型也是实时write()数据。Kryo#writeClass(Output output, Class type)输出class，获得注册对象12345678910111213/** Writes a class and returns its registration. * @param type May be null. * @return Will be null if type is null. * @see ClassResolver#writeClass(Output, Class) */ public Registration writeClass (Output output, Class type) { if (output == null) throw new IllegalArgumentException(\"output cannot be null.\"); try { //class解释器实现类实例对象 return classResolver.writeClass(output, type); } finally { if (depth == 0 &amp;&amp; autoReset) reset(); } } classResolver默认是由DefaultClassResolver()实现123public Kryo () { this(new DefaultClassResolver(), new MapReferenceResolver(), new DefaultStreamFactory());} Kryo#writeReferenceOrNull(Output output, Object object, boolean mayBeNull)write reference 或者 null 对象12345678910111213141516171819202122232425262728293031323334353637/** @param object May be null if mayBeNull is true. * @return true if no bytes need to be written for the object. */ //第1次、基本类型return false；非第1次、null return true //true：缓存中存在数据 //false：缓存中不存在数据 boolean writeReferenceOrNull (Output output, Object object, boolean mayBeNull) { if (object == null) { if (TRACE || (DEBUG &amp;&amp; depth == 1)) log(\"Write\", null); //null object 在byte缓存的数据范围 output.writeVarInt(Kryo.NULL, true); return true; } //true:基本类型对象；false：引用对象 if (!referenceResolver.useReferences(object.getClass())) { //基本类型对象的not null存储范围 if (mayBeNull) output.writeVarInt(Kryo.NOT_NULL, true); return false; } // Determine if this object has already been seen in this object graph. //从缓存中获取referenceId int id = referenceResolver.getWrittenId(object); // If not the first time encountered, only write reference ID. //非第1次 if (id != -1) { if (DEBUG) debug(\"kryo\", \"Write object reference \" + id + \": \" + string(object)); output.writeVarInt(id + 2, true); // + 2 because 0 and 1 are used for NULL and NOT_NULL. return true; } //第1次,添加到缓存中 // Otherwise write NOT_NULL and then the object bytes. id = referenceResolver.addWrittenObject(object); output.writeVarInt(NOT_NULL, true); if (TRACE) trace(\"kryo\", \"Write initial object reference \" + id + \": \" + string(object)); return false; } 引用类型第1次、基本类型是 return false。 引用类型非第1次、null 是return true。 这id就是reference id。 方法返回值，true是缓存中存在数据。false是缓存中不存在数据。 2 ReferenceResolver结构引用解释器接口，根据referenceId获取reference，把reference存入缓存。 1234567891011121314151617181920212223242526272829303132333435/** When references are enabled, this tracks objects that have already been read or written, provides an ID for objects that are 1. written, and looks up by ID objects that have been read. 2. @author Nathan Sweet &lt;misc@n4te.com&gt; */public interface ReferenceResolver { /** Sets the Kryo instance that this ClassResolver will be used for. This is called automatically by Kryo. */ public void setKryo (Kryo kryo); /** Returns an ID for the object if it has been written previously, otherwise returns -1. */ public int getWrittenId (Object object); /** Returns a new ID for an object that is being written for the first time. * @return The ID, which is stored more efficiently if it is positive and must not be -1 or -2. */ public int addWrittenObject (Object object); /** Reserves the ID for the next object that will be read. This is called only the first time an object is encountered. * @param type The type of object that will be read. * @return The ID, which is stored more efficiently if it is positive and must not be -1 or -2. */ public int nextReadId (Class type); /** Sets the ID for an object that has been read. * @param id The ID from {@link #nextReadId(Class)}. */ public void setReadObject (int id, Object object); /** Returns the object for the specified ID. The ID and object are guaranteed to have been previously passed in a call to * {@link #setReadObject(int, Object)}. */ //返回对象指定ID,ID和对象是保证之前调用传入 public Object getReadObject (Class type, int id); /** Called by {@link Kryo#reset()}. */ public void reset (); /** Returns true if references will be written for the specified type. * @param type Will never be a primitive type, but may be a primitive type wrapper. */ public boolean useReferences (Class type);} referenceId和reference是对应的。 3 ClassResolver类解释器接口，类存入缓存方式（classId、nameId），从缓存中获取class方式，对象的注册，获取注册对象，输出类，读取类。 12345678910111213141516171819202122232425262728293031/** Handles class registration, writing class identifiers to bytes, and reading class identifiers from bytes. * @author Nathan Sweet &lt;misc@n4te.com&gt; */public interface ClassResolver { /** Sets the Kryo instance that this ClassResolver will be used for. This is called automatically by Kryo. */ public void setKryo (Kryo kryo); /** Stores the specified registration. * @see Kryo#register(Registration) */ public Registration register (Registration registration); /** Called when an unregistered type is encountered and {@link Kryo#setRegistrationRequired(boolean)} is false. */ public Registration registerImplicit (Class type); /** Returns the registration for the specified class, or null if the class is not registered. */ public Registration getRegistration (Class type); /** Returns the registration for the specified ID, or null if no class is registered with that ID. */ public Registration getRegistration (int classID); /** Writes a class and returns its registration. * @param type May be null. * @return Will be null if type is null. */ public Registration writeClass (Output output, Class type); /** Reads a class and returns its registration. * @return May be null. */ public Registration readClass (Input input); /** Called by {@link Kryo#reset()}. */ public void reset ();} 4 Registration注册对象类（class、reference）12345678910111213141516171819202122/** Describes the {@link Serializer} and class ID to use for a class. * @author Nathan Sweet &lt;misc@n4te.com&gt; */public class Registration { /** * 注册类 */ private final Class type; /** * 注册的id */ private final int id; /** * 序列化方式 */ private Serializer serializer; /** * 复制对象 */ private ObjectInstantiator instantiator; ...} 5 Serializer序列化抽象类1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283/** Reads and writes objects to and from bytes. * @author Nathan Sweet &lt;misc@n4te.com&gt; */public abstract class Serializer&lt;T&gt; { //允许为空、不可变 private boolean acceptsNull, immutable; public Serializer () { } /** @see #setAcceptsNull(boolean) */ public Serializer (boolean acceptsNull) { this.acceptsNull = acceptsNull; } /** @see #setAcceptsNull(boolean) * @see #setImmutable(boolean) */ public Serializer (boolean acceptsNull, boolean immutable) { this.acceptsNull = acceptsNull; this.immutable = immutable; } /** Writes the bytes for the object to the output. * &lt;p&gt; * This method should not be called directly, instead this serializer can be passed to {@link Kryo} write methods that accept a * serialier. * @param object May be null if {@link #getAcceptsNull()} is true. */ abstract public void write (Kryo kryo, Output output, T object); /** Reads bytes and returns a new object of the specified concrete type. * &lt;p&gt; * Before Kryo can be used to read child objects, {@link Kryo#reference(Object)} must be called with the parent object to * ensure it can be referenced by the child objects. Any serializer that uses {@link Kryo} to read a child object may need to * be reentrant. * &lt;p&gt; * This method should not be called directly, instead this serializer can be passed to {@link Kryo} read methods that accept a * serialier. * @return May be null if {@link #getAcceptsNull()} is true. */ abstract public T read (Kryo kryo, Input input, Class&lt;T&gt; type); public boolean getAcceptsNull () { return acceptsNull; } /** If true, this serializer will handle writing and reading null values. If false, the Kryo framework handles null values and * the serializer will never receive null. * &lt;p&gt; * This can be set to true on a serializer that does not accept nulls if it is known that the serializer will never encounter * null. Doing this will prevent the framework from writing a byte to denote null. */ public void setAcceptsNull (boolean acceptsNull) { this.acceptsNull = acceptsNull; } public boolean isImmutable () { return immutable; } /** If true, the type this serializer will be used for is considered immutable. This causes {@link #copy(Kryo, Object)} to * return the original object. */ public void setImmutable (boolean immutable) { this.immutable = immutable; } /** Sets the generic types of the field or method this serializer will be used for on the next call to read or write. * Subsequent calls to read and write must not use this generic type information. The default implementation does nothing. * Subclasses may use the information provided to this method for more efficient serialization, eg to use the same type for all * items in a list. * @param generics Some (but never all) elements may be null if there is no generic type information at that index. */ public void setGenerics (Kryo kryo, Class[] generics) { } /** Returns a copy of the specified object. The default implementation returns the original if {@link #isImmutable()} is true, * else throws {@link KryoException}. Subclasses should override this method if needed to support {@link Kryo#copy(Object)}. * &lt;p&gt; * Before Kryo can be used to copy child objects, {@link Kryo#reference(Object)} must be called with the copy to ensure it can * be referenced by the child objects. Any serializer that uses {@link Kryo} to copy a child object may need to be reentrant. * &lt;p&gt; * This method should not be called directly, instead this serializer can be passed to {@link Kryo} copy methods that accept a * serialier. */ public T copy (Kryo kryo, T original) { if (immutable) return original; throw new KryoException(\"Serializer does not support copy: \" + getClass().getName()); }} 6 MapReferenceResolver结构通过Map来存储reference1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253/** Uses an {@link IdentityObjectIntMap} to track objects that have already been written. This can handle graph with any number of 1. objects, but is slightly slower than {@link ListReferenceResolver} for graphs with few objects. 2. @author Nathan Sweet &lt;misc@n4te.com&gt; */public class MapReferenceResolver implements ReferenceResolver { protected Kryo kryo; /** * 存储id、reference的Map */ protected final IdentityObjectIntMap writtenObjects = new IdentityObjectIntMap(); /** * read根据id作为list的index，获取reference */ protected final ArrayList readObjects = new ArrayList(); public void setKryo (Kryo kryo) { this.kryo = kryo; } public int addWrittenObject (Object object) { int id = writtenObjects.size; writtenObjects.put(object, id); return id; } public int getWrittenId (Object object) { return writtenObjects.get(object, -1); } public int nextReadId (Class type) { int id = readObjects.size(); readObjects.add(null); return id; } public void setReadObject (int id, Object object) { readObjects.set(id, object); } public Object getReadObject (Class type, int id) { return readObjects.get(id); } public void reset () { readObjects.clear(); writtenObjects.clear(); } /** Returns false for all primitive wrappers. */ //true：引用对象 public boolean useReferences (Class type) { return !Util.isWrapperClass(type); }} writtenObjects ，object作为key，id作为value readObjects，id作为index7 IdentityObjectIntMap结构自定义Map，存储id和reference。引用对象：模仿HashMap 12345678910111213141516171819202122232425// primes for hash functions 2, 3, and 4 // 为了hash2、hash3、hash3 private static final int PRIME2 = 0xbe1f14b1; private static final int PRIME3 = 0xb4b82e39; private static final int PRIME4 = 0xced1c241; public int size; /** * key的数组 */ K[] keyTable; /** * value的数组 */ int[] valueTable; /** * 扩容因子 */ int capacity, stashSize; private float loadFactor; private int hashShift, mask, threshold; private int stashCapacity; private int pushIterations; private boolean isBigTable; IdentityObjectIntMap#put()123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081public void put (K key, int value) { if (key == null) throw new IllegalArgumentException(\"key cannot be null.\"); // avoid getfield opcode K[] keyTable = this.keyTable; int mask = this.mask; boolean isBigTable = this.isBigTable; // Check for existing keys. // 从缓存中获取值,4个hashcode中获取值 int hashCode = System.identityHashCode(key); int index1 = hashCode &amp; mask; K key1 = keyTable[index1]; if (key == key1) { valueTable[index1] = value; return; } int index2 = hash2(hashCode); K key2 = keyTable[index2]; if (key == key2) { valueTable[index2] = value; return; } int index3 = hash3(hashCode); K key3 = keyTable[index3]; if (key == key3) { valueTable[index3] = value; return; } int index4 = -1; K key4 = null; if (isBigTable) { index4 = hash4(hashCode); key4 = keyTable[index4]; if (key == key4) { valueTable[index4] = value; return; } } // Update key in the stash. for (int i = capacity, n = i + stashSize; i &lt; n; i++) { if (keyTable[i] == key) { valueTable[i] = value; return; } } // Check for empty buckets. if (key1 == null) { keyTable[index1] = key; valueTable[index1] = value; if (size++ &gt;= threshold) resize(capacity &lt;&lt; 1); return; } if (key2 == null) { keyTable[index2] = key; valueTable[index2] = value; if (size++ &gt;= threshold) resize(capacity &lt;&lt; 1); return; } if (key3 == null) { keyTable[index3] = key; valueTable[index3] = value; if (size++ &gt;= threshold) resize(capacity &lt;&lt; 1); return; } if (isBigTable &amp;&amp; key4 == null) { keyTable[index4] = key; valueTable[index4] = value; if (size++ &gt;= threshold) resize(capacity &lt;&lt; 1); return; } push(key, value, index1, key1, index2, key2, index3, key3, index4, key4); } keyTable[index1] !=null，比较key值，相同则更新数据。 keyTable[index1] ==null，重新给key、value赋值。 以上2条都不执行，则执行push() IdentityObjectIntMap#push()12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091private void push (K insertKey, int insertValue, int index1, K key1, int index2, K key2, int index3, K key3, int index4, K key4) { // avoid getfield opcode K[] keyTable = this.keyTable; int[] valueTable = this.valueTable; int mask = this.mask; boolean isBigTable = this.isBigTable; // Push keys until an empty bucket is found. K evictedKey; int evictedValue; int i = 0, pushIterations = this.pushIterations; int n = isBigTable ? 4 : 3; do { // Replace the key and value for one of the hashes. //随机的覆盖key、value在某个hash点上 switch (ObjectMap.random.nextInt(n)) { case 0: evictedKey = key1; evictedValue = valueTable[index1]; keyTable[index1] = insertKey; valueTable[index1] = insertValue; break; case 1: evictedKey = key2; evictedValue = valueTable[index2]; keyTable[index2] = insertKey; valueTable[index2] = insertValue; break; case 2: evictedKey = key3; evictedValue = valueTable[index3]; keyTable[index3] = insertKey; valueTable[index3] = insertValue; break; default: evictedKey = key4; evictedValue = valueTable[index4]; keyTable[index4] = insertKey; valueTable[index4] = insertValue; break; } // If the evicted key hashes to an empty bucket, put it there and stop. int hashCode = System.identityHashCode(evictedKey); index1 = hashCode &amp; mask; key1 = keyTable[index1]; if (key1 == null) { keyTable[index1] = evictedKey; valueTable[index1] = evictedValue; if (size++ &gt;= threshold) resize(capacity &lt;&lt; 1); return; } index2 = hash2(hashCode); key2 = keyTable[index2]; if (key2 == null) { keyTable[index2] = evictedKey; valueTable[index2] = evictedValue; if (size++ &gt;= threshold) resize(capacity &lt;&lt; 1); return; } index3 = hash3(hashCode); key3 = keyTable[index3]; if (key3 == null) { keyTable[index3] = evictedKey; valueTable[index3] = evictedValue; if (size++ &gt;= threshold) resize(capacity &lt;&lt; 1); return; } if (isBigTable) { index4 = hash4(hashCode); key4 = keyTable[index4]; if (key4 == null) { keyTable[index4] = evictedKey; valueTable[index4] = evictedValue; if (size++ &gt;= threshold) resize(capacity &lt;&lt; 1); return; } } if (++i == pushIterations) break; insertKey = evictedKey; insertValue = evictedValue; } while (true); putStash(evictedKey, evictedValue); } 随机的覆盖key、value在某个hash点上。 keyTable[index1] == null，覆盖当前的key、value在这个hash点上，条件满足时，扩容。IdentityObjectIntMap#putStash()容器size++，put操作的key、value赋值到key[]、value[]1234567891011121314private void putStash (K key, int value) { if (stashSize == stashCapacity) { // Too many pushes occurred and the stash is full, increase the table size. resize(capacity &lt;&lt; 1); put(key, value); return; } // Store key in the stash. int index = capacity + stashSize; keyTable[index] = key; valueTable[index] = value; stashSize++; size++; } IdentityObjectIntMap#get()根据key值获取id，如果都找不到、则返回默认值1234567891011121314151617181920/** @param defaultValue Returned if the key was not associated with a value. */ public int get (K key, int defaultValue) { int hashCode = System.identityHashCode(key); int index = hashCode &amp; mask; if (key != keyTable[index]) { index = hash2(hashCode); if (key != keyTable[index]) { index = hash3(hashCode); if (key != keyTable[index]) { if (isBigTable) { index = hash4(hashCode); if (key != keyTable[index]) return getStash(key, defaultValue); } else { return getStash(key, defaultValue); } } } } return valueTable[index]; } 8 DefaultClassResolver默认类解释器实现类，类存入缓存方式（nameId，classId），从缓存中获取class方式（nameId、classId），对象的注册，获取注册对象，输出类，读取类。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230/** Resolves classes by ID or by fully qualified class name. 1. @author Nathan Sweet &lt;misc@n4te.com&gt; */public class DefaultClassResolver implements ClassResolver { static public final byte NAME = -1; protected Kryo kryo; /** * id获取注册对象 */ protected final IntMap&lt;Registration&gt; idToRegistration = new IntMap(); /** * class类型获取注册对象 */ protected final ObjectMap&lt;Class, Registration&gt; classToRegistration = new ObjectMap(); /** * class、nameId缓存 */ protected IdentityObjectIntMap&lt;Class&gt; classToNameId; /** * nameId、class缓存 */ protected IntMap&lt;Class&gt; nameIdToClass; /** * name、class的缓存 */ protected ObjectMap&lt;String, Class&gt; nameToClass; /** * name的id */ protected int nextNameId; /** * 缓存classId */ private int memoizedClassId = -1; /** * 缓存classId注册对象 */ private Registration memoizedClassIdValue; //缓存中的class private Class memoizedClass; //缓存中的class注册对象 private Registration memoizedClassValue; public void setKryo (Kryo kryo) { this.kryo = kryo; } /** * * @param registration * @return */ public Registration register (Registration registration) { if (registration == null) throw new IllegalArgumentException(\"registration cannot be null.\"); //非原始name值 if (registration.getId() != NAME) { if (TRACE) { trace(\"kryo\", \"Register class ID \" + registration.getId() + \": \" + className(registration.getType()) + \" (\" + registration.getSerializer().getClass().getName() + \")\"); } //根据id存入注册对象 idToRegistration.put(registration.getId(), registration); } else if (TRACE) { trace(\"kryo\", \"Register class name: \" + className(registration.getType()) + \" (\" + registration.getSerializer().getClass().getName() + \")\"); } //根据class存入注册对象 classToRegistration.put(registration.getType(), registration); if (registration.getType().isPrimitive()) classToRegistration.put(getWrapperClass(registration.getType()), registration); return registration; } public Registration registerImplicit (Class type) { return register(new Registration(type, kryo.getDefaultSerializer(type), NAME)); } public Registration getRegistration (Class type) { //直接获取缓存注册对象 if (type == memoizedClass) return memoizedClassValue; //全局状态下，直接获取注册对象 Registration registration = classToRegistration.get(type); if (registration != null) { memoizedClass = type; memoizedClassValue = registration; } return registration; } public Registration getRegistration (int classID) { return idToRegistration.get(classID); } /** * 根据class write操作 * @param output * @param type May be null. * @return */ public Registration writeClass (Output output, Class type) { if (type == null) { if (TRACE || (DEBUG &amp;&amp; kryo.getDepth() == 1)) log(\"Write\", null); //null对象的缓存byte存储的位置 output.writeVarInt(Kryo.NULL, true); return null; } //获取注册对象 Registration registration = kryo.getRegistration(type); //第1次write if (registration.getId() == NAME) //没有classId，根据name获取注册对象 writeName(output, type, registration); else {//非第1次，写入classId if (TRACE) trace(\"kryo\", \"Write class \" + registration.getId() + \": \" + className(type)); output.writeVarInt(registration.getId() + 2, true); } return registration; } /** * 根据name write操作 * @param output * @param type * @param registration */ protected void writeName (Output output, Class type, Registration registration) { output.writeVarInt(NAME + 2, true); //有缓存 if (classToNameId != null) { //根据class获取nameId int nameId = classToNameId.get(type, -1); if (nameId != -1) { if (TRACE) trace(\"kryo\", \"Write class name reference \" + nameId + \": \" + className(type)); output.writeVarInt(nameId, true); return; } } // Only write the class name the first time encountered in object graph. if (TRACE) trace(\"kryo\", \"Write class name: \" + className(type)); //new nameId int nameId = nextNameId++; if (classToNameId == null) classToNameId = new IdentityObjectIntMap(); //class、nameId存入缓存 classToNameId.put(type, nameId); output.writeVarInt(nameId, true); output.writeString(type.getName()); } /** * 读取class * @param input * @return */ public Registration readClass (Input input) { //获取class的id标识 int classID = input.readVarInt(true); switch (classID) { case Kryo.NULL: if (TRACE || (DEBUG &amp;&amp; kryo.getDepth() == 1)) log(\"Read\", null); return null; case NAME + 2: // Offset for NAME and NULL. //classId实际上就是nameId，根据nameId获取对象 return readName(input); } if (classID == memoizedClassId) return memoizedClassIdValue; //class的注册对象 Registration registration = idToRegistration.get(classID - 2); if (registration == null) throw new KryoException(\"Encountered unregistered class ID: \" + (classID - 2)); if (TRACE) trace(\"kryo\", \"Read class \" + (classID - 2) + \": \" + className(registration.getType())); //新的classId、注册对象赋值到缓存变量 memoizedClassId = classID; memoizedClassIdValue = registration; return registration; } /** * 读取class name * @param input * @return */ protected Registration readName (Input input) { int nameId = input.readVarInt(true); //缓存 if (nameIdToClass == null) nameIdToClass = new IntMap(); //根据nameId获取class Class type = nameIdToClass.get(nameId); if (type == null) { // Only read the class name the first time encountered in object graph. String className = input.readString(); type = getTypeByName(className); //class is null,通过反射获取class if (type == null) { try { type = Class.forName(className, false, kryo.getClassLoader()); } catch (ClassNotFoundException ex) { if (WARN) warn(\"kryo\", \"Unable to load class \" + className + \" with kryo's ClassLoader. Retrying with current..\"); try { type = Class.forName(className); } catch (ClassNotFoundException e) { throw new KryoException(\"Unable to find class: \" + className, ex); } } if (nameToClass == null) nameToClass = new ObjectMap(); //根据class存入缓存 nameToClass.put(className, type); } //根据nameId存入缓存中 nameIdToClass.put(nameId, type); if (TRACE) trace(\"kryo\", \"Read class name: \" + className); } else { if (TRACE) trace(\"kryo\", \"Read class name reference \" + nameId + \": \" + className(type)); } return kryo.getRegistration(type); } protected Class&lt;?&gt; getTypeByName (final String className) { return nameToClass != null ? nameToClass.get(className) : null; } public void reset () { if (!kryo.isRegistrationRequired()) { if (classToNameId != null) classToNameId.clear(); if (nameIdToClass != null) nameIdToClass.clear(); nextNameId = 0; } }} writeClass 最终可能还是执行writeName。 readClass 最终执行readName。9 Output结构继承Java的OutputStream，把对象存储byte[]，这byte[]作为缓存使用 1public class Output extends OutputStream Output#writeVarInt (int value, boolean optimizePositive)写入int到byte[]，返回int占byte[]的长度123456789101112131415161718192021222324252627282930313233343536373839404142/** Writes a 1-5 byte int. It is guaranteed that a varible length encoding will be used. * * @param optimizePositive If true, small positive numbers will be more efficient (1 byte) and small negative numbers will be * inefficient (5 bytes). */ public int writeVarInt (int value, boolean optimizePositive) throws KryoException { if (!optimizePositive) value = (value &lt;&lt; 1) ^ (value &gt;&gt; 31); if (value &gt;&gt;&gt; 7 == 0) { require(1); buffer[position++] = (byte)value; return 1; } if (value &gt;&gt;&gt; 14 == 0) { require(2); buffer[position++] = (byte)((value &amp; 0x7F) | 0x80); buffer[position++] = (byte)(value &gt;&gt;&gt; 7); return 2; } if (value &gt;&gt;&gt; 21 == 0) { require(3); buffer[position++] = (byte)((value &amp; 0x7F) | 0x80); buffer[position++] = (byte)(value &gt;&gt;&gt; 7 | 0x80); buffer[position++] = (byte)(value &gt;&gt;&gt; 14); return 3; } if (value &gt;&gt;&gt; 28 == 0) { require(4); buffer[position++] = (byte)((value &amp; 0x7F) | 0x80); buffer[position++] = (byte)(value &gt;&gt;&gt; 7 | 0x80); buffer[position++] = (byte)(value &gt;&gt;&gt; 14 | 0x80); buffer[position++] = (byte)(value &gt;&gt;&gt; 21); return 4; } //需要5个字节的空间 require(5); buffer[position++] = (byte)((value &amp; 0x7F) | 0x80); buffer[position++] = (byte)(value &gt;&gt;&gt; 7 | 0x80); buffer[position++] = (byte)(value &gt;&gt;&gt; 14 | 0x80); buffer[position++] = (byte)(value &gt;&gt;&gt; 21 | 0x80); buffer[position++] = (byte)(value &gt;&gt;&gt; 28); //返回byte[]的长度 return 5; } Output#require (int required)byte[]的扩容1234567891011121314151617181920/** @return true if the buffer has been resized. */ //重置数组的长度 protected boolean require (int required) throws KryoException { if (capacity - position &gt;= required) return false; if (required &gt; maxCapacity) throw new KryoException(\"Buffer overflow. Max capacity: \" + maxCapacity + \", required: \" + required); flush(); while (capacity - position &lt; required) { if (capacity == maxCapacity) throw new KryoException(\"Buffer overflow. Available: \" + (capacity - position) + \", required: \" + required); // Grow buffer. if (capacity == 0) capacity = 1; capacity = Math.min(capacity * 2, maxCapacity); if (capacity &lt; 0) capacity = maxCapacity; byte[] newBuffer = new byte[capacity]; System.arraycopy(buffer, 0, newBuffer, 0, position); buffer = newBuffer; } return true; } 10 JavaSerializerJava自带的序列化方式。官方提示：此方法不高效，应该尽量避免使用。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061/** Serializes objects using Java's built in serialization mechanism. Note that this is very inefficient and should be avoided if * possible. * @see Serializer * @see FieldSerializer * @see KryoSerializable * @author Nathan Sweet &lt;misc@n4te.com&gt; */public class JavaSerializer extends Serializer { public void write (Kryo kryo, Output output, Object object) { try { ObjectMap graphContext = kryo.getGraphContext(); ObjectOutputStream objectStream = (ObjectOutputStream)graphContext.get(this); if (objectStream == null) { objectStream = new ObjectOutputStream(output); graphContext.put(this, objectStream); } objectStream.writeObject(object); objectStream.flush(); } catch (Exception ex) { throw new KryoException(\"Error during Java serialization.\", ex); } } public Object read (Kryo kryo, Input input, Class type) { try { ObjectMap graphContext = kryo.getGraphContext(); ObjectInputStream objectStream = (ObjectInputStream)graphContext.get(this); if (objectStream == null) { objectStream = new ObjectInputStreamWithKryoClassLoader(input, kryo); graphContext.put(this, objectStream); } return objectStream.readObject(); } catch (Exception ex) { throw new KryoException(\"Error during Java deserialization.\", ex); } } /** * ${@link ObjectInputStream} uses the last user-defined ${@link ClassLoader} which may not be the correct one. * This is a known Java issue and is often solved by using a specific class loader. * See: * https://github.com/apache/spark/blob/v1.6.3/streaming/src/main/scala/org/apache/spark/streaming/Checkpoint.scala#L154 * https://issues.apache.org/jira/browse/GROOVY-1627 */ private static class ObjectInputStreamWithKryoClassLoader extends ObjectInputStream { private final ClassLoader loader; ObjectInputStreamWithKryoClassLoader(InputStream in, Kryo kryo) throws IOException { super(in); this.loader = kryo.getClassLoader(); } @Override protected Class&lt;?&gt; resolveClass(ObjectStreamClass desc) { try { return Class.forName(desc.getName(), false, loader); } catch (ClassNotFoundException e) { throw new RuntimeException(\"Class not found: \" + desc.getName(), e); } } }} 11 MapSerializer123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171/** Serializes objects that implement the {@link Map} interface. * &lt;p&gt; * With the default constructor, a map requires a 1-3 byte header and an extra 4 bytes is written for each key/value pair. * @author Nathan Sweet &lt;misc@n4te.com&gt; */public class MapSerializer extends Serializer&lt;Map&gt; { private Class keyClass, valueClass; private Serializer keySerializer, valueSerializer; private boolean keysCanBeNull = true, valuesCanBeNull = true; private Class keyGenericType, valueGenericType; .... /** * 设置泛型 * @param kryo * @param generics Some (but never all) elements may be null if there is no generic type information at that index. */ public void setGenerics (Kryo kryo, Class[] generics) { keyGenericType = null; valueGenericType = null; if (generics != null &amp;&amp; generics.length &gt; 0) { if (generics[0] != null &amp;&amp; kryo.isFinal(generics[0])) keyGenericType = generics[0]; if (generics.length &gt; 1 &amp;&amp; generics[1] != null &amp;&amp; kryo.isFinal(generics[1])) valueGenericType = generics[1]; } } public void write (Kryo kryo, Output output, Map map) { int length = map.size(); //写入Map的长度到缓存中 output.writeInt(length, true); Serializer keySerializer = this.keySerializer; //泛型 if (keyGenericType != null) { if (keySerializer == null) keySerializer = kryo.getSerializer(keyGenericType); keyGenericType = null; } Serializer valueSerializer = this.valueSerializer; if (valueGenericType != null) { if (valueSerializer == null) valueSerializer = kryo.getSerializer(valueGenericType); valueGenericType = null; } //遍历map for (Iterator iter = map.entrySet().iterator(); iter.hasNext();) { Entry entry = (Entry)iter.next(); //写入key的序列化对象值 if (keySerializer != null) { if (keysCanBeNull) kryo.writeObjectOrNull(output, entry.getKey(), keySerializer); else kryo.writeObject(output, entry.getKey(), keySerializer); } else kryo.writeClassAndObject(output, entry.getKey()); //写入value的序列化对象值 if (valueSerializer != null) { if (valuesCanBeNull) kryo.writeObjectOrNull(output, entry.getValue(), valueSerializer); else kryo.writeObject(output, entry.getValue(), valueSerializer); } else kryo.writeClassAndObject(output, entry.getValue()); } } /** Used by {@link #read(Kryo, Input, Class)} to create the new object. This can be overridden to customize object creation, eg * to call a constructor with arguments. The default implementation uses {@link Kryo#newInstance(Class)}. */ protected Map create (Kryo kryo, Input input, Class&lt;Map&gt; type) { return kryo.newInstance(type); } public Map read (Kryo kryo, Input input, Class&lt;Map&gt; type) { Map map = create(kryo, input, type); //读取Map的长度 int length = input.readInt(true); Class keyClass = this.keyClass; Class valueClass = this.valueClass; Serializer keySerializer = this.keySerializer; if (keyGenericType != null) { keyClass = keyGenericType; if (keySerializer == null) keySerializer = kryo.getSerializer(keyClass); keyGenericType = null; } Serializer valueSerializer = this.valueSerializer; if (valueGenericType != null) { valueClass = valueGenericType; if (valueSerializer == null) valueSerializer = kryo.getSerializer(valueClass); valueGenericType = null; } kryo.reference(map); for (int i = 0; i &lt; length; i++) { Object key; if (keySerializer != null) { if (keysCanBeNull) key = kryo.readObjectOrNull(input, keyClass, keySerializer); else key = kryo.readObject(input, keyClass, keySerializer); } else key = kryo.readClassAndObject(input); Object value; if (valueSerializer != null) { if (valuesCanBeNull) value = kryo.readObjectOrNull(input, valueClass, valueSerializer); else value = kryo.readObject(input, valueClass, valueSerializer); } else value = kryo.readClassAndObject(input); map.put(key, value); } return map; } protected Map createCopy (Kryo kryo, Map original) { return kryo.newInstance(original.getClass()); } public Map copy (Kryo kryo, Map original) { Map copy = createCopy(kryo, original); for (Iterator iter = original.entrySet().iterator(); iter.hasNext();) { Entry entry = (Entry)iter.next(); copy.put(kryo.copy(entry.getKey()), kryo.copy(entry.getValue())); } return copy; } /** Used to annotate fields that are maps with specific Kryo serializers for their keys or values. */ @Retention(RetentionPolicy.RUNTIME) @Target(ElementType.FIELD) public @interface BindMap { /** Serializer to be used for keys * * @return the class&lt;? extends serializer&gt; used for keys serialization */ @SuppressWarnings(\"rawtypes\") Class&lt;? extends Serializer&gt; keySerializer() default Serializer.class; /** Serializer to be used for values * * @return the class&lt;? extends serializer&gt; used for values serialization */ @SuppressWarnings(\"rawtypes\") Class&lt;? extends Serializer&gt; valueSerializer() default Serializer.class; /** Class used for keys * * @return the class used for keys */ Class&lt;?&gt; keyClass() default Object.class; /** Class used for values * * @return the class used for values */ Class&lt;?&gt; valueClass() default Object.class; /** Indicates if keys can be null * * @return true, if keys can be null */ boolean keysCanBeNull() default true; /** Indicates if values can be null * * @return true, if values can be null */ boolean valuesCanBeNull() default true; }} 反序列化1 KryoKryo#readClassAndObject (Input input)通过input（输入流）读取对象1234567891011121314151617181920212223242526272829303132/** Reads the class and object or null using the registered serializer. * @return May be null. */ public Object readClassAndObject (Input input) { if (input == null) throw new IllegalArgumentException(\"input cannot be null.\"); beginObject(); try { //先读取class的注册对象 Registration registration = readClass(input); if (registration == null) return null; Class type = registration.getType(); Object object; //有引用 if (references) { //设置泛型 registration.getSerializer().setGenerics(this, null); //返回对象id int stackSize = readReferenceOrNull(input, type, false); //基本类型和第1次读取对象，返回readReferenceIds.size() if (stackSize == REF) return readObject; //直接Serializer实现类中获取readObject object = registration.getSerializer().read(this, input, type); //id=id数组的长度,存储到缓存中 if (stackSize == readReferenceIds.size) reference(object); } else//从实现的Serializer中读取对象 object = registration.getSerializer().read(this, input, type); if (TRACE || (DEBUG &amp;&amp; depth == 1)) log(\"Read\", object); return object; } finally { if (--depth == 0 &amp;&amp; autoReset) reset(); } } readClass，根据nameId获取class。 有引用，返回对象id。如果id是REF值。返回object，object值是not null和null。 无引用，从Serializer实现类中执行read（）。2 Kryo#readClass (Input input)这里是由DefaultClassResolver实现的readClass（） 1234567891011/** Reads a class and returns its registration. * @return May be null. * @see ClassResolver#readClass(Input) */ public Registration readClass (Input input) { if (input == null) throw new IllegalArgumentException(\"input cannot be null.\"); try { return classResolver.readClass(input); } finally { if (depth == 0 &amp;&amp; autoReset) reset(); } } 3 Kryo#readReferenceOrNull (Input input, Class type, boolean mayBeNull)读取对象。根据基本类型与Ref的null和not null获取object123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354/** Returns {@link #REF} if a reference to a previously read object was read, which is stored in {@link #readObject}. Returns a * stack size (&gt; 0) if a reference ID has been put on the stack. */ //读取readobject或者是null int readReferenceOrNull (Input input, Class type, boolean mayBeNull) { //基本数据类型 if (type.isPrimitive()) type = getWrapperClass(type); //是否支持引用类型 boolean referencesSupported = referenceResolver.useReferences(type); int id; //允许null if (mayBeNull) { //获取当前对象的id id = input.readVarInt(true); //当前id对应的对象值是null if (id == Kryo.NULL) { if (TRACE || (DEBUG &amp;&amp; depth == 1)) log(\"Read\", null); readObject = null; //返回对象引用 return REF; } //对象!=null，基本数据类型，添加到id数组中 if (!referencesSupported) { readReferenceIds.add(NO_REF); return readReferenceIds.size; } } else {//not null //基本类型 if (!referencesSupported) { //添加基本类型的id readReferenceIds.add(NO_REF); return readReferenceIds.size; } //引用读取byte[]缓存，返回id值 id = input.readVarInt(true); } //id对应的引用对象!=null，第1次读取，存入read的id数组 if (id == NOT_NULL) { // First time object has been encountered. //id递增 //这里的id是read的reference数组的id id = referenceResolver.nextReadId(type); if (TRACE) trace(\"kryo\", \"Read initial object reference \" + id + \": \" + className(type)); //添加到read的reference数组中 readReferenceIds.add(id); //id值就是readReferenceIds.size return readReferenceIds.size; } // The id is an object reference.id == NULL id -= 2; // - 2 because 0 and 1 are used for NULL and NOT_NULL. //默认从MapReferenceResolver中获取object readObject = referenceResolver.getReadObject(type, id); if (DEBUG) debug(\"kryo\", \"Read object reference \" + id + \": \" + string(readObject)); return REF; } mayBeNull == true，如果object是null，则直接返回REF；如果是基本类型对象，readReferenceIds添加Not_Ref，返回readReferenceIds.size()。 mayBeNull == false，获取id，id == NOT_NULL ，说明是第1次读取，readReferenceIds添加id。返回id，这id=readReferenceIds.size()。 mayBeNull == false，id is Null，存在MapReferenceResolver中，直接获取Object，返回Ref。 基本类型和第1次读取对象，返回readReferenceIds.size()。 4 Kryo#reference (Object object)重置缓存 12345678910111213141516171819202122/** Called by {@link Serializer#read(Kryo, Input, Class)} and {@link Serializer#copy(Kryo, Object)} before Kryo can be used to * deserialize or copy child objects. Calling this method is unnecessary if Kryo is not used to deserialize or copy child * objects. * @param object May be null, unless calling this method from {@link Serializer#copy(Kryo, Object)}. */ //重置引用对象 public void reference (Object object) { //复制深度 if (copyDepth &gt; 0) { //需要复制的引用 if (needsCopyReference != null) { if (object == null) throw new IllegalArgumentException(\"object cannot be null.\"); //原数据 TO 复制 originalToCopy.put(needsCopyReference, object); needsCopyReference = null; } } else if (references &amp;&amp; object != null) { //获取对象对应的id int id = readReferenceIds.pop(); //id==Ref,把id重新存储到MapReferenceResolver中 if (id != NO_REF) referenceResolver.setReadObject(id, object); } } 第1次读取时，MapReferenceResolver存入object对象。 originalToCopy存入Object。5 Kryo#copy(T object)深度复制对象1234567891011121314151617181920212223242526272829/** Returns a deep copy of the object. Serializers for the classes involved must support {@link Serializer#copy(Kryo, Object)}. * @param object May be null. */ //深度复制 public &lt;T&gt; T copy (T object) { if (object == null) return null; //浅度复制对象 if (copyShallow) return object; //深度复制对象序号 copyDepth++; try { if (originalToCopy == null) originalToCopy = new IdentityMap(); //获取深度复制对象 Object existingCopy = originalToCopy.get(object); if (existingCopy != null) return (T)existingCopy; //existingcopy==null if (copyReferences) needsCopyReference = object; Object copy; if (object instanceof KryoCopyable) copy = ((KryoCopyable)object).copy(this); else //默认是直接返回Object copy = getSerializer(object.getClass()).copy(this, object); if (needsCopyReference != null) reference(copy); if (TRACE || (DEBUG &amp;&amp; copyDepth == 1)) log(\"Copy\", copy); return (T)copy; } finally { if (--copyDepth == 0) reset(); } } 6 Kryo#copyShallow (T object)浅度复制123456789101112131415161718192021222324252627/** Returns a shallow copy of the object. Serializers for the classes involved must support * {@link Serializer#copy(Kryo, Object)}. * @param object May be null. */ //浅度复制 public &lt;T&gt; T copyShallow (T object) { if (object == null) return null; copyDepth++; copyShallow = true; try { if (originalToCopy == null) originalToCopy = new IdentityMap(); Object existingCopy = originalToCopy.get(object); if (existingCopy != null) return (T)existingCopy; if (copyReferences) needsCopyReference = object; Object copy; if (object instanceof KryoCopyable) copy = ((KryoCopyable)object).copy(this); else copy = getSerializer(object.getClass()).copy(this, object); if (needsCopyReference != null) reference(copy); if (TRACE || (DEBUG &amp;&amp; copyDepth == 1)) log(\"Shallow copy\", copy); return (T)copy; } finally { copyShallow = false; if (--copyDepth == 0) reset(); } }","link":"/kryo/"},{"title":"清理Spring内省对象","text":"1 问题 2 解决方式 Spring中的描述 1 问题在服务器运行过程中，Spring不停的运行计划任务和OpenSessionInViewFilter，使得Tomcat反复加载对象而产生框架并用时可能产生的内存泄漏，则使用IntrospectorCleanupListener作为相应的解决办法。 2 解决方式Spring中的提供一个名为org.springframework.web.util.IntrospectorCleanupListener的监听器。它主要负责处理由JavaBeans Introspector（内省对象）的使用而引起的内存泄露。 Spring中的描述它是一个在web应用关闭的时候，清除JavaBeans Introspector的监听器。web.xml中注册这个listener。可以保证在web应用关闭的时候释放与掉这个web应用相关的class loader和由它管理的类。如果使用JavaBeans Introspector来分析应用中的类，Introspector中会保留这些类的引用。结果在应用关闭的时候，这些类以及web应用相关的class loader没有被垃圾回收。不幸的是，清除Introspector的唯一方式是刷新整个缓存。这是因为没法判断哪些是属于应用的引用。所以删除被缓存的introspection会导致把这台电脑上的所有应用的introspection都删掉。需要注意的是，Spring托管的bean不需要使用这个监听器。因为Spring它自己的introspection所使用的缓存在分析完一个类之后会被马上从Java Beans Introspector缓存中清除掉。应用程序中的类从来不直接使用Java Beans Introspector。所以一般不会导致内部查看资源泄露。但是一些类库和框架往往会产生这个问题。例如Struts和Quartz，单个的内部查看泄漏会导致整个的web应用的类加载器不能进行垃圾回收。在web应用关闭之后，会看到此应用的所有静态类资源。这个错误当然不是由这个类自身引起的。用法很简单，就是在web.xml中加入:123&lt;listener&gt; &lt;listener-class&gt;org.springframework.web.util.IntrospectorCleanupListener&lt;/listener-class&gt;&lt;/listener&gt; Servlet标准不允许在web容器内自行做线程管理，Quartz的问题确实存在。对于web容器来说，最忌讳应用程序私自启动线程，自行进行线程调度，像Quartz这种在web容器内部默认就自己启动10线程进行异步job调度的框架本身就是很危险的事情，很容易造成Servlet线程资源回收不掉。","link":"/Spring-Introspection/"},{"title":"Spring四种注入方式(IOC)","text":"1 Set方式 2 构造函数方式 3 静态工厂方式 4 实例化工厂方式 1 Set方式12345678910111213public class SpringAction1 { // 注入对象springDao private SpringDao springDao; // 一定要写被注入对象的set方法 public void setSpringDao(SpringDao springDao) { this.springDao = springDao; } public void ok() { springDao.ok(); }} 1234567package test.spring1;public class SpringDao { public void ok() { System.out.println(\"Spring dao\"); }} 12345&lt;bean name=\"springAction\" class=\"test.spring1.SpringAction1\"&gt; &lt;!-- 依赖注入,配置当前类中相应的属性 --&gt; &lt;property name=\"springDao\" ref=\"springDao\"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;bean name=\"springDao\" class=\"test.spring1.SpringDao\"&gt;&lt;/bean&gt; 12SpringAction1 springAction1 = (SpringAction1) ContextUtil.getBean(\"springAction\", SpringAction1.class);springAction1.ok(); 2 构造函数方式12345678910111213141516public class SpringAction2 { // 注入对象springDao private SpringDao2 springDao; private User user; public SpringAction2(SpringDao2 springDao, User user) { this.springDao = springDao; this.user = user; System.out.println(\"构造方法调用springDao和user\"); } public void save() { user.setName(\"卡卡\"); springDao.save(user); }} 123456789public class SpringDao2 { public void ok() { System.out.println(\"Spring dao is 2\"); } public void save(User user) { System.out.println(\"Spring dao is 2 !! save user\"); }} 1234567891011121314package test.spring2;public class User { private String name; public String getName() { return name; } public void setName(String name) { this.name = name; } } 1234567&lt;bean name=\"springAction2\" class=\"test.spring2.SpringAction2\"&gt; &lt;!-- 创建构造器注入,如果主类有带参的构造方法则需添加此配置 --&gt; &lt;constructor-arg index=\"0\" ref=\"springDao\"&gt;&lt;/constructor-arg&gt; &lt;constructor-arg index=\"1\" ref=\"user\"&gt;&lt;/constructor-arg&gt; &lt;/bean&gt; &lt;bean name=\"springDao\" class=\"test.spring2.SpringDao2\"&gt;&lt;/bean&gt; &lt;bean name=\"user\" class=\"test.spring2.User\"&gt;&lt;/bean&gt; 12SpringAction2 springAction2 = (SpringAction2) ContextUtil.getBean(\"springAction2\", SpringAction2.class);springAction2.save(); 3 静态工厂方式 12345678910111213 public class SpringAction3 { // 注入对象 private FactoryDao staticFactoryDao; // 注入对象的set方法 public void setStaticFactoryDao(FactoryDao staticFactoryDao) { this.staticFactoryDao = staticFactoryDao; } public void staticFactoryOk() { staticFactoryDao.saveFactory(); }} 12345678package test.spring3;public class FactoryDao { public void saveFactory() { System.out.println(\"FactoryDao is \"); }} 123456789package test.spring3;public class DaoFactory { // 静态工厂 public static final FactoryDao getStaticFactoryDaoImpl() { System.out.println(\"进入静态工厂方法....\"); return new FactoryDao(); }} 123456 &lt;bean name=\"springAction3\" class=\"test.spring3.SpringAction3\" &gt; &lt;!-- 使用静态工厂的方法注入对象,对应下面的配置文件 --&gt; &lt;property name=\"staticFactoryDao\" ref=\"staticFactoryDao\"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;!-- 此处获取对象的方式是从工厂类中获取静态方法 --&gt;&lt;bean name=\"staticFactoryDao\" class=\"test.spring3.DaoFactory\" factory-method=\"getStaticFactoryDaoImpl\"&gt;&lt;/bean&gt; 12SpringAction3 springAction3= (SpringAction3) ContextUtil.getBean(\"springAction3\", SpringAction3.class);springAction3.staticFactoryOk(); 4 实例化工厂方式 12345678910111213141516package test.spring4;import test.spring4.FactoryDao;public class SpringAction4 { //注入对象 private FactoryDao factoryDao; public void factoryOk(){ factoryDao.saveFactory(); } public void setFactoryDao(FactoryDao factoryDao) { this.factoryDao = factoryDao; } } 12345678package test.spring4;public class FactoryDao { public void saveFactory() { System.out.println(\"实例工厂的方法注入 is \"); }} 12345678910package test.spring4;import test.spring4.FactoryDao;public class DaoFactory { //实例工厂 public FactoryDao getFactoryDaoImpl(){ return new FactoryDao(); } } 12345678 &lt;bean name=\"springAction4\" class=\"test.spring4.SpringAction4\"&gt; &lt;!-- 使用实例工厂的方法注入对象,对应下面的配置文件 --&gt; &lt;property name=\"factoryDao\" ref=\"factoryDao\"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;!-- 此处获取对象的方式是从工厂类中获取实例方法--&gt; &lt;bean name=\"daoFactory\" class=\"test.spring4.DaoFactory\"&gt;&lt;/bean&gt; &lt;bean name=\"factoryDao\" factory-bean=\"daoFactory\" factory-method=\"getFactoryDaoImpl\"&gt;&lt;/bean&gt; 12SpringAction4 springAction4= (SpringAction4) ContextUtil.getBean(\"springAction4\", SpringAction4.class);springAction4.factoryOk();","link":"/Spring-IoC/"},{"title":"临时表和内存表","text":"首先，临时表只在当前连接可见，当关闭连接时，MySQL会自动删除表并释放所有空间。因此在不同的连接中可以创建同名的临时表，并且操作属于本连接的临时表。创建临时表的语法与创建表语法类似，不同之处是增加关键字TEMPORARY。1CREATE TEMPORARY TABLE 表名 (…) 临时表限制条件临时表在memory、myisam、merge或者innodb上使用，并且不支持mysql cluster。show tables语句不会列出临时表，在information_schema中也不存在临时表信息；show create table可以查看临时表。不能使用rename来重命名临时表。但是可以alter table rename代替。1mysql&gt;ALTER TABLE orig_name RENAME new_name; 可以复制临时表得到一个新的临时表。1mysql&gt;create temporary table new_table select * from old_table; 但在同一个query语句中，相同的临时表只能出现一次。正确1mysql&gt; select * from temp_tb; 错误123mysql&gt; select * from temp_tb, temp_tb as t;ERROR 1137 (HY000): Can't reopen table: 'temp_tb' 同样相同临时表不能在存储函数中出现多次，如果在一个存储函数里，用不同的别名查找一个临时表多次，或者在这个存储函数里用不同的语句查找，都会出现这个错误。但不同的临时表可以出现在同一个query语句中，如临时表temp_tb1, temp_tb2。1Mysql&gt; select * from temp_tb1, temp_tb2; 临时表可以手动删除。1DROP TEMPORARY TABLE IF EXISTS temp_tb; 内存表临时表主要用于对大数据量的表上作一个子集，提高查询效率。在创建临时表时声明类型为HEAP，则MySQL会在内存中创建该临时表，即内存表。1CREATE TEMPORARY TABLE 表名 (....) TYPE = HEAP 因为HEAP表存储在内存中，你对它运行的查询可能比磁盘上的临时表快些。12345678910111213141516mysql&gt; create temporary table temp_tb type='heap' select * from temptb;Query OK, 0 rows affected, 1 warning (0.01 sec)Records: 0 Duplicates: 0 Warnings: 0 mysql&gt; show create table temp_tb \\G;*************************** 1. row ***************************Table: temp_tbCreate Table: CREATE TEMPORARY TABLE `temp_tb` ( `id` int(10) unsigned NOT NULL DEFAULT '0', `Name` char(20) NOT NULL, `Age` tinyint(4) NOT NULL) ENGINE=MEMORY DEFAULT CHARSET=gbk1 row in set (0.00 sec) ERROR:No query specified 可以看出来临时表和内存表的ENGINE不同，临时表默认的是MySQL指定的默认Engine，而内存表是MEMORY。官网手册 As indicated by the name, MEMORY tables are stored in memory. They use hash indexes by default, which makes them very fast, and very useful for creating temporary tables. However, when the server shuts down, all rows stored in MEMORY tables are lost. The tables themselves continue to exist because their definitions are stored in .frm files on disk, but they are empty when the server restarts. 限制条件 MEMORY tables cannot contain BLOB or TEXT columns. HEAP不支持BLOB/TEXT列。 The server needs sufficient memory to maintain all MEMORY tables that are in use at the same time. 在同一时间需要足够的内存。 To free memory used by a MEMORY table when you no longer require its contents, you should execute DELETE or TRUNCATE TABLE, or remove the table altogether using DROP TABLE. 为了释放内存，你应该执行DELETE FROM heap_table或DROP TABLE heap_table。 临时表和内存表临时表主要是为了放一些中间大结果集的一些子集，内存表可以放一些经常频繁使用的数据。 临时表表建在内存里，数据在内存里。 内存表表建在磁盘里，数据在内存里。 临时表和内存表所使用内存大小可以通过My.cnf中的max_heap_table_size、tmp_table_size指定。123[mysqld]max_heap_table_size=1024M #内存表容量tmp_table_size=1024M #临时表容量 当数据超过临时表的最大值设定时，自动转为磁盘表，此时因需要进行IO操作，性能会大大下降，而内存表不会，内存表满后，则会提示数据满错误。show tables命令不会显示临时表。 内存表和临时表区别内存表 缺省存储引擎为MEMORY。 可以通过参数max_heap_table_size来设定内存表大小。 到达max_heap_table_size设定的内存上限后将报错。 表定义保存在磁盘上，数据和索引保存在内存中。 不能包含TEXT、BLOB等字段。临时表： 缺省存储引擎为MySQL服务器默认引擎，引擎类型只能是：memory（heap）、myisam、merge、innodb（memory临时表由于表的增大可能会转变为myisam临时表） 可以通过参数tmp_table_size来设定临时表大小。 到达tmp_table_size设定的内存上限后将在磁盘上创建临时文件。 表定义和数据都保存在内存中。 可以包含TEXT, BLOB等字段。 临时表一般比较少用，通常是在应用程序中动态创建或者由MySQL内部根据SQL执行计划需要自己创建。内存表则大多作为Cache来使用，特别在没有第三方cache使用时。如今随着memcache、NoSQL的流行，越来越少选择使用内存表。MySQL服务器使用内部临时表。在某些情况下，MySQL服务器会自动创建内部临时表。查看查询语句的执行计划，如果extra列显示using temporary即使用了内部临时表。内部临时表的创建条件。 group by和order by中的列不相同。 order by的列不是引用from表列表中的第一表。 group by的列不是引用from表列表中的第一表。 使用sql_small_result选项。 含有distinct的order by语句。 初始创建内部myisam临时表的条件。 表中存在text、blob列。 在group by中的列有超过512字节。 在distinct查询中的 列 有超过512字节。 在union、union all联合查询中，select列列表中的列有超过512字节的。 什么时候使用视图应用场景1保密工作，比如有一个员工工资表，如果你只希望财务看到员工工资这个字段，而其他人不能看到工资字段，那就用一个视图，把工资这个敏感字段过滤掉 应用场景2有一个查询语句非常复杂，大概有100行这么多，有时还想把这个巨大无比的select语句和其他表关联起来得到结果，写太多很麻烦，可以用一个视图来代替这100行的select语句，充当一个变量角色 什么时候用临时表应用场景1你在短期内有很多DML操作，比如京东淘宝亚马逊的购物车表，把东西放购物车（insert），变更数量（update），删除商品(delete)，一旦结算金钱后，这些数据就要清掉，这时需要用临时表。 应用场景2在导出数据时，你可能不想导完整的数据库，或者表，你可能只想要导出符合某些条件的数据，那么你可以创建临时表，把select语句插入到临时表，接着导出这个临时表，导完以后通过结束session或者事务的方式，让这些没用的数据自动清理掉。 应用场景3你在写存储过程时，有很多的连接，比如你需要连接A,B,C,D,E,F,G,H那么多张表，才能得到你的结果表，同时做连接的消耗太大，你可以先A,B,C连接的结果，放在临时表，接着再把这张临时表，跟D,E,F连接，作为新的结果放在临时表，接着再把临时表与G,H连接，最后得到临时表数据，一次插入到结果表（永久表）。","link":"/Temporary-Menory-Table/"},{"title":"线程中未捕获异常（UncaughtExceptionHandler）","text":"Thread#run方法是不抛出任何检查型异常(Checked Exception)，但是它自身却可能因为一个异常而被终止，导致这个线程的终结。最麻烦的是，在线程中抛出的异常即使在主线程中使用try...catch也无法截获，因此可能导致一些问题出现，比如异常的时候无法回收一些系统资源，或者没有关闭当前的连接等等。主线程之所以不处理子线程抛出的RuntimeException，是因为线程是异步的，子线程没结束，主线程可能已经结束了。UncaughtExceptionHandler名字意味着处理未捕获的异常。更明确的说，它处理未捕获的运行时异常。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566/** * Package: * Description： 线程异常打印 * Author: yujie * Date: Created in 2018/5/14 18:25 * Company: * Copyright: Copyright (c) 2018 * Version: 1.0.0 * Modified By: */@Slf4jpublic class ThreadExceptionDebugger implements Thread.UncaughtExceptionHandler { ThreadPoolExecutor pool; public ThreadExceptionDebugger() { } public ThreadExceptionDebugger(ThreadPoolExecutor pool) { this.pool = pool; } @Override public void uncaughtException(final Thread t, Throwable e) { log.error(\"当前线程异常\"); if (pool != null) { log.error(\" 当前线程池状态:\"); log.error(\" active:\" + pool.getActiveCount()); log.error(\" corePool:\" + pool.getCorePoolSize()); log.error(\" poolSize:\" + pool.getPoolSize()); log.error(\" taskCount:\" + pool.getTaskCount()); log.error(\" queueCount:\" + pool.getQueue().size()); } log.error(\" 线程信息:\" + e.getMessage() ); log.error(\" 线程名字:\" + t.getName()); log.error(\" 线程ID:\" + t.getId()); log.error(\" 线程状态:\" + t.getState());// log.error(\"[Exception Message]:\" + e.getMessage());// log.error(\"[Exception][Thread Name]:\" + t.getName()// + \",[Exception][Thread id]:\" + t.getId()// + \",[Thread state]:\" + t.getState()); StackTraceElement[] elements = e.getStackTrace(); log.error(\" 异常信息:\" + e.getMessage() ); log.error(\" 异常代码块\" ); for (int i = 0; i &lt; elements.length; i++) {// log.error(\"Number[\" + i + \"],[FileName]:\" + elements[i].getFileName() +// \",[ClassName]:\" + elements[i].getClassName() +// \",[LineNumber]:\" + elements[i].getLineNumber() +// \",[MethodName]:\" + elements[i].getMethodName()); log.error(\" 序列号:\" + i ); log.error(\" 文件名:\" + elements[i].getFileName()); log.error(\" 类名:\" + elements[i].getClassName()); log.error(\" 行号:\" + elements[i].getLineNumber()); log.error(\" 方法名:\" + elements[i].getMethodName());// log.error(\"[序列号]:\" + i + \",[文件名]:\" + elements[i].getFileName() +// \",[类名]:\" + elements[i].getClassName() +// \",[行号]:\" + elements[i].getLineNumber() +// \",[方法名]:\" + elements[i].getMethodName()); }// e.printStackTrace(); }} UncaughtExceptionHandlerUncaughtExceptionHandler#setUncaughtExceptionHandler123456public interface UncaughtExceptionHandler public void setUncaughtExceptionHandler(UncaughtExceptionHandler eh) { checkAccess(); uncaughtExceptionHandler = eh; }","link":"/Thread-UncaughtExceptionHandler/"},{"title":"时间,空间复杂度","text":"1 概念 时间复杂度 空间复杂度 2 示例 时间复杂度 $n^3$ O(n)： O(1)： O($log_{2}n$)： O($n^2$) O($nlog_{2}n$) 时间复杂度 O(1) 1 概念时间复杂度是度量算法执行的时间长短，时间复杂度是指他运行时计算的次数。一般情况下，算法的基本操作重复执行的次数是模块n的某一个函数f(n)，因此，算法的时间复杂度记做：T(n)=O(f(n))随着模块n的增大，算法执行的时间的增长率和f(n)的增长率成正比，所以f(n)越小，算法的时间复杂度越低，算法的效率越高。在计算时间复杂度的时候，先找出算法的基本操作，然后根据相应的各语句确定它的执行次数，再找出T(n)的同数量级（它的同数量级有以下：1，$log_{2}n$，n，$nlog_{2}n$，n的平方，n的三次方，2的n次方），找出后，f(n) = 该数量级，若T(n)/f(n)求极限可得到一常数c，则时间复杂度T(n) = O(f(n)。按数量级递增排列，常见的时间复杂度有：常数阶O(1)，对数阶O(log2n)，线性阶O(n)，线性对数阶O(nlog2n)，平方阶O($n^2$)，立方阶O($n^3$),…，k次方阶O($n^k$)，指数阶O($2^n$)。随着问题规模n的不断增大，上述时间复杂度不断增大，算法的执行效率越低。 空间复杂度是度量算法所需存储空间的大小，空间复杂度是指运行完一个程序所需内存的大小。在算法中所谓的空间复杂度为O(1)并不是说只使用一个空间，而是说在待处理的数据量变化的情况下使用的空间量是不变的。空间复杂度一般算的是辅助空间的大小，如果这个辅助空间的大小不随元素N变化那么就是O(1)。例如：冒泡排序，需要的辅助空间是一个作交换用的临时变量，而且无论任何情况下都只要这一个，所以空间复杂度就是O(1)。但桶排序就不同了，本身需要M个桶，桶的数量是人为决定的，然后需要N个结点，去装原本的N个元素，所以空间复杂度就是O(M+N)。一个程序的空间复杂度是指运行完一个程序所需内存的大小。利用程序的空间复杂度，可以对程序的运行所需要的内存多少有个预先估计。一个程序执行时除了需要存储空间和存储本身所使用的指令、常数、变量和输入数据外，还需要一些对数据进行操作的工作单元和存储一些为现实计算所需信息的辅助空间。程序执行时所需存储空间包括以下两部分。固定部分。这部分空间的大小与输入/输出的数据的个数多少、数值无关。主要包括指令空间（即代码空间）、数据空间（常量、简单变量）等所占的空间。这部分属于静态空间。可变空间，这部分空间的主要包括动态分配的空间，以及递归栈所需的空间等。这部分的空间大小与算法有关。一个算法所需的存储空间用f(n)表示：S(n)=O(f(n))，其中n为问题的规模，S(n)表示空间复杂度。 2 示例时间复杂度$n^3$123456789for(i=1; i&lt;=n; ++i){ for(j=1; j&lt;=n; ++j) { c[i][j] = 0;//该步骤属于基本操作执行次数：n的平方次 for(k=1; k&lt;=n; ++k) c[i][j] += a[i][k] * b[k][j];//该步骤属于基本操作执行次数：n的三次方次 }} 则有T(n) = n的平方+n的三次方，根据上面括号里的同数量级，我们可以确定n的三次方为T(n)的同数量级，则有f(n) = n的三次方，然后根据T(n)/f(n)求极限可得到常数c，则该算法的时间复杂度：T(n) = O($n^3$) 。注：$n^3$即是n的3次方。 O(n)：1234int x = 1;//时间复杂度为O(1) for(int i=0; i&lt;n; i++) { System.out.println(i); }//时间复杂度为O(n) O(1)：1int x = 1; O($log_{2}n$)：1234int n = 8, count = 0;; for(int i=1; i&lt;=n; i *= 2) { count++; } O($n^2$)123456int n = 8, count = 0;; for(int i=1; i&lt;=n; i++) { for(int j=1; j&lt;=n; j++) { count++; } } O($nlog_{2}n$)123456int n = 8, count = 0;; for(int i=1; i&lt;=n; i *= 2) { for(int j=1; j&lt;=n; j++) { count++; } } 时间复杂度O(1)一个临时变量temp，所以空间复杂度为O(1)1234int x=1, y=2; int temp = x; x = y; y = temp;","link":"/Time-Space-Complexity/"},{"title":"sum_i^n","text":"1 用法 2 例子 2.1 2.2 2.3 2.4 2.5 2.6 2.7 1 用法$\\sum_i^n{k}$i表示下界，n表示上界， k从i开始取数，一直取到n，全部加起来。$\\sum{i}$这样表达也可以，表示对i求和，i是变数。 2 例子2.1$\\sum_{i=1}^\\infty{k}$ = 1+2+3+4+5+......+100 2.2$\\sum_{i=5}^{200}{i}$ = 5+6+7+8+9+......+200 2.3$\\sum_{i=10}^{500}i$ = 10+11+12+13+14+......+500 2.4$\\sum_{i=1}^{444}{Xi}$ = X+ 2X+ 3X+ 4X+......+ 444X 2.5$\\sum_{i=1}^{50}i$ = 1 + 2 + 3 + 4 +......+ 50 = 1275 2.6$\\sum_{i=1}^{70}X$ = X + X + X + X +......+ X = 70X 2.7$\\sum_{n=1}{An}$ = A1+A2+...+An$\\sum_{k=1}^n{k^2}$$\\sum$是数列求和的简记号，它后面的k^2是通项公式，下面的k=1是初始项开始的项数，顶上的n是末项的项数。 $\\sum_{k=1}^n{k^2}$ = $1^2+2^2+……+n^2$ $\\sum_{k=1}^n{(2k+1)}$ = 3+5+……+(2n+1) (1)+(2) = $\\sum_{k=1}^n{(k+1)}^2$ = $2^2+3^2+……+(n+1)^2$","link":"/sum/"},{"title":"(转载)Spring Bean生命周期，实例化顺序","text":"1 简介 实例化 销毁 2 程序 2.1 A类 B类 Spring配置 控制台 2.2 xml配置方式 Spring XML配置 控制台 注解方式 Spring XML 3 XML中指定Init-method，@PostConstruct注解方法哪个先执行 1 简介Spring中Bean容器的生命周期。首先明确一点，并非Spring容器中所有的Bean都有生命周期行为，只有接受容器管理生命周期的Bean才具有生命周期行为；而单例（Singleton）Bean接受容器管理，非单例（non-singleton）Bean在实例化后，完全交给了客户端代码管理，容器不再跟踪其生命周期，每次客户请求，容器都会创建一个新的实例，所以Spring容易无法知晓Bean何时销毁。Bean容器的生命周期。其实上图有个节点没有画出，就是在实例化所有Bean之前会执行BeanFactoryPostProcessors。 实例化从图中，我们可以看到实例化Bean的顺序： 构造函数实例化。 设置属性值（ioc）。 如果该Bean实现BeanNameAware接口，调用Bean中的BeanNameAware#setBeanName()。 如果该Bean实现BeanFactoryAware接口，调用Bean中的BeanFactoryAware#setBeanFactory()。 调用BeanPostProcessors#postProcessBeforeInitialization()。 如果该Bean实现InitializingBean接口，调用Bean中的afterPropertiesSet()。 调用Bean中的init-method，通常是在配置Bean的时候指定init-method，例如：&lt;bean class=&quot;beanClass&quot; init-method=&quot;init&quot;&gt;&lt;/bean&gt;。 调用BeanPostProcessors#postProcessAfterInitialization()。销毁销毁Bean的顺序： 在指定方法上加上@PreDestroy注解来制定该方法是在销毁之前调用。 通过实现DisposableBean接口来定制销毁之前的操作方法。 通过&lt;bean&gt;元素的destroy-method属性指定销毁之前调用的操作方法。 如果该Bean是单例的，则当容器销毁并且该Bean实现DisposableBean接口的时候，调用destory()；如果该Bean是prototype，则将准备好的Bean提交给调用者，后续不再管理该Bean的生命周期。 2 程序2.1内容：A类中有B类的引用，A类实例化的时候，B类也实例化好，init-method最后执行。 A类1234567891011121314151617181920212223242526272829303132package test;import org.springframework.beans.factory.InitializingBean;public class A implements InitializingBean { private B b; private String name; // = b.funb(); public void setB(B b) { System.out.println(\"A.setB initialed\"); this.b = b; } public A() { System.out.println(\"A initialed\"); } public void init() { System.out.println(\"init\"); //this.name = b.funb(); } public void initA() { System.out.println(\"initA\"); //this.name = b.funb(); } @Override public String toString() { return super.toString() + this.name; } public void afterPropertiesSet() throws Exception { this.name = b.funb(); System.out.println(\"afterPropertiesSet\"); }} B类1234567891011121314package test;public class B { public B() { System.out.println(\"B initialed\"); } public String funb() { System.out.println(\"funb\"); return \"B.funb\"; }} Spring配置12&lt;bean id=\"a\" class=\"test.A\" init-method=\"initA\"&gt;&lt;/bean&gt;&lt;bean id=\"b\" class=\"test.B\"&gt;&lt;/bean&gt; 控制台123456A initialedB initialedA.setB initialedfunb //afterPropertiesSet方法里afterPropertiesSetinitA 2.2xml配置方式上面顺序第6和第7条。先执行afterPropertiesSet()，再执行init()12345678910111213141516171819202122232425package test;import javax.annotation.PostConstruct;import org.springframework.beans.factory.InitializingBean;public class AnotherDemoBean implements InitializingBean { //初始化之后执行 @PostConstruct public void postConstruct() { System.out.println(\"AnotherDemoBean: postConstruct-method\"); } //xml配置里初始化执行 public void init() { System.out.println(\"AnotherDemoBean: init-method\"); } //重载InitializingBean的方法 @Override public void afterPropertiesSet() throws Exception { System.out.println(\"AnotherDemoBean: after properties set!\"); }} Spring XML配置1&lt;bean class=\"test.AnotherDemoBean\" init-method=\"init\"&gt;&lt;/bean&gt; 控制台123AnotherDemoBean: postConstruct-methodAnotherDemoBean: after properties set!AnotherDemoBean: init-method 注解方式123456789101112131415161718192021222324252627282930313233343536package test;import javax.annotation.PostConstruct;import org.springframework.beans.BeansException;import org.springframework.beans.factory.BeanFactory;import org.springframework.beans.factory.BeanFactoryAware;import org.springframework.beans.factory.BeanNameAware;import org.springframework.beans.factory.DisposableBean;import org.springframework.beans.factory.InitializingBean;import org.springframework.stereotype.Component;@Componentpublic class DemoBean implements BeanFactoryAware, BeanNameAware, InitializingBean, DisposableBean { @PostConstruct public void init() { System.out.println(\"DemoBean: init-method\"); } public void destroy() throws Exception { System.out.println(\"DemoBean: destroy-method!\"); } public void afterPropertiesSet() throws Exception { System.out.println(\"DemoBean: after properties set!\"); } public void setBeanName(String name) { System.out.println(\"DemoBean: beanName aware, [name=\" + name + \"]\"); } public void setBeanFactory(BeanFactory beanFactory) throws BeansException { System.out.println(\"DemoBean: beanFactory aware, [beanFactory=\" + beanFactory.toString() + \"]\"); }} Spring XML1&lt;context:component-scan base-package=\"test\"&gt;&lt;/context:component-scan&gt; 控制台1234DemoBean: beanName aware, [name=demoBean]DemoBean: beanFactory aware, [beanFactory=org.springframework.beans.factory.support.DefaultListableBeanFactory@26aa4a14: defining beans [org.springframework.beans.factory.config.PropertyPlaceholderConfigurer#0,demoBean,org.springframework.context.annotation.internalConfigurationAnnotationProcessor,org.springframework.context.annotation.internalAutowiredAnnotationProcessor,org.springframework.context.annotation.internalRequiredAnnotationProcessor,org.springframework.context.annotation.internalCommonAnnotationProcessor,propertyConfigurer,abstractBaseDao,crawlerService,erShouFangService,historyPriceService,crawlerPageDao,erShouFangDao,historyPriceDao,wenZhangDao,zuFangDao,wenZhangService,zuFangService,wubaErShouFangServer,xmfishNewsServer,_4399NewsServer,xmfishESFServer,com.amoyz.util.ContextUtil#0,fcJobTask,wzJobTask,fc_min30_server,fangchanCrawler30min,jobTrigger_FangChan_30min,wz_min5_server,wenzhangCrawler5min,jobTrigger_Wenzhang_5min,scheduler,mongo,org.springframework.beans.factory.config.CustomEditorConfigurer#0,org.springframework.beans.factory.config.CustomEditorConfigurer#1,org.springframework.beans.factory.config.CustomEditorConfigurer#2,mongoDbFactory,mongoTemplate,org.springframework.context.annotation.ConfigurationClassPostProcessor.importAwareProcessor]; root of factory hierarchy]DemoBean: init-methodDemoBean: after properties set! 3 XML中指定Init-method，@PostConstruct注解方法哪个先执行根据上一个例子结果123456789101112131415161718192021AnotherDemoBean: postConstruct-methodAnotherDemoBean: after properties set!AnotherDemoBean: init-method``` `PostConstruct`先执行，`Init-method`最后执行，跟踪源码得知这个类`CommonAnnotationBeanPostProcessor`，从命名上，我们就可以得到某些信息——这是一个`BeanPostProcessor`。想到什么？在也谈Spring容器的生命周期中，我们提到过`BeanPostProcessor#postProcessBeforeInitialization`是在Bean生命周期中`afterPropertiesSet`和`init-method`之前执被调用的。再次观察`CommonAnnotationBeanPostProcessor`这个类，它继承自`InitDestroyAnnotationBeanPostProcessor`。`InitDestroyAnnotationBeanPostProcessor`顾名思义，就是在Bean初始化和销毁的时候所作的一个前置/后置处理器。 通过查看`InitDestroyAnnotationBeanPostProcessor#postProcessBeforeInitialization()` ```` javapublic Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException { LifecycleMetadata metadata = findLifecycleMetadata(bean.getClass()); try { metadata.invokeInitMethods(bean, beanName); } catch (InvocationTargetException ex) { throw new BeanCreationException(beanName, &quot;Invocation of init method failed&quot;, ex.getTargetException()); } catch (Throwable ex) { throw new BeanCreationException(beanName, &quot;Couldn&apos;t invoke init method&quot;, ex); } return bean; } ` 查看findLifecycleMetadata()，跟踪到buildLifecycleMetadata()中12345678910111213141516171819202122232425private LifecycleMetadata buildLifecycleMetadata(final Class clazz) { final LifecycleMetadata newMetadata = new LifecycleMetadata(); final boolean debug = logger.isDebugEnabled(); ReflectionUtils.doWithMethods(clazz, new ReflectionUtils.MethodCallback() { public void doWith(Method method) { if (initAnnotationType != null) { if (method.getAnnotation(initAnnotationType) != null) { newMetadata.addInitMethod(method); if (debug) { logger.debug(\"Found init method on class [\" + clazz.getName() + \"]: \" + method); } } } if (destroyAnnotationType != null) { if (method.getAnnotation(destroyAnnotationType) != null) { newMetadata.addDestroyMethod(method); if (debug) { logger.debug(\"Found destroy method on class [\" + clazz.getName() + \"]: \" + method); } } } } }); return newMetadata; } 在这里会去判断某方法有没有被initAnnotationType/destroyAnnotationType注释，如果有，则把方法添加到init/destroy队列中，后续一一执行。@PostConstruct注解后的方法在BeanPostProcessor前置处理器中就被执行，所以当然要先于InitializingBean和init-method执行。","link":"/Spring-Bean-Life/"},{"title":"线程安全","text":"1 核心概念 1.1 原子性 原子操作 例子 1.2 可见性 volatile、final和synchronized volatile synchronized final 1.3 顺序性 2 Java解决多线程并发问题 2.1 lock和synchronized synchronized synchronized当作函数修饰符 synchronized代码块 synchronized作用于static函数 2.2 CAS（compare and swap） 2.3 Java如何保持可见性 2.4 Java如何保持顺序性 3 参考 1 核心概念1.1 原子性原子性是指不可再分的最小操作指令，即单条机器指令，原子性操作任意时刻只能有一个线程，因此是线程安全的。Java内存模型中通过read、load、assign、use、store和write这6个操作保证变量的原子性操作。这一点，跟数据库事务的原子性概念差不多，即一个操作（有可能包含有多个子操作）要么全部执行（生效），要么全部都不执行（都不生效）。 就是原子性说一个操作不可以被中途CPU暂停然后调度, 即不能被中断, 要不就执行完, 要不就不执行。一个不正确的知识：“原子操作不需要进行同步控制”。 原子操作是不能被线程调度机制中断的操作，一旦操作开始，那么它一定可以在可能发生中断之前执行完毕。原子性可以应用于基本数据类型（除了long和double），对于写入和读取，可以把它们当作原子操作来操作内存。但是，long和double这两个64位长度的数据类型Java虚拟机并没有强制规定他们的read、load、store和write操作的原子性，即所谓的非原子性协定，但是目前的各种商业Java虚拟机都把long和double数据类型的4中非原子性协定操作实现为原子性。所以Java中基本数据类型的访问读写是原子性操作。对于大范围的原子性保证需要通过lock和unlock操作以及synchronized同步块来保证。 例子比如A和B同时向C转账10万元。如果转账操作不具有原子性，A在向C转账时，读取了C的余额为20万，然后加上转账的10万，计算出此时应该有30万，但还未来及将30万写回C的账户，此时B的转账请求过来了，B发现C的余额为20万，然后将其加10万并写回。然后A的转账操作技术——将30万写回C的余额。这种情况下C的最终余额为30万，而非预期的40万。 1.2 可见性可见性是指，当多个线程并发访问共享变量时，一个线程对共享变量的修改，其它线程能够立即看到。可见性问题是好多人忽略或者理解错误的一点。CPU从主内存中读数据的效率相对来说不高，现在主流的计算机中，都有几级缓存。每个线程读取共享变量时，都会将该变量加载进其对应CPU的高速缓存里，修改该变量后，CPU会立即更新该缓存，但并不一定会立即将其写回主内存（实际上写回主内存的时间不可预期）。此时其它线程（尤其是不在同一个CPU上执行的线程）访问该变量时，从主内存中读到的就是旧的数据，而非第一个线程更新后的数据。这一点是操作系统或者说是硬件层面的机制，所以很多应用开发人员经常会忽略。 volatile、final和synchronizedJava中通过volatile、final和synchronized这三个关键字保证可见性。 volatile通过刷新变量值确保可见性。 synchronized同步块通过变量lock锁定前必须清空工作内存中变量值，重新从主内存中读取变量值，unlock解锁前必须把变量值同步回主内存来确保可见性。 final被final修饰的字段在构造器中一旦被初始化完成，并且构造器没有把this引用传递进去，那么在其他线程中就能看见final字段的值，无需同步就可以被其他线程正确访问。 1.3 顺序性程序执行的顺序按照代码的先后顺序执行。12345678// 语句1boolean started = false; // 语句2long counter = 0L; // 语句3counter = 1; // 语句4started = true; 从代码顺序上看，上面四条语句应该依次执行，但实际上JVM真正在执行这段代码时，并不保证它们一定完全按照此顺序执行。处理器为了提高程序整体的执行效率，可能会对代码进行优化，其中的一项优化方式就是调整代码顺序，按照更高效的顺序执行代码。CPU虽然并不保证完全按照代码顺序执行，但它会保证程序最终的执行结果和代码顺序执行时的结果一致。 2 Java解决多线程并发问题2.1 lock和synchronized常用的保证Java操作原子性的工具是锁和同步方法。无论使用锁还是synchronized，本质都是一样，通过锁来实现资源的排它性，从而实际目标代码段同一时间只会被一个线程执行，进而保证了目标代码段的原子性。这是一种以牺牲性能为代价的方法。 synchronizedsynchronized当作函数修饰符123public synchronized void method(){ //….} 锁定的是调用这个同步方法对象。也就是说，当一个对象在不同的线程中执行这个同步方法时，会形成互斥，达到同步的效果。但是这个对象所属的Class所产生的另一对象却能够任意调用这个被加了synchronized关键字的方法。上边的示例代码等同于如下代码。1234567public void method(){ synchronized (this) // (1) { //….. }} this是调用这个方法的对象。可见，同步方法实质是将synchronized作用于Object Reference。那个拿到了对象锁的线程，才能够调用同步方法，而对另一个对象而言，这个锁对其没有影响，这个对象也可能在这种情形下摆脱同步机制的控制，造成数据混乱。 synchronized代码块123456public void method(SomeObject so) { synchronized(so) { //….. }} 零长度的byte[]对象创建起来将比任何对象都经济。查看编译后的字节码：生成零长度的byte[]对象只需3条操作码，而Object lock = new Object()则需要7行操作码。123456789class Foo implements Runnable{ private byte[] lock = new byte[0]; Public void method() { synchronized(lock) { //… } } //…..} synchronized作用于static函数1234567891011Class Foo{ public synchronized static void method1() // 同步的static 函数 { //…. } public void method2() { synchronized(Foo.class) // class literal(类名称字面常量) }} method2()方法是把class作为锁的情况，和同步的static函数产生的效果是相同的，取得的锁很特别，是当前调用这个方法的对象所属的类。 2.2 CAS（compare and swap）基础类型变量自增（i++）是一种常被新手误以为是原子操作而实际不是的操作。Java中提供了对应的原子操作类来实现该操作，并保证原子性，其本质是利用了CPU级别的CAS指令。由于是CPU级别的指令，其开销比需要操作系统参与的锁的开销小。12345678AtomicInteger atomicInteger = new AtomicInteger();for(int b = 0; b &lt; numThreads; b++) { new Thread(() -&gt; { for(int a = 0; a &lt; iteration; a++) { atomicInteger.incrementAndGet(); } }).start();} 2.3 Java如何保持可见性Java提供了volatile关键字来保证可见性。当使用volatile修饰某个变量时，它会保证对该变量的修改会立即被更新到内存中，并且将其它缓存中对该变量的缓存设置成无效，因此其它线程需要读取该值时必须从主内存中读取，从而得到最新的值。volatile适用于不需要保证原子性，但却需要保证可见性的场景。一种典型的使用场景是用它修饰用于停止线程的状态标记。1234567891011boolean isRunning = false;public void start () { new Thread( () -&gt; { while(isRunning) { someOperation(); } }).start();}public void stop () { isRunning = false;} 在这种实现方式下，即使其它线程通过调用stop()方法将isRunning设置为false，循环也不一定会立即结束。可以通过volatile关键字，保证while循环及时得到isRunning最新的状态从而及时停止循环，结束线程。 2.4 Java如何保持顺序性编译器和处理器对指令进行重新排序时，会保证重新排序后的执行结果和代码顺序执行的结果一致，所以重新排序过程并不会影响单线程程序的执行，却可能影响多线程程序并发执行的正确性。Java中可通过volatile在一定程序上保证顺序性，另外还可以通过synchronized和锁来保证顺序性。synchronized和锁保证顺序性的原理和保证原子性一样，都是通过保证同一时间只会有一个线程执行目标代码段来实现的。除了从应用层面保证目标代码段执行的顺序性外，JVM还通过被称为happens-before原则隐式的保证顺序性。两个操作的执行顺序只要可以通过happens-before推导出来，则JVM会保证其顺序性，反之JVM对其顺序性不作任何保证，可对其进行任意必要的重新排序以获取高效率。 3 参考 http://www.jasongj.com/java/thread_safe/","link":"/Thread-Safety/"},{"title":"Tomcat（一）总体结构","text":"1 前言 2 Tomcat的总体结构 3 Server 4 Service 5 Connector HTTP/1.1 AJP/1.3 6 Engine 7 Host 8 Context 9 Valve 1 前言本章以Tomcat7为主。 2 Tomcat的总体结构Tomcat即是一个Http服务器也是一个Servlet容器，它的总体结构我们可以用下图来描述。通过上图我们可以看出Tomcat中主要涉及Server，Service，Engine，Connector，Host，Context组件。在Tomcat二进制分发包解压后，在conf目录中有一个server.xml文件，server.xml文件中已经包含上述的几个名称。Tomcat7.0.42分发包中的server.xml来具体分析一下，它的内容如下。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142&lt;?xml version='1.0' encoding='utf-8'?&gt;&lt;!-- Licensed to the Apache Software Foundation (ASF) under one or more contributor license agreements. See the NOTICE file distributed with this work for additional information regarding copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.--&gt;&lt;!-- Note: A \"Server\" is not itself a \"Container\", so you may not define subcomponents such as \"Valves\" at this level. Documentation at /docs/config/server.html --&gt;&lt;Server port=\"8005\" shutdown=\"SHUTDOWN\"&gt; &lt;!-- Security listener. Documentation at /docs/config/listeners.html &lt;Listener className=\"org.apache.catalina.security.SecurityListener\" /&gt; --&gt; &lt;!--APR library loader. Documentation at /docs/apr.html --&gt; &lt;Listener className=\"org.apache.catalina.core.AprLifecycleListener\" SSLEngine=\"on\" /&gt; &lt;!--Initialize Jasper prior to webapps are loaded. Documentation at /docs/jasper-howto.html --&gt; &lt;Listener className=\"org.apache.catalina.core.JasperListener\" /&gt; &lt;!-- Prevent memory leaks due to use of particular java/javax APIs--&gt; &lt;Listener className=\"org.apache.catalina.core.JreMemoryLeakPreventionListener\" /&gt; &lt;Listener className=\"org.apache.catalina.mbeans.GlobalResourcesLifecycleListener\" /&gt; &lt;Listener className=\"org.apache.catalina.core.ThreadLocalLeakPreventionListener\" /&gt; &lt;!-- Global JNDI resources Documentation at /docs/jndi-resources-howto.html --&gt; &lt;GlobalNamingResources&gt; &lt;!-- Editable user database that can also be used by UserDatabaseRealm to authenticate users --&gt; &lt;Resource name=\"UserDatabase\" auth=\"Container\" type=\"org.apache.catalina.UserDatabase\" description=\"User database that can be updated and saved\" factory=\"org.apache.catalina.users.MemoryUserDatabaseFactory\" pathname=\"conf/tomcat-users.xml\" /&gt; &lt;/GlobalNamingResources&gt; &lt;!-- A \"Service\" is a collection of one or more \"Connectors\" that share a single \"Container\" Note: A \"Service\" is not itself a \"Container\", so you may not define subcomponents such as \"Valves\" at this level. Documentation at /docs/config/service.html --&gt; &lt;Service name=\"Catalina\"&gt; &lt;!--The connectors can use a shared executor, you can define one or more named thread pools--&gt; &lt;!-- &lt;Executor name=\"tomcatThreadPool\" namePrefix=\"catalina-exec-\" maxThreads=\"150\" minSpareThreads=\"4\"/&gt; --&gt; &lt;!-- A \"Connector\" represents an endpoint by which requests are received and responses are returned. Documentation at : Java HTTP Connector: /docs/config/http.html (blocking &amp; non-blocking) Java AJP Connector: /docs/config/ajp.html APR (HTTP/AJP) Connector: /docs/apr.html Define a non-SSL HTTP/1.1 Connector on port 8080 --&gt; &lt;Connector port=\"8080\" protocol=\"HTTP/1.1\" connectionTimeout=\"20000\" redirectPort=\"8443\" /&gt; &lt;!-- A \"Connector\" using the shared thread pool--&gt; &lt;!-- &lt;Connector executor=\"tomcatThreadPool\" port=\"8080\" protocol=\"HTTP/1.1\" connectionTimeout=\"20000\" redirectPort=\"8443\" /&gt; --&gt; &lt;!-- Define a SSL HTTP/1.1 Connector on port 8443 This connector uses the JSSE configuration, when using APR, the connector should be using the OpenSSL style configuration described in the APR documentation --&gt; &lt;!-- &lt;Connector port=\"8443\" protocol=\"HTTP/1.1\" SSLEnabled=\"true\" maxThreads=\"150\" scheme=\"https\" secure=\"true\" clientAuth=\"false\" sslProtocol=\"TLS\" /&gt; --&gt; &lt;!-- Define an AJP 1.3 Connector on port 8009 --&gt; &lt;Connector port=\"8009\" protocol=\"AJP/1.3\" redirectPort=\"8443\" /&gt; &lt;!-- An Engine represents the entry point (within Catalina) that processes every request. The Engine implementation for Tomcat stand alone analyzes the HTTP headers included with the request, and passes them on to the appropriate Host (virtual host). Documentation at /docs/config/engine.html --&gt; &lt;!-- You should set jvmRoute to support load-balancing via AJP ie : &lt;Engine name=\"Catalina\" defaultHost=\"localhost\" jvmRoute=\"jvm1\"&gt; --&gt; &lt;Engine name=\"Catalina\" defaultHost=\"localhost\"&gt; &lt;!--For clustering, please take a look at documentation at: /docs/cluster-howto.html (simple how to) /docs/config/cluster.html (reference documentation) --&gt; &lt;!-- &lt;Cluster className=\"org.apache.catalina.ha.tcp.SimpleTcpCluster\"/&gt; --&gt; &lt;!-- Use the LockOutRealm to prevent attempts to guess user passwords via a brute-force attack --&gt; &lt;Realm className=\"org.apache.catalina.realm.LockOutRealm\"&gt; &lt;!-- This Realm uses the UserDatabase configured in the global JNDI resources under the key \"UserDatabase\". Any edits that are performed against this UserDatabase are immediately available for use by the Realm. --&gt; &lt;Realm className=\"org.apache.catalina.realm.UserDatabaseRealm\" resourceName=\"UserDatabase\"/&gt; &lt;/Realm&gt; &lt;Host name=\"localhost\" appBase=\"webapps\" unpackWARs=\"true\" autoDeploy=\"true\"&gt; &lt;!-- SingleSignOn valve, share authentication between web applications Documentation at: /docs/config/valve.html --&gt; &lt;!-- &lt;Valve className=\"org.apache.catalina.authenticator.SingleSignOn\" /&gt; --&gt; &lt;!-- Access log processes all example. Documentation at: /docs/config/valve.html Note: The pattern used is equivalent to using pattern=\"common\" --&gt; &lt;Valve className=\"org.apache.catalina.valves.AccessLogValve\" directory=\"logs\" prefix=\"localhost_access_log.\" suffix=\".txt\" pattern=\"%h %l %u %t &amp;quot;%r&amp;quot; %s %b\" /&gt; &lt;/Host&gt; &lt;/Engine&gt; &lt;/Service&gt;&lt;/Server&gt; 3 ServerServer是Tomcat中最顶层的组件，它可以包含多个Service组件。在Tomcat源代码中Server组件对应源码中的org.apache.catalina.core.StandardServer类。 StandardServer的继承关系图如下图所示。 4 ServiceService组件，Service组件相当于Connetor和Engine组件的包装器，它将一个或者多个Connector组件和一个Engine建立关联。缺省的的配置文件中，定义一个叫Catalina的服务，并将Http，AJP这两个Connector关联到一个名为Catalina的Engine。Service组件对应Tomcat源代码中的org.apache.catalina.core.StandardService。StandardService的继承关系图如下图所示。 5 Connector既然Tomcat需要提供http服务，而我们知道http应用层协议最终都是需要通过TCP层的协议进行包传递的，而Connector正是Tomcat中监听TCP网络连接的组件，一个Connector会监听一个独立的端口来处理来自客户端的连接。缺省的情况下Tomcat提供如下两个Connector。分别描述一下。 HTTP/1.11&lt;Connector port=\"8080\" protocol=\"HTTP/1.1\" connectionTimeout=\"20000\" redirectPort=\"8443\" /&gt; 上面定义一个Connector，它缺省监听端口8080，这个端口我们可以根据具体情况进行改动。connectionTimeout定义连接超时时间，单位是毫秒，redirectPort定义ssl的重定向接口，根据缺省的配置，Connector会将ssl请求重定向到8443端口。 AJP/1.3AJP表示Apache Jserv Protocol，此连接器将处理Tomcat和Aapache http服务器之间的交互，这个连机器是用来处理我们将Tomcat和Apache http服务器结合使用的情况。假如在同样的一台物理Server上面部署一台Apache http服务器和多台Tomcat服务器，通过Apache服务器来处理静态资源以及负载均衡的时候，针对不同的Tomcat实例需要AJP监听不同的端口。Connector对应源代码中的org.apache.catalina.connector.Connector，它的继承关系图如下所示。 6 EngineTomcat中有一个容器的概念，而Engine，Host，Context都属于Contanier（容器），我们先来说说最顶层的容器Engine。一个Engine可以包含一个或者多个Host，也就是说我们一个Tomcat的实例可以配置多个虚拟主机。缺省的情况下&lt;Engine name=&quot;Catalina&quot; defaultHost=&quot;localhost&quot;&gt;定义一个名称为Cataline的Engine。Engine对应源代码中的org.apache.catalina.core.StandardEngine，它的继承关系图如下图所示。 7 HostHost定义一个虚拟主机，一个虚拟主机可以有多个Context，缺省的配置如下。1&lt;Host name=\"localhost\" appBase=\"webapps\" unpackWARs=\"true\" autoDeploy=\"true\"&gt;….&lt;/Host&gt; 其中appBase为webapps，也就是&lt;CATALINA_HOME&gt;\\webapps目录，unpackingWARS属性指定在appBase指定的目录中的war包都自动的解压，缺省配置为true，autoDeploy属性指定是否对加入到appBase目录的war包进行自动的部署，缺省为true。Host对应源代码中的org.apache.catalina.core.StandardHost，它的继承关系图如下所示。 8 Context在Tomcat中，每一个运行的webapp其实最终都是以Context的形成存在，每个Context都有一个根路径和请求URL路径，Context对应源代码中的org.apache.catalina.core.StandardContext，它的继承关系图如下图所示。在Tomcat中我们通常采用如下的两种方式创建一个Context。下面分别描述一下。 在&lt;CATALINA-HOME&gt;\\webapps目录中创建一个目录，这个时候将自动创建一个context，默认context的访问url为http://host:port/dirname,你也可以通过在ContextRoot\\META-INF中创建一个context.xml的文件，其中包含如下的内容来指定应用的访问路径。 &lt;Context path=&quot;/urlPath&quot;/&gt; conf\\server.xml文件中增加context元素。 第二种创建context的方法，我们可以选择在server.xml文件的&lt;Host&gt;元素，比如我们在server.xml文件中增加如下内容。12345678 ...... ...... &lt;Context path=\"/mypath\" docBase=\"/Users/path\" reloadable=\"true\"&gt; &lt;/Context&gt; &lt;/Host&gt;&lt;/Engine&gt; &lt;/Service&gt;&lt;/Server&gt; 这样的话，我们就可以通过http://host:port/path访问上面配置的context。 9 ValveValve中文意思是阀门，Valve是Tomcat中责任链模式的实现，通过链接多个Valve对请求进行处理。其中Valve可以定义在任何的Container中，上面说的Engine，Host，Context都属于容器。tomcat默认定义一个名为org.apache.catalina.valves.AccessLogValve的Valve，这个Valve负责拦截每个请求，然后记录一条访问日志。通过上面的分析，我们发现Server，Service，Engine，Host，Context都实现org.apache.catalina.Lifecycle接口，通过这个接口管理这些核心组件的生命周期。","link":"/Tomcat-1/"},{"title":"非Fork/Join源码分析","text":"1 ForkJoinPool属性 2 ForkJoinWorkerThread属性 3 ForkJoinTask属性 4 非ForkJoin任务的执行过程 4.1 例 4.2 ForkJoinPool ForkJoinPool ForkJoinPool默认的工作线程工厂 ForkJoinPool#submit() ForkJoinTask#adapt() ForkJoinTask#AdaptedCallable() ForkJoinTask#AdaptedRunnable() ForkJoinPool#forkOrSubmit() ForkJoinPool#addSubmission() addSubmission() ForkJoinPool#growSubmissionQueue() ForkJoinPool#signalWork() signalWork 标注0 e&gt;=0前代码 e&gt;=0代码 ForkJoinPool#addWorker() ForkJoinPool#ForkJoinWorkerThreadFactory#newThread() ForkJoinPool#nextWorkerName() ForkJoinPool#registerWorker() registerWorker() ForkJoinWorkerThread#run() ForkJoinWorkerThread#onStart() ForkJoinWorkerThread#onTermination() ForkJoinPool#work ForkJoinPool#scan() scan() ForkJoinWorkerThread#execTask() ForJoinTask#doExec() RecursiveAction#exec() RecursiveAction#compute() RecursiveTask#exec() RecursiveTask#compute() ForkJoinTask#setCompletion() ForkJoinTask#setExceptionalCompletion() 这里为什么会有一个异常表呢？ 异常表的结构是怎么样的呢？ Exception table ForkJoinPool#tryAwaitWork() ForkJoinPool#idleAwaitWork() ForkJoinWorkerThread#onTermination() ForkJoinWorkerThread#cancelTasks() ForkJoinTask#cancel() ForkJoinPool#deregisterWorker() ForkJoinPool#tryTerminate() 参数为false 参数为true ForkJoinPool#startTerminating() startTerminating流程 ForkJoinPool#cancelSubmissions() ForkJoinPool#pollSubmission() ForkJoinPool#terminateWaiters() ForkJoinPool#tryReleaseWaiter() ForkJoinWorkerThread#execTask() ForkJoinWorkerThread#popTask() ForkJoinWorkerThread#locallyDeqTask() 5 总结 1 ForkJoinPool属性部分参数12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455/** * Main pool control -- a long packed with: * AC: Number of active running workers minus target parallelism (16 bits) * TC: Number of total workers minus target parallelism (16bits) * ST: true if pool is terminating (1 bit) * EC: the wait count of top waiting thread (15 bits) * ID: ~poolIndex of top of Treiber stack of waiting threads (16 bits) * * When convenient, we can extract the upper 32 bits of counts and * the lower 32 bits of queue state, u = (int)(ctl &gt;&gt;&gt; 32) and e = * (int)ctl. The ec field is never accessed alone, but always * together with id and st. The offsets of counts by the target * parallelism and the positionings of fields makes it possible to * perform the most common checks via sign tests of fields: When * ac is negative, there are not enough active workers, when tc is * negative, there are not enough total workers, when id is * negative, there is at least one waiting worker, and when e is * negative, the pool is terminating. To deal with these possibly * negative fields, we use casts in and out of \"short\" and/or * signed shifts to maintain signedness. */ volatile long ctl; // bit positions/shifts for fields private static final int AC_SHIFT = 48; private static final int TC_SHIFT = 32; private static final int ST_SHIFT = 31; private static final int EC_SHIFT = 16; // bounds private static final int MAX_ID = 0x7fff; // max poolIndex private static final int SMASK = 0xffff; // mask short bits private static final int SHORT_SIGN = 1 &lt;&lt; 15; private static final int INT_SIGN = 1 &lt;&lt; 31; // masks private static final long STOP_BIT = 0x0001L &lt;&lt; ST_SHIFT; private static final long AC_MASK = ((long)SMASK) &lt;&lt; AC_SHIFT; private static final long TC_MASK = ((long)SMASK) &lt;&lt; TC_SHIFT; // units for incrementing and decrementing private static final long TC_UNIT = 1L &lt;&lt; TC_SHIFT; private static final long AC_UNIT = 1L &lt;&lt; AC_SHIFT; // masks and units for dealing with u = (int)(ctl &gt;&gt;&gt; 32) private static final int UAC_SHIFT = AC_SHIFT - 32; private static final int UTC_SHIFT = TC_SHIFT - 32; private static final int UAC_MASK = SMASK &lt;&lt; UAC_SHIFT; private static final int UTC_MASK = SMASK &lt;&lt; UTC_SHIFT; private static final int UAC_UNIT = 1 &lt;&lt; UAC_SHIFT; private static final int UTC_UNIT = 1 &lt;&lt; UTC_SHIFT; // masks and units for dealing with e = (int)ctl private static final int E_MASK = 0x7fffffff; // no STOP_BIT private static final int EC_UNIT = 1 &lt;&lt; EC_SHIFT; ForkJoinPool的总控制信息，包含在一个long(64bit)里面。 AC: 表示当前活动的工作线程的数量减去并行度得到的数值。(16 bits) TC: 表示全部工作线程的数量减去并行度得到的数值。(16bits) ST: 表示当前ForkJoinPool是否正在关闭。(1 bit) EC: 表示Treiber stack顶端的等待工作线程的等待次数。(15 bits) ID: Treiber stack顶端的等待工作线程的下标取反。(16 bits) 1111111111111111 1111111111111111 1 111111111111111 1111111111111111 AC TC ST EC ID 如果AC为负数，说明没有足够的活动工作线程。 如果TC为负数，说明工作线程数量没达到最大工作线程数量。 如果ID为负数，说明至少有一个等待的工作线程。 如果(int)ctl为负数，说明ForkJoinPool正在关闭。 ctl是ForkJoinPool中最重要的，也是设计最精密的域，它是整个ForkJoinPool的总控信息。所有信息包含在一个long(64bit)中，这些信息包括：当前活动的工作线程数量、当前总的工作线程数量、ForkJoinPool的关闭标志、在Treiber stack(由全部等待工作线程组成的一个链)顶端等待的工作线程的等待次数、Treiber stack(由全部等待工作线程组成的一个链)顶端等待的工作线程的ID信息(工作线程的下标取反)。ctl还有一个相对不重要的作用就是，某些非volatile域会依赖ctl来保证可见性。 1234567891011/** * Array holding all worker threads in the pool. Initialized upon * construction. Array size must be a power of two. Updates and * replacements are protected by scanGuard, but the array is * always kept in a consistent enough state to be randomly * accessed without locking by workers performing work-stealing, * as well as other traversal-based methods in this class, so long * as reads memory-acquire by first reading ctl. All readers must * tolerate that some array slots may be null. */ForkJoinWorkerThread[] workers; workers是ForkJoinPool中保存工作线程的数组，它的更新会由一个锁(scanGuard)来保护。1234567891011/** * SeqLock and index masking for updates to workers array. Locked * when SG_UNIT is set. Unlocking clears bit by adding * SG_UNIT. Staleness of read-only operations can be checked by * comparing scanGuard to value before the reads. The low 16 bits * (i.e, anding with SMASK) hold (the smallest power of two * covering all worker indices, minus one, and is used to avoid * dealing with large numbers of null slots when the workers array * is overallocated. */volatile int scanGuard; scanGuard是另外一个比较重要的域，它有两个作用。 作为更新工作线程数组是使用的(顺序)锁。 作为扫描工作线程数组时使用的边界值来避免一些没用的扫描(当数组过大时)。123456789101112131415161718192021222324/** * Initial size for submission queue array. Must be a power of * two. In many applications, these always stay small so we use a * small initial cap. */ private static final int INITIAL_QUEUE_CAPACITY = 8; /** * Maximum size for submission queue array. Must be a power of two * less than or equal to 1 &lt;&lt; (31 - width of array entry) to * ensure lack of index wraparound, but is capped at a lower * value to help users trap runaway computations. */ private static final int MAXIMUM_QUEUE_CAPACITY = 1 &lt;&lt; 24; // 16M /** * Array serving as submission queue. Initialized upon construction. */ private ForkJoinTask&lt;?&gt;[] submissionQueue; /** * Lock protecting submissions array for addSubmission */ private final ReentrantLock submissionLock; ForkJoinPool中也有一个队列submissionQueue，这个队列里存放的是有外部(非ForkJoin工作线程)提交到ForkJoinPool中的任务。123456789101112131415/** * Index (mod submission queue length) of next element to take * from submission queue. Usage is identical to that for * per-worker queues -- see ForkJoinWorkerThread internal * documentation. */volatile int queueBase;/** * Index (mod submission queue length) of next element to add * in submission queue. Usage is identical to that for * per-worker queues -- see ForkJoinWorkerThread internal * documentation. */int queueTop; 这两个域分别表示submissionQueue的底部和顶部。12345/** * True if use local fifo, not default lifo, for local polling * Read by, and replicated by ForkJoinWorkerThreads */final boolean locallyFifo; locallyFifo域也比较重要，它有ForkJoinPool的构造方法的参数asyncMode来指定。如果locallyFifo为true，表示内部将才用FIFO的方式来调度任务队列中的任务，而且这些任务可以分裂(fork)，但最好不要合并(join)，这种模式很适合来处理事件形式(event-style)的异步任务。默认locallyFifo为false。 2 ForkJoinWorkerThread属性ForkJoinWorkerThread是ForkJoin框架中负责执行具体任务的工作线程。1234567891011121314151617181920212223242526272829303132333435363738394041/** * Capacity of work-stealing queue array upon initialization. * Must be a power of two. Initial size must be at least 4, but is * padded to minimize cache effects. */ private static final int INITIAL_QUEUE_CAPACITY = 1 &lt;&lt; 13; /** * Maximum size for queue array. Must be a power of two * less than or equal to 1 &lt;&lt; (31 - width of array entry) to * ensure lack of index wraparound, but is capped at a lower * value to help users trap runaway computations. */ private static final int MAXIMUM_QUEUE_CAPACITY = 1 &lt;&lt; 24; // 16M /** * The work-stealing queue array. Size must be a power of two. * Initialized when started (as oposed to when constructed), to * improve memory locality. */ ForkJoinTask&lt;?&gt;[] queue; /** * The pool this thread works in. Accessed directly by ForkJoinTask. */ final ForkJoinPool pool; /** * Index (mod queue.length) of next queue slot to push to or pop * from. It is written only by owner thread, and accessed by other * threads only after reading (volatile) queueBase. Both queueTop * and queueBase are allowed to wrap around on overflow, but * (queueTop - queueBase) still estimates size. */ int queueTop; /** * Index (mod queue.length) of least valid queue slot, which is * always the next position to steal from if nonempty. */ volatile int queueBase; queue就是ForkJoinWorkerThread中的任务队列，当从其他工作线程中窃取任务时，就是从这个队列中进行窃取。123456/** * Index of this worker in pool array. Set once by pool before * running, and accessed directly by pool to locate this worker in * its workers array. */final int poolIndex; 工作线程在ForkJoinPool中工作线程数组中的下标。12345678/** * The index of most recent stealer, used as a hint to avoid * traversal in method helpJoinTask. This is only a hint because a * worker might have had multiple steals and this only holds one * of them (usually the most current). Declared non-volatile, * relying on other prevailing sync to keep reasonably current. */int stealHint; stealHint保存了最近的窃取者(来窃取任务的工作线程)的下标(poolIndex)。注意这个值不准确，因为可能同时有很多窃取者来窃取任务，这个值只能记录其中之一。12345/** * Encoded record for pool task waits. Usages are always * surrounded by volatile reads/writes */ int nextWait; nextWait算是比较难理解的一个域。首先所有的等待工作线程组成了一个隐式的单链(代码中也叫Treiber stack，由于行为类似于栈)，链顶端的等待工作线程的信息保存在Pool的ctl中，新来的等待工作线程会将ctl中之前的等待工作线程信息保存到nextWait上，然后将自己的信息设置到ctl上。12345/** * True if use local fifo, not default lifo, for local polling. * Shadows value from ForkJoinPool. */final boolean locallyFifo; 这个和ForkJoinPool#locallyFifo一致。123456/** * The task most recently stolen from another worker (or * submission queue). All uses are surrounded by enough volatile * reads/writes to maintain as non-volatile. */ForkJoinTask&lt;?&gt; currentSteal; 当前工作线程最新窃取的任务。注意可以从其他工作线程的任务队列或者从Pool中的提交任务队列(submissionQueue)中窃取任务。123456/** * The task currently being joined, set only when actively trying * to help other stealers in helpJoinTask. All uses are surrounded * by enough volatile reads/writes to maintain as non-volatile. */ ForkJoinTask&lt;?&gt; currentJoin; 当前工作线程正在合并的任务。 3 ForkJoinTask属性1234567891011121314151617181920212223/* * The status field holds run control status bits packed into a * single int to minimize footprint and to ensure atomicity (via * CAS). Status is initially zero, and takes on nonnegative * values until completed, upon which status holds value * NORMAL, CANCELLED, or EXCEPTIONAL. Tasks undergoing blocking * waits by other threads have the SIGNAL bit set. Completion of * a stolen task with SIGNAL set awakens any waiters via * notifyAll. Even though suboptimal for some purposes, we use * basic builtin wait/notify to take advantage of \"monitor * inflation\" in JVMs that we would otherwise need to emulate to * avoid adding further per-task bookkeeping overhead. We want * these monitors to be \"fat\", i.e., not use biasing or thin-lock * techniques, so use some odd coding idioms that tend to avoid * them. *//** The run status of this task */volatile int status; // accessed directly by pool and workersprivate static final int NORMAL = -1;private static final int CANCELLED = -2;private static final int EXCEPTIONAL = -3;private static final int SIGNAL = 1; ForkJoinTask中只有一个表示运行状态的域。初始为0；1表示在等待被唤醒；负数都表示执行完毕。 -1表示正常完成。 -2表示被取消。 -3表示异常结束。4 非ForkJoin任务的执行过程非ForkJoin(Runnable或者Callable)任务的执行过程来分析ForkJoin的相关代码，注意这里说的非ForkJoin任务实际上也是ForkJoinTask，只是没有分裂(fork)/合并(join)过程。4.1 例非ForkJoin任务的代码123456789101112131415public static void main(String[] args) { ForkJoinPool forkJoinPool = new ForkJoinPool(); ForkJoinTask&lt;?&gt; task = forkJoinPool.submit(new Runnable() { @Override public void run() { System.out.println(\"AAA\"); } }); try { task.get(); forkJoinPool.shutdown(); } catch (Exception e) { e.printStackTrace(); } } 代码中提交了一个Runnable的任务到ForkJoinPool，任务的执行就是打印一句话。下面就从提交一个Runnable的任务到ForkJoinPool，直到任务被执行的过程来分析源码。 4.2 ForkJoinPool123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566...../** * Creates a {@code ForkJoinPool} with the given parameters. * * @param parallelism the parallelism level. For default value, * use {@link java.lang.Runtime#availableProcessors}. * @param factory the factory for creating new threads. For default value, * use {@link #defaultForkJoinWorkerThreadFactory}. * @param handler the handler for internal worker threads that * terminate due to unrecoverable errors encountered while executing * tasks. For default value, use {@code null}. * @param asyncMode if true, * establishes local first-in-first-out scheduling mode for forked * tasks that are never joined. This mode may be more appropriate * than default locally stack-based mode in applications in which * worker threads only process event-style asynchronous tasks. * For default value, use {@code false}. * @throws IllegalArgumentException if parallelism less than or * equal to zero, or greater than implementation limit * @throws NullPointerException if the factory is null * @throws SecurityException if a security manager exists and * the caller is not permitted to modify threads * because it does not hold {@link * java.lang.RuntimePermission}{@code (\"modifyThread\")} */public ForkJoinPool(int parallelism, ForkJoinWorkerThreadFactory factory, Thread.UncaughtExceptionHandler handler, boolean asyncMode) { checkPermission(); if (factory == null) throw new NullPointerException(); if (parallelism &lt;= 0 || parallelism &gt; MAX_ID) throw new IllegalArgumentException(); // 1 this.parallelism = parallelism; // 2 this.factory = factory; // 3 this.ueh = handler; // 4 this.locallyFifo = asyncMode; // 5 long np = (long)(-parallelism); // offset ctl counts this.ctl = ((np &lt;&lt; AC_SHIFT) &amp; AC_MASK) | ((np &lt;&lt; TC_SHIFT) &amp; TC_MASK); // 6 this.submissionQueue = new ForkJoinTask&lt;?&gt;[INITIAL_QUEUE_CAPACITY]; // initialize workers array with room for 2*parallelism if possible // 7 int n = parallelism &lt;&lt; 1; if (n &gt;= MAX_ID) n = MAX_ID; else { // See Hackers Delight, sec 3.2, where n &lt; (1 &lt;&lt; 16) n |= n &gt;&gt;&gt; 1; n |= n &gt;&gt;&gt; 2; n |= n &gt;&gt;&gt; 4; n |= n &gt;&gt;&gt; 8; } // 8 workers = new ForkJoinWorkerThread[n + 1]; this.submissionLock = new ReentrantLock(); this.termination = submissionLock.newCondition(); // 9 StringBuilder sb = new StringBuilder(\"ForkJoinPool-\"); sb.append(poolNumberGenerator.incrementAndGet()); sb.append(\"-worker-\"); this.workerNamePrefix = sb.toString();} 标注代码分析 设置并行度。 设置工作线程工厂。 设置线程未捕获异常处理器。 设置是否为异步模式。 参考我们之前介绍的ctl的内容，由于ctl中的AC表示当前活动。工作线程数量减去并行度，所以这里要将这个信息加到ctl上。 初始化提交任务队列。 这里需要根据并行度来算出工作线程数组的大小。由于数组大小必须的2的幂，这里的算法是算出比。parallelism的2倍大的最小的2的幂，但不能超过。MAX_ID + 1(1 &lt;&lt; 16)的数作为工作线程数组大小。 创建存放工作线程的数组。 生成工作线程名称前缀。ForkJoinPool 并行度如果未提供，默认就是当前处理器核数。 初始化控制信息的部分，注意在AC和TC的信息上减掉了并行度，比如如果并行度为4，那么初始的AC和TC就都是-4，那么如果后续发现AC等于0，就说明当前活动的线程数正好等于处理器核心数量。 确定工作线程数组大小的过程是这样的，首先取一个数n，默认是并行度的2倍。然后会使用来自HD的一个位操作技巧，就是将n的位模式的前导1后面所有的位都变成1，其实就是一个比n大的2的幂减1的数。当然n最大不能超过MAX_ID，最终数组的大小是n+1，是一个2的幂，能简化后续的取模操作。ForkJoinPool默认的工作线程工厂1234567891011121314151617181920212223242526272829303132static { poolNumberGenerator = new AtomicInteger(); workerSeedGenerator = new Random(); modifyThreadPermission = new RuntimePermission(\"modifyThread\"); defaultForkJoinWorkerThreadFactory = new DefaultForkJoinWorkerThreadFactory(); int s; try { UNSAFE = sun.misc.Unsafe.getUnsafe(); Class k = ForkJoinPool.class; ctlOffset = UNSAFE.objectFieldOffset (k.getDeclaredField(\"ctl\")); stealCountOffset = UNSAFE.objectFieldOffset (k.getDeclaredField(\"stealCount\")); blockedCountOffset = UNSAFE.objectFieldOffset (k.getDeclaredField(\"blockedCount\")); quiescerCountOffset = UNSAFE.objectFieldOffset (k.getDeclaredField(\"quiescerCount\")); scanGuardOffset = UNSAFE.objectFieldOffset (k.getDeclaredField(\"scanGuard\")); nextWorkerNumberOffset = UNSAFE.objectFieldOffset (k.getDeclaredField(\"nextWorkerNumber\")); Class a = ForkJoinTask[].class; ABASE = UNSAFE.arrayBaseOffset(a); s = UNSAFE.arrayIndexScale(a); } catch (Exception e) { throw new Error(e); } if ((s &amp; (s-1)) != 0) throw new Error(\"data type scale not a power of two\"); ASHIFT = 31 - Integer.numberOfLeadingZeros(s); } 12345678910/** * Default ForkJoinWorkerThreadFactory implementation; creates a * new ForkJoinWorkerThread. */static class DefaultForkJoinWorkerThreadFactory implements ForkJoinWorkerThreadFactory { public ForkJoinWorkerThread newThread(ForkJoinPool pool) { return new ForkJoinWorkerThread(pool); }} 123456789101112131415/** * Factory for creating new {@link ForkJoinWorkerThread}s. * A {@code ForkJoinWorkerThreadFactory} must be defined and used * for {@code ForkJoinWorkerThread} subclasses that extend base * functionality or initialize threads with different contexts. */public static interface ForkJoinWorkerThreadFactory { /** * Returns a new worker thread operating in the given pool. * * @param pool the pool this thread works in * @throws NullPointerException if the pool is null */ public ForkJoinWorkerThread newThread(ForkJoinPool pool);} ForkJoinPool#submit()12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758/** * Submits a ForkJoinTask for execution. * * @param task the task to submit * @return the task * @throws NullPointerException if the task is null * @throws RejectedExecutionException if the task cannot be * scheduled for execution */ public &lt;T&gt; ForkJoinTask&lt;T&gt; submit(ForkJoinTask&lt;T&gt; task) { if (task == null) throw new NullPointerException(); forkOrSubmit(task); return task; } /** * @throws NullPointerException if the task is null * @throws RejectedExecutionException if the task cannot be * scheduled for execution */ public &lt;T&gt; ForkJoinTask&lt;T&gt; submit(Callable&lt;T&gt; task) { if (task == null) throw new NullPointerException(); ForkJoinTask&lt;T&gt; job = ForkJoinTask.adapt(task); forkOrSubmit(job); return job; } /** * @throws NullPointerException if the task is null * @throws RejectedExecutionException if the task cannot be * scheduled for execution */ public &lt;T&gt; ForkJoinTask&lt;T&gt; submit(Runnable task, T result) { if (task == null) throw new NullPointerException(); ForkJoinTask&lt;T&gt; job = ForkJoinTask.adapt(task, result); forkOrSubmit(job); return job; } /** * @throws NullPointerException if the task is null * @throws RejectedExecutionException if the task cannot be * scheduled for execution */ public ForkJoinTask&lt;?&gt; submit(Runnable task) { if (task == null) throw new NullPointerException(); ForkJoinTask&lt;?&gt; job; if (task instanceof ForkJoinTask&lt;?&gt;) // avoid re-wrap job = (ForkJoinTask&lt;?&gt;) task; else job = ForkJoinTask.adapt(task, null); forkOrSubmit(job); return job; } ForkJoinPool中定义了一些列重载的submit()，这些submit()在ForkJoinTask内部会先将Callable、Runnable包装(适配)成ForkJoinTask，然后再进行提交。 ForkJoinTask#adapt()12345678910111213141516171819202122232425262728293031323334353637/** * Returns a new {@code ForkJoinTask} that performs the {@code run} * method of the given {@code Runnable} as its action, and returns * a null result upon {@link #join}. * * @param runnable the runnable action * @return the task */ public static ForkJoinTask&lt;?&gt; adapt(Runnable runnable) { return new AdaptedRunnable&lt;Void&gt;(runnable, null); } /** * Returns a new {@code ForkJoinTask} that performs the {@code run} * method of the given {@code Runnable} as its action, and returns * the given result upon {@link #join}. * * @param runnable the runnable action * @param result the result upon completion * @return the task */ public static &lt;T&gt; ForkJoinTask&lt;T&gt; adapt(Runnable runnable, T result) { return new AdaptedRunnable&lt;T&gt;(runnable, result); } /** * Returns a new {@code ForkJoinTask} that performs the {@code call} * method of the given {@code Callable} as its action, and returns * its result upon {@link #join}, translating any checked exceptions * encountered into {@code RuntimeException}. * * @param callable the callable action * @return the task */ public static &lt;T&gt; ForkJoinTask&lt;T&gt; adapt(Callable&lt;? extends T&gt; callable) { return new AdaptedCallable&lt;T&gt;(callable); } ForkJoinTask#AdaptedCallable()Callable会包装成一个AdaptedCallable。12345678910111213141516171819202122232425262728/** * Adaptor for Callables */ static final class AdaptedCallable&lt;T&gt; extends ForkJoinTask&lt;T&gt; implements RunnableFuture&lt;T&gt; { final Callable&lt;? extends T&gt; callable; T result; AdaptedCallable(Callable&lt;? extends T&gt; callable) { if (callable == null) throw new NullPointerException(); this.callable = callable; } public T getRawResult() { return result; } public void setRawResult(T v) { result = v; } public boolean exec() { try { result = callable.call(); return true; } catch (Error err) { throw err; } catch (RuntimeException rex) { throw rex; } catch (Exception ex) { throw new RuntimeException(ex); } } public void run() { invoke(); } private static final long serialVersionUID = 2838392045355241008L; } ForkJoinTask#AdaptedRunnable()Runnable会包装成一个AdaptedRunnable。12345678910111213141516171819202122232425/** * Adaptor for Runnables. This implements RunnableFuture * to be compliant with AbstractExecutorService constraints * when used in ForkJoinPool. */static final class AdaptedRunnable&lt;T&gt; extends ForkJoinTask&lt;T&gt; implements RunnableFuture&lt;T&gt; { final Runnable runnable; final T resultOnCompletion; T result; AdaptedRunnable(Runnable runnable, T result) { if (runnable == null) throw new NullPointerException(); this.runnable = runnable; this.resultOnCompletion = result; } public T getRawResult() { return result; } public void setRawResult(T v) { result = v; } public boolean exec() { runnable.run(); result = resultOnCompletion; return true; } public void run() { invoke(); } private static final long serialVersionUID = 5232453952276885070L;} ForkJoinPool#forkOrSubmit()123456789101112131415/** * Unless terminating, forks task if within an ongoing FJ * computation in the current pool, else submits as external task. */ private &lt;T&gt; void forkOrSubmit(ForkJoinTask&lt;T&gt; task) { ForkJoinWorkerThread w; Thread t = Thread.currentThread(); if (shutdown) throw new RejectedExecutionException(); if ((t instanceof ForkJoinWorkerThread) &amp;&amp; (w = (ForkJoinWorkerThread)t).pool == this) w.pushTask(task); else addSubmission(task); } 如果当前线程是ForkJoin工作线程，说明是在ForkJoinTask内部提交的任务(比如分裂出子任务然后提交执行)，这种情况下会将任务添加到工作线程的任务队列中；如果当前线程不是ForkJoin工作线程，说明是初始提交ForkJoin任务(外部将ForkJoinTask初次提交给ForkJoinPool)，这种情况下会将任务添加到ForkJoinPool的任务队列中。 ForkJoinPool#addSubmission()123456789101112131415161718192021222324252627/** * Enqueues the given task in the submissionQueue. Same idea as * ForkJoinWorkerThread.pushTask except for use of submissionLock. * * @param t the task */ private void addSubmission(ForkJoinTask&lt;?&gt; t) { final ReentrantLock lock = this.submissionLock; lock.lock(); try { ForkJoinTask&lt;?&gt;[] q; int s, m; if ((q = submissionQueue) != null) { // ignore if queue removed // 1 long u = (((s = queueTop) &amp; (m = q.length-1)) &lt;&lt; ASHIFT)+ABASE; // 2 UNSAFE.putOrderedObject(q, u, t); queueTop = s + 1; if (s - queueBase == m) // 3 growSubmissionQueue(); } } finally { lock.unlock(); } // 4 signalWork(); } 标注代码分析 这步计算内存偏移地址。 将t设置到q的对应位置。(LazySet) 如果队列满了，扩展队列。 唤醒工作线程。 addSubmission()添加一个任务到提交任务队列(过程要加锁)，如果队列满了，扩展一下。然后唤醒工作线程。这时候是非fork-join提交任务。在forkOrSubmit()中一定会走addSubmission()的分支。代码可以看到通过Unsafe设置Task到数组的方式，之后所有的设置任务到数组都会采取这种方式，之所以这样做是为了提高性能：这种方式其实和数组原子量(AtomicReferenceArray)中一致，但减少了2方面的性能损耗。 不用像AtomicReferenceArray内部一样再做边界检测(由外部保证)。 由于队列最大容量的限制(工作线程中的任务队列也一样)，不用像AtomicReferenceArray一样在计算偏移量过程中不会进行从int到long的提升。ForkJoinPool#growSubmissionQueue()12345678910111213141516171819202122232425/** * Creates or doubles submissionQueue array. * Basically identical to ForkJoinWorkerThread version. */ private void growSubmissionQueue() { ForkJoinTask&lt;?&gt;[] oldQ = submissionQueue; int size = oldQ != null ? oldQ.length &lt;&lt; 1 : INITIAL_QUEUE_CAPACITY; if (size &gt; MAXIMUM_QUEUE_CAPACITY) throw new RejectedExecutionException(\"Queue capacity exceeded\"); if (size &lt; INITIAL_QUEUE_CAPACITY) size = INITIAL_QUEUE_CAPACITY; ForkJoinTask&lt;?&gt;[] q = submissionQueue = new ForkJoinTask&lt;?&gt;[size]; int mask = size - 1; int top = queueTop; int oldMask; if (oldQ != null &amp;&amp; (oldMask = oldQ.length - 1) &gt;= 0) { for (int b = queueBase; b != top; ++b) { long u = ((b &amp; oldMask) &lt;&lt; ASHIFT) + ABASE; Object x = UNSAFE.getObjectVolatile(oldQ, u); if (x != null &amp;&amp; UNSAFE.compareAndSwapObject(oldQ, u, x, null)) UNSAFE.putObjectVolatile (q, ((b &amp; mask) &lt;&lt; ASHIFT) + ABASE, x); } } } 很容易看懂，最小容量为INITIAL_QUEUE_CAPACITY = 8，每次扩展为原来的2倍，最大不能超过MAXIMUM_QUEUE_CAPACITY = 1 &lt;&lt; 24(16777216)。现在任务已经提交到ForkJoinPool#submissionQueue()。还会执行一个唤醒工作线程的动作，这样就会有工作线程来执行我们提交的任务了。 ForkJoinPool#signalWork()1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950/** * Wakes up or creates a worker. */ final void signalWork() { /* * The while condition is true if: (there is are too few total * workers OR there is at least one waiter) AND (there are too * few active workers OR the pool is terminating). The value * of e distinguishes the remaining cases: zero (no waiters) * for create, negative if terminating (in which case do * nothing), else release a waiter. The secondary checks for * release (non-null array etc) can fail if the pool begins * terminating after the test, and don't impose any added cost * because JVMs must perform null and bounds checks anyway. */ long c; int e, u; // 0 while ((((e = (int)(c = ctl)) | (u = (int)(c &gt;&gt;&gt; 32))) &amp; (INT_SIGN|SHORT_SIGN)) == (INT_SIGN|SHORT_SIGN) &amp;&amp; e &gt;= 0) { if (e &gt; 0) { // release a waiting worker // 1 int i; ForkJoinWorkerThread w; ForkJoinWorkerThread[] ws; // 2 if ((ws = workers) == null || (i = ~e &amp; SMASK) &gt;= ws.length || (w = ws[i]) == null) break; // 3 long nc = (((long)(w.nextWait &amp; E_MASK)) | ((long)(u + UAC_UNIT) &lt;&lt; 32)); if (w.eventCount == e &amp;&amp; UNSAFE.compareAndSwapLong(this, ctlOffset, c, nc)) { // 4 w.eventCount = (e + EC_UNIT) &amp; E_MASK; if (w.parked) // 5 UNSAFE.unpark(w); break; } }//6 else if (UNSAFE.compareAndSwapLong (this, ctlOffset, c, (long)(((u + UTC_UNIT) &amp; UTC_MASK) | ((u + UAC_UNIT) &amp; UAC_MASK)) &lt;&lt; 32)) { // 8 addWorker(); break; } } } 标注代码分析 唤醒一个等待的工作线程。 等待工作线程的下标比workers的size大||获取不到等待线程。 将Treiber stack中下一个等待线程的信息(下标)放到控制信息上||控制信息上添加一个AC计数。 累加w的等待次数。 唤醒w。 添加一个工作线程。CAS操作累加控制信息上AC和TC。 添加工作线程。 signalWork标注0while循环内部由e来区分，当e==0，表示当前没有等待的工作线程，这种情况下要创建一个工作线程；当e&gt;0，说明当前有等待线程，这种情况下唤醒一下等待的工作线程。 e&gt;=0前代码 当e的第32位bit为1或者u的第32位bit为1 并且 e的第16位bit为1或者u的第16位bit为1，结合上一篇我们了解到的ForkJoinPool中的控制信息可知。 e的第32位bit为1，说明ST为1，表示当前ForkJoinPool正在关闭。 u的第32位bit为1，说明AC为负数，表示没有足够多的活动的工作线程。 e的第16位bit为1，说明ID为负数，表示至少有一个等待线程。 u的第16位bit为1，说明TC为负数，表示没有足够多的(总的)工作线程。e&gt;=0代码 排除了当前ForkJoinPool正在关闭的情况。ForkJoinPool#addWorker()新创建的Pool，里面还没有工作线程，所以signalWork()中一定会走添加工作线程的流程。1234567891011121314151617181920212223242526272829/** * Tries to create and start a worker; minimally rolls back counts * on failure. */ private void addWorker() { Throwable ex = null; ForkJoinWorkerThread t = null; try { t = factory.newThread(this); } catch (Throwable e) { ex = e; } if (t == null) { // null or exceptional factory return // 1 long c; // adjust counts do {} while (!UNSAFE.compareAndSwapLong (this, ctlOffset, c = ctl, (((c - AC_UNIT) &amp; AC_MASK) | ((c - TC_UNIT) &amp; TC_MASK) | (c &amp; ~(AC_MASK|TC_MASK))))); // Propagate exception if originating from an external caller // 2 if (!tryTerminate(false) &amp;&amp; ex != null &amp;&amp; !(Thread.currentThread() instanceof ForkJoinWorkerThread)) UNSAFE.throwException(ex); } else // 3 t.start(); } 标注代码分析 如果发生了异常导致工作线程创建失败，需要把之前累加的到控制信息的AC和TC计数减回去。 如果调用来之外部，需要将异常传递出去。 创建成功的话，启动工作线程。ForkJoinPool#ForkJoinWorkerThreadFactory#newThread()工作线程的创建过程。调用ForkJoinWorkerThread的构造方法。1234567891011121314151617181920212223242526/** * Factory for creating new {@link ForkJoinWorkerThread}s. * A {@code ForkJoinWorkerThreadFactory} must be defined and used * for {@code ForkJoinWorkerThread} subclasses that extend base * functionality or initialize threads with different contexts. */ public static interface ForkJoinWorkerThreadFactory { /** * Returns a new worker thread operating in the given pool. * * @param pool the pool this thread works in * @throws NullPointerException if the pool is null */ public ForkJoinWorkerThread newThread(ForkJoinPool pool); } /** * Default ForkJoinWorkerThreadFactory implementation; creates a * new ForkJoinWorkerThread. */ static class DefaultForkJoinWorkerThreadFactory implements ForkJoinWorkerThreadFactory { public ForkJoinWorkerThread newThread(ForkJoinPool pool) { return new ForkJoinWorkerThread(pool); } } ForkJoinPool#nextWorkerName()设置线程名称123456789101112131415/** * Counter for worker Thread names (unrelated to their poolIndex) */ private volatile int nextWorkerNumber; /** * Callback from ForkJoinWorkerThread constructor to assign a * public name */ final String nextWorkerName() { for (int n;;) { if (UNSAFE.compareAndSwapInt(this, nextWorkerNumberOffset, n = nextWorkerNumber, ++n)) return workerNamePrefix + n; } } ForkJoinPool#registerWorker()ForkJoinWorkerThread注册到ForkJoinPool。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152/** * Callback from ForkJoinWorkerThread constructor to * determine its poolIndex and record in workers array. * * @param w the worker * @return the worker's pool index */ final int registerWorker(ForkJoinWorkerThread w) { /* * In the typical case, a new worker acquires the lock, uses * next available index and returns quickly. Since we should * not block callers (ultimately from signalWork or * tryPreBlock) waiting for the lock needed to do this, we * instead help release other workers while waiting for the * lock. */ for (int g;;) { ForkJoinWorkerThread[] ws; // 1 if (((g = scanGuard) &amp; SG_UNIT) == 0 &amp;&amp; UNSAFE.compareAndSwapInt(this, scanGuardOffset, g, g | SG_UNIT)) { int k = nextWorkerIndex; try { if ((ws = workers) != null) { // ignore on shutdown int n = ws.length; if (k &lt; 0 || k &gt;= n || ws[k] != null) { for (k = 0; k &lt; n &amp;&amp; ws[k] != null; ++k) ; if (k == n) ws = workers = Arrays.copyOf(ws, n &lt;&lt; 1); } ws[k] = w; nextWorkerIndex = k + 1; int m = g &amp; SMASK; g = (k &gt; m) ? ((m &lt;&lt; 1) + 1) &amp; SMASK : g + (SG_UNIT&lt;&lt;1); } } finally { scanGuard = g; } return k; } else if ((ws = workers) != null) { // help release others for (ForkJoinWorkerThread u : ws) { if (u != null &amp;&amp; u.queueBase != u.queueTop) { if (tryReleaseWaiter()) break; } } } } } 标注代码分析 如果当前scanGuard中没有SG_UNIT标记，尝试设置SG_UNIT标记。这是一个加锁的过程。registerWorker()registerWorker()的主要逻辑就是要注册一个工作线程到ForkJoinPool，然后返回工作线程在Pool内部工作线程数组的下标。说明一下。 方法内部的主流程(无限循环)中，首先尝试获取一个顺序锁。如果获取失败，会遍历下所有的工作线程，如果发现有工作线程的任务队列里还有未处理的任务，就会尝试唤醒等待的工作线程，然后再尝试去获取顺序锁。 如果获取顺序锁成功，内部会将传入的工作线程设置到相应的位置(必要的时候工作线程数组需要扩容)，然后返回下标。过程中会调整scanGuard的低16比特。 这里再次分析一下scanGuard这个神奇的域。 它的高16位用来做顺序锁，我们看到在主流程中首先会查看scanGuard中是否含有SG_UNIT对应的bit信息，如果有说明已经有其他线程持有这个锁了；如果没有，就可以通过一个CAS操作来获取这个锁，获取动作就是给scanGuard上添加上SG_UNIT对应的bit信息，在内部完成逻辑后会清除scanGuard上的SG_UNIT信息。 它的低16位就像它的命名一样，表示扫描的边界。上面的代码中可以看到，在注册工作线程时候会调整这个边界值，规律是这样，边界值的大小=比当前工作线程最大下标大的最小的2的幂减1(有点绕，不要晕)，举几个栗子：maxIndex=5，guard=7、maxIndex=10，guard=15，看出规律了吧。这个值的作用是为了避免不必要的扫描，因为Pool内部的工作线程数组size可能比较大(初始化的时候就比并行度要大很多，回去看下Pool的构造方法。而且还有可能扩展)，但实际的工作线程数量可能比较小(比如可能数组size是16，但里面只有4个工作线程，14个空位)，如果扫描的时候扫描范围是全部数组，那一定会在空位上浪费很多时间，有了这个guard作为边界(而不是数组的length-1)，会避免这些时间的浪费。ForkJoinWorkerThread#run()ForkJoinPool#addWorker()的t.start()，实际上是执行ForkJoinWorkerThread#run()。12345678910111213141516/** * This method is required to be public, but should never be * called explicitly. It performs the main run loop to execute * {@link ForkJoinTask}s. */ public void run() { Throwable exception = null; try { onStart(); pool.work(this); } catch (Throwable ex) { exception = ex; } finally { onTermination(exception); } } 启动前回调下onStart()，然后是主流程(pool#work)，如果方法结束，还会回调下onTermination()。 ForkJoinWorkerThread#onStart()1234567891011121314151617/** * Initializes internal state after construction but before * processing any tasks. If you override this method, you must * invoke {@code super.onStart()} at the beginning of the method. * Initialization requires care: Most fields must have legal * default values, to ensure that attempted accesses from other * threads work correctly even before this thread starts * processing tasks. */ protected void onStart() { // 1 queue = new ForkJoinTask&lt;?&gt;[INITIAL_QUEUE_CAPACITY]; // 2 int r = pool.workerSeedGenerator.nextInt(); // 3 seed = (r == 0) ? 1 : r; // must be nonzero } 标注代码分析 初始化工作线程的任务队列。 生成工作线程的种子。 确保种子不为0。ForkJoinWorkerThread#onTermination()123456789101112131415161718192021222324/** * Performs cleanup associated with termination of this worker * thread. If you override this method, you must invoke * {@code super.onTermination} at the end of the overridden method. * * @param exception the exception causing this thread to abort due * to an unrecoverable error, or {@code null} if completed normally */ protected void onTermination(Throwable exception) { try { // 1 terminate = true; // 2 cancelTasks(); // 3 pool.deregisterWorker(this, exception); } catch (Throwable ex) { // Shouldn't ever happen if (exception == null) // but if so, at least rethrown exception = ex; } finally { if (exception != null) UNSAFE.throwException(exception); } } 标注代码分析 设置关闭标志。 取消任务。 从ForkJoinPool上注销当前工作线程。ForkJoinPool#workForkJoinWorkerThread#run()中pool#work(this)12345678910111213141516171819202122/** * Top-level loop for worker threads: On each step: if the * previous step swept through all queues and found no tasks, or * there are excess threads, then possibly blocks. Otherwise, * scans for and, if found, executes a task. Returns when pool * and/or worker terminate. * * @param w the worker */ final void work(ForkJoinWorkerThread w) { boolean swept = false; // true on empty scans long c; // 1 while (!w.terminate &amp;&amp; (int)(c = ctl) &gt;= 0) { int a; // active count // 2 if (!swept &amp;&amp; (a = (int)(c &gt;&gt; AC_SHIFT)) &lt;= 0) swept = scan(w, a); else if (tryAwaitWork(w, c))// 3 swept = false; } } 标注代码分析 while条件就是当前工作线程未结束且pool未关闭。while循环中，会不断的扫描(scan)或等待(tryAwaitWork)。 如果扫描标志(起始为false)表示上一次扫描不是空扫描(false)，并且当前活动线程数量小于处理器核数(这里要注意下，返回去在看下控制信息中AC的定义)，那么执行scan(w, a)。 当前没有任务需要执行的任务 或者 当前活动的线程数量已经大于处理器核心数。进行等待(tryAwaitWork(w, c))。ForkJoinPool#scan()1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677/** * Scans for and, if found, executes one task. Scans start at a * random index of workers array, and randomly select the first * (2*#workers)-1 probes, and then, if all empty, resort to 2 * circular sweeps, which is necessary to check quiescence. and * taking a submission only if no stealable tasks were found. The * steal code inside the loop is a specialized form of * ForkJoinWorkerThread.deqTask, followed bookkeeping to support * helpJoinTask and signal propagation. The code for submission * queues is almost identical. On each steal, the worker completes * not only the task, but also all local tasks that this task may * have generated. On detecting staleness or contention when * trying to take a task, this method returns without finishing * sweep, which allows global state rechecks before retry. * * @param w the worker * @param a the number of active workers * @return true if swept all queues without finding a task */ private boolean scan(ForkJoinWorkerThread w, int a) { int g = scanGuard; // mask 0 avoids useless scans if only one active // 1 int m = (parallelism == 1 - a &amp;&amp; blockedCount == 0) ? 0 : g &amp; SMASK; ForkJoinWorkerThread[] ws = workers; if (ws == null || ws.length &lt;= m) // staleness check return false; for (int r = w.seed, k = r, j = -(m + m); j &lt;= m + m; ++j) { ForkJoinTask&lt;?&gt; t; ForkJoinTask&lt;?&gt;[] q; int b, i; // 2 ForkJoinWorkerThread v = ws[k &amp; m]; if (v != null &amp;&amp; (b = v.queueBase) != v.queueTop &amp;&amp; (q = v.queue) != null &amp;&amp; (i = (q.length - 1) &amp; b) &gt;= 0) { // 3 long u = (i &lt;&lt; ASHIFT) + ABASE; if ((t = q[i]) != null &amp;&amp; v.queueBase == b &amp;&amp; UNSAFE.compareAndSwapObject(q, u, t, null)) { // 4 int d = (v.queueBase = b + 1) - v.queueTop; // 5 v.stealHint = w.poolIndex; if (d != 0) // 6 signalWork(); // propagate if nonempty w.execTask(t); } // 7 r ^= r &lt;&lt; 13; r ^= r &gt;&gt;&gt; 17; w.seed = r ^ (r &lt;&lt; 5); // 不是一个空扫描 return false; // store next seed } else if (j &lt; 0) { // xorshift // 8 r ^= r &lt;&lt; 13; r ^= r &gt;&gt;&gt; 17; k = r ^= r &lt;&lt; 5; } else // 9 ++k; } if (scanGuard != g) // staleness check return false; else { // try to take submission // 10 ForkJoinTask&lt;?&gt; t; ForkJoinTask&lt;?&gt;[] q; int b, i; if ((b = queueBase) != queueTop &amp;&amp; (q = submissionQueue) != null &amp;&amp; (i = (q.length - 1) &amp; b) &gt;= 0) { long u = (i &lt;&lt; ASHIFT) + ABASE; if ((t = q[i]) != null &amp;&amp; queueBase == b &amp;&amp; UNSAFE.compareAndSwapObject(q, u, t, null)) { queueBase = b + 1; w.execTask(t); } return false; } // 11 return true; // all queues empty } } 标注代码分析 如果当前只有一个工作线程，将m设置为0，避免没用的扫描。否则获取guard值。 随机选出一个牺牲者(工作线程)。 如果这个牺牲者的任务队列中还有任务，尝试窃取这个任务。 窃取成功后，调整queueBase。 将牺牲者的stealHint设置为当前工作线程在pool中的下标。 如果牺牲者的任务队列还有任务，继续唤醒(或创建)线程。 计算出下一个随机种子。 前2*m次，随机扫描。 后2*m次，顺序扫描。 如果扫描完毕后没找到可窃取的任务，那么从Pool的提交任务队列中取一个任务来执行。 如果所有的队列(工作线程的任务队列和pool的任务队列)都是空的，返回true。scan() 需要确定扫描边界值m，如果当前只有一个工作线程，那么m就为0，避免多余的扫描；如果当前有多个工作线程，那么m就是scanGuard的低16位表示的值(去前面看看scanGuard)。 确定m以后，开始一个for循环进行扫描。扫描的目的就是要通过工作线程的seed(这个域之前没提，使用来选择一个窃取牺牲者的)算出一个牺牲者(victim)的下标，牺牲者也是一个工作线程，然后当前工作线程便会从牺牲者的任务队列里面窃取一个任务来执行。当然如果算出的下标对应的位置上没有牺牲者(工作线程)，或者牺牲者的任务队列里没有任务，就会进行下一次尝试。整个for循环最多会尝试4*m次，前2*m次是随机算下标，每次会通过xorshift算法来生成新的k。后2*m次是顺序递增k来算下标。 如果for循环结束了还没有扫描到任务，那么就会从Pool的submissionQueue中窃取一个任务来执行了。ForkJoinWorkerThread#execTask()由于是初始提交，scan()中一定是从ForkJoinPool#submissionQueue()中获取提交的任务，然后执行execTask()。12345678910111213141516171819/** * Runs the given task, plus any local tasks until queue is empty */ final void execTask(ForkJoinTask&lt;?&gt; t) { currentSteal = t; for (;;) { if (t != null) // 1 t.doExec(); // 2 if (queueTop == queueBase) break; // 3 t = locallyFifo ? locallyDeqTask() : popTask(); } // 4 ++stealCount; currentSteal = null; } 标注代码分析 执行任务。 如果当前工作线程的任务队列里没有任务了，退出循环。 根据模式来获取任务。如果Pool中指定为异步模式，这里从当前任务队列的尾部获取任务；否则，从任务队列头部获取任务。 最后累加窃取任务计数。ForJoinTask#doExec()123456789101112131415161718192021/** * Primary execution method for stolen tasks. Unless done, calls * exec and records status if completed, but doesn't wait for * completion otherwise. */ final void doExec() { if (status &gt;= 0) { boolean completed; try { // 1 completed = exec(); } catch (Throwable rex) { // 2 setExceptionalCompletion(rex); return; } if (completed) // 3 setCompletion(NORMAL); // must be outside try block } } 标注代码分析 调用exec()执行任务。 设置异常完成结果。 设置正常完成结果。 ForJoinTask#exec()是一个抽象方法，具体执行逻辑交给子类去实现，前面看到的适配类AdaptedRunnable和AdaptedCallable里面，会在exec()里面分别调用runnable#run()和callable#call()；而在ForJoinTask的两个子类RecursiveAction和RecursiveTask里面，exec()里面调用的是compute()。 RecursiveAction#exec()1234567/** * Implements execution conventions for RecursiveActions. */ protected final boolean exec() { compute(); return true; } RecursiveAction#compute()1234/** * The main computation performed by this task. */protected abstract void compute(); RecursiveTask#exec()1234567/** * Implements execution conventions for RecursiveTask. */ protected final boolean exec() { result = compute(); return true; } RecursiveTask#compute()1234/** * The main computation performed by this task. */protected abstract V compute(); ForJoinTask#exec()有返回值，表示任务是否执行完毕。doExec()中会根据这个返回值来设置任务的完成状态，如果任务正常完成，会调用setCompletion(NORMAL)。 ForkJoinTask#setCompletion()12345678910111213141516171819202122volatile int status; // accessed directly by pool and workersprivate static final int NORMAL = -1;/** * Marks completion and wakes up threads waiting to join this task, * also clearing signal request bits. * * @param completion one of NORMAL, CANCELLED, EXCEPTIONAL * @return completion status on exit */private int setCompletion(int completion) { for (int s;;) { if ((s = status) &lt; 0) return s; // 1 if (UNSAFE.compareAndSwapInt(this, statusOffset, s, completion)) { if (s != 0) // 2 synchronized (this) { notifyAll(); } return completion; } }} 标注代码分析 尝试将任务状态设置为正常完成。 同时唤醒合并当前任务的等待线程。ForkJoinTask#setExceptionalCompletion()doExec()中如果执行exec()发生异常，会调用setExceptionalCompletion()来设置异常完成状态。123456789101112131415161718192021222324252627282930/** * Records exception and sets exceptional completion. * * @return status on exit */ private int setExceptionalCompletion(Throwable ex) { // 1 int h = System.identityHashCode(this); final ReentrantLock lock = exceptionTableLock; lock.lock(); try { // 2 expungeStaleExceptions(); // 3 ExceptionNode[] t = exceptionTable; // 4 int i = h &amp; (t.length - 1); for (ExceptionNode e = t[i]; ; e = e.next) { if (e == null) { t[i] = new ExceptionNode(this, ex, t[i]); break; } if (e.get() == this) // already present break; } } finally { lock.unlock(); } return setCompletion(EXCEPTIONAL); } 标注代码分析 计算当前对象的原生hashCode。 删除异常表中过期的异常。 获取异常数组。 通过当前对象hashCode获取在异常表中的下标。 注意到setExceptionalCompletion()中最后还是调用setCompletion，但之前会做一下将异常放入一个异常表的工作。看到这里可能会有疑问，我们通过2个问题来了解下这个异常表。 这里为什么会有一个异常表呢？因为异常很少发生，所以没有将异常保存在任务对象内，而是放在一个弱引用异常表里(异常表里不会保存取消异常)。 异常表的结构是怎么样的呢？这里的异常表结构上是一个哈希表，每个桶里是单链，弱引用Key。 Exception table1234567891011121314151617181920212223242526272829303132333435363738394041/** * Table of exceptions thrown by tasks, to enable reporting by * callers. Because exceptions are rare, we don't directly keep * them with task objects, but instead use a weak ref table. Note * that cancellation exceptions don't appear in the table, but are * instead recorded as status values. * * Note: These statics are initialized below in static block. */ private static final ExceptionNode[] exceptionTable; private static final ReentrantLock exceptionTableLock; private static final ReferenceQueue&lt;Object&gt; exceptionTableRefQueue; /** * Fixed capacity for exceptionTable. */ private static final int EXCEPTION_MAP_CAPACITY = 32; /** * Key-value nodes for exception table. The chained hash table * uses identity comparisons, full locking, and weak references * for keys. The table has a fixed capacity because it only * maintains task exceptions long enough for joiners to access * them, so should never become very large for sustained * periods. However, since we do not know when the last joiner * completes, we must use weak references and expunge them. We do * so on each operation (hence full locking). Also, some thread in * any ForkJoinPool will call helpExpungeStaleExceptions when its * pool becomes isQuiescent. */ static final class ExceptionNode extends WeakReference&lt;ForkJoinTask&lt;?&gt;&gt;{ final Throwable ex; ExceptionNode next; final long thrower; // use id not ref to avoid weak cycles ExceptionNode(ForkJoinTask&lt;?&gt; task, Throwable ex, ExceptionNode next) { super(task, exceptionTableRefQueue); this.ex = ex; this.next = next; this.thrower = Thread.currentThread().getId(); } } 123456789101112131415// Unsafe mechanics private static final sun.misc.Unsafe UNSAFE; private static final long statusOffset; static { exceptionTableLock = new ReentrantLock(); exceptionTableRefQueue = new ReferenceQueue&lt;Object&gt;(); exceptionTable = new ExceptionNode[EXCEPTION_MAP_CAPACITY]; try { UNSAFE = sun.misc.Unsafe.getUnsafe(); statusOffset = UNSAFE.objectFieldOffset (ForkJoinTask.class.getDeclaredField(\"status\")); } catch (Exception e) { throw new Error(e); } } 继续流程，执行完doExec()，方法返回到execTask()，接下来由于当前工作线程自身的任务队列中并没有任务，所以queueTop == queueBase成立，execTask()退出到scan()，scan()返回false到ForkJoinPool#work()，进行下一次扫描(scan)，由于工作线程本身的任务队列和Pool的任务队列都为空，所以下一次扫描一定是个空扫描，然后程序会走到work()的tryAwaitWork分支，看下tryAwaitWork()。 ForkJoinPool#tryAwaitWork()12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091/** * Tries to enqueue worker w in wait queue and await change in * worker's eventCount. If the pool is quiescent and there is * more than one worker, possibly terminates worker upon exit. * Otherwise, before blocking, rescans queues to avoid missed * signals. Upon finding work, releases at least one worker * (which may be the current worker). Rescans restart upon * detected staleness or failure to release due to * contention. Note the unusual conventions about Thread.interrupt * here and elsewhere: Because interrupts are used solely to alert * threads to check termination, which is checked here anyway, we * clear status (using Thread.interrupted) before any call to * park, so that park does not immediately return due to status * being set via some other unrelated call to interrupt in user * code. * * @param w the calling worker * @param c the ctl value on entry * @return true if waited or another thread was released upon enq */ private boolean tryAwaitWork(ForkJoinWorkerThread w, long c) { int v = w.eventCount; // 1 w.nextWait = (int)c; // w's successor record // 2 long nc = (long)(v &amp; E_MASK) | ((c - AC_UNIT) &amp; (AC_MASK|TC_MASK)); if (ctl != c || !UNSAFE.compareAndSwapLong(this, ctlOffset, c, nc)) { long d = ctl; // return true if lost to a deq, to force scan // 3 return (int)d != (int)c &amp;&amp; ((d - c) &amp; AC_MASK) &gt;= 0L; } for (int sc = w.stealCount; sc != 0;) { // accumulate stealCount // 4 long s = stealCount; if (UNSAFE.compareAndSwapLong(this, stealCountOffset, s, s + sc)) sc = w.stealCount = 0; else if (w.eventCount != v) // 5 return true; // update next time } // 6 if ((!shutdown || !tryTerminate(false)) &amp;&amp; (int)c != 0 &amp;&amp; parallelism + (int)(nc &gt;&gt; AC_SHIFT) == 0 &amp;&amp; blockedCount == 0 &amp;&amp; quiescerCount == 0) // 7 idleAwaitWork(w, nc, c, v); // quiescent for (boolean rescanned = false;;) { if (w.eventCount != v) // 8 return true; if (!rescanned) { int g = scanGuard, m = g &amp; SMASK; ForkJoinWorkerThread[] ws = workers; if (ws != null &amp;&amp; m &lt; ws.length) { rescanned = true; // 9 for (int i = 0; i &lt;= m; ++i) { ForkJoinWorkerThread u = ws[i]; if (u != null) { if (u.queueBase != u.queueTop &amp;&amp; !tryReleaseWaiter()) // 10 rescanned = false; // contended if (w.eventCount != v) return true; } } } // 11 if (scanGuard != g || // stale (queueBase != queueTop &amp;&amp; !tryReleaseWaiter())) rescanned = false; if (!rescanned) // 12 Thread.yield(); // reduce contention else // 13 Thread.interrupted(); // clear before park } else { // 14 w.parked = true; // must recheck if (w.eventCount != v) { w.parked = false; return true; } LockSupport.park(this); rescanned = w.parked = false; } } } 标注代码分析 w#nextWait保存的是等待之前Pool的控制信息。 这里是将当前线程的ID信息(下标取反)记录到Pool控制信息上,同时将控制信息上的活动工作线程计数减1。 如果和另外的一个窃取线程竞争并失败，这里返回true，work()中会继续扫描。 将工作线程上的stealCount原子累加到Pool#stealCount上面。 如果eventCount发生变化，重试。 Pool未关闭且有工作线程且活动的工作线程数量等于cpu核心数量，且没有工作线程在合并过程中阻塞且没有工作线程休眠。 如果满足条件，说明当前Pool休眠，需要调用下idleAwaitWork进行处理。 如果eventCount发生变化，重试。 这里再重新扫描一下，如果从其他工作线程任务队列里找到任务，尝试唤醒等待的工作线程。 发生竞争，再次扫描。 scanGuard发生变化或者从Pool任务队列中找到任务,再次扫描。 出让cpu，减少竞争。 park前清除中断标记。 设置park标记。 这个方法的目的就是阻塞工作线程w，但过程中有一些细节。 首先，方法中要调整Pool的控制信息ctl，将w#ID信息设置到ctl上并将ctl上保存的活动工作线程数量减1。 其次，在阻塞前，还会将w的窃取任务数量累计到Pool的总窃取任务数量(stealCount)上；再次，如果当前Pool正好处理休眠状态，那么要调用idleAwaitWork处理一下(可能会结束工作线程)。 最后，再真正阻塞前还要扫描一下工作线程任务队列和Pool任务队列，如果发现有任务，会尝试唤醒一个等待工作线程(可能是自己)，这个过程要结束时会清除一下当前线程的中断标记，然后进行阻塞(以Pool为Blocker，相当于进入Pool的等待队列)。ForkJoinPool#idleAwaitWork()如果按照流程，到这儿就结束了，工作线程已经执行提交的任务，然后阻塞等待了。但如果当前Pool正好处于休眠状态了，看看会怎么样，继续看下上面方法中调用的idleAwaitWork()。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647/** * If inactivating worker w has caused pool to become * quiescent, check for pool termination, and wait for event * for up to SHRINK_RATE nanosecs (rescans are unnecessary in * this case because quiescence reflects consensus about lack * of work). On timeout, if ctl has not changed, terminate the * worker. Upon its termination (see deregisterWorker), it may * wake up another worker to possibly repeat this process. * * @param w the calling worker * @param currentCtl the ctl value after enqueuing w * @param prevCtl the ctl value if w terminated * @param v the eventCount w awaits change */private void idleAwaitWork(ForkJoinWorkerThread w, long currentCtl, long prevCtl, int v) { if (w.eventCount == v) { if (shutdown) // 1 tryTerminate(false); // 2 ForkJoinTask.helpExpungeStaleExceptions(); // help clean weak refs while (ctl == currentCtl) { long startTime = System.nanoTime(); w.parked = true; if (w.eventCount == v) // must recheck // 3 LockSupport.parkNanos(this, SHRINK_RATE); w.parked = false; if (w.eventCount != v) break; else if (System.nanoTime() - startTime &lt; SHRINK_RATE - (SHRINK_RATE / 10)) // timing slop // 4 Thread.interrupted(); // spurious wakeup else if (UNSAFE.compareAndSwapLong(this, ctlOffset, currentCtl, prevCtl)) {// 5 // 6 w.terminate = true; // restore previous // 7 w.eventCount = ((int)currentCtl + EC_UNIT) &amp; E_MASK; break; } } }} 标注代码分析 如果关闭方法已经被调用，那么调用tryTerminate()。 清理一下异常表中weak key。 阻塞给定时间(4秒)。 如果发生伪唤醒，清除中断标志。 恢复之前的ctl，如果ctl一直没发生变化，会进入if。 结束工作线程,设置结束标志。 设置w#eventCount。 idleAwaitWork()中开始会检测一下Pool是否正在关闭，是的话要调用tryTerminate；否则会先将工作线程w阻塞一段时间(4s)，如果超过了这个时间，Pool的控制信息还没发生变化(说明Pool还是休眠状态)，那么就需要将w结束掉，会设置w的结束标记为true，同时设置w#eventCount，然后退出到tryAwaitWork()，tryAwaitWork()中检测到w#eventCount发生变化，会退出到work()，work()中检测到w的结束标记为true，主循环回退出，工作线程w就要结束了，结束时会调用w#onTermination()。 ForkJoinWorkerThread#onTermination()123456789101112131415161718192021/** * Performs cleanup associated with termination of this worker * thread. If you override this method, you must invoke * {@code super.onTermination} at the end of the overridden method. * * @param exception the exception causing this thread to abort due * to an unrecoverable error, or {@code null} if completed normally */ protected void onTermination(Throwable exception) { try { terminate = true; cancelTasks(); pool.deregisterWorker(this, exception); } catch (Throwable ex) { // Shouldn't ever happen if (exception == null) // but if so, at least rethrown exception = ex; } finally { if (exception != null) UNSAFE.throwException(exception); } } ForkJoinWorkerThread#cancelTasks()取消任务。1234567891011121314151617181920/** * Removes and cancels all tasks in queue. Can be called from any * thread. */ final void cancelTasks() { ForkJoinTask&lt;?&gt; cj = currentJoin; // try to cancel ongoing tasks if (cj != null &amp;&amp; cj.status &gt;= 0) // 1 cj.cancelIgnoringExceptions(); ForkJoinTask&lt;?&gt; cs = currentSteal; if (cs != null &amp;&amp; cs.status &gt;= 0) // 2 cs.cancelIgnoringExceptions(); while (queueBase != queueTop) { // 3 ForkJoinTask&lt;?&gt; t = deqTask(); if (t != null) t.cancelIgnoringExceptions(); } } 标注代码分析 取消正在合并的任务。 取消窃取的任务。 取消工作线程任务队列中的所有任务。 ForkJoinTask#cancel()1234567891011121314151617181920212223242526272829303132333435.....public boolean cancel(boolean mayInterruptIfRunning) { return setCompletion(CANCELLED) == CANCELLED;}/** * Cancels, ignoring any exceptions thrown by cancel. Used during * worker and pool shutdown. Cancel is spec'ed not to throw any * exceptions, but if it does anyway, we have no recourse during * shutdown, so guard against this case. */final void cancelIgnoringExceptions() { try { cancel(false); } catch (Throwable ignore) { }}/** * Marks completion and wakes up threads waiting to join this task, * also clearing signal request bits. * * @param completion one of NORMAL, CANCELLED, EXCEPTIONAL * @return completion status on exit */private int setCompletion(int completion) { for (int s;;) { if ((s = status) &lt; 0) return s; if (UNSAFE.compareAndSwapInt(this, statusOffset, s, completion)) { if (s != 0) synchronized (this) { notifyAll(); } return completion; } }} ForkJoinPool#deregisterWorker()从Pool中注销自己。123456789101112131415161718192021222324252627282930313233343536373839404142434445/** * Final callback from terminating worker. Removes record of * worker from array, and adjusts counts. If pool is shutting * down, tries to complete termination. * * @param w the worker */ final void deregisterWorker(ForkJoinWorkerThread w, Throwable ex) { int idx = w.poolIndex; int sc = w.stealCount; int steps = 0; // Remove from array, adjust worker counts and collect steal count. // We can intermix failed removes or adjusts with steal updates do { long s, c; int g; if (steps == 0 &amp;&amp; ((g = scanGuard) &amp; SG_UNIT) == 0 &amp;&amp; UNSAFE.compareAndSwapInt(this, scanGuardOffset, g, g |= SG_UNIT)) { ForkJoinWorkerThread[] ws = workers; if (ws != null &amp;&amp; idx &gt;= 0 &amp;&amp; idx &lt; ws.length &amp;&amp; ws[idx] == w) ws[idx] = null; // verify nextWorkerIndex = idx; scanGuard = g + SG_UNIT; steps = 1; } if (steps == 1 &amp;&amp; UNSAFE.compareAndSwapLong(this, ctlOffset, c = ctl, (((c - AC_UNIT) &amp; AC_MASK) | ((c - TC_UNIT) &amp; TC_MASK) | (c &amp; ~(AC_MASK|TC_MASK))))) steps = 2; if (sc != 0 &amp;&amp; UNSAFE.compareAndSwapLong(this, stealCountOffset, s = stealCount, s + sc)) sc = 0; } while (steps != 2 || sc != 0); if (!tryTerminate(false)) { if (ex != null) // possibly replace if died abnormally signalWork(); else tryReleaseWaiter(); } } deregisterWorker()中首先在一个while无限循环中完成工作线程注销的工作，包括3个阶段，全部完成后再执行下一步。之所以这样做是由于每个阶段都可能发生竞争，需要重试。 第1阶段，会在获取顺序锁(scanGuard高16位)的情况下将Pool中工作线程对应的数组位置置空，并调整nextWorkerIndex。 第2阶段，将控制信息ctl中的活动工作线程数量和总工作线程数量减1。 第3阶段，将要注销工作线程的窃取任务数量累加到Pool的总窃取任务数量上。 deregisterWorker()在完成注销线程工作后，还有可能会唤醒其他等待线程，首先会调用一下tryTerminate(false)。 ForkJoinPool#tryTerminate()12345678910111213141516171819202122232425262728293031323334/** * Possibly initiates and/or completes termination. * * @param now if true, unconditionally terminate, else only * if shutdown and empty queue and no active workers * @return true if now terminating or terminated */ private boolean tryTerminate(boolean now) { long c; while (((c = ctl) &amp; STOP_BIT) == 0) { if (!now) { if ((int)(c &gt;&gt; AC_SHIFT) != -parallelism) return false; if (!shutdown || blockedCount != 0 || quiescerCount != 0 || queueBase != queueTop) { if (ctl == c) // staleness check return false; continue; } } if (UNSAFE.compareAndSwapLong(this, ctlOffset, c, c | STOP_BIT)) startTerminating(); } if ((short)(c &gt;&gt;&gt; TC_SHIFT) == -parallelism) { // signal when 0 workers final ReentrantLock lock = this.submissionLock; lock.lock(); try { termination.signalAll(); } finally { lock.unlock(); } } return true; } 参数为false参数为false(表示不会马上关闭Pool)，那么实现中会查看是否有活动的工作线程，有的话返回false。然后检查Pool是否还在运行中(包括Pool有没有被关闭、有没有等待合并的工作线程、有没有空闲的工作线程、提交队列中是否有任务等)，如果还在运行中，返回false。 否则会尝试设置关闭标志到控制信息，然后调用startTerminating()。 参数为true参数为true的话也会直接进行这些操作。然后再检测下如果当前总的工作线程为0，就会唤醒在termination条件上等待的线程了。 ForkJoinPool#startTerminating()123456789101112131415161718192021222324252627282930313233343536/** * Runs up to three passes through workers: (0) Setting * termination status for each worker, followed by wakeups up to * queued workers; (1) helping cancel tasks; (2) interrupting * lagging threads (likely in external tasks, but possibly also * blocked in joins). Each pass repeats previous steps because of * potential lagging thread creation. */private void startTerminating() { // 1 cancelSubmissions(); for (int pass = 0; pass &lt; 3; ++pass) { ForkJoinWorkerThread[] ws = workers; if (ws != null) { for (ForkJoinWorkerThread w : ws) { if (w != null) { // 2 w.terminate = true; if (pass &gt; 0) { // 3 w.cancelTasks(); if (pass &gt; 1 &amp;&amp; !w.isInterrupted()) { try { // 4 w.interrupt(); } catch (SecurityException ignore) { } } } } } // 5 terminateWaiters(); } }} 标注代码分析 取消Pool提交任务队列中的任务。 结束工作线程。 取消工作线程中任务队列的任务。 中断工作线程。 结束等待的工作线程。startTerminating流程 取消Pool#submissionQueue中的任务。 将所有的工作线程的结束状态设置为true。 取消所有工作线程的任务队列中未完成的任务。 中断所有工作线程。 结束还在等待的工作线程。ForkJoinPool#cancelSubmissions()1234567891011121314/** * Polls and cancels all submissions. Called only during termination. */ private void cancelSubmissions() { while (queueBase != queueTop) { ForkJoinTask&lt;?&gt; task = pollSubmission(); if (task != null) { try { task.cancel(false); } catch (Throwable ignore) { } } } } ForkJoinPool#pollSubmission()12345678910111213141516171819202122/** * Removes and returns the next unexecuted submission if one is * available. This method may be useful in extensions to this * class that re-assign work in systems with multiple pools. * * @return the next submission, or {@code null} if none */protected ForkJoinTask&lt;?&gt; pollSubmission() { ForkJoinTask&lt;?&gt; t; ForkJoinTask&lt;?&gt;[] q; int b, i; while ((b = queueBase) != queueTop &amp;&amp; (q = submissionQueue) != null &amp;&amp; (i = (q.length - 1) &amp; b) &gt;= 0) { long u = (i &lt;&lt; ASHIFT) + ABASE; if ((t = q[i]) != null &amp;&amp; queueBase == b &amp;&amp; UNSAFE.compareAndSwapObject(q, u, t, null)) { queueBase = b + 1; return t; } } return null;} ForkJoinPool#terminateWaiters()1234567891011121314151617181920212223/** * Tries to set the termination status of waiting workers, and * then wakes them up (after which they will terminate). */ private void terminateWaiters() { ForkJoinWorkerThread[] ws = workers; if (ws != null) { ForkJoinWorkerThread w; long c; int i, e; int n = ws.length; while ((i = ~(e = (int)(c = ctl)) &amp; SMASK) &lt; n &amp;&amp; (w = ws[i]) != null &amp;&amp; w.eventCount == (e &amp; E_MASK)) { if (UNSAFE.compareAndSwapLong(this, ctlOffset, c, (long)(w.nextWait &amp; E_MASK) | ((c + AC_UNIT) &amp; AC_MASK) | (c &amp; (TC_MASK|STOP_BIT)))) { w.terminate = true; w.eventCount = e + EC_UNIT; if (w.parked) UNSAFE.unpark(w); } } } } 隐式的等待工作线程组成的链(也叫Treiber stack)。这里可能猛地一看，方法内部只唤醒了一个等待线程，这个等待线程的ID信息存储在Pool的控制信息中。但仔细看会发现，在设置(调整)ctl的时候，有这句w.nextWait &amp; E_MASK，也就是说，唤醒w之后，ctl里又会有另一个等待工作线程的ID信息(这个信息之前是存在w#nextWait上面的)。deregisterWorker()里，假设当前Pool还在运行，那么tryTerminate(false)返回false，就会执行if里的语句。1234567if (!tryTerminate(false)) { // 1 if (ex != null) // possibly replace if died abnormally signalWork(); else// 2 tryReleaseWaiter();} 标注代码分析 如果有异常发生，会调用signalWork()来唤醒或者创建一个工作线程。 调用tryReleaseWaiter()来尝试唤醒一个等待工作线程。ForkJoinPool#tryReleaseWaiter()1234567891011121314151617181920212223242526272829/** * Variant of signalWork to help release waiters on rescans. * Tries once to release a waiter if active count &lt; 0. * * @return false if failed due to contention, else true */ private boolean tryReleaseWaiter() { long c; int e, i; ForkJoinWorkerThread w; ForkJoinWorkerThread[] ws; // 1 if ((e = (int)(c = ctl)) &gt; 0 &amp;&amp; (int)(c &gt;&gt; AC_SHIFT) &lt; 0 &amp;&amp; (ws = workers) != null &amp;&amp; (i = ~e &amp; SMASK) &lt; ws.length &amp;&amp; (w = ws[i]) != null) { // 2 long nc = ((long)(w.nextWait &amp; E_MASK) | ((c + AC_UNIT) &amp; (AC_MASK|TC_MASK))); if (w.eventCount != e || !UNSAFE.compareAndSwapLong(this, ctlOffset, c, nc)) // 3 return false; // 4 w.eventCount = (e + EC_UNIT) &amp; E_MASK; if (w.parked) // 5 UNSAFE.unpark(w); } return true; } 标注代码分析 (e = (int)(c = ctl)) &gt; 0如果有等待线程,(int)(c &gt;&gt; AC_SHIFT) &lt; 0当前活动线程数小于CPU核数,(ws = workers) != null检测工作线程数组合法性,(i = ~e &amp; SMASK) &lt; ws.length检测控制信息中等待的工作线程的ID信息的合法性,(w = ws[i]) != null检测工作线程的合法性。 尝试调整控制信息，增加活动工作线程计数，将Treiber stack下一个等待线程的ID信息设置到ctl。 如果发生冲突。 累加w#eventCount。 唤醒w。ForkJoinWorkerThread#execTask()123456789101112131415/** * Runs the given task, plus any local tasks until queue is empty */ final void execTask(ForkJoinTask&lt;?&gt; t) { currentSteal = t; for (;;) { if (t != null) t.doExec(); if (queueTop == queueBase) break; t = locallyFifo ? locallyDeqTask() : popTask(); } ++stealCount; currentSteal = null; } 假如执行完t，发现当前工作的任务队列中还有任务，那么接下来就会根据当前Pool的工作模式(是否是同步模式)，来通过locallyDeqTask()或者popTask()获取一个任务出来继续执行。工作线程中的任务队列(Pool中的任务队列也一样)，形式上是一个数组，但概念上是一个双端队列。但和其他双端队列(JDK里另外的双端队列实现)不一样的是，这里的队列只定义了三种操作：从队列首部入队(push)、从队列首部出队(pop)、从队列尾部出队(deg)。这里既然说是队列，但又说什么push、pop可能会让人感觉晕晕的，其实可以这样理解，双端队列就可以看成是栈和队列的混血。结合使用Pool内部工作原理来说，如果不是异步模式(默认)，那么就会把任务队列当成一个FIFO队列来使用；否则就相当于把任务队列当成一个栈来使用。 ForkJoinWorkerThread#popTask()12345678910111213141516171819202122/** * Returns a popped task, or null if empty. * Called only by this thread. */ private ForkJoinTask&lt;?&gt; popTask() { int m; ForkJoinTask&lt;?&gt;[] q = queue; if (q != null &amp;&amp; (m = q.length - 1) &gt;= 0) { for (int s; (s = queueTop) != queueBase;) { int i = m &amp; --s; long u = (i &lt;&lt; ASHIFT) + ABASE; // raw offset ForkJoinTask&lt;?&gt; t = q[i]; if (t == null) // lost to stealer break; if (UNSAFE.compareAndSwapObject(q, u, t, null)) { queueTop = s; // or putOrderedInt return t; } } } return null; } 如果Pool不是异步模式(locallyFifo为false)，那么会执行popTask()。从当前任务队列pop一个任务出来。 ForkJoinWorkerThread#locallyDeqTask()12345678910111213141516171819202122/** * Tries to take a task from the base of own queue. Called only * by this thread. * * @return a task, or null if none */final ForkJoinTask&lt;?&gt; locallyDeqTask() { ForkJoinTask&lt;?&gt; t; int m, b, i; ForkJoinTask&lt;?&gt;[] q = queue; if (q != null &amp;&amp; (m = q.length - 1) &gt;= 0) { while (queueTop != (b = queueBase)) { if ((t = q[i = m &amp; b]) != null &amp;&amp; queueBase == b &amp;&amp; UNSAFE.compareAndSwapObject(q, (i &lt;&lt; ASHIFT) + ABASE, t, null)) { queueBase = b + 1; return t; } } } return null;} 如果Pool是异步模式(locallyFifo为true)，那么会执行locallyDeqTask()。就是从当前任务队列deg一个任务出来。 5 总结 被创建，注册到Pool中，然后启动。 扫描所有工作线程的队列和Pool中的任务队列，窃取一个任务来执行。 执行完毕后，在从自身工作队列中获取任务来执行。 没任务执行了，会阻塞等待，如果正好赶上了Pool休眠，那么会被结束掉，从Pool中注销。","link":"/No-Fork-Join-Source/"},{"title":"线程安全和锁机制","text":"1 概念 1.1 临界区 1.2 互斥量 1.3 管程 1.4 信号量 1.5 CAS操作（Compare-and-swap） 1.6 重排序 2 线程与内存交互操作 2.1 Java内存模型定义了八种指令操作 lock（锁定） unlock（解锁） read（读取） load（载入） use（使用） assign（赋值） store（存储） write（写入） 2.2 volatile关键字作用 3 Java线程的实现方式 3.1 内核线程（Kernal Thread） 3.2 轻量级用户进程（Light Weight Process） 3.3 用户线程/混合线程（User Thread） 3.4 线程调度有两种方式 3.4.1 协同式 优点 缺点 3.4.2 抢占式 优点 4 Java中线程状态的调度关系 5 同步原理 6 Java对象头 7 锁的升级 8 偏向锁 偏向锁的撤销 关闭偏向锁 9 轻量级锁 加锁 解锁 10 锁的优缺点对比 1 概念1.1 临界区临界区指的是一个访问共用资源（例如：共用设备或是共用存储器）的程序片段，而这些共用资源又无法同时被多个线程访问的特性。当有线程进入临界区段时，其他线程或是进程必须等待（例如：bounded waiting等待法），有一些同步的机制必须在临界区段的进入点与离开点实现，以确保这些共用资源是被互斥获得使用。只能被单一线程访问的设备，例如：打印机。 1.2 互斥量互斥量是一个可以处于两态之一的变量：解锁和加锁。这样，只需要一个二进制位表示它，不过实际上，常常使用一个整型量，0表示解锁，而其他所有的值则表示加锁。互斥量使用两个过程。当一个线程（或进程）需要访问临界区时，它调用mutex_lock。如果该互斥量当前是解锁的（即临界区可用），此调用成功，调用线程可以自由进入该临界区。另一方面，如果该互斥量已经加锁，调用线程被阻塞，直到在临界区中的线程完成并调用mutex_unlock。如果多个线程被阻塞在该互斥量上，将随机选择一个线程并允许它获得锁。 1.3 管程管程(Monitors，也称为监视器) 是一种程序结构，结构内的多个子程序（对象或模块）形成的多个工作线程互斥访问共享资源。这些共享资源一般是硬件设备或一群变数。管程实现了在一个时间点，最多只有一个线程在执行管程的某个子程序。与那些通过修改数据结构实现互斥访问的并发程序设计相比，管程实现很大程度上简化了程序设计。系统中的各种硬件资源和软件资源，均可用数据结构抽象地描述其资源特性，即用少量信息和对资源所执行的操作来表征该资源，而忽略了它们的内部结构和实现细节。利用共享数据结构抽象地表示系统中的共享资源，而把对该共享数据结构实施的操作定义为一组过程。 1.4 信号量信号量(Semaphore)，有时被称为信号灯，是在多线程环境下使用的一种设施，是可以用来保证两个或多个关键代码段不被并发调用。在进入一个关键代码段之前，线程必须获取一个信号量；一旦该关键代码段完成了，那么该线程必须释放信号量。其它想进入该关键代码段的线程必须等待直到第一个线程释放信号量。为了完成这个过程，需要创建一个信号量VI，然后将Acquire Semaphore VI以及Release Semaphore VI分别放置在每个关键代码段的首末端。确认这些信号量VI引用的是初始创建的信号量。 1.5 CAS操作（Compare-and-swap）CAS有3个操作数，内存值V，旧的预期值A，要修改的新值B。当且仅当预期值A和内存值V相同时，将内存值V修改为B，否则什么都不做。 1.6 重排序编译器和处理器”为了提高性能，而在程序执行时会对程序进行的重排序。它的出现是为了提高程序的并发度，从而提高性能！但是对于多线程程序，重排序可能会导致程序执行的结果不是我们需要的结果！重排序分为”编译器”和”处理器”两个方面，而”处理器”重排序又包括”指令级重排序”和”内存的重排序”。 2 线程与内存交互操作所有的变量（实例字段，静态字段，构成数组对象的 元素，不包括局部变量和方法参数）都存储在主内存中，每个线程有自己的工作内存，线程的工作内存保存被线程使用到变量的主内存副本拷贝。线程对变量的所有操作都必须在工作内存中进行，而不能直接读写主内存的变量。不同线程之间也不能直接访问对方工作内存中的变量，线程间变量值的传递通过主内存来完成。 2.1 Java内存模型定义了八种指令操作lock（锁定）作用于主内存的变量，它把一个变量标识为一个线程独占的状态。 unlock（解锁）作用于主内存的变量，它把一个处于锁定状态的变量释放出来，释放后的变量才可以被其他线程锁定。 read（读取）作用于主内存的变量，它把一个变量的值从主内存传送到线程中的工作内存，以便随后的load动作使用。 load（载入）作用于工作内存的变量，它把read操作从主内存中得到的变量值放入工作内存的变量副本中。 use（使用）作用于工作内存的变量，它把工作内存中一个变量的值传递给执行引擎。 assign（赋值）作用于工作内存的变量，它把一个从执行引擎接收到的值赋值给工作内存中的变量。 store（存储）作用于工作内存的变量，它把工作内存中的一个变量的值传送到主内存中，以便随后的write操作。 write（写入）作用于主内存的变量，它把store操作从工作内存中得到的变量的值写入主内存的变量中。 2.2 volatile关键字作用 保证了新值能立即存储到主内存，每次使用前立即从主内存中刷新。 禁止指令重排序优化。 volatile关键字不能保证在多线程环境下对共享数据的操作的正确性(保证可见性)。可以使用在自己状态改变之后需要立即通知所有线程的情况下。 3 Java线程的实现方式3.1 内核线程（Kernal Thread）内核线程（Kernel Thread，KLT）就是直接由操作系统内核支持的线程，这种线程由内核来完成线程切换，内核通过操作调度器对线程进行调度，并负责将线程的任务映射到各个处理器上。程序一般不会直接去使用内核线程，而是去使用内核线程的一种高级接口——轻量级进程（Light Weight Process，LWP），轻量级进程就是我们通常意义上所讲的线程，由于每个轻量级进程都由一个内核线程支持，因此只有先支持内核线程，才能有轻量级进程。这种轻量级进程与内核线程之间1:1的关系称为一对一的线程模型。轻量级进程要消耗一定的内核资源（如内核线程的栈空间），而且系统调用的代价相对较高，因此一个系统支持轻量级进程的数量是有限的。 3.2 轻量级用户进程（Light Weight Process）广义上来讲，一个线程只要不是内核线程，那就可以认为是用户线程（User Thread，UT），而狭义的用户线程指的是完全建立在用户空间的线程库上，系统内核不能感知到线程存在的实现，用户线程的建立、同步、销毁和调度完全在用户态中完成，不需要内核的帮助。如果程序实现得当，这种线程不需要切换到内核态，因此操作可以是非常快速且低消耗的，也可以支持规模更大的线程数量，部分高性能数据库中的多线程就是由用户线程实现的。这种进程与用户线程之间1:N的关系称为一对多的线程模型。（Windows和Linux使用的是这种方式）使用用户线程的优势在于不需要系统内核的支援，劣势在于没有系统内核的支援，所有的线程操作都需要用户程序自己处理，因而使用用户线程实现的程序一般都比较复杂，现在使用用户线程的程序越来越少了。 3.3 用户线程/混合线程（User Thread）既存在用户线程，又存在轻量级进程。用户线程还是完全建立在用户空间中，而操作系统所支持的轻量级进程则作为用户线程和内核线程之间的桥梁。这种混合模式下，用户线程与轻量级进程的数量比是不定的，是M:N的关系。许多Unix系列的系统，都提供了M:N的线程模型实现。 3.4 线程调度有两种方式3.4.1 协同式线程的执行时间由线程本身来控制，线程任务执行完成之后主动通知系统切换到另一个线程去执行。（不推荐） 优点实现简单，线程切换操作对线程本身是可知的，不存在线程同步问题。 缺点线程执行时间不可控制，如果线程长时间执行不让出CPU执行时间可能导致系统崩溃。 3.4.2 抢占式每个线程的执行时间有操作系统来分配，操作系统给每个线程分配执行的时间片，抢到时间片的线程执行，时间片用完之后重新抢占执行时间，线程的切换不由线程本身来决定。（Java使用的线程调度方式就是抢占式调度） 优点线程执行时间可控制，不会因为一个线程阻塞问题导致系统崩溃。 4 Java中线程状态的调度关系 5 同步原理JVM规范规定JVM基于进入和退出Monitor对象来实现方法同步和代码块同步，但两者的实现细节不一样。代码块同步是使用monitorenter和monitorexit指令实现，而方法同步是使用另外一种方式实现的，细节在JVM规范里并没有详细说明，但是方法的同步同样可以使用这两个指令来实现。monitorenter指令是在编译后插入到同步代码块的开始位置，而monitorexit是插入到方法结束处和异常处，JVM要保证每个monitorenter必须有对应的monitorexit与之配对。任何对象都有一个monitor与之关联，当且一个monitor被持有后，它将处于锁定状态。线程执行到monitorenter指令时，将会尝试获取对象所对应的monitor的所有权，即尝试获得对象的锁。 6 Java对象头锁存在Java对象头里。如果对象是数组类型，则虚拟机用3个Word（字宽）存储对象头，如果对象是非数组类型，则用2字宽存储对象头。在32位虚拟机中，一字宽等于四字节，即32bit。长度 | 内容 | 说明—|—-|—32/64bit | Mark Word | 存储对象的hashCode或锁信息等。32/64bit | Class Metadata Address | 存储到对象类型数据的指针32/64bit | Array length | 数组的长度（如果当前对象是数组）Java对象头里的Mark Word里默认存储对象的HashCode，分代年龄和锁标记位。32位JVM的Mark Word的默认存储结构如下。状态 | 25 bit | 4bit | 1bit(是否是偏向锁) | 2bit(锁标志位)—|——–|——|————–|—–无锁状态 | 对象的hashCode | 对象分代年龄 | 0 | 01在运行期间Mark Word里存储的数据会随着锁标志位的变化而变化。Mark Word可能变化为存储以下4种数据。:合并单元格锁状态 | 25 bit | 4bit | 1bit(是否是偏向锁) | 2bit(锁标志位)—-|——–|——|——|—–轻量级锁 | 指向栈中锁记录的指针(30bit) | | | 00重量级锁 | 指向互斥量（重量级锁）的指针(30bit) | | | 10GC标记 | 空 | 空 | 空 | 11偏向锁 | 线程ID(23bit)，Epoch(2bit) | 对象分代年龄 | 1 | 01在64位虚拟机下，Mark Word是64bit大小的，其存储结构如下。锁状态 | 25bit | 31bit | 1bit(cms_free) | 4bit(分代年龄) | 1bit(偏向锁) | 2bit(锁标志位)—-|——-|——-|—————-|————|———–|———–无锁 | unused | hashCode | - | - | 0 | 01偏向锁 | ThreadID(54bit) Epoch(2bit) = 25bit+31bit | | - | - | 1 | 01 7 锁的升级Java SE1.6为了减少获得锁和释放锁所带来的性能消耗，引入了“偏向锁”和“轻量级锁”，所以在Java SE1.6里锁一共有四种状态，无锁状态，偏向锁状态，轻量级锁状态和重量级锁状态，它会随着竞争情况逐渐升级。锁可以升级但不能降级，意味着偏向锁升级成轻量级锁后不能降级成偏向锁。这种锁升级却不能降级的策略，目的是为了提高获得锁和释放锁的效率，下文会详细分析。锁的升级不是需要同步块执行完成的。持有锁的线程在执行完同步块的时候检查下锁是否升级了，如果升级了就唤醒等待的线程重新竞争。 8 偏向锁Hotspot的作者经过以往的研究发现大多数情况下锁不仅不存在多线程竞争，而且总是由同一线程多次获得，为了让线程获得锁的代价更低而引入了偏向锁。当一个线程访问同步块并获取锁时，会在对象头和栈帧中的锁记录里存储锁偏向的线程ID，以后该线程在进入和退出同步块时不需要花费CAS操作来加锁和解锁，而只需简单的测试一下对象头的Mark Word里是否存储着指向当前线程的偏向锁，如果测试成功，表示线程已经获得了锁，如果测试失败，则需要再测试下Mark Word中偏向锁的标识是否设置成1（表示当前是偏向锁），如果没有设置，则使用CAS竞争锁，如果设置了，则尝试使用CAS将对象头的偏向锁指向当前线程。 偏向锁的撤销偏向锁使用了一种等到竞争出现才释放锁的机制，所以当其他线程尝试竞争偏向锁时，持有偏向锁的线程才会释放锁。偏向锁的撤销，需要等待全局安全点（在这个时间点上没有字节码正在执行，那么这个时间点有可能是未进入同步代码快，也有可能是退出的同步代码块时候），它会首先暂停拥有偏向锁的线程，然后检查持有偏向锁的线程是否活着，如果线程不处于活动状态，则将对象头设置成无锁状态，如果线程仍然活着，拥有偏向锁的栈会被执行，遍历偏向对象的锁记录，栈中的锁记录和对象头的Mark Word要么重新偏向于其他线程，要么恢复到无锁或者标记对象不适合作为偏向锁，最后唤醒暂停的线程。下图中的线程1演示了偏向锁初始化的流程，线程2演示了偏向锁撤销的流程。viso附件 关闭偏向锁偏向锁在Java 6和Java 7里是默认启用的，但是它在应用程序启动几秒钟之后才激活，如有必要可以使用JVM参数来关闭延迟-XX：BiasedLockingStartupDelay = 0。如果你确定自己应用程序里所有的锁通常情况下处于竞争状态，可以通过JVM参数关闭偏向锁-XX:-UseBiasedLocking=false，那么默认会进入轻量级锁状态。 9 轻量级锁加锁线程在执行同步块之前，JVM会先在当前线程的栈桢中创建用于存储锁记录的空间，并将对象头中的Mark Word复制到锁记录中，官方称为Displaced Mark Word。然后线程尝试使用CAS将对象头中的Mark Word替换为指向锁记录的指针。如果成功，当前线程获得锁，如果失败，表示其他线程竞争锁，当前线程便尝试使用自旋来获取锁。（轻量级锁就是Sync和lock） 解锁轻量级解锁时，会使用原子的CAS操作来将Displaced Mark Word替换回到对象头，如果成功，则表示没有竞争发生。如果失败，表示当前锁存在竞争，锁就会膨胀成重量级锁。下图是两个线程同时争夺锁，导致锁膨胀的流程图。viso附件因为自旋会消耗CPU，为了避免无用的自旋（比如获得锁的线程被阻塞住了），一旦锁升级成重量级锁，就不会再恢复到轻量级锁状态。当锁处于这个状态下，其他线程试图获取锁时，都会被阻塞住，当持有锁的线程释放锁之后会唤醒这些线程，被唤醒的线程就会进行新一轮的夺锁之争。 10 锁的优缺点对比 锁 优点 缺点 适用场景 偏向锁 加锁和解锁不需要额外的消耗，和执行非同步方法比仅存在纳秒级的差距。 如果线程间存在锁竞争，会带来额外的锁撤销的消耗。 适用于只有一个线程访问同步块场景。 轻量级锁 竞争的线程不会阻塞，提高了程序的响应速度。 如果始终得不到锁竞争的线程使用自旋会消耗CPU。 追求响应时间。同步块执行速度非常快。 重量级锁 线程竞争不使用自旋，不会消耗CPU。 线程阻塞，响应时间缓慢。 追求吞吐量。同步块执行速度较长。","link":"/Thread-Safety-Lock/"},{"title":"Tomcat（三）关闭过程","text":"1 源码分析 2 总结 1 源码分析已经知道Tomcat启动以后，会启动6条线程，它们分别如下Tomcat threads123456\"ajp-bio-8009-AsyncTimeout\" daemon prio=5 tid=7f8738afe000 nid=0x115ad6000 waiting on condition [115ad5000]\"ajp-bio-8009-Acceptor-0\" daemon prio=5 tid=7f8738b05800 nid=0x1159d3000 runnable [1159d2000]\"http-bio-8080-AsyncTimeout\" daemon prio=5 tid=7f8735acb800 nid=0x1158d0000 waiting on condition [1158cf000]\"http-bio-8080-Acceptor-0\" daemon prio=5 tid=7f8735acd000 nid=0x1157cd000 runnable [1157cc000]\"ContainerBackgroundProcessor[StandardEngine[Catalina]]\" daemon prio=5 tid=7f8732850800 nid=0x111203000 waiting on condition [111202000]\"main\" prio=5 tid=7f8735000800 nid=0x10843e000 runnable [10843c000] 其中5条是Dameon线程，而对于Java程序来说，当所有非Dameon程序都终止的时候，JVM就会退出，因此要想终止Tomcat就只需要将main()这一条非Dameon线程终止即可。Dameon线程又叫后台或者守护线程，它负责在程序运行期提供一种通用服务的线程，比如垃圾收集线程，非Dameon线程和Dameon线程的区别就在于当程序中所有的非Daemon线程都终止的时候，JVM会杀死余下的Dameon线程，然后退出。接下来，一步步的分析如何来让main()线程终止，要想终止它，还是得从Tomcat的启动中来寻找答案，在分析Tomcat容器启动的时候，在Catalina#start()中有一段代码，接下来就来看看这段代码。org.apache.catalina.startup.Catalina#start()123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657/** * Start a new server instance. */ public void start() { if (getServer() == null) { load(); } if (getServer() == null) { log.fatal(\"Cannot start server. Server instance is not configured.\"); return; } long t1 = System.nanoTime(); // Start the new server try { getServer().start(); } catch (LifecycleException e) { log.fatal(sm.getString(\"catalina.serverStartFail\"), e); try { getServer().destroy(); } catch (LifecycleException e1) { log.debug(\"destroy() failed for failed Server \", e1); } return; } long t2 = System.nanoTime(); if(log.isInfoEnabled()) { log.info(\"Server startup in \" + ((t2 - t1) / 1000000) + \" ms\"); } // Register shutdown hook // 1 if (useShutdownHook) { if (shutdownHook == null) { shutdownHook = new CatalinaShutdownHook(); } Runtime.getRuntime().addShutdownHook(shutdownHook); // If JULI is being used, disable JULI's shutdown hook since // shutdown hooks run in parallel and log messages may be lost // if JULI's hook completes before the CatalinaShutdownHook() LogManager logManager = LogManager.getLogManager(); if (logManager instanceof ClassLoaderLogManager) { ((ClassLoaderLogManager) logManager).setUseShutdownHook( false); } } // 2 if (await) { await(); stop(); } } 这里就是Tomcat关闭流程的入口代码。在代码中标注两处，首先来看标注1的地方。 标注1的代码：我们用到JVM的Shutdown Hook机制。一个简单的介绍，Shutdown Hook是一个已经初始化但是还没有启动的线程，当JVM关闭的时候，它会启动并并发的运行所有已经注册过的Shutdown Hook，知道这点，就来看看CatalinaShutdownHook线程做什么事情？它的代码如下。 org.apache.catalina.startup.Catalina.CatalinaShutdownHook#run()123456789101112131415161718192021222324/** * Shutdown hook which will perform a clean shutdown of Catalina if needed. */ protected class CatalinaShutdownHook extends Thread { @Override public void run() { try { if (getServer() != null) { Catalina.this.stop(); } } catch (Throwable ex) { ExceptionUtils.handleThrowable(ex); log.error(sm.getString(\"catalina.shutdownHookFail\"), ex); } finally { // If JULI is used, shut JULI down *after* the server shuts down // so log messages aren't lost LogManager logManager = LogManager.getLogManager(); if (logManager instanceof ClassLoaderLogManager) { ((ClassLoaderLogManager) logManager).shutdown(); } } } } 通过上面的代码，可以清楚的看到调用Catalina#stop()。而Catalina#stop()最终又是调用StandardServer#stop()和destroy()。通过这里，知道Tomcat利用shutdown hook机制来在JVM关闭的时候关闭各个组件。但是JVM又是何时退出的呢？这就要来看标注为2的代码。 org.apache.catalina.startup.Catalina#stop()1234567891011121314151617181920212223242526272829303132333435363738394041/** * Stop an existing server instance. */ public void stop() { try { // Remove the ShutdownHook first so that server.stop() // doesn't get invoked twice if (useShutdownHook) { Runtime.getRuntime().removeShutdownHook(shutdownHook); // If JULI is being used, re-enable JULI's shutdown to ensure // log messages are not lost LogManager logManager = LogManager.getLogManager(); if (logManager instanceof ClassLoaderLogManager) { ((ClassLoaderLogManager) logManager).setUseShutdownHook( true); } } } catch (Throwable t) { ExceptionUtils.handleThrowable(t); // This will fail on JDK 1.2. Ignoring, as Tomcat can run // fine without the shutdown hook. } // Shut down the server try { Server s = getServer(); LifecycleState state = s.getState(); if (LifecycleState.STOPPING_PREP.compareTo(state) &lt;= 0 &amp;&amp; LifecycleState.DESTROYED.compareTo(state) &gt;= 0) { // Nothing to do. stop() was already called } else { s.stop(); s.destroy(); } } catch (LifecycleException e) { log.error(\"Catalina.stop\", e); } } 标注2的地方：首先判断await属性是否为true，如果为true就调用await()，调用完以后，再调用stop()，接下来就来看await()，而catalina#awit()又调用StandardServer#awit()，它的代码如下。 org.apache.catalina.startup.Catalina#await()123456/** * Await and shutdown. */ public void await() { getServer().await(); } org.apache.catalina.core.StandardServer#await()123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126/** * Wait until a proper shutdown command is received, then return. * This keeps the main thread alive - the thread pool listening for http * connections is daemon threads. */ @Override public void await() { // Negative values - don't wait on port - tomcat is embedded or we just don't like ports if( port == -2 ) { // undocumented yet - for embedding apps that are around, alive. return; } if( port==-1 ) { try { awaitThread = Thread.currentThread(); while(!stopAwait) { try { Thread.sleep( 10000 ); } catch( InterruptedException ex ) { // continue and check the flag } } } finally { awaitThread = null; } return; } // Set up a server socket to wait on try { awaitSocket = new ServerSocket(port, 1, InetAddress.getByName(address)); } catch (IOException e) { log.error(\"StandardServer.await: create[\" + address + \":\" + port + \"]: \", e); return; } try { awaitThread = Thread.currentThread(); // Loop waiting for a connection and a valid command while (!stopAwait) { ServerSocket serverSocket = awaitSocket; if (serverSocket == null) { break; } // Wait for the next connection Socket socket = null; StringBuilder command = new StringBuilder(); try { InputStream stream; try { socket = serverSocket.accept(); socket.setSoTimeout(10 * 1000); // Ten seconds stream = socket.getInputStream(); } catch (AccessControlException ace) { log.warn(\"StandardServer.accept security exception: \" + ace.getMessage(), ace); continue; } catch (IOException e) { if (stopAwait) { // Wait was aborted with socket.close() break; } log.error(\"StandardServer.await: accept: \", e); break; } // Read a set of characters from the socket int expected = 1024; // Cut off to avoid DoS attack while (expected &lt; shutdown.length()) { if (random == null) random = new Random(); expected += (random.nextInt() % 1024); } while (expected &gt; 0) { int ch = -1; try { ch = stream.read(); } catch (IOException e) { log.warn(\"StandardServer.await: read: \", e); ch = -1; } if (ch &lt; 32) // Control character or EOF terminates loop break; command.append((char) ch); expected--; } } finally { // Close the socket now that we are done with it try { if (socket != null) { socket.close(); } } catch (IOException e) { // Ignore } } // Match against our command string boolean match = command.toString().equals(shutdown); if (match) { log.info(sm.getString(\"standardServer.shutdownViaPort\")); break; } else log.warn(\"StandardServer.await: Invalid command '\" + command.toString() + \"' received\"); } } finally { ServerSocket serverSocket = awaitSocket; awaitThread = null; awaitSocket = null; // Close the server socket and return if (serverSocket != null) { try { serverSocket.close(); } catch (IOException e) { // Ignore } } } } 通过上面的代码，可以看出在配置的端口上通过ServerSocket来监听一个请求的到来，如果请求的字符串和配置的字符串相同的话即跳出循环，这样的话就会运行stop()，运行完以后，main线程就退出。这里ServerSocket监听的端口，以及对比的字符串都是在conf/server.xml中配置的，缺省情况下，配置如下：从这里可以看出监听端口为8005，关闭请求发送的字符串为SHUTDOWN。看到这里，基本上已经清楚Tomcat的关闭就是通过在8005端口，发送一个SHUTDOWN字符串。那么就来实验一下。首先启动Tomcat，然后在终端运行如下指令。123456telnet 127.0.0.1 8005Trying 127.0.0.1...Connected to localhost.Escape character is &apos;^]&apos;.SHUTDOWNConnection closed by foreign host. 运行telnet命令，并发送SHUTDOWN字符串以后，发现Tomcat就会退出await()，然后执行stop()最终停止。但是一般情况下，停止tomcat都不会像上面那种方式来关闭，一般有两种方式来关闭： ps aux | grep java ,kill -9对于这种方式，比较简单粗暴会直接干掉进程。 运行shutdown.sh这种方式其实最终也是向server发送一个SHUTDOWN字符串，接下来分析下第二种情况。 查看shutdown.sh最终是调用catalina.sh，并传递stop参数。查看catalina.sh脚本，最终其实是调用org.apache.catalina.startup.Bootstrap#main，并传递参数stop。查看Bootstrap#main()，发现会调用org.apache.catalina.startup.Bootstrap#stopServer，而Bootstrap#stopServer通过反射调用org.apache.catalina.startup.Catalina#stopServer，看看Catalina#stopServer()，代码如下。org.apache.catalina.startup.Catalina#stopServer()1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586public void stopServer(String[] arguments) { if (arguments != null) { arguments(arguments); } Server s = getServer(); // 1 if( s == null ) { // Create and execute our Digester Digester digester = createStopDigester(); digester.setClassLoader(Thread.currentThread().getContextClassLoader()); File file = configFile(); FileInputStream fis = null; try { InputSource is = new InputSource(file.toURI().toURL().toString()); fis = new FileInputStream(file); is.setByteStream(fis); digester.push(this); digester.parse(is); } catch (Exception e) { log.error(\"Catalina.stop: \", e); System.exit(1); } finally { if (fis != null) { try { fis.close(); } catch (IOException e) { // Ignore } } } } else { // Server object already present. Must be running as a service try { s.stop(); } catch (LifecycleException e) { log.error(\"Catalina.stop: \", e); } return; } // Stop the existing server s = getServer(); // 2 if (s.getPort()&gt;0) { Socket socket = null; OutputStream stream = null; try { socket = new Socket(s.getAddress(), s.getPort()); stream = socket.getOutputStream(); String shutdown = s.getShutdown(); for (int i = 0; i &lt; shutdown.length(); i++) { stream.write(shutdown.charAt(i)); } stream.flush(); } catch (ConnectException ce) { log.error(sm.getString(\"catalina.stopServer.connectException\", s.getAddress(), String.valueOf(s.getPort()))); log.error(\"Catalina.stop: \", ce); System.exit(1); } catch (IOException e) { log.error(\"Catalina.stop: \", e); System.exit(1); } finally { if (stream != null) { try { stream.close(); } catch (IOException e) { // Ignore } } if (socket != null) { try { socket.close(); } catch (IOException e) { // Ignore } } } } else { log.error(sm.getString(\"catalina.stopServer\")); System.exit(1); } } 分析一下标注的地方： 标注1的代码：此时因为是新开一个进程，并且conf/server.xml还没有解析，因此s是NULL，通过Digester解析conf/server.xml，最终生成未初始化的StandardServer对象。 标注2的代码：向standardServer#getPort返回的端口（其实这里面返回即是conf/server.xml中Server根节点配置的port和shutdown属性）发送standardServer#getShutdown()返回的字符串，而默认情况下这个字符串就是SHUTDOWN。2 总结Tomcat启动的时候的主线程会在8005端口（默认配置，可以更改）上建立socket监听，当关闭的时候，最终其实就是新起一个进程然后向Tomcat主线程监听的8005端口发送一个SHUTDOWN字符串，这样主线程就会结束，主线程结束以后，因为其它的线程都是dameon线程，不会退出。","link":"/Tomcat-3/"},{"title":"Tomcat（六）Session管理机制","text":"Tomcat session相关的类图通过上图，可以看出每一个StandardContext会关联一个Manager，默认情况下Manager的实现类是StandardManager，而StandardManager内部会聚合多个Session，其中StandardSession是Session的默认实现类，当我们调用Request#getSession()的时候，Tomcat通过StandardSessionFacade这个外观类将StandardSession包装以后返回。org.apache.catalina.connector.Request#getSession()12345678910111213/** * Return the session associated with this Request, creating one * if necessary. */ @Override public HttpSession getSession() { Session session = doGetSession(true); if (session == null) { return null; } return session.getSession(); } 从上面的代码，可以看出首先首先调用doGetSession()获取Session，然后再调用Session#getSession()返回HttpSession，那接下来再来看看doGetSession()。org.apache.catalina.connector.Request#doGetSession()1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586protected Session doGetSession(boolean create) { // There cannot be a session if no context has been assigned yet if (context == null) { return (null); } // Return the current session if it exists and is valid if ((session != null) &amp;&amp; !session.isValid()) { session = null; } if (session != null) { return (session); } // Return the requested session if it exists and is valid // 1 Manager manager = null; if (context != null) { manager = context.getManager(); } if (manager == null) { return (null); // Sessions are not supported } // 2 if (requestedSessionId != null) { try { session = manager.findSession(requestedSessionId); } catch (IOException e) { session = null; } if ((session != null) &amp;&amp; !session.isValid()) { session = null; } if (session != null) { session.access(); return (session); } } // Create a new session if requested and the response is not committed // 3 if (!create) { return (null); } if ((context != null) &amp;&amp; (response != null) &amp;&amp; context.getServletContext().getEffectiveSessionTrackingModes(). contains(SessionTrackingMode.COOKIE) &amp;&amp; response.getResponse().isCommitted()) { throw new IllegalStateException (sm.getString(\"coyoteRequest.sessionCreateCommitted\")); } // Attempt to reuse session id if one was submitted in a cookie // Do not reuse the session id if it is from a URL, to prevent possible // phishing attacks // Use the SSL session ID if one is present. // 4 if ((\"/\".equals(context.getSessionCookiePath()) &amp;&amp; isRequestedSessionIdFromCookie()) || requestedSessionSSL ) { session = manager.createSession(getRequestedSessionId()); } else { session = manager.createSession(null); } // Creating a new session cookie based on that session if ((session != null) &amp;&amp; (getContext() != null) &amp;&amp; getContext().getServletContext(). getEffectiveSessionTrackingModes().contains( SessionTrackingMode.COOKIE)) { // 5 Cookie cookie = ApplicationSessionCookieConfig.createSessionCookie( context, session.getIdInternal(), isSecure()); response.addSessionCookieInternal(cookie); } if (session == null) { return null; } session.access(); return session;} 标注1的代码：首先从StandardContext中获取对应的Manager对象，缺省情况下，这个地方获取的其实就是StandardManager的实例。 标注2的代码：从Manager中根据requestedSessionId获取session，如果session已经失效，则将session置为null以便下面创建新的session，如果session不为空则通过调用session#access()标注session的访问时间，然后返回。 标注3的代码：判断传递的参数，如果为false，则直接返回空，这其实就是对应的Request#getSession(true/false)的情况，当传递false的时候，如果不存在session，则直接返回空，不会新建。 标注4的代码：调用Manager来创建一个新的session，这里默认会调用到StandardManager()，而StandardManager继承ManagerBase，那么默认其实是调用ManagerBase()。 标注5的代码：创建一个Cookie，而Cookie的名称就是大家熟悉的JSESSIONID，另外JSESSIONID其实也是可以配置的，这个可以通过context节点的sessionCookieName来修改。 通过doGetSession()获取到Session以后，调用session#getSession()，而Session的实现类是StandardSession，那么再来看下StandardSession#getSession()。org.apache.catalina.session.StandardSession#getSession()123456789101112131415161718192021222324/** * Return the &lt;code&gt;HttpSession&lt;/code&gt; for which this object * is the facade. */ @Override public HttpSession getSession() { if (facade == null){ if (SecurityUtil.isPackageProtectionEnabled()){ final StandardSession fsession = this; facade = AccessController.doPrivileged( new PrivilegedAction&lt;StandardSessionFacade&gt;(){ @Override public StandardSessionFacade run(){ return new StandardSessionFacade(fsession); } }); } else { facade = new StandardSessionFacade(this); } } return (facade); } StandardSessionFacade的包装类将StandardSession包装以后返回。这里是Session创建过程。Sesssion是如何被销毁的。在Tomcat启动过程中，在容器启动以后会启动一个ContainerBackgroundProcessor线程，这个线程是在Container启动的时候启动的，这条线程就通过后台周期性的调用org.apache.catalina.core.ContainerBase#backgroundProcess()（ContainerBase实现Container接口）。org.apache.catalina.core.ContainerBase#threadStart()thread = new Thread(new ContainerBackgroundProcessor(), threadName);org.apache.catalina.core.ContainerBase#ContainerBackgroundProcessor1234567891011121314151617181920212223242526272829303132333435363738394041424344454647/** * Private thread class to invoke the backgroundProcess method * of this container and its children after a fixed delay. */ protected class ContainerBackgroundProcessor implements Runnable { @Override public void run() { while (!threadDone) { try { Thread.sleep(backgroundProcessorDelay * 1000L); } catch (InterruptedException e) { // Ignore } if (!threadDone) { Container parent = (Container) getMappingObject(); ClassLoader cl = Thread.currentThread().getContextClassLoader(); if (parent.getLoader() != null) { cl = parent.getLoader().getClassLoader(); } processChildren(parent, cl); } } } protected void processChildren(Container container, ClassLoader cl) { try { if (container.getLoader() != null) { Thread.currentThread().setContextClassLoader (container.getLoader().getClassLoader()); } container.backgroundProcess(); //ContainerBase实现Container接口 } catch (Throwable t) { ExceptionUtils.handleThrowable(t); log.error(\"Exception invoking periodic operation: \", t); } finally { Thread.currentThread().setContextClassLoader(cl); } Container[] children = container.findChildren(); for (int i = 0; i &lt; children.length; i++) { if (children[i].getBackgroundProcessorDelay() &lt;= 0) { processChildren(children[i], cl); } } } } org.apache.catalina.core.ContainerBase#backgroundProcess()123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051/** * Execute a periodic task, such as reloading, etc. This method will be * invoked inside the classloading context of this container. Unexpected * throwables will be caught and logged. */ @Override public void backgroundProcess() { if (!getState().isAvailable()) return; if (cluster != null) { try { cluster.backgroundProcess(); } catch (Exception e) { log.warn(sm.getString(\"containerBase.backgroundProcess.cluster\", cluster), e); } } if (loader != null) { try { loader.backgroundProcess(); } catch (Exception e) { log.warn(sm.getString(\"containerBase.backgroundProcess.loader\", loader), e); } } if (manager != null) { try { manager.backgroundProcess(); } catch (Exception e) { log.warn(sm.getString(\"containerBase.backgroundProcess.manager\", manager), e); } } Realm realm = getRealmInternal(); if (realm != null) { try { realm.backgroundProcess(); } catch (Exception e) { log.warn(sm.getString(\"containerBase.backgroundProcess.realm\", realm), e); } } Valve current = pipeline.getFirst(); while (current != null) { try { current.backgroundProcess(); } catch (Exception e) { log.warn(sm.getString(\"containerBase.backgroundProcess.valve\", current), e); } current = current.getNext(); } fireLifecycleEvent(Lifecycle.PERIODIC_EVENT, null); } backgroundProcess()最终又会调用org.apache.catalina.session.ManagerBase#backgroundProcess。org.apache.catalina.session.ManagerBase#backgroundProcess()123456789/** * Implements the Manager interface, direct call to processExpires */ @Override public void backgroundProcess() { count = (count + 1) % processExpiresFrequency; if (count == 0) processExpires(); } 默认情况下backgroundProcess是每10秒运行一次（StandardEngine构造的时候，将backgroundProcessorDelay设置为10），而这里通过processExpiresFrequency来控制频率，例如processExpiresFrequency的值默认为6，那么相当于每一分钟运行一次processExpires()。org.apache.catalina.session.ManagerBase#processExpires()12345678910111213141516171819202122/** * Invalidate all sessions that have expired. */ public void processExpires() { long timeNow = System.currentTimeMillis(); Session sessions[] = findSessions(); int expireHere = 0 ; if(log.isDebugEnabled()) log.debug(\"Start expire sessions \" + getName() + \" at \" + timeNow + \" sessioncount \" + sessions.length); for (int i = 0; i &lt; sessions.length; i++) { if (sessions[i]!=null &amp;&amp; !sessions[i].isValid()) { expireHere++; } } long timeEnd = System.currentTimeMillis(); if(log.isDebugEnabled()) log.debug(\"End expire sessions \" + getName() + \" processingTime \" + (timeEnd - timeNow) + \" expired sessions: \" + expireHere); processingTime += ( timeEnd - timeNow ); } 上面的代码比较简单，首先查找出当前context的所有的session，然后调用Session#isValid()，看看Session#isValid()。org.apache.catalina.session.StandardSession#isValid()123456789101112131415161718192021222324252627282930313233/** * Return the &lt;code&gt;isValid&lt;/code&gt; flag for this session. */ @Override public boolean isValid() { if (this.expiring) { return true; } if (!this.isValid) { return false; } if (ACTIVITY_CHECK &amp;&amp; accessCount.get() &gt; 0) { return true; } if (maxInactiveInterval &gt; 0) { long timeNow = System.currentTimeMillis(); int timeIdle; if (LAST_ACCESS_AT_START) { timeIdle = (int) ((timeNow - lastAccessedTime) / 1000L); } else { timeIdle = (int) ((timeNow - thisAccessedTime) / 1000L); } if (timeIdle &gt;= maxInactiveInterval) { expire(true); } } return (this.isValid); } 查看上面的代码，主要就是通过对比当前时间和上次访问的时间差是否大于最大的非活动时间间隔，如果大于就会调用expire(true)对session进行超期处理。这里需要注意一点，默认情况下LAST_ACCESS_AT_START = false，也可以通过设置系统属性的方式进行修改，而如果采用LAST_ACCESS_AT_START的时候，那么请求本身的处理时间将不算在内。比如一个请求处理开始的时候是10:00,请求处理时间1分钟，那么如果LAST_ACCESS_AT_START = true，则算是否超期的时候，是从10:00算起，而不是10:01。org.apache.catalina.session.StandardSession#expire()123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125/** * Perform the internal processing required to invalidate this session, * without triggering an exception if the session has already expired. * * @param notify Should we notify listeners about the demise of * this session? */ public void expire(boolean notify) { // Check to see if expire is in progress or has previously been called if (expiring || !isValid) return; synchronized (this) { // Check again, now we are inside the sync so this code only runs once // Double check locking - expiring and isValid need to be volatile if (expiring || !isValid) return; if (manager == null) return; // Mark this session as \"being expired\" // 1 expiring = true; // Notify interested application event listeners // FIXME - Assumes we call listeners in reverse order Context context = (Context) manager.getContainer(); // The call to expire() may not have been triggered by the webapp. // Make sure the webapp's class loader is set when calling the // listeners ClassLoader oldTccl = null; if (context.getLoader() != null &amp;&amp; context.getLoader().getClassLoader() != null) { oldTccl = Thread.currentThread().getContextClassLoader(); if (Globals.IS_SECURITY_ENABLED) { PrivilegedAction&lt;Void&gt; pa = new PrivilegedSetTccl( context.getLoader().getClassLoader()); AccessController.doPrivileged(pa); } else { Thread.currentThread().setContextClassLoader( context.getLoader().getClassLoader()); } } try { // 2 Object listeners[] = context.getApplicationLifecycleListeners(); if (notify &amp;&amp; (listeners != null)) { HttpSessionEvent event = new HttpSessionEvent(getSession()); for (int i = 0; i &lt; listeners.length; i++) { int j = (listeners.length - 1) - i; if (!(listeners[j] instanceof HttpSessionListener)) continue; HttpSessionListener listener = (HttpSessionListener) listeners[j]; try { context.fireContainerEvent(\"beforeSessionDestroyed\", listener); listener.sessionDestroyed(event); context.fireContainerEvent(\"afterSessionDestroyed\", listener); } catch (Throwable t) { ExceptionUtils.handleThrowable(t); try { context.fireContainerEvent( \"afterSessionDestroyed\", listener); } catch (Exception e) { // Ignore } manager.getContainer().getLogger().error (sm.getString(\"standardSession.sessionEvent\"), t); } } } } finally { if (oldTccl != null) { if (Globals.IS_SECURITY_ENABLED) { PrivilegedAction&lt;Void&gt; pa = new PrivilegedSetTccl(oldTccl); AccessController.doPrivileged(pa); } else { Thread.currentThread().setContextClassLoader(oldTccl); } } } if (ACTIVITY_CHECK) { accessCount.set(0); } setValid(false); // 3 // Remove this session from our manager's active sessions manager.remove(this, true); // Notify interested session event listeners if (notify) { fireSessionEvent(Session.SESSION_DESTROYED_EVENT, null); } // Call the logout method if (principal instanceof GenericPrincipal) { GenericPrincipal gp = (GenericPrincipal) principal; try { gp.logout(); } catch (Exception e) { manager.getContainer().getLogger().error( sm.getString(\"standardSession.logoutfail\"), e); } } // We have completed expire of this session expiring = false; // Unbind any objects associated with this session // 4 String keys[] = keys(); for (int i = 0; i &lt; keys.length; i++) removeAttributeInternal(keys[i], notify); } } 标注1：标记当前的session为超期。 标注2：出发HttpSessionListener监听器的方法。 标注3：从Manager里面移除当前的session。 标注4：将session中保存的属性移除。 到这里已经清楚Tomcat中对与StandardSession的创建以及销毁的过程，其实StandardSession仅仅是实现内存中Session的存储，而Tomcat还支持将Session持久化，以及Session集群节点间的同步。","link":"/Tomcat-6/"},{"title":"Tomcat（五）类加载器机制","text":"当一个JVM启动时，至少有三个ClassLoader会被启动： Bootstrap 类加载器：加载Java核心包，它们被置放在(&lt;JAVA_HOME&gt;/lib目录下，这部分是JVM的一部分，往往使用native code完成。 Extensions类加载器：加载Java扩展包，即位于&lt;JAVA_HOME&gt;/lib/ext下的包，这里要注意的是，有些JVM的这个加载器和Bootstrap类加载器是同一个加载器，而Sun是把二者分开的，其实现类为sun.misc.Launcher$ExtClassLoader。 System类加载器：这个类加载器加载CLASSPATH下的类，Sun的默认实现是sun.misc.Launcher$ExtClassLoader。 这三者之间的父子关系是：Bootstrap类加载器是Extensions类加载器的父类加载器，而Extensions类加载器是System类加载器的父类加载器。Tomcat的Classloader机制，从Bootstrap开始。在BootStrap初始化的时候，调用org.apache.catalina.startup.Bootstrap#initClassLoaders()，这个方法里面创建3个ClassLoader，它们分别是commonLoader，catalinaLoader，sharedLoader，其中catalinaLoader，sharedLoader的父亲加载器是commonLoader，initClassLoaders执行的过程中会执行createClassLoader，而createClassLoader是根据conf/catalina.properties文件中common.loader，server.loader，shared.loader的值来初始化，它的代码如下。org.apache.catalina.startup.Bootstrap#createClassLoader()12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364private ClassLoader createClassLoader(String name, ClassLoader parent) throws Exception { String value = CatalinaProperties.getProperty(name + \".loader\"); // 1 if ((value == null) || (value.equals(\"\"))) return parent; // 2 value = replace(value); List&lt;Repository&gt; repositories = new ArrayList&lt;Repository&gt;(); StringTokenizer tokenizer = new StringTokenizer(value, \",\"); while (tokenizer.hasMoreElements()) { String repository = tokenizer.nextToken().trim(); if (repository.length() == 0) { continue; } // Check for a JAR URL repository try { @SuppressWarnings(\"unused\") URL url = new URL(repository); repositories.add( new Repository(repository, RepositoryType.URL)); continue; } catch (MalformedURLException e) { // Ignore } // Local repository if (repository.endsWith(\"*.jar\")) { repository = repository.substring (0, repository.length() - \"*.jar\".length()); repositories.add( new Repository(repository, RepositoryType.GLOB)); } else if (repository.endsWith(\".jar\")) { repositories.add( new Repository(repository, RepositoryType.JAR)); } else { repositories.add( new Repository(repository, RepositoryType.DIR)); } } // 3 ClassLoader classLoader = ClassLoaderFactory.createClassLoader (repositories, parent); // Retrieving MBean server MBeanServer mBeanServer = null; if (MBeanServerFactory.findMBeanServer(null).size() &gt; 0) { mBeanServer = MBeanServerFactory.findMBeanServer(null).get(0); } else { mBeanServer = ManagementFactory.getPlatformMBeanServer(); } // Register the server classloader ObjectName objectName = new ObjectName(\"Catalina:type=ServerClassLoader,name=\" + name); mBeanServer.registerMBean(classLoader, objectName); return classLoader;} 标注1的代码：判断如果catalina.properties中没有配置对应的loader属性的话，直接返回父加载器，而默认情况下，server.loader，shared.loader为空，那么此时的catalinaLoader，sharedLoader其实是同一个ClassLoader。 标注2的代码：根据环境变量的配置替换字符串中的值，默认情况下，common.loader的值为common.loader=${catalina.base}/lib，${catalina.base}/lib/.jar，${catalina.home}/lib，${catalina.home}/lib/.jar，这里会将catalina.base和catalina.home用环境变量的值替换。 标注3的代码：最终调用org.apache.catalina.startup.ClassLoaderFactory#createClassLoader()静态工厂方法创建URLClassloader的实例，而具体的URL其实就是*.loader属性配置的内容，此外如果parent = null的话，则直接用系统类加载器。 上面分析Tomcat在启动的时候，初始化的几个ClassLoader，接下再来继续看看，这些ClassLoader具体都用在什么地方。接着来看org.apache.catalina.startup.Bootstrap#init()，在初始化完3个classLoader以后，接下来首先通过catalinaLoader加载org.apache.catalina.startup.Catalinal类，然后通过反射调用org.apache.catalina.startup.Catalina#setParentClassLoader()，具体代码片段如下。org.apache.catalina.startup.Bootstrap#init()1234567891011121314151617181920212223242526272829303132333435363738/** * Initialize daemon. */public void init() throws Exception{ // Set Catalina path setCatalinaHome(); setCatalinaBase(); initClassLoaders(); Thread.currentThread().setContextClassLoader(catalinaLoader); SecurityClassLoad.securityClassLoad(catalinaLoader); // Load our startup class and call its process() method if (log.isDebugEnabled()) log.debug(\"Loading startup class\"); Class&lt;?&gt; startupClass = catalinaLoader.loadClass (\"org.apache.catalina.startup.Catalina\"); Object startupInstance = startupClass.newInstance(); // Set the shared extensions class loader if (log.isDebugEnabled()) log.debug(\"Setting startup class properties\"); String methodName = \"setParentClassLoader\"; Class&lt;?&gt; paramTypes[] = new Class[1]; paramTypes[0] = Class.forName(\"java.lang.ClassLoader\"); Object paramValues[] = new Object[1]; paramValues[0] = sharedLoader; Method method = startupInstance.getClass().getMethod(methodName, paramTypes); method.invoke(startupInstance, paramValues); catalinaDaemon = startupInstance;} 通过上面的代码，可以清楚的看到调用Catalina#setParentClassLoader()，设置parentClassLoader以后，sharedLoader又是在哪里使用的呢？这就需要接着来分析容器启动的代码。通过查看org.apache.catalina.startup.Catalina#getParentClassLoader()调用栈，看到在StandardContext#startInternal()中调用它，那么查看一下它的代码，包含如下代码片段。org.apache.catalina.core.StandardContext#startInternal()123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311/** * Start this component and implement the requirements * of {@link org.apache.catalina.util.LifecycleBase#startInternal()}. * * @exception LifecycleException if this component detects a fatal error * that prevents this component from being used */ @Override protected synchronized void startInternal() throws LifecycleException { if(log.isDebugEnabled()) log.debug(\"Starting \" + getBaseName()); // Send j2ee.state.starting notification if (this.getObjectName() != null) { Notification notification = new Notification(\"j2ee.state.starting\", this.getObjectName(), sequenceNumber.getAndIncrement()); broadcaster.sendNotification(notification); } setConfigured(false); boolean ok = true; // Currently this is effectively a NO-OP but needs to be called to // ensure the NamingResources follows the correct lifecycle if (namingResources != null) { namingResources.start(); } // Add missing components as necessary if (webappResources == null) { // (1) Required by Loader if (log.isDebugEnabled()) log.debug(\"Configuring default Resources\"); try { if ((getDocBase() != null) &amp;&amp; (getDocBase().endsWith(\".war\")) &amp;&amp; (!(new File(getBasePath())).isDirectory())) setResources(new WARDirContext()); else setResources(new FileDirContext()); } catch (IllegalArgumentException e) { log.error(\"Error initializing resources: \" + e.getMessage()); ok = false; } } if (ok) { if (!resourcesStart()) { log.error( \"Error in resourceStart()\"); ok = false; } } // 1 if (getLoader() == null) { WebappLoader webappLoader = new WebappLoader(getParentClassLoader()); webappLoader.setDelegate(getDelegate()); setLoader(webappLoader); } // Initialize character set mapper getCharsetMapper(); // Post work directory postWorkDirectory(); // Validate required extensions boolean dependencyCheck = true; try { dependencyCheck = ExtensionValidator.validateApplication (getResources(), this); } catch (IOException ioe) { log.error(\"Error in dependencyCheck\", ioe); dependencyCheck = false; } if (!dependencyCheck) { // do not make application available if depency check fails ok = false; } // Reading the \"catalina.useNaming\" environment variable String useNamingProperty = System.getProperty(\"catalina.useNaming\"); if ((useNamingProperty != null) &amp;&amp; (useNamingProperty.equals(\"false\"))) { useNaming = false; } if (ok &amp;&amp; isUseNaming()) { if (getNamingContextListener() == null) { NamingContextListener ncl = new NamingContextListener(); ncl.setName(getNamingContextName()); ncl.setExceptionOnFailedWrite(getJndiExceptionOnFailedWrite()); addLifecycleListener(ncl); setNamingContextListener(ncl); } } // Standard container startup if (log.isDebugEnabled()) log.debug(\"Processing standard container startup\"); // Binding thread ClassLoader oldCCL = bindThread(); try { if (ok) { // 2 // Start our subordinate components, if any if ((loader != null) &amp;&amp; (loader instanceof Lifecycle)) ((Lifecycle) loader).start(); // since the loader just started, the webapp classloader is now // created. // By calling unbindThread and bindThread in a row, we setup the // current Thread CCL to be the webapp classloader unbindThread(oldCCL); oldCCL = bindThread(); // Initialize logger again. Other components might have used it // too early, so it should be reset. logger = null; getLogger(); if ((cluster != null) &amp;&amp; (cluster instanceof Lifecycle)) ((Lifecycle) cluster).start(); Realm realm = getRealmInternal(); if ((realm != null) &amp;&amp; (realm instanceof Lifecycle)) ((Lifecycle) realm).start(); if ((resources != null) &amp;&amp; (resources instanceof Lifecycle)) ((Lifecycle) resources).start(); // Notify our interested LifecycleListeners fireLifecycleEvent(Lifecycle.CONFIGURE_START_EVENT, null); // Start our child containers, if not already started for (Container child : findChildren()) { if (!child.getState().isAvailable()) { child.start(); } } // Start the Valves in our pipeline (including the basic), // if any if (pipeline instanceof Lifecycle) { ((Lifecycle) pipeline).start(); } // Acquire clustered manager Manager contextManager = null; if (manager == null) { if (log.isDebugEnabled()) { log.debug(sm.getString(\"standardContext.cluster.noManager\", Boolean.valueOf((getCluster() != null)), Boolean.valueOf(distributable))); } if ( (getCluster() != null) &amp;&amp; distributable) { try { contextManager = getCluster().createManager(getName()); } catch (Exception ex) { log.error(\"standardContext.clusterFail\", ex); ok = false; } } else { contextManager = new StandardManager(); } } // Configure default manager if none was specified if (contextManager != null) { if (log.isDebugEnabled()) { log.debug(sm.getString(\"standardContext.manager\", contextManager.getClass().getName())); } setManager(contextManager); } if (manager!=null &amp;&amp; (getCluster() != null) &amp;&amp; distributable) { //let the cluster know that there is a context that is distributable //and that it has its own manager getCluster().registerManager(manager); } } } finally { // Unbinding thread unbindThread(oldCCL); } if (!getConfigured()) { log.error( \"Error getConfigured\"); ok = false; } // We put the resources into the servlet context if (ok) getServletContext().setAttribute (Globals.RESOURCES_ATTR, getResources()); // Initialize associated mapper mapper.setContext(getPath(), welcomeFiles, resources); // Binding thread oldCCL = bindThread(); if (ok ) { if (getInstanceManager() == null) { javax.naming.Context context = null; if (isUseNaming() &amp;&amp; getNamingContextListener() != null) { context = getNamingContextListener().getEnvContext(); } Map&lt;String, Map&lt;String, String&gt;&gt; injectionMap = buildInjectionMap( getIgnoreAnnotations() ? new NamingResources(): getNamingResources()); setInstanceManager(new DefaultInstanceManager(context, injectionMap, this, this.getClass().getClassLoader())); getServletContext().setAttribute( InstanceManager.class.getName(), getInstanceManager()); } } try { // Create context attributes that will be required if (ok) { getServletContext().setAttribute( JarScanner.class.getName(), getJarScanner()); } // Set up the context init params mergeParameters(); // Call ServletContainerInitializers for (Map.Entry&lt;ServletContainerInitializer, Set&lt;Class&lt;?&gt;&gt;&gt; entry : initializers.entrySet()) { try { entry.getKey().onStartup(entry.getValue(), getServletContext()); } catch (ServletException e) { log.error(sm.getString(\"standardContext.sciFail\"), e); ok = false; break; } } // Configure and call application event listeners if (ok) { if (!listenerStart()) { log.error( \"Error listenerStart\"); ok = false; } } try { // Start manager if ((manager != null) &amp;&amp; (manager instanceof Lifecycle)) { ((Lifecycle) getManager()).start(); } } catch(Exception e) { log.error(\"Error manager.start()\", e); ok = false; } // Configure and call application filters if (ok) { if (!filterStart()) { log.error(\"Error filterStart\"); ok = false; } } // Load and initialize all \"load on startup\" servlets if (ok) { loadOnStartup(findChildren()); } // Start ContainerBackgroundProcessor thread super.threadStart(); } finally { // Unbinding thread unbindThread(oldCCL); } // Set available status depending upon startup success if (ok) { if (log.isDebugEnabled()) log.debug(\"Starting completed\"); } else { log.error(sm.getString(\"standardContext.startFailed\", getName())); } startTime=System.currentTimeMillis(); // Send j2ee.state.running notification if (ok &amp;&amp; (this.getObjectName() != null)) { Notification notification = new Notification(\"j2ee.state.running\", this.getObjectName(), sequenceNumber.getAndIncrement()); broadcaster.sendNotification(notification); } // Close all JARs right away to avoid always opening a peak number // of files on startup if (getLoader() instanceof WebappLoader) { ((WebappLoader) getLoader()).closeJARs(true); } // Reinitializing if something went wrong if (!ok) { setState(LifecycleState.FAILED); } else { setState(LifecycleState.STARTING); } } 标注1的代码：在StandardContext启动的时候，会创建webapploader，创建webapploader的时候会将getParentClassLoader()返回的结果（这里返回的其实就是sharedLoader）赋值给自己的parentClassLoader变量。 标注2的代码：调用到Webapploader#start()，因为WebappLoader符合Tomcat组件生命周期管理的模板方法模式，因此会调用到它的startInternal()。 接下来就来看看WebappLoader#startInternal()。org.apache.catalina.loader.WebappLoader#startInternal()123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293/** * Start associated {@link ClassLoader} and implement the requirements * of {@link org.apache.catalina.util.LifecycleBase#startInternal()}. * * @exception LifecycleException if this component detects a fatal error * that prevents this component from being used */ @Override protected void startInternal() throws LifecycleException { if (log.isDebugEnabled()) log.debug(sm.getString(\"webappLoader.starting\")); if (container.getResources() == null) { log.info(\"No resources for \" + container); setState(LifecycleState.STARTING); return; } // Register a stream handler factory for the JNDI protocol URLStreamHandlerFactory streamHandlerFactory = DirContextURLStreamHandlerFactory.getInstance(); if (first) { first = false; try { URL.setURLStreamHandlerFactory(streamHandlerFactory); } catch (Exception e) { // Log and continue anyway, this is not critical log.error(\"Error registering jndi stream handler\", e); } catch (Throwable t) { ExceptionUtils.handleThrowable(t); // This is likely a dual registration log.info(\"Dual registration of jndi stream handler: \" + t.getMessage()); } } // Construct a class loader based on our current repositories list try { // 1 classLoader = createClassLoader(); classLoader.setResources(container.getResources()); classLoader.setDelegate(this.delegate); classLoader.setSearchExternalFirst(searchExternalFirst); if (container instanceof StandardContext) { classLoader.setAntiJARLocking( ((StandardContext) container).getAntiJARLocking()); classLoader.setClearReferencesStatic( ((StandardContext) container).getClearReferencesStatic()); classLoader.setClearReferencesStopThreads( ((StandardContext) container).getClearReferencesStopThreads()); classLoader.setClearReferencesStopTimerThreads( ((StandardContext) container).getClearReferencesStopTimerThreads()); classLoader.setClearReferencesHttpClientKeepAliveThread( ((StandardContext) container).getClearReferencesHttpClientKeepAliveThread()); } for (int i = 0; i &lt; repositories.length; i++) { classLoader.addRepository(repositories[i]); } // Configure our repositories setRepositories(); setClassPath(); setPermissions(); ((Lifecycle) classLoader).start(); // Binding the Webapp class loader to the directory context DirContextURLStreamHandler.bind(classLoader, this.container.getResources()); StandardContext ctx=(StandardContext)container; String contextName = ctx.getName(); if (!contextName.startsWith(\"/\")) { contextName = \"/\" + contextName; } ObjectName cloname = new ObjectName (MBeanUtils.getDomain(ctx) + \":type=WebappClassLoader,context=\" + contextName + \",host=\" + ctx.getParent().getName()); Registry.getRegistry(null, null) .registerComponent(classLoader, cloname, null); } catch (Throwable t) { t = ExceptionUtils.unwrapInvocationTargetException(t); ExceptionUtils.handleThrowable(t); log.error( \"LifecycleException \", t ); throw new LifecycleException(\"start: \", t); } setState(LifecycleState.STARTING); } 标注1的代码：调用createClassLoader()创建一个classLoader。 org.apache.catalina.loader.WebappLoader#createClassLoader()12345678910111213141516171819/** * Create associated classLoader. */ private WebappClassLoader createClassLoader() throws Exception { Class&lt;?&gt; clazz = Class.forName(loaderClass); WebappClassLoader classLoader = null; if (parentClassLoader == null) { parentClassLoader = container.getParentClassLoader(); } Class&lt;?&gt;[] argTypes = { ClassLoader.class }; Object[] args = { parentClassLoader }; Constructor&lt;?&gt; constr = clazz.getConstructor(argTypes); classLoader = (WebappClassLoader) constr.newInstance(args); return classLoader; } 在上面的代码里面，classLoader是WebappLoader的实例变量，其值为org.apache.catalina.loader.WebappClassLoader，那么上面的代码其实就是通过反射调用WebappClassLoader的构造函数，然后传递sharedLoader作为其父亲加载器。代码阅读到这里，已经基本清楚Tomcat中ClassLoader的总体结构，总结如下： 在Tomcat存在common，cataina，shared三个公共的classloader，默认情况下，这三个classloader其实是同一个，都是common classloader，而针对每个webapp，也就是context（对应代码中的StandardContext类），WebappClassLoader为每个应用创建类加载器实例。上面的描述，我们可以通过下图形象化的描述。清楚Tomcat总体的ClassLoader结构以后，进一步来分析一下WebAppClassLoader的代码，Java的ClassLoader机制有parent-first的机制，而这种机制是在loadClass()保证的，一般情况下，只需要重写findClass()就好，而对于WebAppClassLoader，通过查看源代码，发现loadClass()和findClass()都进行重写，那么首先就来看看它的loadClass()，它的代码如下。org.apache.catalina.loader.WebappClassLoader#loadClass()123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156/** * Load the class with the specified name, searching using the following * algorithm until it finds and returns the class. If the class cannot * be found, returns &lt;code&gt;ClassNotFoundException&lt;/code&gt;. * &lt;ul&gt; * &lt;li&gt;Call &lt;code&gt;findLoadedClass(String)&lt;/code&gt; to check if the * class has already been loaded. If it has, the same * &lt;code&gt;Class&lt;/code&gt; object is returned.&lt;/li&gt; * &lt;li&gt;If the &lt;code&gt;delegate&lt;/code&gt; property is set to &lt;code&gt;true&lt;/code&gt;, * call the &lt;code&gt;loadClass()&lt;/code&gt; method of the parent class * loader, if any.&lt;/li&gt; * &lt;li&gt;Call &lt;code&gt;findClass()&lt;/code&gt; to find this class in our locally * defined repositories.&lt;/li&gt; * &lt;li&gt;Call the &lt;code&gt;loadClass()&lt;/code&gt; method of our parent * class loader, if any.&lt;/li&gt; * &lt;/ul&gt; * If the class was found using the above steps, and the * &lt;code&gt;resolve&lt;/code&gt; flag is &lt;code&gt;true&lt;/code&gt;, this method will then * call &lt;code&gt;resolveClass(Class)&lt;/code&gt; on the resulting Class object. * * @param name Name of the class to be loaded * @param resolve If &lt;code&gt;true&lt;/code&gt; then resolve the class * * @exception ClassNotFoundException if the class was not found */ @Override public synchronized Class&lt;?&gt; loadClass(String name, boolean resolve) throws ClassNotFoundException { if (log.isDebugEnabled()) log.debug(\"loadClass(\" + name + \", \" + resolve + \")\"); Class&lt;?&gt; clazz = null; // Log access to stopped classloader if (!started) { try { throw new IllegalStateException(); } catch (IllegalStateException e) { log.info(sm.getString(\"webappClassLoader.stopped\", name), e); } } // (0) Check our previously loaded local class cache // 1 clazz = findLoadedClass0(name); if (clazz != null) { if (log.isDebugEnabled()) log.debug(\" Returning class from cache\"); if (resolve) resolveClass(clazz); return (clazz); } // (0.1) Check our previously loaded class cache // 2 clazz = findLoadedClass(name); if (clazz != null) { if (log.isDebugEnabled()) log.debug(\" Returning class from cache\"); if (resolve) resolveClass(clazz); return (clazz); } // (0.2) Try loading the class with the system class loader, to prevent // the webapp from overriding J2SE classes try { // 3 clazz = system.loadClass(name); if (clazz != null) { if (resolve) resolveClass(clazz); return (clazz); } } catch (ClassNotFoundException e) { // Ignore } // (0.5) Permission to access this class when using a SecurityManager if (securityManager != null) { int i = name.lastIndexOf('.'); if (i &gt;= 0) { try { securityManager.checkPackageAccess(name.substring(0,i)); } catch (SecurityException se) { String error = \"Security Violation, attempt to use \" + \"Restricted Class: \" + name; log.info(error, se); throw new ClassNotFoundException(error, se); } } } // 4 boolean delegateLoad = delegate || filter(name); // 5 // (1) Delegate to our parent if requested if (delegateLoad) { if (log.isDebugEnabled()) log.debug(\" Delegating to parent classloader1 \" + parent); ClassLoader loader = parent; if (loader == null) loader = system; try { clazz = Class.forName(name, false, loader); if (clazz != null) { if (log.isDebugEnabled()) log.debug(\" Loading class from parent\"); if (resolve) resolveClass(clazz); return (clazz); } } catch (ClassNotFoundException e) { // Ignore } } // (2) Search local repositories if (log.isDebugEnabled()) log.debug(\" Searching local repositories\"); // 6 try { clazz = findClass(name); if (clazz != null) { if (log.isDebugEnabled()) log.debug(\" Loading class from local repository\"); if (resolve) resolveClass(clazz); return (clazz); } } catch (ClassNotFoundException e) { // Ignore } // (3) Delegate to parent unconditionally // 7 if (!delegateLoad) { if (log.isDebugEnabled()) log.debug(\" Delegating to parent classloader at end: \" + parent); ClassLoader loader = parent; if (loader == null) loader = system; try { clazz = Class.forName(name, false, loader); if (clazz != null) { if (log.isDebugEnabled()) log.debug(\" Loading class from parent\"); if (resolve) resolveClass(clazz); return (clazz); } } catch (ClassNotFoundException e) { // Ignore } } throw new ClassNotFoundException(name); } 标注1代码：首先从当前ClassLoader的本地缓存中加载类，如果找到则返回。 标注2代码：在本地缓存没有的情况下，调用ClassLoader#findLoadedClass()查看JVM是否已经加载过此类，如果已经加载则直接返回。 标注3代码：通过系统的来加载器加载此类，这里防止应用写的类覆盖J2SE的类，这句代码非常关键，如果不写的话，就会造成你自己写的类有可能会把J2SE的类给替换调，另外假如你写一个javax.servlet.Servlet类，放在当前应用的WEB-INF/class中，如果没有此句代码的保证，那么你自己写的类就会替换到Tomcat容器Lib中包含的类。 标注4代码：判断是否需要委托给父类加载器进行加载，delegate属性默认为false，那么delegatedLoad的值就取决于filter的返回值，filter()中根据包名来判断是否需要进行委托加载，默认情况下会返回false。因此delegatedLoad = false。 标注5代码：因为delegatedLoad = false，那么此时不会委托父加载器去加载，这里其实是没有遵循parent-first的加载机制。 标注6代码：调用findClass()在webapp级别进行加载。 标注7代码：如果还是没有加载到类，并且不采用委托机制的话，则通过父类加载器去加载。 通过上面的描述，可以知道Tomcat在加载webapp级别的类的时候，默认是不遵守parent-first的，这样做的好处是更好的实现应用的隔离，但是坏处就是加大内存浪费，同样的类库要在不同的app中都要加载一份。上面分析完loadClass，接着在来分析一下findClass。org.apache.catalina.loader.WebappClassLoader#findClass()123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113/** * Find the specified class in our local repositories, if possible. If * not found, throw &lt;code&gt;ClassNotFoundException&lt;/code&gt;. * * @param name Name of the class to be loaded * * @exception ClassNotFoundException if the class was not found */ @Override public Class&lt;?&gt; findClass(String name) throws ClassNotFoundException { if (log.isDebugEnabled()) log.debug(\" findClass(\" + name + \")\"); // Cannot load anything from local repositories if class loader is stopped if (!started) { throw new ClassNotFoundException(name); } // (1) Permission to define this class when using a SecurityManager if (securityManager != null) { int i = name.lastIndexOf('.'); if (i &gt;= 0) { try { if (log.isTraceEnabled()) log.trace(\" securityManager.checkPackageDefinition\"); securityManager.checkPackageDefinition(name.substring(0,i)); } catch (Exception se) { if (log.isTraceEnabled()) log.trace(\" --&gt;Exception--&gt;ClassNotFoundException\", se); throw new ClassNotFoundException(name, se); } } } // Ask our superclass to locate this class, if possible // (throws ClassNotFoundException if it is not found) Class&lt;?&gt; clazz = null; try { if (log.isTraceEnabled()) log.trace(\" findClassInternal(\" + name + \")\"); if (hasExternalRepositories &amp;&amp; searchExternalFirst) { try { clazz = super.findClass(name); } catch(ClassNotFoundException cnfe) { // Ignore - will search internal repositories next } catch(AccessControlException ace) { log.warn(\"WebappClassLoader.findClassInternal(\" + name + \") security exception: \" + ace.getMessage(), ace); throw new ClassNotFoundException(name, ace); } catch (RuntimeException e) { if (log.isTraceEnabled()) log.trace(\" --&gt;RuntimeException Rethrown\", e); throw e; } } if ((clazz == null)) { try { clazz = findClassInternal(name); } catch(ClassNotFoundException cnfe) { if (!hasExternalRepositories || searchExternalFirst) { throw cnfe; } } catch(AccessControlException ace) { log.warn(\"WebappClassLoader.findClassInternal(\" + name + \") security exception: \" + ace.getMessage(), ace); throw new ClassNotFoundException(name, ace); } catch (RuntimeException e) { if (log.isTraceEnabled()) log.trace(\" --&gt;RuntimeException Rethrown\", e); throw e; } } if ((clazz == null) &amp;&amp; hasExternalRepositories &amp;&amp; !searchExternalFirst) { try { clazz = super.findClass(name); } catch(AccessControlException ace) { log.warn(\"WebappClassLoader.findClassInternal(\" + name + \") security exception: \" + ace.getMessage(), ace); throw new ClassNotFoundException(name, ace); } catch (RuntimeException e) { if (log.isTraceEnabled()) log.trace(\" --&gt;RuntimeException Rethrown\", e); throw e; } } if (clazz == null) { if (log.isDebugEnabled()) log.debug(\" --&gt; Returning ClassNotFoundException\"); throw new ClassNotFoundException(name); } } catch (ClassNotFoundException e) { if (log.isTraceEnabled()) log.trace(\" --&gt; Passing on ClassNotFoundException\"); throw e; } // Return the class we have located if (log.isTraceEnabled()) log.debug(\" Returning class \" + clazz); if (log.isTraceEnabled()) { ClassLoader cl; if (Globals.IS_SECURITY_ENABLED){ cl = AccessController.doPrivileged( new PrivilegedGetClassLoader(clazz)); } else { cl = clazz.getClassLoader(); } log.debug(\" Loaded by \" + cl.toString()); } return (clazz); } 通过分析findClass的代码，最终会调用org.apache.catalina.loader.WebappClassLoader#findClassInternal()，那我们就来分析一下它的代码。org.apache.catalina.loader.WebappClassLoader#findClassInternal()123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106/** * Find specified class in local repositories. * * @return the loaded class, or null if the class isn't found */ protected Class&lt;?&gt; findClassInternal(String name) throws ClassNotFoundException { if (!validate(name)) throw new ClassNotFoundException(name); String tempPath = name.replace('.', '/'); String classPath = tempPath + \".class\"; ResourceEntry entry = null; if (securityManager != null) { PrivilegedAction&lt;ResourceEntry&gt; dp = new PrivilegedFindResourceByName(name, classPath); entry = AccessController.doPrivileged(dp); } else { // 1 entry = findResourceInternal(name, classPath); } if (entry == null) throw new ClassNotFoundException(name); Class&lt;?&gt; clazz = entry.loadedClass; if (clazz != null) return clazz; synchronized (this) { clazz = entry.loadedClass; if (clazz != null) return clazz; if (entry.binaryContent == null) throw new ClassNotFoundException(name); // Looking up the package String packageName = null; int pos = name.lastIndexOf('.'); if (pos != -1) packageName = name.substring(0, pos); Package pkg = null; if (packageName != null) { pkg = getPackage(packageName); // Define the package (if null) if (pkg == null) { try { if (entry.manifest == null) { definePackage(packageName, null, null, null, null, null, null, null); } else { definePackage(packageName, entry.manifest, entry.codeBase); } } catch (IllegalArgumentException e) { // Ignore: normal error due to dual definition of package } pkg = getPackage(packageName); } } if (securityManager != null) { // Checking sealing if (pkg != null) { boolean sealCheck = true; if (pkg.isSealed()) { sealCheck = pkg.isSealed(entry.codeBase); } else { sealCheck = (entry.manifest == null) || !isPackageSealed(packageName, entry.manifest); } if (!sealCheck) throw new SecurityException (\"Sealing violation loading \" + name + \" : Package \" + packageName + \" is sealed.\"); } } try { // 2 clazz = defineClass(name, entry.binaryContent, 0, entry.binaryContent.length, new CodeSource(entry.codeBase, entry.certificates)); } catch (UnsupportedClassVersionError ucve) { throw new UnsupportedClassVersionError( ucve.getLocalizedMessage() + \" \" + sm.getString(\"webappClassLoader.wrongVersion\", name)); } entry.loadedClass = clazz; entry.binaryContent = null; entry.source = null; entry.codeBase = null; entry.manifest = null; entry.certificates = null; } return clazz; } 标注1代码：通过名称去当前webappClassLoader的仓库中查找对应的类文件。 标注2代码：将找到的类文件通过defineClass转变为JVM可以识别的Class对象返回。","link":"/Tomcat-5/"},{"title":"排序算法","text":"1 排序 稳定性的定义 稳定性的意义 稳定排序 不稳定排序 2 直接插入排序 基本思想 时间复杂度 空间复杂度 稳定性 Java C++ 2 希尔排序 类型 基本思想 时间复杂度 空间复杂度 稳定性 规模大小 java C++ 3 简单选择排序 基本思想 时间复杂度 空间复杂度 稳定性 Java 例1 例2 例3 4 堆排序 基本思想 构建堆 排序 时间复杂度 空间复杂度 稳定性 Java 例1 例2 5 冒泡排序 基本思想 时间复杂度 空间复杂度 稳定性 Java 例1 例2 C++ 6 快速排序 基本思想 步骤 时间复杂度 空间复杂度 稳定性 规模大小 优化 Java 例1 例2 C++ 7 两路合并排序 基本思想 时间复杂度 空间复杂度 稳定性 Java 例1 例2 C++ 8 基数排序 基本思想 时间复杂度 空间复杂度 稳定排序 Java 例1 例2 1 排序内部排序：待排序的元素总数相对于内存而言较小，整个排序过程可以在内存中进行。外部排序：待排序的元素总数较多，不能全部放入内存，排序过程中需要访问外存。内部排序算法有很多，各有其优缺点和适合的场合。排序的稳定性：如果在排序的序列中，存在前后相同的两个元素的话，排序前和排序后他们的相对位置不发生变化。 稳定性的定义假定在待排序的记录序列中，存在多个具有相同的关键字的记录，若经过排序，这些记录的相对次序保持不变，即在原序列中，$r_i$=$r_j$，且$r_i$在$r_j$之前，而在排序后的序列中，$r_i$仍在$r_j$之前，则称这种排序算法是稳定的；否则称为不稳定的。对于不稳定的排序算法，只要举出一个实例，即可说明它的不稳定性；而对于稳定的排序算法，必须对算法进行分析从而得到稳定的特性。需要注意的是，排序算法是否为稳定的是由具体算法决定的，不稳定的算法在某种条件下可以变为稳定的算法，而稳定的算法在某种条件下也可以变为不稳定的算法。 稳定性的意义 如果只是简单的进行数字的排序，那么稳定性将毫无意义。 如果排序的内容仅仅是一个复杂对象的某一个数字属性，那么稳定性依旧将毫无意义。 如果要排序的内容是一个复杂对象的多个数字属性，但是其原本的初始顺序毫无意义，那么稳定性依旧将毫无意义。 除非要排序的内容是一个复杂对象的多个数字属性，且其原本的初始顺序存在意义，那么我们需要在二次排序的基础上保持原有排序的意义，才需要使用到稳定性的算法，例如要排序的内容是一组原本按照价格高低排序的对象，如今需要按照销量高低排序，使用稳定性算法，可以使得想同销量的对象依旧保持着价格高低的排序展现，只有销量不同的才会重新排序。稳定排序基数排序、冒泡排序、直接插入排序、两两插入排序、归并排序。不稳定排序堆排序、快速排序、希尔排序、简单选择排序。2 直接插入排序基本思想将数组中第1个元素作为有序序列，然后将剩下的n-1数组元素，按照顺序插入第1个元素的序列中。插入第1个元素后，第1个元素的序列保持有序。将待插入有序序列的元素存入临时变量temp中，在有序序列从后往前比较大小，查找插入的位置。当temp小于有序序列的元素时，该有序序列元素往后移1位，temp元素继续比较。直到有序序列中有元素比temp小、或者到有序序列第1个元素时结束，这时将temp插入有序序列元素的位置。插入排序会优于选择排序，理由是它在排序过程中能够利用前部分数组元素已经排好序的一个优势，有效地减少一些比较的次数，当然这种优势得看数组的初始顺序如何，最坏的情况下(给定的数组恰好为倒序)插入排序需要比较和移动的次数将会等于 1 + 2 + 3… + n = n * (n + 1) / 2 ，这种极端情况下，插入排序的效率甚至比选择排序更差。 时间复杂度最好情况比较次数是O(n)(有序)，最坏情况比较次数O(n*n)无序。空间复杂度O(1)每次都交换一个元素 稳定性插入排序是稳定排序，如果碰到相等的元素，就把新元素插入相等元素的后面，即他们原来的顺序没有变化。（插入排序在全部元素插入完毕之前，都不能确定最终一个元素的位置）temp &lt; A[j - 1]，如果改成temp &lt;= A[j - 1]，则是不稳定排序。 Java 12345678910111213141516171819202122232425package insert;public class InsertSort { void sort(int[] A) { for (int i = 1; i &lt; A.length; i++) { int temp = A[i];//待插入的元素存入临时变量 int j = i; while (j &gt; 0 &amp;&amp; temp &lt; A[j - 1]) {//临时变量与排好序的数组元素进行比较（从后往前进行查找），如果临时变量比数组元素值要小，排好序的数组元素往后移1位 A[j] = A[j - 1];//A[j-1]位置往后移 j--; } A[j] = temp;//临时元素temp插入A[j]位置，temp&gt;A[j] } } public static void main(String[] args) { InsertSort insertSort=new InsertSort(); int a[] = { 49, 38, 65, 97, 76, 13, 27, 49, 78, 34, 12, 64, 5, 4, 62, 99, 98, 54, 101, 56, 17, 18, 23, 34, 15, 35, 25, 53, 51 }; insertSort.sort(a); for (int i = 0; i &lt; a.length; i++) { System.out.print(a[i]+\"，\"); } }} C++高亮数字标记的数字为插入的数字，被划掉的数字是未参与此次排序的元素，高亮数字标记的数字与被划掉数字之间的元素为逐个向后移动的元素，比如第二趟参与排序的元素为[11, 31, 12]，需要插入的元素为12，但是12当前并没有处于正确的位置，于是我们需要依次与前面的元素31、11做比较，一边比较一边移动比较过的元素，直到找到第一个比12小的元素11时停止比较，此时31对应的索引1则是12需要插入的位置。初始： [11, 31, 12, 5, 34, 30, 26, 38, 36, 18]第一趟： [11, 31 , 12, 5, 34, 30, 26, 38, 36, 18] (无移动的元素)第二趟： [11, 12 , 31, 5, 34, 30, 26, 38, 36, 18] (31 向后移动)第三趟： [5 , 11, 12, 31, 34, 30, 26, 38, 36, 18] (11, 12, 31 皆向后移动)第四趟： [5, 11, 12, 31, 34 , 30, 26, 38, 36, 18] (无移动的元素)第五趟： [5, 11, 12, 30 , 31, 34, 26, 38, 36, 18] (31, 34 向后移动)第六趟： [5, 11, 12, 26 , 30, 31, 34, 38, 36, 18] (30, 31, 34 向后移动)第七趟： [5, 11, 12, 26, 30, 31, 34, 38 , 36, 18] (无移动的元素)第八趟： [5, 11, 12, 26, 30, 31, 34, 36 , 38, 18] (38 向后移动)第九趟： [5, 11, 12, 18 , 26, 30, 31, 34, 36, 38] (26, 30, 31, 34, 36, 38 向后移动) 123456789101112131415161718192021/** * Insertion Sorting */ INSERTION(new Sortable() { public &lt;T extends Comparable&lt;T&gt;&gt; void sort(T[] array, boolean ascend) { int len = array.length; for (int i = 1; i &lt; len; i++) { T toInsert = array[i]; //定义一个临时变量，待插入元素 int j = i; for (; j &gt; 0; j--) { int compare = array[j - 1].compareTo(toInsert); //有序序列中的元素和待插入的元素比较 if (compare == 0 || compare &lt; 0 == ascend) { break; } array[j] = array[j - 1]; //有序序列中的元素往后移1位 } array[j] = toInsert; } } }) 2 希尔排序类型插入排序。 基本思想按下标的一定增量分组(把所有序号相隔d的数组元素放一组，d=n/2，n为要排序数的个数)，每组中记录的下标相差d，对每组使用直接插入排序算法排序。随着增量逐渐减少，每组包含的关键词越来越多，然后再用一个较小的增量(d/2)对它进行分组，当增量减至1时，整个文件恰被分成一组，进行直接插入排序后，排序完成。该方法实质上是一种分组插入方法：比较相隔较远距离(称为增量)的数，使得数移动时能跨过多个元素，则进行一次比较就可能消除多个元素交换。本质上讲，希尔排序算法是直接插入排序算法的一种改进，减少了其复制的次数，速度要快很多。原因是，当n值很大时数据项每一趟排序需要的个数很少，但数据项的距离很长。当n值减小时每一趟需要和动的数据增多，此时已经接近于它们排序后的最终位置。 正是这两种情况的结合才使希尔排序效率比插入排序高很多。希尔排序的诞生是由于插入排序在处理大规模数组的时候会遇到需要移动太多元素的问题。希尔排序的思想是将一个大的数组“分而治之”，划分为若干个小的数组。比如数组[1, 2, 3, 4, 5, 6, 7, 8]，如果以gap = 2来划分，可以分为[1, 3, 5, 7]和[2, 4, 6, 8]两个数组(对应的，如gap = 3，则划分的数组为：[1, 4, 7] 、[2, 5, 8]、[3, 6])然后分别对划分出来的数组进行插入排序，待各个子数组排序完毕之后，再减小gap值重复进行之前的步骤，直至gap = 1，即对整个数组进行插入排序，此时的数组已经基本上快排好序了，所以需要移动的元素会很小很小，解决了插入排序在处理大规模数组时较多移动次数的问题。希尔排序是插入排序的改进版，在数据量大的时候对效率的提升帮助很大，数据量小的时候建议直接使用插入排序就好了。 时间复杂度希尔排序的时间复杂度与增量序列的选取有关。例如希尔增量时间复杂度为O($n^2$)，希尔排序时间复杂度的下界是$nlog2n$。希尔排序没有快速排序算法快O(n(logn))，因此中等大小规模表现良好，对规模非常大的数据排序不是最优选择。但是比`O(nn)`复杂度的算法快得多。 空间复杂度O(1) 稳定性由于多次插入排序，知道一次插入排序是稳定的，不会改变相同元素的相对顺序，但在不同的插入排序过程中，相同的元素可能在各自的插入排序中移动，最后其稳定性就会被打乱，所以希尔排序是不稳定排序。 规模大小中等规模比较适合，数据量大排序不是最好选择。基于插入排序的以下两点性质而提出改进方法的：插入排序在对几乎已经排好序的数据操作时，效率高，即可以达到线性排序的效率。但插入排序一般来说是低效的，因为插入排序每次只能将数据移动一位。 java123456789101112131415161718192021222324252627282930313233343536package hill; public class HillSort2 { public static void main(String[] args) { shellSort(); } public static void shellSort() { int a[] = { 1, 54, 6, 3, 78, 34, 12, 45, 56, 100 }; double d1 = a.length; int temp = 0; while (true) { //增量 d1 = Math.ceil(d1 / 2); int d = (int) d1; //对每个分组进行插入排序 for (int x = 0; x &lt; d; x++) { //第1个位置的增量i for (int i = x + d; i &lt; a.length; i += d) { //每个小分组进行插入排序 int j = i - d; temp = a[i]; for (; j &gt;= 0 &amp;&amp; temp &lt; a[j]; j -= d) { a[j + d] = a[j]; } a[j + d] = temp; } } if (d == 1) break; } for (int i = 0; i &lt; a.length; i++) System.out.print(a[i]+\"，\"); }} 123456789101112131415161718192021222324252627282930313233343536373839404142434445package hill;import java.util.Arrays;public class HillSort { public static int[] a = { 29, 1, 59, 12, 4, 77, 40, 20, 15, 10, 44, 8, 81, 0, 8, 13, 16 }; public static void main(String[] args) { // 设置循环 - 步长 - 间隔 for (int m = a.length / 2; m &gt; 0; m = m / 2) { // 根据步长确定需要排序的数组下标索引 //根据步长进行分组的 for (int n = 0; n &lt; a.length; n = n + m) { // 对特定数组索引构成的数组进行插入排序 shellSort(a, n, m); } } System.out.println(Arrays.toString(a)); } /** * 简单的插入排序算法 * * @param a * 需要进行插入排序的数组 * @param startIndex * 插入排序的起始索引 * @param space * 插入排序的步长 */ public static void shellSort(int[] a, int startIndex, int space) { // 循环右边的无序队列 - 从左到右 for (int i = startIndex + space; i &lt; a.length; i += space) { // 循环插入到左边的有序队列中,并且使队列有序 - 从左到右 for (int j = i - space; j &gt;= startIndex; j -= space) { if (a[j + space] &lt; a[j]) { // 移动有序交换位置 int temp = a[j + space]; a[j + space] = a[j]; a[j] = temp; } } } }} C++1234567891011121314151617181920212223242526272829303132/** * Shell Sorting */ SHELL(new Sortable() { public &lt;T extends Comparable&lt;T&gt;&gt; void sort(T[] array, boolean ascend) { int length = array.length; int gap = 1; // use the most next to length / 3 as the first gap while (gap &lt; length / 3) { gap = gap * 3 + 1; } while (gap &gt;= 1) { for (int i = gap; i &lt; length; i++) { T next = array[i]; int j = i; while (j &gt;= gap) { int compare = array[j - gap].compareTo(next); // already find its position if (compare == 0 || compare &lt; 0 == ascend) { break; } array[j] = array[j - gap]; j -= gap; } if (j != i) { array[j] = next; } } gap /= 3; } } }) 3 简单选择排序基本思想在数组A[n]寻找最小值元素，最小元素与数组第一个元素进行比较，然后交换。下一趟排序在A[1]~A[n-1]中进行，第i趟排序在待排序子序列(A[i-1]~A[n-1])中寻找最小值元素，这最小值元素与第一个元素A[i-1]交换。 时间复杂度O(N*N)最好情况比较次数是0(默认就是有序)，最坏情况是无序。比较次数。对于n个元素的序列，找出最小元素需要比较n-1次。第1回合后，序列只剩下n-1个元素，下1次找最小元素还需要n-2次比较。最后直到2个元素需要比较1次。所以最后比较次数总共为(n-1)+(n-2)+...+1=n(n-1)/2。最多交换次数为n-1。 空间复杂度O(n) 稳定性进过一趟排序之后，就可以确定元素的位置，选择排序是不稳定排序。比如[4,8,3,4,2,9,7]，第1个位置选择最小的元素2，与第一个位置的4交换，这破环了原来两个4之间的顺序。 Java例11234567891011121314151617181920212223242526272829public class SelectSort { void sort(int[] A) { int small;// 数组中最小值 for (int i = 0; i &lt; A.length; i++) { small = i; //假设，第一个元素最小 for (int j = i + 1; j &lt; A.length; j++) { //与A[1]~A[n]的 if (A[j] &lt; A[small]) { small = j;// j是最小值，赋值给small } } //swap(A[i], A[small]);// 最小值元素与待排序第一个元素交换位置 int temp = A[i]; A[i] = A[small]; A[small] = temp; } } public static void main(String[] args) { SelectSort selectSort = new SelectSort(); int a[] = { 49, 38, 65, 97, 76, 13, 27, 49, 78, 34, 12, 64, 5, 4, 62, 99, 98, 54, 101, 56, 17, 18, 23, 34, 15, 35, 25, 53, 51 }; selectSort.sort(a); for (int i = 0; i &lt; a.length; i++) { System.out.print(a[i] + \"，\"); } }} 例2高亮数字是交换数字。初始： [38, 17, 16, 16, 7, 31, 39, 32, 2, 11]i = 0: [2 , 17, 16, 16, 7, 31, 39, 32, 38 , 11] ([38]8th [2])i = 1: [2, 7 , 16, 16, 17 , 31, 39, 32, 38, 11] ([38]4th [17])i = 2: [2, 7, 11, 16, 17, 31, 39, 32, 38, 16] ([11]9th [16])i = 3: [2, 7, 11, 16, 17, 31, 39, 32, 38, 16] (无需交换)i = 4: [2, 7, 11, 16, 16, 31, 39, 32, 38, 17] ([17]9th [16])i = 5: [2, 7, 11, 16, 16, 17, 39, 32, 38, 31] ([31]9th [17])i = 6: [2, 7, 11, 16, 16, 17, 31, 32, 38, 39] ([39]9th [31])i = 7: [2, 7, 11, 16, 16, 17, 31, 32, 38, 39] (无需交换)i = 8: [2, 7, 11, 16, 16, 17, 31, 32, 38, 39] (无需交换)i = 9: [2, 7, 11, 16, 16, 17, 31, 32, 38, 39] (无需交换) 由例子可以看出，选择排序随着排序的进行(i逐渐增大)，比较的次数会越来越少，但是不论数组初始是否有序，选择排序都会从i至数组末尾进行一次选择比较，所以给定长度的数组，选择排序的比较次数是固定的：1 + 2 + 3 + …. + n = n * (n + 1) / 2，而交换的次数则跟初始数组的顺序有关，如果初始数组顺序为随机，则在最坏情况下，数组元素将会交换n次，最好的情况下则可能0次(数组本身即为有序)。123456789101112131415161718/** * Selection Sorting */ SELECTION(new Sortable() { public &lt;T extends Comparable&lt;T&gt;&gt; void sort(T[] array, boolean ascend) { int len = array.length; for (int i = 0; i &lt; len; i++) { int selected = i; for (int j = i + 1; j &lt; len; j++) { int compare = array[j].compareTo(array[selected]); if (compare != 0 &amp;&amp; compare &lt; 0 == ascend) { selected = j; } } exchange(array, i, selected); } } }) 例312345678910111213141516171819202122232425public class selectSort { public selectSort(){ int a[]={1,54,6,3,78,34,12,45}; int position=0; for(int i=0;i&lt;a.length;i++){ int j=i+1; //记录最小值下标 position=i; //记录最小值 int temp=a[i]; for(;j&lt;a.length;j++){ //比最小值还要小 if(a[j]&lt;temp){ temp=a[j]; position=j; } } a[position]=a[i]; //最小值赋值给i的位置 a[i]=temp; } for(int i=0;i&lt;a.length;i++) System.out.println(a[i]); }} 4 堆排序基本思想堆排序是一种树形选择排序，是对直接选择排序的有效改进。堆的定义如下：具有n个元素的序列$h_1$,$h_2$,…,$h_n$,当且仅当满足($h_i$&gt;=$h_{2i}$,$h_i$&gt;=2i+1)或($h_i$&lt;=$h_{2i}$,hi&lt;=2i+1)(i=1,2,…,n/2)时称之为堆。在这里只讨论满足前者条件的堆。由堆的定义可以看出，堆顶元素(即第一个元素)必为最大项(大顶堆)。完全二叉树可以很直观地表示堆的结构。堆顶为根，其它为左子树、右子树。初始时把要排序的数的序列看作是一棵顺序存储的二叉树，调整它们的存储序，使之成为一个堆，这时堆的根节点的数最大。然后将根节点与堆的最后一个节点交换。然后对前面n-1个数重新调整使之成为堆。依此类推，直到只有两个节点的堆，并对它们作交换，最后得到有n个节点的有序序列。从算法描述来看，堆排序需要两个过程，一是建立堆，二是堆顶与堆的最后一个元素交换位置。所以堆排序有两个函数组成。一是建堆的渗透函数，二是反复调用渗透函数实现排序的函数。堆排序主要2部分，构建堆和排序。 构建堆堆是包含N个节点的完全二叉树，每个节点的关键字大于等于双亲节点的关键字。定义一个关键字temp=A[r]，temp大于左右子数较小者，将temp与较小节点交换。 排序将初始化队列构成最大堆，第一趟将堆顶节点A[0]与A[n-1]节点进行交换；交换后，使得前n-1个节点还是堆。第i趟时，将顶节点A[0]与A[n-i]节点进行交换，交换后，使得前n-i个节点还是堆。简单概括堆排序就是顶节点与末尾节点进行交换，交换之后，重新构建堆。 时间复杂度建堆的时间复杂度是O(n)(调用一次)；调整堆的时间复杂度是$lgn$，调用n-1次，所以堆排序的时间复杂度是O($nlgn$) 空间复杂度O(1) 稳定性添加新节点不会破坏相同元素的顺序，但删除根节点获取会破坏，因此堆排序是不稳定排序。 Java例1初始序列：46,79,56,38,40,84建堆交换，从堆中踢出最大数123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566public class HeapSort1 { public static void main(String[] args) { HeapSort1 heapSort=new HeapSort1(); int a[] = { 49, 38, 65, 97, 76, 13, 27, 49, 78, 34, 12, 64, 5, 4, 62, 99, 98, 54, 101, 56, 17, 18, 23, 34, 15, 35, 25, 53, 51 }; int n=a.length; //建最大的堆 for (int i = (n-2)/2; i &gt;-1; i--) { heapSort.creatHeap(a, i, n-1); } for (int i = n-1; i &gt;0; i--) { //堆顶元素和堆底元素进行交换 int tmp=a[i]; a[i]=a[0]; a[0]=tmp; //创建堆 heapSort.creatHeap(a, 0, i-1); } for (int i = 0; i &lt; a.length; i++) { System.out.print(a[i]+\"，\"); } } /** * * @param data * @param i * @param j 堆底下标，最后一个数字下标 */ private void swap(int[] data, int i, int j) { int tmp=data[i]; data[i]=data[j]; data[j]=tmp; } // 创建最大堆 void creatHeap(int[] A, int r, int j) { // 左节点 int child = 2 * r + 1; // 做比较的节点 int temp = A[r]; while (child &lt;= j) { // 找到左右子数中较大的节点 if ((child &lt; j) &amp;&amp; (A[child] &lt; A[child + 1])) { child++; } // temp节点&gt;右子节点（大于较大的那个节点） //退出循环 if (temp &gt;= A[child]) { break; } //子节点值赋值给父节点 A[(child - 1) / 2] = A[child]; //child的子节点，为了下一次循环 child = child * 2 + 1; } //与较大的元素的父节点进行交换 A[(child - 1) / 2] = temp; }} 例212345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970package heap;public class HeapSort2 { int a[] = { 49, 38, 65, 97, 76, 13, 27, 49, 78, 34, 12, 64, 5, 4, 62, 99, 98, 54, 56, 17, 18, 23, 34, 15, 35, 25, 53, 51 }; public static void main(String[] args) { new HeapSort2(); } public HeapSort2() { heapSort(a); for (int i = 0; i &lt; a.length; i++) { System.out.print(a[i]+\"，\"); } } public void heapSort(int[] a) { System.out.println(\"开始排序\"); int arrayLength = a.length; // 循环建堆 for (int i = 0; i &lt; arrayLength - 1; i++) { // 建堆 buildMaxHeap(a, arrayLength - 1 - i); // 交换堆顶和最后一个元素 swap(a, 0, arrayLength - 1 - i); //System.out.println(Arrays.toString(a)); } } private void swap(int[] data, int i, int j) { int tmp = data[i]; data[i] = data[j]; data[j] = tmp; } // 对data数组从0到lastIndex建大顶堆 private void buildMaxHeap(int[] data, int lastIndex) { // 从lastIndex处节点（最后一个节点）的父节点开始 for (int i = (lastIndex - 1) / 2; i &gt;= 0; i--) { // k保存正在判断的节点，k作为父节点 int k = i; // 如果当前k节点的子节点存在 while (k * 2 + 1 &lt;= lastIndex) { // k节点的右子节点的索引 int biggerIndex = 2 * k + 1; // 如果biggerIndex小于lastIndex，即biggerIndex+1代表的k节点的右子节点存在 if (biggerIndex &lt; lastIndex) { // 若果右子节点的值较大 if (data[biggerIndex] &lt; data[biggerIndex + 1]) { // biggerIndex总是记录较大子节点的索引 biggerIndex++; } } // 如果k节点的值小于其较大的子节点的值 // 或者k节点的值大于其子节点较小的值 if (data[k] &lt; data[biggerIndex]) { // 交换他们 swap(data, k, biggerIndex); // 将biggerIndex赋予k，开始while循环的下一次循环，重新保证k节点的值大于其左右子节点的值（重新保证了，k节点作为父节点，继续下一次比较） k = biggerIndex; } else { break; } } } }} 5 冒泡排序基本思想冒泡排序通过交换2个元素实现，在数组内，2个相邻元素进行比较。若后者比较小，进行交换，比较n-1次。第一趟排序结束，最大元素被交换到数组末尾，下一趟排序在A[0]~A[n-2]中比较。冒泡排序跟选择排序比较相像，比较次数一样，都为n*(n+1)/2，但是冒泡排序在挑选最小值的过程中会进行额外的交换(冒泡排序在排序中只要发现相邻元素的顺序不对就会进行交换，与之对应的是选择排序，只会在内层循环比较结束之后根据情况决定是否进行交换)，所以在我看来，选择排序属于冒泡排序的改进版。对于n个元素，相邻元素均要比较，共有n-1次。经过一回合冒泡过程后，最大元素沉淀到最右位置。第二回合，只剩下n-1个元素，只需要比较n-2次。依次类推，其他比较次数为n-3,……,2,1. 所以总共比较次数为n*(n-1)/2。 时间复杂度最好情况比较次数是O(n)(有序)，最坏情况比较次数O(n*n)无序。 空间复杂度O(1) 稳定性每次都交换一个元素冒泡排序是稳定排序。 Java例112345678910111213141516171819202122232425262728293031323334353637public class maopaoSort { void sort(int[] A) { // last：值最大元素的下标位置 int i, j, last; i = A.length - 1; while (i &gt; 0) { last = 0; for (j = 0; j &lt; i; j++) { if (A[j] &gt; A[j + 1]) { //swap(A[j], A[j + 1]); int temp = A[j]; A[j] = A[j + 1]; A[j + 1] = temp; last = j;// last存，值最大元素的下标 } } i = last;// last值赋值i，表示last已经在数组最末尾了，每一次比较i的值逐渐变小，直到while循环结束 } } void swap(int a, int b) { int temp = a; a = b; b = temp; } public static void main(String[] args) { maopaoSort maopaoSort = new maopaoSort(); int a[] = { 49, 38, 65, 97, 76, 13, 27, 49, 78, 34, 12, 64, 5, 4, 62, 99, 98, 54, 101, 56, 17, 18, 23, 34, 15, 35, 25, 53, 51 }; maopaoSort.sort(a); for (int i = 0; i &lt; a.length; i++) { System.out.print(a[i] + \"，\"); } }} 例21234567891011121314151617public class bubbleSort { public bubbleSort(){ int a[]={49,38,65,97,76,13,27,49,78,34,12,64,5,4,62,99,98,54,56,17,18,23,34,15,35,25,53,51}; int temp=0; for(int i=0;i&lt;a.length-1;i++){ for(int j=0;j&lt;a.length-1-i;j++){ if(a[j]&gt;a[j+1]){ temp=a[j]; a[j]=a[j+1]; a[j+1]=temp; } } } for(int i=0;i&lt;a.length;i++) System.out.println(a[i]); }} C++初始状态： [24, 19, 26, 39, 36, 7, 31, 29, 38, 23]内层第一趟： [24, 19, 26, 39, 36, 7, 31, 29, 23, 38] ( [23][38] )内层第二趟： [24, 19, 26, 39, 36, 7, 31, 23, 29, 38] ( [23][29] )内层第三趟： [24, 19, 26, 39, 36, 7, 23, 31 , 29, 38] ( [23][31] )内层第四趟： [24, 19, 26, 39, 36, 7, 23, 31, 29, 38] ( 7 、 23 都位于正确的顺序，无需交换)内层第五趟： [24, 19, 26, 39, 7, 36, 23, 31, 29, 38] ( [7][36] )内层第六趟： [24, 19, 26, 7, 39, 36, 23, 31, 29, 38] ( [7][39] )内层第七趟： [24, 19, 7, 26, 39, 36, 23, 31, 29, 38] ( [7][26] )内层第八趟： [24, 7, 19, 26, 39, 36, 23, 31, 29, 38] ( [7][19] )内层第九趟： [7, 24, 19, 26, 39, 36, 23, 31, 29, 38] ( [7][24] )123456789101112131415161718192021222324252627/** * Bubble Sorting, it's very similar with Insertion Sorting */ BUBBLE(new Sortable() { public &lt;T extends Comparable&lt;T&gt;&gt; void sort(T[] array, boolean ascend) { int length = array.length; int lastExchangedIdx = 0; for (int i = 0; i &lt; length; i++) { // mark the flag to identity whether exchange happened to false boolean isExchanged = false; // last compare and exchange happened before reaching index i int currOrderedIdx = lastExchangedIdx &gt; i ? lastExchangedIdx : i; for (int j = length - 1; j &gt; currOrderedIdx; j--) { int compare = array[j - 1].compareTo(array[j]); if (compare != 0 &amp;&amp; compare &gt; 0 == ascend) { exchange(array, j - 1, j); isExchanged = true; lastExchangedIdx = j; } } // if no exchange happen means array is already in order if (isExchanged == false) { break; } } } }) 6 快速排序基本思想快速排序也是用归并方法实现的一个“分而治之”的排序算法，它的魅力之处在于它能在每次partition(排序算法的核心所在)都能为一个数组元素确定其排序最终正确位置(下次循环就不考虑这个元素了)。 步骤 确定一个元素R(第一个元素是分割元素)是数组分割元素，将数组分割成低端序列(比分割元素值小)和高端序列(比分割元素值大)。 用left和right来指向原序列第一个元素和最后一个元素，2个变量i，j作为游动指针，初始化为i=left,j=right+1；i从低端序列左边开始向右扫描，找到第1个大于或者等于分割元素的元素，i&lt;j；则A[i]赋值A[j]； j从高端序列右边开始向左扫描，找到第1个小于或者等于分割元素的元素，i&lt;j；则A[j]赋值A[i]；然后，继续次操作，直到i&gt;=j时，这趟排序结束。原来属于低端的值，放在低端。属于高端的值，在高端。 分割元素A[left]和A[i]交换，分割元素回到分割位置，分别对低端序列和高端序列排序。 时间复杂度初始序列有序，这时候快速排序效率最低平均情况下，最坏情况比较次数O(n*n)。最优情况是O($nlogN$)。 空间复杂度最坏情况下O(n)。 稳定性进过1趟排序，就可以确认元素的位置，是不稳定排序。如[5,3,3,4,3,8,9,10]第1次切分，主元5要和元素3交换，即改变了3和另两个相等元素之间的顺序。 规模大小元素多的情形，适合无序序列，元素较小，还不如其他排序。 优化分割元素最大值或者最小值，会导致排序效率最低，为了避免这种情况，选取分割元素的时候，可以做如下处理。 A[(left+right)/2]作为分割元素，与A[left]进行交换。 取left和right随机数，与A[left]进行交换。 去A[left]，A[(left+right)/2]和A[right]之间的值，与A[left]进行交换。 Java例1123456789101112131415161718192021222324252627282930313233343536373839404142package quick;public class QuickSort { void sort(int[] A, int left, int right) { int i = 0, j = 0; if (left &lt; right) { i = left; j = right; int key = A[left]; // 将小于分割元素放到低端，将大于分割元素放到高端 while (i &lt; j) { while (i &lt; j &amp;&amp; A[j] &gt;= key) { j--; } if (i &lt; j) { A[i] = A[j]; } while (i &lt; j &amp;&amp; A[i] &lt;= key) { i++; } if (i &lt; j) { A[j] = A[i]; } } A[j] = key; // 对低端元素进行排序 sort(A, 0, i - 1); // 对高端元素进行排序 sort(A, j + 1, right); } } public static void main(String[] args) { QuickSort quickSort = new QuickSort(); int a[] = { 49, 38, 65, 97, 76, 13, 27, 49, 78, 34, 12, 64, 5, 4, 62, 99, 98, 54, 101, 56, 17, 18, 23, 34, 15, 35, 25, 53, 51 }; quickSort.sort(a, 0, a.length - 1); for (int i = 0; i &lt; a.length; i++) { System.out.print(a[i] + \"，\"); } }} 例2123456789101112131415161718192021222324252627282930313233343536public class quickSort { int a[]={49,38,65,97,76,13,27,49,78,34,12,64,5,4,62,99,98,54,56,17,18,23,34,15,35,25,53,51}; public quickSort(){ quick(a); for(int i=0;i&lt;a.length;i++) System.out.println(a[i]); } public int getMiddle(int[] list, int low, int high) { int tmp = list[low]; //数组的第一个作为中轴 while (low &lt; high) { while (low &lt; high &amp;&amp; list[high] &gt;= tmp) { high--; } list[low] = list[high]; //比中轴小的记录移到低端 while (low &lt; high &amp;&amp; list[low] &lt;= tmp) { low++; } list[high] = list[low]; //比中轴大的记录移到高端 } list[low] = tmp; //中轴记录到尾 return low; //返回中轴的位置 } public void _quickSort(int[] list, int low, int high) { if (low &lt; high) { int middle = getMiddle(list, low, high); //将list数组进行一分为二 _quickSort(list, low, middle - 1); //对低字表进行递归排序 _quickSort(list, middle + 1, high); //对高字表进行递归排序 } } public void quick(int[] a2) { if (a2.length &gt; 0) { //查看数组是否为空 _quickSort(a2, 0, a2.length - 1); } } } C++初始（i = 1, lt = 0, gt = 8）：[41, 59, 43, 26, 63, 30, 29, 26, 42]（需要确定位置的为[41]）第一趟（i = 1, lt = 0, gt = 8）：[41, 42, 43, 26, 63, 30, 29, 26, 59]（59&gt;41，[59][42]，gt–）第二趟（i = 1, lt = 0, gt = 7）：[41, 26, 43, 26, 63, 30, 29, 42, 59]（42&gt;41，[42][26]，gt–）第三趟（i = 1, lt = 0, gt = 6）：[26, 41, 43, 26, 63, 30, 29, 42, 59]（26&lt;41, [26][41]，i++, lt++）第四趟（i = 2, lt = 1, gt = 6）：[26, 41, 29, 26, 63, 30, 43, 42, 59]（43&gt;41，[43][29]，gt–）第五趟（i = 2, lt = 1, gt = 5）：[26, 29, 41, 26, 63, 30, 43, 42, 59]（29&lt;41, [29][41]，i++，lt++）第六趟（i = 3, lt = 2, gt = 5）：[26, 29, 26, 41, 63, 30, 43, 42, 59]（26&lt;41，[26][41]，i++，lt++）第七趟（i = 4, lt = 3, gt = 5）：[26, 29, 26, 41, 30, 63, 43, 42, 59] （63&gt;41，[63][30]，gt–）第八趟（i = 4, lt = 3, gt = 4）：[26, 29, 26, 30, 41, 63, 43, 42, 59]（30&lt;41，[30][41]，i++，lt++） 可以看出，在一次partition之后，以41为分割线，41左侧皆为比它小的元素，41右侧皆为比它大或相等的元素（当然这个实例比较特殊，没有出现和41相等的元素）。快速排序顾名思义就是排序速度非常快。值得一提的是JDK中在Arrays工具内中内置的sort方法就是接合插入排序和三路快速排序实现的，有兴趣的同学可以看看JDK的源码。123456789101112131415161718192021222324252627282930313233/** * Quick Sorting */ QUICK(new Sortable() { public &lt;T extends Comparable&lt;T&gt;&gt; void sort(T[] array, boolean ascend) { this.sort(array, 0, array.length - 1, ascend); } private &lt;T extends Comparable&lt;T&gt;&gt; void sort(T[] array, int lo, int hi, boolean ascend) { if (lo &gt;= hi) { return; } T toFinal = array[lo]; int leftIdx = lo; int rightIdx = hi; int i = lo + 1; while (i &lt;= rightIdx) { int compare = array[i].compareTo(toFinal); if (compare == 0) { i++; } else if (compare &lt; 0 == ascend) { exchange(array, leftIdx++, i++); } else { exchange(array, rightIdx--, i); } } // partially sort left array and right array // no need to include the leftIdx-th to rightIdx-th elements // since they are already in its final position sort(array, lo, leftIdx - 1, ascend); sort(array, rightIdx + 1, hi, ascend); } }) 7 两路合并排序基本思想归并排序采用的是递归来实现，属于“分而治之”，将目标数组从中间一分为二，之后分别对这两个数组进行排序，排序完毕之后再将排好序的两个数组“归并”到一起，归并排序最重要的也就是这个“归并”的过程。将N个元素的数组，看成N个长度为1的子序列，然后进行两两合并子序列，得到N/2个长度为2的有序子序列，然后不停的两两2合并，新创建一个临时数组，来存放临时排序的数据，定义子序列的上界和下界。 时间复杂度最差情况O(n$\\log{N}$)，最好情况O($\\log{N}$) 空间复杂度O(n) 稳定性将待排序列递归地划分为短序列，指导每部分都只包含一个元素，然后再合并，合并时如果两个元素相等也会按照元素之前的顺序，把下标小的元素先放入结果列表中，依然没有破环相同元素之间原本的顺序，因此归并算法也是稳定排序。 Java例1123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263package merge; public class MergeSort { /** * 子序列1的上界：i1；下界：j1 * 子序列1的上界：i2，下界：j2 * 2个子序列是相邻的，所以：i2=j1+1 * @param A * @param i1 子序列1上界 * @param j1 子序列1下界 * @param i2 子序列2上界 * @param j2 子序列2下界 */ void merge(int[] A, int i1, int j1, int i2, int j2) { // 创建一个临时数组，来存取子序列 int[] temp = new int[A.length]; // i，j是子序列的游动指针，k是临时数组游动指针 int i = i1, j = i2, k = 0; // 将2个子序列中最小值，存入临时数组 while (i &lt;= j1 &amp;&amp; j &lt;= j2) { if (A[i] &lt;= A[j]) { temp[k++] = A[i++]; } else { temp[k++] = A[j++]; } } //第一个序列还有剩余元素，再存入temp while (i &lt;= j1) { temp[k++] = A[i++]; } //第二个序列还有剩余元素，再存入temp while (j &lt;= j2) { temp[k++] = A[j++]; } // 将临时数组值赋值给原数组A for (int k2 = 0; k2 &lt; k; k2++) { A[i1++] = temp[k2]; } } public void sort(int[] A, int left, int right) { if(left&lt;right){ // 找出中间索引 int center = (left + right) / 2; // 对左边数组进行递归 sort(A, left, center); // 对右边数组进行递归 sort(A, center + 1, right); merge(A, left, center, center + 1, right); } } public static void main(String[] args) { MergeSort mergeSort = new MergeSort(); int a[] = { 49, 38, 65, 97, 76, 13, 27, 49, 78, 34, 12, 64, 5, 4, 62, 99, 98, 54, 101, 56, 17, 18, 23, 34, 15, 35, 25, 53, 51 }; mergeSort.sort(a, 0, a.length-1); for (int i = 0; i &lt; a.length; i++) { System.out.print(a[i] + \"，\"); } }} 例212345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152import java.util.Arrays; public class mergingSort { int a[]={49,38,65,97,76,13,27,49,78,34,12,64,5,4,62,99,98,54,56,17,18,23,34,15,35,25,53,51}; public mergingSort(){ sort(a,0,a.length-1); for(int i=0;i&lt;a.length;i++) System.out.println(a[i]); } public void sort(int[] data, int left, int right) { if(left&lt;right){ //找出中间索引 int center=(left+right)/2; //对左边数组进行递归 sort(data,left,center); //对右边数组进行递归 sort(data,center+1,right); //合并 merge(data,left,center,right); } } public void merge(int[] data, int left, int center, int right) { int [] tmpArr=new int[data.length]; int mid=center+1; //third记录中间数组的索引 int third=left; int tmp=left; while(left&lt;=center&amp;&amp;mid&lt;=right){ //从两个数组中取出最小的放入中间数组 if(data[left]&lt;=data[mid]){ tmpArr[third++]=data[left++]; }else{ tmpArr[third++]=data[mid++]; } } //剩余部分依次放入中间数组 while(mid&lt;=right){ tmpArr[third++]=data[mid++]; } while(left&lt;=center){ tmpArr[third++]=data[left++]; } //将中间数组中的内容复制回原数组 while(tmp&lt;=right){ data[tmp]=tmpArr[tmp++]; } System.out.println(Arrays.toString(data)); } } C++归并的过程中需要额外的跟需要归并的两个数组长度一致的空间(另外开辟一个数组空间)，比如需要规定的数组分别为：[3, 6, 8, 11]和[1, 3, 12, 15](虽然逻辑上被划为为两个数组，但实际上这些元素还是位于原来数组中的，只是通过一些index将其划分成两个数组，原数组为[3, 6, 8, 11, 1, 3, 12, 15]，我们设置三个指针lo,mid,high分别为0,3,7就可以实现逻辑上的子数组划分)那么需要的额外数组的长度为4 + 4 = 8。归并的过程可以简要地概括为如下。 将两个子数组中的元素复制到新copiedArray[]中，以前面提到的例子为例，则copiedArray=[3, 6, 8, 11, 1, 3, 12, 15]； 设置两个指针分别指向原子数组中对应的第一个元素，假定这两个指针取名为leftIdx和rightIdx，则leftIdx=0(对应copiedArray中的第一个元素[3])，rightIdx=4(对应copiedArray中的第五个元素[1])； 比较leftIdx和rightIdx指向的数组元素值，选取其中较小的一个并将其值赋给原数组中对应的位置i，赋值完毕后分别对参与赋值的这两个索引做自增1操作，如果leftIdx或rigthIdx值已经达到对应数组的末尾，则余下只需要将剩下数组的元素按顺序copy到余下的位置即可。 例：第一趟：辅助数组[21, 28, 39 | 35, 38] (数组被拆分为左右两个子数组，以 | 分隔开)[21 , , , , ] (第一次 21 与 35 比较 , 左边子数组胜出，leftIdx = 0, i = 0)第二趟：辅助数组[21, 28 , 39 | 35, 38][21 , 28, , , ] (第二次 28 与 35 比较，左边子数组胜出，leftIdx = 1, i = 1)第三趟：[21, 28, 39 | 35 , 38][21 , 28 , 35, , ] (第三次 39 与 35 比较，右边子数组胜出，rightIdx = 0, i = 2)第四趟：[21, 28, 39 | 35, 38 ][21 , 28 , 35 , 38, ] (第四次 39 与 38 比较，右边子数组胜出，rightIdx = 1, i = 3)第五趟：[21, 28, 39 | 35, 38][21 , 28 , 35 , 38 , 39] (第五次时右边子数组已复制完，无需比较leftIdx = 2, i = 4)以上便是一次归并的过程，我们可以将整个需要排序的数组做有限次拆分(每次一分为二)直到分为长度为1的小数组为止，长度为1时数组已经不用排序了。在这之后再逆序(由于采用递归)依次对这些数组进行归并操作，直到最后一次归并长度为n/2的子数组，归并完成之后数组排序也完成。归并排序需要的额外空间是所有排序中最多的，每次归并需要与参与归并的两个数组长度之和相同个元素(为了提供辅助数组)。则可以推断归并排序的空间复杂度为1+2+4+…+n=n*(n+2)/4(忽略了n的奇偶性的判断)。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263/** * Merge sorting */ MERGE(new Sortable() { public &lt;T extends Comparable&lt;T&gt;&gt; void sort(T[] array, boolean ascend) { this.sort(array, 0, array.length - 1, ascend); } private &lt;T extends Comparable&lt;T&gt;&gt; void sort(T[] array, int lo, int hi, boolean ascend) { // OPTIMIZE ONE // if the substring's length is less than 20, // use insertion sort to reduce recursive invocation if (hi - lo &lt; 20) { for (int i = lo + 1; i &lt;= hi; i++) { T toInsert = array[i]; int j = i; for (; j &gt; lo; j--) { int compare = array[j - 1].compareTo(toInsert); if (compare == 0 || compare &lt; 0 == ascend) { break; } array[j] = array[j - 1]; } array[j] = toInsert; } return; } int mid = lo + (hi - lo) / 2; sort(array, lo, mid, ascend); sort(array, mid + 1, hi, ascend); merge(array, lo, mid, hi, ascend); } private &lt;T extends Comparable&lt;T&gt;&gt; void merge(T[] array, int lo, int mid, int hi, boolean ascend) { // OPTIMIZE TWO // if it is already in right order, skip this merge // since there's no need to do so int leftEndCompareToRigthStart = array[mid].compareTo(array[mid + 1]); if (leftEndCompareToRigthStart == 0 || leftEndCompareToRigthStart &lt; 0 == ascend) { return; } @SuppressWarnings(\"unchecked\") T[] arrayCopy = (T[]) new Comparable[hi - lo + 1]; System.arraycopy(array, lo, arrayCopy, 0, arrayCopy.length); int lowIdx = 0; int highIdx = mid - lo + 1; for (int i = lo; i &lt;= hi; i++) { if (lowIdx &gt; mid - lo) { // left sub array exhausted array[i] = arrayCopy[highIdx++]; } else if (highIdx &gt; hi - lo) { // right sub array exhausted array[i] = arrayCopy[lowIdx++]; } else if (arrayCopy[lowIdx].compareTo(arrayCopy[highIdx]) &lt; 0 == ascend) { array[i] = arrayCopy[lowIdx++]; } else { array[i] = arrayCopy[highIdx++]; } } } }) 8 基数排序基本思想将所有待比较数值(正整数)统一为同样的数位长度，数位较短的数前面补零。然后，从最低位开始，依次进行一次排序。这样从最低位排序一直到最高位排序完成以后,数列就变成一个有序序列。N个元素进行d趟排序，每趟分配的元素放到r个队列中，需要收集N个元素，这样每趟分配和收集时间需要O(N+r)，d趟需要时间O(d*(r+N))。 时间复杂度O(d*(r+N)) 空间复杂度(N+2*r) 稳定排序等到排序之后才能确定元素的位置，是稳定排序。 Java例112345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273package base;import java.util.ArrayList;import java.util.List;/** * 基准排序 * */public class BaseSort { int a[] = { 49, 38, 65, 97, 76, 13, 27, 49, 78, 34, 12, 64, 5, 4, 62, 99, 98, 54, 101, 56, 17, 18, 23, 34, 15, 35, 25, 53, 51 }; public static void main(String[] args) { new BaseSort(); } public BaseSort() { sort(a); for (int i = 0; i &lt; a.length; i++) { System.out.print(a[i]+\"， \"); } } public void sort(int[] array) { // 首先确定排序的趟数; // 最大值 int max = array[0]; for (int i = 1; i &lt; array.length; i++) { if (array[i] &gt; max) { max = array[i]; } } int time = 0; // 判断位数; while (max &gt; 0) { max /= 10; time++; } // 建立10个队列; List&lt;ArrayList&gt; queue = new ArrayList&lt;ArrayList&gt;(); for (int i = 0; i &lt; 10; i++) { ArrayList&lt;Integer&gt; queue1 = new ArrayList&lt;Integer&gt;(); queue.add(queue1); } // 进行time次分配和收集; for (int i = 0; i &lt; time; i++) { // 分配数组元素; for (int j = 0; j &lt; array.length; j++) { // 得到数字的第time+1位数; int x = array[j] % (int) Math.pow(10, i + 1) / (int) Math.pow(10, i); // 位数队列 ArrayList&lt;Integer&gt; queue2 = queue.get(x); queue2.add(array[j]); queue.set(x, queue2); } int count = 0;// 元素计数器; // 收集队列元素; // 重新给array排序 for (int k = 0; k &lt; 10; k++) { while (queue.get(k).size() &gt; 0) { ArrayList&lt;Integer&gt; queue3 = queue.get(k); array[count] = queue3.get(0); queue3.remove(0); count++; } } } }} 例212345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061import java.util.ArrayList; import java.util.List; public class radixSort { int a[]={49,38,65,97,76,13,27,49,78,34,12,64,5,4,62,99,98,54,101,56,17,18,23,34,15,35,25,53,51}; public radixSort(){ sort(a); for(int i=0;i&lt;a.length;i++) System.out.println(a[i]); } public void sort(int[] array){ //首先确定排序的趟数; //最大值 int max=array[0]; for(int i=1;i&lt;array.length;i++){ if(array[i]&gt;max){ max=array[i]; } } int time=0; //判断位数; while(max&gt;0){ max/=10; time++; } //建立10个队列; List&lt;ArrayList&gt; queue=new ArrayList&lt;ArrayList&gt;(); for(int i=0;i&lt;10;i++){ ArrayList&lt;Integer&gt; queue1=new ArrayList&lt;Integer&gt;(); queue.add(queue1); } //进行time次分配和收集; for(int i=0;i&lt;time;i++){ //分配数组元素; for(int j=0;j&lt;array.length;j++){ //得到数字的第time+1位数; int x=array[j]%(int)Math.pow(10, i+1)/(int)Math.pow(10, i); //位数队列 ArrayList&lt;Integer&gt; queue2=queue.get(x); queue2.add(array[j]); queue.set(x, queue2); } int count=0;//元素计数器; //收集队列元素; for(int k=0;k&lt;10;k++){ while(queue.get(k).size()&gt;0){ ArrayList&lt;Integer&gt; queue3=queue.get(k); array[count]=queue3.get(0); queue3.remove(0); count++; } } } } }","link":"/Sorting-Algorithm/"},{"title":"Tomcat（四）请求处理流程","text":"1、前言 2、Http协议请求解析 3、如何转发到Servlet 1、前言在开始本文之前，先来看看一个Http请求处理的过程，一般情况下是12345浏览器发送http请求-&gt;建立Socket连接-&gt;通过Socket读取数据-&gt;根据http协议解析数据-&gt;调用后台服务完成响应 详细的流程图如上图所示。Tomcat既是一个HttpServer也是一个Servlet 容器，那么这里必然也涉及到如上过程，首先根据HTTP协议规范解析请求数据，然后将请求转发给Servlet进行处理，因此顺应这样的思路，本文也将从Http协议请求解析，请求如何转发给Servlet两个方面来进行分析。首先来看Http协议请求解析。 2、Http协议请求解析Tomcat启动以后，默认情况下会通过org.apache.tomcat.util.net.JIoEndpoint.Acceptor监听Socket连接，当监听到有Socket连接的时候，就会调用org.apache.tomcat.util.net.JIoEndpoint#processSocket()进行处理，下面我们就来看看此方法的代码。org.apache.tomcat.util.net.JIoEndpoint#processSocket()1234567891011121314151617181920212223242526272829303132333435/** * Process a new connection from a new client. Wraps the socket so * keep-alive and other attributes can be tracked and then passes the socket * to the executor for processing. * * @param socket The socket associated with the client. * * @return &lt;code&gt;true&lt;/code&gt; if the socket is passed to the * executor, &lt;code&gt;false&lt;/code&gt; if something went wrong or * if the endpoint is shutting down. Returning * &lt;code&gt;false&lt;/code&gt; is an indication to close the socket * immediately. */ protected boolean processSocket(Socket socket) { // Process the request from this socket try { SocketWrapper&lt;Socket&gt; wrapper = new SocketWrapper&lt;Socket&gt;(socket); wrapper.setKeepAliveLeft(getMaxKeepAliveRequests()); // During shutdown, executor may be null - avoid NPE if (!running) { return false; } getExecutor().execute(new SocketProcessor(wrapper)); } catch (RejectedExecutionException x) { log.warn(\"Socket processing request was rejected for:\"+socket,x); return false; } catch (Throwable t) { ExceptionUtils.handleThrowable(t); // This means we got an OOM or similar creating a thread, or that // the pool and its queue are full log.error(sm.getString(\"endpoint.process.fail\"), t); return false; } return true; } 通过上面的代码，可以看出首先将Socket封装为SocketWrapper，然后通过SocketProcessor来进行处理，因为Tomcat必然面对用户并发请求，因此这里Socket的处理通过新的线程池来处理。接下来再来看看SocketProcess的代码，代码如下。org.apache.tomcat.util.net.JIoEndpoint.SocketProcessor#run()12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394/** * This class is the equivalent of the Worker, but will simply use in an * external Executor thread pool. */ protected class SocketProcessor implements Runnable { protected SocketWrapper&lt;Socket&gt; socket = null; protected SocketStatus status = null; public SocketProcessor(SocketWrapper&lt;Socket&gt; socket) { if (socket==null) throw new NullPointerException(); this.socket = socket; } public SocketProcessor(SocketWrapper&lt;Socket&gt; socket, SocketStatus status) { this(socket); this.status = status; } @Override public void run() { boolean launch = false; synchronized (socket) { try { SocketState state = SocketState.OPEN; try { // SSL handshake serverSocketFactory.handshake(socket.getSocket()); } catch (Throwable t) { ExceptionUtils.handleThrowable(t); if (log.isDebugEnabled()) { log.debug(sm.getString(\"endpoint.err.handshake\"), t); } // Tell to close the socket state = SocketState.CLOSED; } if ((state != SocketState.CLOSED)) { if (status == null) { // 1 state = handler.process(socket, SocketStatus.OPEN); } else { state = handler.process(socket,status); } } if (state == SocketState.CLOSED) { // Close socket if (log.isTraceEnabled()) { log.trace(\"Closing socket:\"+socket); } countDownConnection(); try { socket.getSocket().close(); } catch (IOException e) { // Ignore } } else if (state == SocketState.OPEN || state == SocketState.UPGRADING || state == SocketState.UPGRADED){ socket.setKeptAlive(true); socket.access(); launch = true; } else if (state == SocketState.LONG) { socket.access(); waitingRequests.add(socket); } } finally { if (launch) { try { getExecutor().execute(new SocketProcessor(socket, SocketStatus.OPEN)); } catch (RejectedExecutionException x) { log.warn(\"Socket reprocessing request was rejected for:\"+socket,x); try { //unable to handle connection at this time handler.process(socket, SocketStatus.DISCONNECT); } finally { countDownConnection(); } } catch (NullPointerException npe) { if (running) { log.error(sm.getString(\"endpoint.launch.fail\"), npe); } } } } } socket = null; // Finish up this request } } 默认情况下，代码会运行到标注1的地方，标注1的地方又通过org.apache.tomcat.util.net.JIoEndpoint.Handler#process()进行处理，而通过前面Tomcat启动的文章，已经知道handler属性是在org.apache.coyote.http11.Http11Protocol的构造方法中初始化的，构造方法如下。org.apache.coyote.http11.Http11Protocol()12345678public Http11Protocol() { endpoint = new JIoEndpoint(); cHandler = new Http11ConnectionHandler(this); ((JIoEndpoint) endpoint).setHandler(cHandler); setSoLinger(Constants.DEFAULT_CONNECTION_LINGER); setSoTimeout(Constants.DEFAULT_CONNECTION_TIMEOUT); setTcpNoDelay(Constants.DEFAULT_TCP_NO_DELAY);} 从构造方法中，可以清楚的看到，其实初始化org.apache.coyote.http11.Http11Protocol.Http11ConnectionHandler的实例，那么接下来就来看看它的process()，因为Http11ConnectionHandler继承org.apache.coyote.AbstractProtocol.AbstractConnectionHandler，而自己没有实现process()，因此会调用到父类的process()，那么接下来我们就来看看AbstractConnectionHandler#process()，代码如下。1protected static class Http11ConnectionHandler extends AbstractConnectionHandler&lt;Socket, Http11Processor&gt; implements Handler org.apache.coyote.AbstractProtocol.AbstractConnectionHandler#process()123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105public SocketState process(SocketWrapper&lt;S&gt; socket, SocketStatus status) { Processor&lt;S&gt; processor = connections.remove(socket.getSocket()); if (status == SocketStatus.DISCONNECT &amp;&amp; processor == null) { //nothing more to be done endpoint requested a close //and there are no object associated with this connection return SocketState.CLOSED; } socket.setAsync(false); try { if (processor == null) { processor = recycledProcessors.poll(); } if (processor == null) { processor = createProcessor(); //子类覆写createProcessor方法 } initSsl(socket, processor); SocketState state = SocketState.CLOSED; do { if (status == SocketStatus.DISCONNECT &amp;&amp; !processor.isComet()) { // Do nothing here, just wait for it to get recycled // Don't do this for Comet we need to generate an end // event (see BZ 54022) } else if (processor.isAsync() || state == SocketState.ASYNC_END) { state = processor.asyncDispatch(status); } else if (processor.isComet()) { state = processor.event(status); } else if (processor.isUpgrade()) { state = processor.upgradeDispatch(); } else { state = processor.process(socket); } if (state != SocketState.CLOSED &amp;&amp; processor.isAsync()) { state = processor.asyncPostProcess(); } if (state == SocketState.UPGRADING) { // Get the UpgradeInbound handler UpgradeInbound inbound = processor.getUpgradeInbound(); // Release the Http11 processor to be re-used release(socket, processor, false, false); // Create the light-weight upgrade processor processor = createUpgradeProcessor(socket, inbound); inbound.onUpgradeComplete(); } } while (state == SocketState.ASYNC_END || state == SocketState.UPGRADING); if (state == SocketState.LONG) { // In the middle of processing a request/response. Keep the // socket associated with the processor. Exact requirements // depend on type of long poll longPoll(socket, processor); } else if (state == SocketState.OPEN) { // In keep-alive but between requests. OK to recycle // processor. Continue to poll for the next request. release(socket, processor, false, true); } else if (state == SocketState.SENDFILE) { // Sendfile in progress. If it fails, the socket will be // closed. If it works, the socket will be re-added to the // poller release(socket, processor, false, false); } else if (state == SocketState.UPGRADED) { // Need to keep the connection associated with the processor longPoll(socket, processor); } else { // Connection closed. OK to recycle the processor. if (!(processor instanceof UpgradeProcessor)) { release(socket, processor, true, false); } } return state; } catch(java.net.SocketException e) { // SocketExceptions are normal getLog().debug(sm.getString( \"abstractConnectionHandler.socketexception.debug\"), e); } catch (java.io.IOException e) { // IOExceptions are normal getLog().debug(sm.getString( \"abstractConnectionHandler.ioexception.debug\"), e); } // Future developers: if you discover any other // rare-but-nonfatal exceptions, catch them here, and log as // above. catch (Throwable e) { ExceptionUtils.handleThrowable(e); // any other exception or error is odd. Here we log it // with \"ERROR\" level, so it will show up even on // less-than-verbose logs. getLog().error( sm.getString(\"abstractConnectionHandler.error\"), e); } // Don't try to add upgrade processors back into the pool if (!(processor instanceof UpgradeProcessor)) { release(socket, processor, true, false); } return SocketState.CLOSED;} 通过查看上面的代码，默认一个新连接的情况下，会调用org.apache.coyote.Processor#process()，而Processor的实例实在org.apache.coyote.AbstractProtocol.AbstractConnectionHandler#createProcessor中创建的。AbstractConnectionHandler被Http11ConnectionHandler继承。org.apache.coyote.http11.Http11Protocol.Http11ConnectionHandler#createProcessor()12345678910111213141516171819202122@Overrideprotected Http11Processor createProcessor() { Http11Processor processor = new Http11Processor(proto.getMaxHttpHeaderSize(), (JIoEndpoint)proto.endpoint,proto.getMaxTrailerSize()); processor.setAdapter(proto.adapter); processor.setMaxKeepAliveRequests(proto.getMaxKeepAliveRequests()); processor.setKeepAliveTimeout(proto.getKeepAliveTimeout()); processor.setConnectionUploadTimeout( proto.getConnectionUploadTimeout()); processor.setDisableUploadTimeout(proto.getDisableUploadTimeout()); processor.setCompressionMinSize(proto.getCompressionMinSize()); processor.setCompression(proto.getCompression()); processor.setNoCompressionUserAgents(proto.getNoCompressionUserAgents()); processor.setCompressableMimeTypes(proto.getCompressableMimeTypes()); processor.setRestrictedUserAgents(proto.getRestrictedUserAgents()); processor.setSocketBuffer(proto.getSocketBuffer()); processor.setMaxSavePostSize(proto.getMaxSavePostSize()); processor.setServer(proto.getServer()); processor.setDisableKeepAlivePercentage( proto.getDisableKeepAlivePercentage()); register(processor); return processor;} 通过查看createProcessor代码，发现是创建一个org.apache.coyote.http11.Http11Processor的实例，那么接下来，就来看看它的process()，因为Http11Processor继承AbstractHttp11Processor，最终其实调用的是AbstractHttp11Processor#process()，代码如下。org.apache.coyote.http11.AbstractHttp11Processor#process()123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239/** * Process pipelined HTTP requests using the specified input and output * streams. * * @param socketWrapper Socket from which the HTTP requests will be read * and the HTTP responses will be written. * * @throws IOException error during an I/O operation */@Overridepublic SocketState process(SocketWrapper&lt;S&gt; socketWrapper) throws IOException { RequestInfo rp = request.getRequestProcessor(); rp.setStage(org.apache.coyote.Constants.STAGE_PARSE); // Setting up the I/O // 1 setSocketWrapper(socketWrapper); getInputBuffer().init(socketWrapper, endpoint); getOutputBuffer().init(socketWrapper, endpoint); // Flags error = false; keepAlive = true; comet = false; openSocket = false; sendfileInProgress = false; readComplete = true; if (endpoint.getUsePolling()) { keptAlive = false; } else { keptAlive = socketWrapper.isKeptAlive(); } if (disableKeepAlive()) { socketWrapper.setKeepAliveLeft(0); } while (!error &amp;&amp; keepAlive &amp;&amp; !comet &amp;&amp; !isAsync() &amp;&amp; upgradeInbound == null &amp;&amp; !endpoint.isPaused()) { // Parsing the request header try { setRequestLineReadTimeout(); // 2 if (!getInputBuffer().parseRequestLine(keptAlive)) { if (handleIncompleteRequestLineRead()) { break; } } if (endpoint.isPaused()) { // 503 - Service unavailable response.setStatus(503); error = true; } else { // Make sure that connectors that are non-blocking during // header processing (NIO) only set the start time the first // time a request is processed. if (request.getStartTime() &lt; 0) { request.setStartTime(System.currentTimeMillis()); } keptAlive = true; // Set this every time in case limit has been changed via JMX request.getMimeHeaders().setLimit(endpoint.getMaxHeaderCount()); // Currently only NIO will ever return false here // 3 if (!getInputBuffer().parseHeaders()) { // We've read part of the request, don't recycle it // instead associate it with the socket openSocket = true; readComplete = false; break; } if (!disableUploadTimeout) { setSocketTimeout(connectionUploadTimeout); } } } catch (IOException e) { if (getLog().isDebugEnabled()) { getLog().debug( sm.getString(\"http11processor.header.parse\"), e); } error = true; break; } catch (Throwable t) { ExceptionUtils.handleThrowable(t); UserDataHelper.Mode logMode = userDataHelper.getNextMode(); if (logMode != null) { String message = sm.getString( \"http11processor.header.parse\"); switch (logMode) { case INFO_THEN_DEBUG: message += sm.getString( \"http11processor.fallToDebug\"); //$FALL-THROUGH$ case INFO: getLog().info(message); break; case DEBUG: getLog().debug(message); } } // 400 - Bad Request response.setStatus(400); adapter.log(request, response, 0); error = true; } if (!error) { // Setting up filters, and parse some request headers rp.setStage(org.apache.coyote.Constants.STAGE_PREPARE); try { prepareRequest(); } catch (Throwable t) { ExceptionUtils.handleThrowable(t); if (getLog().isDebugEnabled()) { getLog().debug(sm.getString( \"http11processor.request.prepare\"), t); } // 400 - Internal Server Error response.setStatus(400); adapter.log(request, response, 0); error = true; } } if (maxKeepAliveRequests == 1) { keepAlive = false; } else if (maxKeepAliveRequests &gt; 0 &amp;&amp; socketWrapper.decrementKeepAlive() &lt;= 0) { keepAlive = false; } // Process the request in the adapter if (!error) { try { // 4 rp.setStage(org.apache.coyote.Constants.STAGE_SERVICE); adapter.service(request, response); // Handle when the response was committed before a serious // error occurred. Throwing a ServletException should both // set the status to 500 and set the errorException. // If we fail here, then the response is likely already // committed, so we can't try and set headers. if(keepAlive &amp;&amp; !error) { // Avoid checking twice. error = response.getErrorException() != null || (!isAsync() &amp;&amp; statusDropsConnection(response.getStatus())); } setCometTimeouts(socketWrapper); } catch (InterruptedIOException e) { error = true; } catch (HeadersTooLargeException e) { error = true; // The response should not have been committed but check it // anyway to be safe if (!response.isCommitted()) { response.reset(); response.setStatus(500); response.setHeader(\"Connection\", \"close\"); } } catch (Throwable t) { ExceptionUtils.handleThrowable(t); getLog().error(sm.getString( \"http11processor.request.process\"), t); // 500 - Internal Server Error response.setStatus(500); adapter.log(request, response, 0); error = true; } } // Finish the handling of the request rp.setStage(org.apache.coyote.Constants.STAGE_ENDINPUT); if (!isAsync() &amp;&amp; !comet) { if (error) { // If we know we are closing the connection, don't drain // input. This way uploading a 100GB file doesn't tie up the // thread if the servlet has rejected it. getInputBuffer().setSwallowInput(false); } endRequest(); } rp.setStage(org.apache.coyote.Constants.STAGE_ENDOUTPUT); // If there was an error, make sure the request is counted as // and error, and update the statistics counter if (error) { response.setStatus(500); } request.updateCounters(); if (!isAsync() &amp;&amp; !comet || error) { getInputBuffer().nextRequest(); getOutputBuffer().nextRequest(); } if (!disableUploadTimeout) { if(endpoint.getSoTimeout() &gt; 0) { setSocketTimeout(endpoint.getSoTimeout()); } else { setSocketTimeout(0); } } rp.setStage(org.apache.coyote.Constants.STAGE_KEEPALIVE); if (breakKeepAliveLoop(socketWrapper)) { break; } } rp.setStage(org.apache.coyote.Constants.STAGE_ENDED); if (error || endpoint.isPaused()) { return SocketState.CLOSED; } else if (isAsync() || comet) { return SocketState.LONG; } else if (isUpgrade()) { return SocketState.UPGRADING; } else { if (sendfileInProgress) { return SocketState.SENDFILE; } else { if (openSocket) { if (readComplete) { return SocketState.OPEN; } else { return SocketState.LONG; } } else { return SocketState.CLOSED; } } }} 标注1的代码：将Socket的输入流和输出流通过InternalInputBuffer进行包装，InternalInputBuffer是在Http11Processor的构造函数中初始化的。 标注2的代码：调用InternalInputBuffer#parseRequesLine()解析http请求的请求行。 标注3的代码：调用InternalInputBuffer#prarseHeaders()解析http请求的请求头。解析完以后，会将http header保存在org.apache.tomcat.util.http.MimeHeaders。 标注4的代码：调用org.apache.coyote.Adapter#service()，次方法就会最终调用到具体的Servlet。 对于Http请求行和请求头，大家可以看下面的例子：Http get request1234567891011121314151617GET /contextpath/querystring HTTP/1.1Host: 127.0.0.1:8080User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.9; rv:23.0) Gecko/20100101 Firefox/23.0Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8Accept-Language: en-US,en;q=0.5Accept-Encoding: gzip, deflateCookie: JSESSIONID=9F5897FEF3CDBCB234C050C132DCAE52; __atuvc=384%7C39; __utma=96992031.358732763.1380383869.1381468490.1381554710.38; __utmz=96992031.1380383869.1.1.utmcsr=(direct)|utmccn=(direct)|utmcmd=(none); Hm_lvt_21e144d0df165d6556d664e2836dadfe=1381330561,1381368826,1381395666,1381554711Connection: keep-aliveCache-Control: max-age=0 在上面的Http协议get请求中，其中请求行就是第一行，GET /contextpath/querystring HTTP/1.1,余下的都是请求头。这里面需要注意根据Http协议的要求，请求行末尾必须是CRLF，而请求行与请求头，以及请求头之间必须用空行隔开，而空行也必须只包含CRLF。对于Http协议请求头的规范可以参考这里。通过上面的描述，可以整理出如下的一个请求解析流程。Request http header parse1234567org.apache.tomcat.util.net.JIoEndpoint.Acceptor#run-&gt;org.apache.tomcat.util.net.JIoEndpoint.SocketProcessor#run(请求处理线程池中运行)--&gt;org.apache.coyote.AbstractProtocol.AbstractConnectionHandler#process (createProcess)---&gt;org.apache.coyote.http11.AbstractHttp11Processor#process----&gt;org.apache.coyote.http11.InternalInputBuffer#parseRequestLine----&gt;org.apache.coyote.http11.InternalInputBuffer#parseHeaders----&gt;org.apache.catalina.connector.CoyoteAdapter#service （调用最终servlet） 3、如何转发到Servlet一个请求过来是如何根据http协议解析Socket的数据，最终将生成org.apache.coyote.Request和org.apache.coyote.Response，接下来我们就来看看request，reponse是如何一步步的进入最终的Servlet进行处理的。这一步的入口就是CoyoteAdapter#service()。 接下来我们就来看看它的代码。org.apache.catalina.connector.CoyoteAdapter#service()123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111/** * Service method. */ @Override public void service(org.apache.coyote.Request req, org.apache.coyote.Response res) throws Exception { Request request = (Request) req.getNote(ADAPTER_NOTES); Response response = (Response) res.getNote(ADAPTER_NOTES); // 1 if (request == null) { // Create objects request = connector.createRequest(); request.setCoyoteRequest(req); response = connector.createResponse(); response.setCoyoteResponse(res); // Link objects request.setResponse(response); response.setRequest(request); // Set as notes req.setNote(ADAPTER_NOTES, request); res.setNote(ADAPTER_NOTES, response); // Set query string encoding req.getParameters().setQueryStringEncoding (connector.getURIEncoding()); } if (connector.getXpoweredBy()) { response.addHeader(\"X-Powered-By\", POWERED_BY); } boolean comet = false; boolean async = false; try { // Parse and set Catalina and configuration specific // request parameters req.getRequestProcessor().setWorkerThreadName(Thread.currentThread().getName()); // 2 boolean postParseSuccess = postParseRequest(req, request, res, response); if (postParseSuccess) { //check valves if we support async request.setAsyncSupported(connector.getService().getContainer().getPipeline().isAsyncSupported()); // Calling the container // 3 connector.getService().getContainer().getPipeline().getFirst().invoke(request, response); //终于参数传递给servlet if (request.isComet()) { if (!response.isClosed() &amp;&amp; !response.isError()) { if (request.getAvailable() || (request.getContentLength() &gt; 0 &amp;&amp; (!request.isParametersParsed()))) { // Invoke a read event right away if there are available bytes if (event(req, res, SocketStatus.OPEN)) { comet = true; res.action(ActionCode.COMET_BEGIN, null); } } else { comet = true; res.action(ActionCode.COMET_BEGIN, null); } } else { // Clear the filter chain, as otherwise it will not be reset elsewhere // since this is a Comet request request.setFilterChain(null); } } } AsyncContextImpl asyncConImpl = (AsyncContextImpl)request.getAsyncContext(); if (asyncConImpl != null) { async = true; } else if (!comet) { request.finishRequest(); response.finishResponse(); if (postParseSuccess &amp;&amp; request.getMappingData().context != null) { // Log only if processing was invoked. // If postParseRequest() failed, it has already logged it. // If context is null this was the start of a comet request // that failed and has already been logged. ((Context) request.getMappingData().context).logAccess( request, response, System.currentTimeMillis() - req.getStartTime(), false); } req.action(ActionCode.POST_REQUEST , null); } } catch (IOException e) { // Ignore } finally { req.getRequestProcessor().setWorkerThreadName(null); // Recycle the wrapper request and response if (!comet &amp;&amp; !async) { request.recycle(); response.recycle(); } else { // Clear converters so that the minimum amount of memory // is used by this processor request.clearEncoders(); response.clearEncoders(); } } } 标注1的代码：将org.apache.coyote.Request和org.apache.coyote.Response对象转变为org.apache.catalina.connector.Request,org.apache.catalina.connector.Response类型的对象。其中coyote包中的Request仅仅只是包含解析出来的http协议的数据，而connector包中的Request才是真正Servlet容器中的HttpServletRequest，它里面包含完成请求需要的host，context和wrapper信息，在这里每一个wrapper其实都对应web.xml配置的一个Servlet。 标注2的代码：调用postParseRequest()，这个方法里面做的事情非常多，但是最终都是为根据Request对象找到对应的Host，Conext和Wrapper对象，也就是说最终要清楚这个请求应该由哪个Servlet来处理。 标注3的代码：将已经设置好Host，Context，Wrapper对象的Request通过Pipeline机制链式传递给最终的Servlet。 上面只是从整体上说明org.apache.catalina.connector.CoyoteAdapter#service方法做的事情，接下来进一步分解每一个步骤都具体做哪些工作。第一步比较简单，可以自己阅读，关键来看2，3步。首先来看看postParseRequest()。org.apache.catalina.connector.CoyoteAdapter#postParseRequest()123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256/** * Parse additional request parameters. */ protected boolean postParseRequest(org.apache.coyote.Request req, Request request, org.apache.coyote.Response res, Response response) throws Exception { // XXX the processor may have set a correct scheme and port prior to this point, // in ajp13 protocols dont make sense to get the port from the connector... // otherwise, use connector configuration if (! req.scheme().isNull()) { // use processor specified scheme to determine secure state request.setSecure(req.scheme().equals(\"https\")); } else { // use connector scheme and secure configuration, (defaults to // \"http\" and false respectively) req.scheme().setString(connector.getScheme()); request.setSecure(connector.getSecure()); } // FIXME: the code below doesnt belongs to here, // this is only have sense // in Http11, not in ajp13.. // At this point the Host header has been processed. // Override if the proxyPort/proxyHost are set String proxyName = connector.getProxyName(); int proxyPort = connector.getProxyPort(); if (proxyPort != 0) { req.setServerPort(proxyPort); } if (proxyName != null) { req.serverName().setString(proxyName); } // Copy the raw URI to the decodedURI MessageBytes decodedURI = req.decodedURI(); decodedURI.duplicate(req.requestURI()); // Parse the path parameters. This will: // - strip out the path parameters // - convert the decodedURI to bytes parsePathParameters(req, request); // URI decoding // %xx decoding of the URL try { req.getURLDecoder().convert(decodedURI, false); } catch (IOException ioe) { res.setStatus(400); res.setMessage(\"Invalid URI: \" + ioe.getMessage()); connector.getService().getContainer().logAccess( request, response, 0, true); return false; } // Normalization if (!normalize(req.decodedURI())) { res.setStatus(400); res.setMessage(\"Invalid URI\"); connector.getService().getContainer().logAccess( request, response, 0, true); return false; } // Character decoding convertURI(decodedURI, request); // Check that the URI is still normalized if (!checkNormalize(req.decodedURI())) { res.setStatus(400); res.setMessage(\"Invalid URI character encoding\"); connector.getService().getContainer().logAccess( request, response, 0, true); return false; } // Set the remote principal String principal = req.getRemoteUser().toString(); if (principal != null) { request.setUserPrincipal(new CoyotePrincipal(principal)); } // Set the authorization type String authtype = req.getAuthType().toString(); if (authtype != null) { request.setAuthType(authtype); } // Request mapping. MessageBytes serverName; if (connector.getUseIPVHosts()) { serverName = req.localName(); if (serverName.isNull()) { // well, they did ask for it res.action(ActionCode.REQ_LOCAL_NAME_ATTRIBUTE, null); } } else { serverName = req.serverName(); } if (request.isAsyncStarted()) { //TODO SERVLET3 - async //reset mapping data, should prolly be done elsewhere request.getMappingData().recycle(); } boolean mapRequired = true; String version = null; while (mapRequired) { if (version != null) { // Once we have a version - that is it mapRequired = false; } // This will map the the latest version by default connector.getMapper().map(serverName, decodedURI, version, request.getMappingData()); request.setContext((Context) request.getMappingData().context); request.setWrapper((Wrapper) request.getMappingData().wrapper); // Single contextVersion therefore no possibility of remap if (request.getMappingData().contexts == null) { mapRequired = false; } // If there is no context at this point, it is likely no ROOT context // has been deployed if (request.getContext() == null) { res.setStatus(404); res.setMessage(\"Not found\"); // No context, so use host Host host = request.getHost(); // Make sure there is a host (might not be during shutdown) if (host != null) { host.logAccess(request, response, 0, true); } return false; } // Now we have the context, we can parse the session ID from the URL // (if any). Need to do this before we redirect in case we need to // include the session id in the redirect String sessionID = null; if (request.getServletContext().getEffectiveSessionTrackingModes() .contains(SessionTrackingMode.URL)) { // Get the session ID if there was one sessionID = request.getPathParameter( SessionConfig.getSessionUriParamName( request.getContext())); if (sessionID != null) { request.setRequestedSessionId(sessionID); request.setRequestedSessionURL(true); } } // Look for session ID in cookies and SSL session parseSessionCookiesId(req, request); parseSessionSslId(request); sessionID = request.getRequestedSessionId(); if (mapRequired) { if (sessionID == null) { // No session means no possibility of needing to remap mapRequired = false; } else { // Find the context associated with the session Object[] objs = request.getMappingData().contexts; for (int i = (objs.length); i &gt; 0; i--) { Context ctxt = (Context) objs[i - 1]; if (ctxt.getManager().findSession(sessionID) != null) { // Was the correct context already mapped? if (ctxt.equals(request.getMappingData().context)) { mapRequired = false; } else { // Set version so second time through mapping the // correct context is found version = ctxt.getWebappVersion(); // Reset mapping request.getMappingData().recycle(); break; } } } if (version == null) { // No matching context found. No need to re-map mapRequired = false; } } } if (!mapRequired &amp;&amp; request.getContext().getPaused()) { // Found a matching context but it is paused. Mapping data will // be wrong since some Wrappers may not be registered at this // point. try { Thread.sleep(1000); } catch (InterruptedException e) { // Should never happen } // Reset mapping request.getMappingData().recycle(); mapRequired = true; } } // Possible redirect MessageBytes redirectPathMB = request.getMappingData().redirectPath; if (!redirectPathMB.isNull()) { String redirectPath = urlEncoder.encode(redirectPathMB.toString()); String query = request.getQueryString(); if (request.isRequestedSessionIdFromURL()) { // This is not optimal, but as this is not very common, it // shouldn't matter redirectPath = redirectPath + \";\" + SessionConfig.getSessionUriParamName( request.getContext()) + \"=\" + request.getRequestedSessionId(); } if (query != null) { // This is not optimal, but as this is not very common, it // shouldn't matter redirectPath = redirectPath + \"?\" + query; } response.sendRedirect(redirectPath); request.getContext().logAccess(request, response, 0, true); return false; } // Filter trace method if (!connector.getAllowTrace() &amp;&amp; req.method().equalsIgnoreCase(\"TRACE\")) { Wrapper wrapper = request.getWrapper(); String header = null; if (wrapper != null) { String[] methods = wrapper.getServletMethods(); if (methods != null) { for (int i=0; i&lt;methods.length; i++) { if (\"TRACE\".equals(methods[i])) { continue; } if (header == null) { header = methods[i]; } else { header += \", \" + methods[i]; } } } } res.setStatus(405); res.addHeader(\"Allow\", header); res.setMessage(\"TRACE method is not allowed\"); request.getContext().logAccess(request, response, 0, true); return false; } return true; } 通过分析org.apache.catalina.connector.CoyoteAdapter#postParseRequest()的代码，我们会发现它最终是通过org.apache.tomcat.util.http.mapper.Mapper#map()来达到匹配请求到对应的Context和Wrapper(Servlet包装类)目的。1234// This will map the the latest version by defaultconnector.getMapper().map(serverName, decodedURI, version, request.getMappingData()); request.setContext((Context) request.getMappingData().context); request.setWrapper((Wrapper) request.getMappingData().wrapper); org.apache.tomcat.util.http.mapper#map()12345678910111213141516171819/** * Map the specified host name and URI, mutating the given mapping data. * * @param host Virtual host name * @param uri URI * @param mappingData This structure will contain the result of the mapping * operation */ public void map(MessageBytes host, MessageBytes uri, String version, MappingData mappingData) throws Exception { if (host.isNull()) { host.getCharChunk().append(defaultHostName); } host.toChars(); uri.toChars(); internalMap(host.getCharChunk(), uri.getCharChunk(), version, mappingData); } 通过分析它的代码，发现最终其实是调用几个internalMap()将找到的Context，Wrapper设置到org.apache.catalina.connector.Request对象的org.apache.tomcat.util.http.mapper.MappingData类型的属性中，map()执行完以后，然后接下来就从MappingData中获取已经找到的Context和Wrapper，再设置到Request的context和wrapper中。第3步通过pipeline链式调用机制最终调用Servlet对象，而对于pipeline其实是运用责任链模式，它将各个阀门链接起来，然后一步步的调用，而至于有多少个阀门（Valve）对象，主要来源于两个地方，一个是conf/server.xml中配置的valve，所有的容器都是支持pipeline机制的，另外一个就是每一个容器的构造其中自己初始化的阀门对象。对于StandardEngine来说有一个与之对应的StandardEngineValve，对于StandardHost有一个StandardHostValve与之对应，StandardContext有一个StandardContextValve与之对应，StandardWrapper与StandardWrapperValve对应，通过分析代码，可以得到如下的一个调用链。1234567-&gt;org.apache.catalina.core.StandardEngineValve#invoke--&gt;org.apache.catalina.valves.AccessLogValve#invoke---&gt;org.apache.catalina.valves.ErrorReportValve#invoke----&gt;org.apache.catalina.core.StandardHostValve#invoke-----&gt;org.apache.catalina.authenticator.AuthenticatorBase#invoke------&gt;org.apache.catalina.core.StandardContextValve#invoke-------&gt;org.apache.catalina.core.StandardWrapperValve#invoke 上述的调用栈中，最后会调用到StandardWrapperValve，它其实也是最终调用Servlet的地方，接下来就来看看它的代码。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244/** * Invoke the servlet we are managing, respecting the rules regarding * servlet lifecycle and SingleThreadModel support. * * @param request Request to be processed * @param response Response to be produced * * @exception IOException if an input/output error occurred * @exception ServletException if a servlet error occurred */ @Override public final void invoke(Request request, Response response) throws IOException, ServletException { // Initialize local variables we may need boolean unavailable = false; Throwable throwable = null; // This should be a Request attribute... long t1=System.currentTimeMillis(); requestCount++; StandardWrapper wrapper = (StandardWrapper) getContainer(); Servlet servlet = null; Context context = (Context) wrapper.getParent(); // Check for the application being marked unavailable if (!context.getState().isAvailable()) { response.sendError(HttpServletResponse.SC_SERVICE_UNAVAILABLE, sm.getString(\"standardContext.isUnavailable\")); unavailable = true; } // Check for the servlet being marked unavailable if (!unavailable &amp;&amp; wrapper.isUnavailable()) { container.getLogger().info(sm.getString(\"standardWrapper.isUnavailable\", wrapper.getName())); long available = wrapper.getAvailable(); if ((available &gt; 0L) &amp;&amp; (available &lt; Long.MAX_VALUE)) { response.setDateHeader(\"Retry-After\", available); response.sendError(HttpServletResponse.SC_SERVICE_UNAVAILABLE, sm.getString(\"standardWrapper.isUnavailable\", wrapper.getName())); } else if (available == Long.MAX_VALUE) { response.sendError(HttpServletResponse.SC_NOT_FOUND, sm.getString(\"standardWrapper.notFound\", wrapper.getName())); } unavailable = true; } // Allocate a servlet instance to process this request try { // 1 if (!unavailable) { servlet = wrapper.allocate(); } } catch (UnavailableException e) { container.getLogger().error( sm.getString(\"standardWrapper.allocateException\", wrapper.getName()), e); long available = wrapper.getAvailable(); if ((available &gt; 0L) &amp;&amp; (available &lt; Long.MAX_VALUE)) { response.setDateHeader(\"Retry-After\", available); response.sendError(HttpServletResponse.SC_SERVICE_UNAVAILABLE, sm.getString(\"standardWrapper.isUnavailable\", wrapper.getName())); } else if (available == Long.MAX_VALUE) { response.sendError(HttpServletResponse.SC_NOT_FOUND, sm.getString(\"standardWrapper.notFound\", wrapper.getName())); } } catch (ServletException e) { container.getLogger().error(sm.getString(\"standardWrapper.allocateException\", wrapper.getName()), StandardWrapper.getRootCause(e)); throwable = e; exception(request, response, e); } catch (Throwable e) { ExceptionUtils.handleThrowable(e); container.getLogger().error(sm.getString(\"standardWrapper.allocateException\", wrapper.getName()), e); throwable = e; exception(request, response, e); servlet = null; } // Identify if the request is Comet related now that the servlet has been allocated boolean comet = false; if (servlet instanceof CometProcessor &amp;&amp; request.getAttribute( Globals.COMET_SUPPORTED_ATTR) == Boolean.TRUE) { comet = true; request.setComet(true); } MessageBytes requestPathMB = request.getRequestPathMB(); DispatcherType dispatcherType = DispatcherType.REQUEST; if (request.getDispatcherType()==DispatcherType.ASYNC) dispatcherType = DispatcherType.ASYNC; request.setAttribute(Globals.DISPATCHER_TYPE_ATTR,dispatcherType); request.setAttribute(Globals.DISPATCHER_REQUEST_PATH_ATTR, requestPathMB); // Create the filter chain for this request ApplicationFilterFactory factory = ApplicationFilterFactory.getInstance(); ApplicationFilterChain filterChain = factory.createFilterChain(request, wrapper, servlet); // Reset comet flag value after creating the filter chain request.setComet(false); // Call the filter chain for this request // NOTE: This also calls the servlet's service() method // 2 try { if ((servlet != null) &amp;&amp; (filterChain != null)) { // Swallow output if needed if (context.getSwallowOutput()) { try { SystemLogHandler.startCapture(); if (request.isAsyncDispatching()) { //TODO SERVLET3 - async ((AsyncContextImpl)request.getAsyncContext()).doInternalDispatch(); } else if (comet) { filterChain.doFilterEvent(request.getEvent()); request.setComet(true); } else { filterChain.doFilter(request.getRequest(), response.getResponse()); } } finally { String log = SystemLogHandler.stopCapture(); if (log != null &amp;&amp; log.length() &gt; 0) { context.getLogger().info(log); } } } else { if (request.isAsyncDispatching()) { //TODO SERVLET3 - async ((AsyncContextImpl)request.getAsyncContext()).doInternalDispatch(); } else if (comet) { request.setComet(true); filterChain.doFilterEvent(request.getEvent()); } else { filterChain.doFilter (request.getRequest(), response.getResponse()); } } } } catch (ClientAbortException e) { throwable = e; exception(request, response, e); } catch (IOException e) { container.getLogger().error(sm.getString( \"standardWrapper.serviceException\", wrapper.getName(), context.getName()), e); throwable = e; exception(request, response, e); } catch (UnavailableException e) { container.getLogger().error(sm.getString( \"standardWrapper.serviceException\", wrapper.getName(), context.getName()), e); // throwable = e; // exception(request, response, e); wrapper.unavailable(e); long available = wrapper.getAvailable(); if ((available &gt; 0L) &amp;&amp; (available &lt; Long.MAX_VALUE)) { response.setDateHeader(\"Retry-After\", available); response.sendError(HttpServletResponse.SC_SERVICE_UNAVAILABLE, sm.getString(\"standardWrapper.isUnavailable\", wrapper.getName())); } else if (available == Long.MAX_VALUE) { response.sendError(HttpServletResponse.SC_NOT_FOUND, sm.getString(\"standardWrapper.notFound\", wrapper.getName())); } // Do not save exception in 'throwable', because we // do not want to do exception(request, response, e) processing } catch (ServletException e) { Throwable rootCause = StandardWrapper.getRootCause(e); if (!(rootCause instanceof ClientAbortException)) { container.getLogger().error(sm.getString( \"standardWrapper.serviceExceptionRoot\", wrapper.getName(), context.getName(), e.getMessage()), rootCause); } throwable = e; exception(request, response, e); } catch (Throwable e) { ExceptionUtils.handleThrowable(e); container.getLogger().error(sm.getString( \"standardWrapper.serviceException\", wrapper.getName(), context.getName()), e); throwable = e; exception(request, response, e); } // Release the filter chain (if any) for this request if (filterChain != null) { if (request.isComet()) { // If this is a Comet request, then the same chain will be used for the // processing of all subsequent events. filterChain.reuse(); } else { filterChain.release(); } } // Deallocate the allocated servlet instance try { if (servlet != null) { wrapper.deallocate(servlet); } } catch (Throwable e) { ExceptionUtils.handleThrowable(e); container.getLogger().error(sm.getString(\"standardWrapper.deallocateException\", wrapper.getName()), e); if (throwable == null) { throwable = e; exception(request, response, e); } } // If this servlet has been marked permanently unavailable, // unload it and release this instance try { if ((servlet != null) &amp;&amp; (wrapper.getAvailable() == Long.MAX_VALUE)) { wrapper.unload(); } } catch (Throwable e) { ExceptionUtils.handleThrowable(e); container.getLogger().error(sm.getString(\"standardWrapper.unloadException\", wrapper.getName()), e); if (throwable == null) { throwable = e; exception(request, response, e); } } long t2=System.currentTimeMillis(); long time=t2-t1; processingTime += time; if( time &gt; maxTime) maxTime=time; if( time &lt; minTime) minTime=time; } 标注1的代码：实例化Servlet对象，在实例化的过程中使用Java双检查锁的机制来实例化Servlet。这里需要注意的是在Servlet2.4规范之前，有一个singleThreadMode模型，这个机制类似与之前EJB的无状态会话Bean机制，每个线程过来会通过实例池中取出一个实例来完成响应。在Servlet规范2.4之后，单线程模型已经被废除。 org.apache.catalina.core.StandardWrapper#allocate()123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109/** * Allocate an initialized instance of this Servlet that is ready to have * its &lt;code&gt;service()&lt;/code&gt; method called. If the servlet class does * not implement &lt;code&gt;SingleThreadModel&lt;/code&gt;, the (only) initialized * instance may be returned immediately. If the servlet class implements * &lt;code&gt;SingleThreadModel&lt;/code&gt;, the Wrapper implementation must ensure * that this instance is not allocated again until it is deallocated by a * call to &lt;code&gt;deallocate()&lt;/code&gt;. * * @exception ServletException if the servlet init() method threw * an exception * @exception ServletException if a loading error occurs */ @Override public Servlet allocate() throws ServletException { // If we are currently unloading this servlet, throw an exception if (unloading) throw new ServletException (sm.getString(\"standardWrapper.unloading\", getName())); boolean newInstance = false; // If not SingleThreadedModel, return the same instance every time if (!singleThreadModel) { // Load and initialize our instance if necessary if (instance == null) { synchronized (this) { if (instance == null) { try { if (log.isDebugEnabled()) log.debug(\"Allocating non-STM instance\"); instance = loadServlet(); if (!singleThreadModel) { // For non-STM, increment here to prevent a race // condition with unload. Bug 43683, test case // #3 newInstance = true; countAllocated.incrementAndGet(); } } catch (ServletException e) { throw e; } catch (Throwable e) { ExceptionUtils.handleThrowable(e); throw new ServletException (sm.getString(\"standardWrapper.allocate\"), e); } } } } if (!instanceInitialized) { initServlet(instance); } if (singleThreadModel) { if (newInstance) { // Have to do this outside of the sync above to prevent a // possible deadlock synchronized (instancePool) { instancePool.push(instance); nInstances++; } } } else { if (log.isTraceEnabled()) log.trace(\" Returning non-STM instance\"); // For new instances, count will have been incremented at the // time of creation if (!newInstance) { countAllocated.incrementAndGet(); } return (instance); } } synchronized (instancePool) { while (countAllocated.get() &gt;= nInstances) { // Allocate a new instance if possible, or else wait if (nInstances &lt; maxInstances) { try { instancePool.push(loadServlet()); nInstances++; } catch (ServletException e) { throw e; } catch (Throwable e) { ExceptionUtils.handleThrowable(e); throw new ServletException (sm.getString(\"standardWrapper.allocate\"), e); } } else { try { instancePool.wait(); } catch (InterruptedException e) { // Ignore } } } if (log.isTraceEnabled()) log.trace(\" Returning allocated STM instance\"); countAllocated.incrementAndGet(); return instancePool.pop(); } } 标注2的代码：其实调用熟悉的Servlet的过滤器链，过滤器链最终就会调用到Servlet。 最后，看看过滤器滤链的处理，来看看org.apache.catalina.core.ApplicationFilterChain#doFilter，doFilter()中会根据filterConfig中取的web.xml配置的过滤器，然后一个个调用，等每个过滤器执行完以后，最终就会调用到Servlet#Service()。通过上面的分析，其实已经清楚一个请求过来以后，Tomcat是如何一步步处理的。再来做一个总体的总结。 用户浏览器发送请求，请求会发送到对应的Connector监听的Socket端口。 Connector从Socket流中获取数据，然后根据Http协议将其解析为Request和Reponse对象。 找到Request对象对应的Host，Context，Wrapper。 调用最终的Servelt#service()进行处理。","link":"/Tomcat-4/"},{"title":"Tomcat（二）启动过程","text":"1 Tomcat组件生命周期管理 2 Tomcat启动的总过程 BootStrap#init() BootStrap#load() 3 Tomcat启动过程关键步骤分析 Connector#init() Connector#start() StandardEngine#start() 1 Tomcat组件生命周期管理Tomcat中Server，Service，Connector，Engine，Host，Context的继承关系图，你会发现它们都实现org.apache.catalina.Lifecycle接口，而org.apache.catalina.util.LifecycleBase采用模板方法模式来对所有支持生命周期管理的组件的生命周期各个阶段进行总体管理，每个需要生命周期管理的组件只需要继承这个基类，然后覆盖对应的钩子方法即可完成相应的生命周期阶段性的管理工作。下面我们首先来看看org.apache.catalina.Lifecycle接口的定义，它的类图如下图所示。从上图我们可以清楚的看到LifeCycle中主要有四个生命周期阶段，它们分别是init()初始化，start()启动，stop()停止，destory()销毁。知道这四个生命周期阶段以后，看看org.apache.catalina.util.LifecycleBase是如何实现模板方法模式的。那接下来我们就来看看org.apache.catalina.util.LifecycleBase类的定义，它的类图如下所示。上图中用红色标注的四个方法就是模板方法模式中的钩子方法，子类可以通过实现钩子方法来纳入到基类已经流程化好的生命周期管理中。上面我们对LifeCycle和LifeCycleBase有一个总体的认识，接下来，我们通过查看org.apache.catalina.util.LifecycleBase的源代码来具体的分析一下。org.apache.catalina.util.LifecycleBase#init12345678910111213141516171819@Overridepublic final synchronized void init() throws LifecycleException { // 1 if (!state.equals(LifecycleState.NEW)) { invalidTransition(Lifecycle.BEFORE_INIT_EVENT); } setStateInternal(LifecycleState.INITIALIZING, null, false); try { // 2 initInternal(); } catch (Throwable t) { ExceptionUtils.handleThrowable(t); setStateInternal(LifecycleState.FAILED, null, false); throw new LifecycleException( sm.getString(\"lifecycleBase.initFail\",toString()), t); } // 3 setStateInternal(LifecycleState.INITIALIZED, null, false);} 下面我们逐一来分析一下上述代码中标注数字的地方。 标注1的代码：首先检测当前组件的状态是不是LifecycleState.NEW(新建)，如果不是就调用 org.apache.catalina.util.LifecycleBase#invalidTransition()来将当前的状态转换过程终止，而invalidTransition的实现是抛出org.apache.catalina.LifecycleException异常。接着调用setStateInternal()将状态设置为INITIALIZING（正在初始化） 标注2的代码：就是init()模板方法的钩子，子类可以通过实现protected abstract void initInternal() throws LifecycleException;来纳入初始化的流程。 标注3的代码：将组件的状态改为LifecycleState.INITIALIZED(已初始化)。 上面我们分析init()模板方法，接下来我们再看看start()具体做什么事情。org.apache.catalina.util.LifecycleBase#start()12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152/** * {@inheritDoc} */@Overridepublic final synchronized void start() throws LifecycleException { // 1 if (LifecycleState.STARTING_PREP.equals(state) || LifecycleState.STARTING.equals(state) || LifecycleState.STARTED.equals(state)) { if (log.isDebugEnabled()) { Exception e = new LifecycleException(); log.debug(sm.getString(\"lifecycleBase.alreadyStarted\", toString()), e); } else if (log.isInfoEnabled()) { log.info(sm.getString(\"lifecycleBase.alreadyStarted\", toString())); } return; } // 2 if (state.equals(LifecycleState.NEW)) { init(); } else if (state.equals(LifecycleState.FAILED)){ stop(); } else if (!state.equals(LifecycleState.INITIALIZED) &amp;&amp; !state.equals(LifecycleState.STOPPED)) { invalidTransition(Lifecycle.BEFORE_START_EVENT); } // 3 setStateInternal(LifecycleState.STARTING_PREP, null, false); try { // 4 startInternal(); } catch (Throwable t) { ExceptionUtils.handleThrowable(t); setStateInternal(LifecycleState.FAILED, null, false); throw new LifecycleException( sm.getString(\"lifecycleBase.startFail\",toString()), t); } // 5 if (state.equals(LifecycleState.FAILED) || state.equals(LifecycleState.MUST_STOP)) { stop(); } else { // Shouldn't be necessary but acts as a check that sub-classes are // doing what they are supposed to. if (!state.equals(LifecycleState.STARTING)) { invalidTransition(Lifecycle.AFTER_START_EVENT); } setStateInternal(LifecycleState.STARTED, null, false); }} 下面我们逐一来分析一下上述代码中标注数字的地方： 标注1的代码：检测当前组件的状态是不是LifecycleState.STARTING_PREP(准备启动)，LifecycleState.STARTING（正在启动），LifecycleState.STARTED（已启动）。如果是这三个状态中的任何一个，则抛出LifecycleException。 标注2的代码：检查其实主要是为保证组件状态的完整性，在正常启动的流程中，应该是不会出现没有初始化就启动，或者还没启动就已经失败的情况。 标注3的代码：设置组件的状态为LifecycleState.STARTING_PREP（准备启动状态）。 标注4的代码：start()模板方法的钩子方法，子类通过实现 org.apache.catalina.util.LifecycleBase#startInternal()这个方法来纳入到组件启动的流程中来。 标注5的代码：做一些状态检查，然后最终将组件的状态设置为LifecycleState.STARTED（已启动）。 上面我们分析init()和start()的流程，对于stop()和destroy()的总体过程是类似的，通过上面的分析，我们可以得出生命周期方法的总体的骨架，如果用伪代码来表示可以简化为如下。org.apache.catalina.util.LifecycleBase#lifeCycleMethod()12345678public final synchronized void lfieCycleMethod() throws LifecycleException { stateCheck();//状态检查 //设置为进入相应的生命周期之前的状态 setStateInternal(LifecycleState.BEFORE_STATE, null, false); lfieCycleMethodInternal();//钩子方法 //进入相应的生命周期之后的状态 setStateInternal(LifecycleState.AFTER_STATE, null, false);} 2 Tomcat启动的总过程通过上面的介绍，清楚各个组件的生命周期的各个阶段具体都是如何运作的。接下来我们就来看看，Tomcat具体是如何一步步启动起来的。我们都知道任何Java程序都有一个main()入口，Tomcat中的main()入口是 org.apache.catalina.startup.Bootstrap#main(),下面我们就来分析一下它的代码。org.apache.catalina.startup.Bootstrap#main()123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566/** * Main method and entry point when starting Tomcat via the provided * scripts. * * @param args Command line arguments to be processed */ public static void main(String args[]) { if (daemon == null) { // Don't set daemon until init() has completed // 1 Bootstrap bootstrap = new Bootstrap(); try { // 2 bootstrap.init(); } catch (Throwable t) { handleThrowable(t); t.printStackTrace(); return; } // 3 daemon = bootstrap; } else { // When running as a service the call to stop will be on a new // thread so make sure the correct class loader is used to prevent // a range of class not found exceptions. Thread.currentThread().setContextClassLoader(daemon.catalinaLoader); } try { String command = \"start\"; if (args.length &gt; 0) { command = args[args.length - 1]; } if (command.equals(\"startd\")) { args[args.length - 1] = \"start\"; daemon.load(args); daemon.start(); } else if (command.equals(\"stopd\")) { args[args.length - 1] = \"stop\"; daemon.stop(); } else if (command.equals(\"start\")) { // 4 daemon.setAwait(true); daemon.load(args); daemon.start(); } else if (command.equals(\"stop\")) { daemon.stopServer(args); } else if (command.equals(\"configtest\")) { daemon.load(args); if (null==daemon.getServer()) { System.exit(1); } System.exit(0); } else { log.warn(\"Bootstrap: command \\\"\" + command + \"\\\" does not exist.\"); } } catch (Throwable t) { // Unwrap the Exception for clearer error reporting if (t instanceof InvocationTargetException &amp;&amp; t.getCause() != null) { t = t.getCause(); } handleThrowable(t); t.printStackTrace(); System.exit(1); } } 下面我们逐一来分析一下上述代码中标注数字的地方： 标注1的代码：初始化自举类的实例。 标注2的代码：对BootStrap实例进行初始化。 标注3的代码：将实例赋值给daemon。 标注4的代码：首先调用BootStrap#load()，然后调用start()。 分别分析一下BootStrap的init()，load()，start()具体做哪些工作。 BootStrap#init()org.apache.catalina.startup.Bootstrap#init()1234567891011121314151617181920212223242526272829303132/** * Initialize daemon. */ public void init() throws Exception { // Set Catalina path setCatalinaHome(); setCatalinaBase(); initClassLoaders(); Thread.currentThread().setContextClassLoader(catalinaLoader); SecurityClassLoad.securityClassLoad(catalinaLoader); // Load our startup class and call its process() method if (log.isDebugEnabled()) log.debug(\"Loading startup class\"); // 1 Class&lt;?&gt; startupClass = catalinaLoader.loadClass (\"org.apache.catalina.startup.Catalina\"); Object startupInstance = startupClass.newInstance(); // Set the shared extensions class loader if (log.isDebugEnabled()) log.debug(\"Setting startup class properties\"); String methodName = \"setParentClassLoader\"; Class&lt;?&gt; paramTypes[] = new Class[1]; paramTypes[0] = Class.forName(\"java.lang.ClassLoader\"); Object paramValues[] = new Object[1]; paramValues[0] = sharedLoader; Method method = startupInstance.getClass().getMethod(methodName, paramTypes); // 2 method.invoke(startupInstance, paramValues); // 3 catalinaDaemon = startupInstance; } 下面我们重点逐一来分析一下上述代码中标注数字的地方： 标注1的代码：通过反射实例化org.apache.catalina.startup.Catalina类的实例; 标注2的代码：调用Catalina实例的setParentClassLoader()设置父亲ClassLoader，对于ClassLoader方面的内容，在本系列的后续文章再来看看。 标注3的代码：将Catalina实例赋值给Bootstrap实例的catalinaDaemon。 BootStrap#load()接下来我们再来看看org.apache.catalina.startup.Bootstrap#load()org.apache.catalina.startup.Bootstrap#load()12345678910111213141516171819202122/** * Load daemon. */ private void load(String[] arguments) throws Exception { // Call the load() method String methodName = \"load\"; Object param[]; Class&lt;?&gt; paramTypes[]; if (arguments==null || arguments.length==0) { paramTypes = null; param = null; } else { paramTypes = new Class[1]; paramTypes[0] = arguments.getClass(); param = new Object[1]; param[0] = arguments; } Method method = catalinaDaemon.getClass().getMethod(methodName, paramTypes); if (log.isDebugEnabled()) log.debug(\"Calling startup class \" + method); method.invoke(catalinaDaemon, param); } 通过查看源代码，知道此方法通过反射调用org.apache.catalina.startup.Catalina#load()，那我们就来看看Catalina#load()，Catalina#load()代码如下。org.apache.catalina.startup.Catalina#load()123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596/** * Start a new server instance. */ public void load() { long t1 = System.nanoTime(); initDirs(); // Before digester - it may be needed initNaming(); // 1 // Create and execute our Digester Digester digester = createStartDigester(); InputSource inputSource = null; InputStream inputStream = null; File file = null; try { file = configFile(); inputStream = new FileInputStream(file); inputSource = new InputSource(file.toURI().toURL().toString()); } catch (Exception e) { if (log.isDebugEnabled()) { log.debug(sm.getString(\"catalina.configFail\", file), e); } } if (inputStream == null) { try { inputStream = getClass().getClassLoader().getResourceAsStream(getConfigFile()); inputSource = new InputSource(getClass().getClassLoader().getResource(getConfigFile()).toString()); } catch (Exception e) { if (log.isDebugEnabled()) { log.debug(sm.getString(\"catalina.configFail\",getConfigFile()), e); } } } // This should be included in catalina.jar // Alternative: don't bother with xml, just create it manually. if( inputStream==null ) { try { inputStream = getClass().getClassLoader().getResourceAsStream(\"server-embed.xml\"); inputSource = new InputSource(getClass().getClassLoader().getResource(\"server-embed.xml\").toString()); } catch (Exception e) { if (log.isDebugEnabled()) { log.debug(sm.getString(\"catalina.configFail\", \"server-embed.xml\"), e); } } } if (inputStream == null || inputSource == null) { if (file == null) { log.warn(sm.getString(\"catalina.configFail\", getConfigFile() + \"] or [server-embed.xml]\")); } else { log.warn(sm.getString(\"catalina.configFail\", file.getAbsolutePath())); if (file.exists() &amp;&amp; !file.canRead()) { log.warn(\"Permissions incorrect, read permission is not allowed on the file.\"); } } return; } try { inputSource.setByteStream(inputStream); digester.push(this); digester.parse(inputSource); } catch (SAXParseException spe) { log.warn(\"Catalina.start using \" + getConfigFile() + \": \" + spe.getMessage()); return; } catch (Exception e) { log.warn(\"Catalina.start using \" + getConfigFile() + \": \" , e); return; } finally { try { inputStream.close(); } catch (IOException e) { // Ignore } } getServer().setCatalina(this); // Stream redirection initStreams(); // Start the new server try { // 2 getServer().init(); } catch (LifecycleException e) { if (Boolean.getBoolean(\"org.apache.catalina.startup.EXIT_ON_INIT_FAILURE\")) { throw new java.lang.Error(e); } else { log.error(\"Catalina.start\", e); } } long t2 = System.nanoTime(); if(log.isInfoEnabled()) { log.info(\"Initialization processed in \" + ((t2 - t1) / 1000000) + \" ms\"); } } 下面重点逐一来分析一下上述代码中标注数字的地方： 标注1的代码：创建Digester实例解析conf/server.xml文件。 标注2的代码：最终调用StandardServer#init()。自行查看下源代码，我们会发现如下的一个调用流程：1234org.apache.catalina.core.StandardServer#init-&gt;org.apache.catalina.core.StandardService#init--&gt;org.apache.catalina.connector.Connector#init--&gt;org.apache.catalina.core.StandardEngine#init 因为StandardService，Connector，StandardEngine实现LifeCycle接口，因此符合我们上文所获的生命周期的管理，最终都是通过他们自己实现的initInternal()进行初始化。以为StandardEngine#init()会调用StandardHost#init()，但是当查看StandardEngine#init()的时候，发现并没有进行StandardHost的初始化，它到底做什么呢？来具体分析一下，首先拿StandardEngine的继承关系图来看下。通过上图以及前面说的LifeCyecle的模板方法模式，知道StandardEngine的初始化钩子方法initInternal()最终调用ContainerBase#initInternal()，那我们拿ContainerBase#initInternal()的代码看看。org.apache.catalina.core.ContainerBase#initInternal()1234567891011@Overrideprotected void initInternal() throws LifecycleException { BlockingQueue&lt;Runnable&gt; startStopQueue = new LinkedBlockingQueue&lt;Runnable&gt;(); startStopExecutor = new ThreadPoolExecutor( getStartStopThreadsInternal(), getStartStopThreadsInternal(), 10, TimeUnit.SECONDS, startStopQueue, new StartStopThreadFactory(getName() + \"-startStop-\")); startStopExecutor.allowCoreThreadTimeOut(true); super.initInternal();} 我们可以看到StandardEngine的初始化仅仅是创建一个ThreadPoolExecutor，StandardEngine#init()竟然没有调用StandardHost#init()，那么StandardHost#init()是什么时候被调用的呢？遇到这种不知道到底方法怎么调用的时候怎么办呢？现在需要知道StandardHost#init()何时被调用的，知道init()最终会调用钩子的initInternal()，因此这个时候，可以在StandardHost中override initInternal()，增加实现方法以后，有两种方法可以用，一种就是设置个断点debug一下就可以看出线程调用栈，另外一种就是在新增的方法中打印出调用栈。这里采用第二种方法，增加如下的initInternal()到StandardHost中。org.apache.catalina.core.StandardHost#initInternal()12345678910111213protected void initInternal() throws LifecycleException { Throwable ex = new Throwable(); StackTraceElement[] stackElements = ex.getStackTrace(); if (stackElements != null) { for (int i = stackElements.length - 1; i &gt;= 0; i--) { System.out.print(stackElements[i].getClassName() + \"\\t\"); System.out.print(stackElements[i].getMethodName() + \"\\t\"); System.out.print(stackElements[i].getFileName() + \"\\t\"); System.out.println(stackElements[i].getLineNumber()); } } super.initInternal();} 上面的代码将会打印出方法调用堆栈，对于调试非常有用，上面的方法运行以后在控制台打印出如下的堆栈信息。12345678910java.lang.Thread run Thread.java 680java.util.concurrent.ThreadPoolExecutor$Worker run ThreadPoolExecutor.java 918java.util.concurrent.ThreadPoolExecutor$Worker runTask ThreadPoolExecutor.java 895java.util.concurrent.FutureTask run FutureTask.java 138java.util.concurrent.FutureTask$Sync innerRun FutureTask.java 303org.apache.catalina.core.ContainerBase$StartChild call ContainerBase.java 1549org.apache.catalina.core.ContainerBase$StartChild call ContainerBase.java 1559org.apache.catalina.util.LifecycleBase start LifecycleBase.java 139org.apache.catalina.util.LifecycleBase init LifecycleBase.java 102org.apache.catalina.core.StandardHost initInternal StandardHost.java 794 通过控制台的信息，我们看到是StartChild#call()调用的，而我们查看StartChild#call()其实是在StandardEngine#startInternal()中通过异步线程池去初始化子容器。org.apache.catalina.core. StandardEngine#startInternal()123456789101112131415/** * Start this component and implement the requirements * of {@link org.apache.catalina.util.LifecycleBase#startInternal()}. * * @exception LifecycleException if this component detects a fatal error * that prevents this component from being used */ @Override protected synchronized void startInternal() throws LifecycleException { // Log our server identification information if(log.isInfoEnabled()) log.info( \"Starting Servlet Engine: \" + ServerInfo.getServerInfo()); // Standard container startup super.startInternal(); } 这里StandardEngine#startInternal()调用父类的startInternal()。org.apache.catalina.core.ContainerBase#startInternal()12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849/** * Start this component and implement the requirements * of {@link org.apache.catalina.util.LifecycleBase#startInternal()}. * * @exception LifecycleException if this component detects a fatal error * that prevents this component from being used */ @Override protected synchronized void startInternal() throws LifecycleException { // Start our subordinate components, if any if ((loader != null) &amp;&amp; (loader instanceof Lifecycle)) ((Lifecycle) loader).start(); logger = null; getLogger(); if ((manager != null) &amp;&amp; (manager instanceof Lifecycle)) ((Lifecycle) manager).start(); if ((cluster != null) &amp;&amp; (cluster instanceof Lifecycle)) ((Lifecycle) cluster).start(); Realm realm = getRealmInternal(); if ((realm != null) &amp;&amp; (realm instanceof Lifecycle)) ((Lifecycle) realm).start(); if ((resources != null) &amp;&amp; (resources instanceof Lifecycle)) ((Lifecycle) resources).start(); // Start our child containers, if any Container children[] = findChildren(); List&lt;Future&lt;Void&gt;&gt; results = new ArrayList&lt;Future&lt;Void&gt;&gt;(); for (int i = 0; i &lt; children.length; i++) { results.add(startStopExecutor.submit(new StartChild(children[i]))); } boolean fail = false; for (Future&lt;Void&gt; result : results) { try { result.get(); } catch (Exception e) { log.error(sm.getString(\"containerBase.threadedStartFailed\"), e); fail = true; } } if (fail) { throw new LifecycleException( sm.getString(\"containerBase.threadedStartFailed\")); } // Start the Valves in our pipeline (including the basic), if any if (pipeline instanceof Lifecycle) ((Lifecycle) pipeline).start(); setState(LifecycleState.STARTING); // Start our thread threadStart(); } 因此到这里我们就理清楚，StarndardHost#init()是在调用start()的时候被初始化。那么接下来我们就来看看，start()的整体调用流程。BootStrap#start()采用分析load()一样的方法，经过对BootStrap#start()的分析，最终可以得到得到如下的调用链。org.apache.catalina.startup.Bootstrap#start call stack1234567org.apache.catalina.startup.Bootstrap#start-&gt;org.apache.catalina.startup.Catalina#start 通过反射调用--&gt;org.apache.catalina.core.StandardServer#start---&gt;org.apache.catalina.core.StandardService#start----&gt;org.apache.catalina.core.StandardEngine#start----&gt;org.apache.catalina.Executor#start----&gt;org.apache.catalina.connector.Connector#start 综合上文的描述总体得到如下的调用链。1org.apache.catalina.startup.Bootstrap#main call stack 123456789101112131415org.apache.catalina.startup.Bootstrap#main-&gt;org.apache.catalina.startup.Bootstrap#init-&gt;org.apache.catalina.startup.Bootstrap#load--&gt;org.apache.catalina.startup.Catalina#load---&gt;org.apache.catalina.core.StandardServer#init----&gt;org.apache.catalina.core.StandardService#init-----&gt;org.apache.catalina.connector.Connector#init-----&gt;org.apache.catalina.core.StandardEngine#init-&gt;org.apache.catalina.startup.Bootstrap#start--&gt;org.apache.catalina.startup.Catalina#start 通过反射调用---&gt;org.apache.catalina.core.StandardServer#start----&gt;org.apache.catalina.core.StandardService#start-----&gt;org.apache.catalina.core.StandardEngine#start-----&gt;org.apache.catalina.Executor#start-----&gt;org.apache.catalina.connector.Connector#start 3 Tomcat启动过程关键步骤分析Connector#init()首先来看一下org.apache.catalina.connector.Connector#init()，知道Connector的生命周期也是通过LifeCycle的模板方法模式来管理的，那么只需要查看一下它的initInternal()即可知道它是如何初始化的。接下来就来看一下initInternal()，代码如下。org.apache.catalina.connector.Connector#initInternal()1234567891011121314151617181920212223242526@Overrideprotected void initInternal() throws LifecycleException { super.initInternal(); // Initialize adapter adapter = new CoyoteAdapter(this); protocolHandler.setAdapter(adapter); // Make sure parseBodyMethodsSet has a default if( null == parseBodyMethodsSet ) { setParseBodyMethods(getParseBodyMethods()); } if (protocolHandler.isAprRequired() &amp;&amp; !AprLifecycleListener.isAprAvailable()) { throw new LifecycleException( sm.getString(\"coyoteConnector.protocolHandlerNoApr\", getProtocolHandlerClassName())); } try { // 1 protocolHandler.init(); } catch (Exception e) { throw new LifecycleException (sm.getString(\"coyoteConnector.protocolHandlerInitializationFailed\"), e); } // Initialize mapper listener mapperListener.init();} 上面代码中，本文最关心的是标注1的地方，这个地方调用org.apache.coyote.ProtocolHandler#init()，而ProtocolHandler是在Connector的构造函数中初始化，而Connector的构造函数又是Digester类解析conf/server.xml的时候调用的，在来具体看看Connector构造函数中调用的一个核心的方法setProtocol()，下面是其代码。org.apache.catalina.connector.Connector#Connector()1234567891011public Connector(String protocol) { setProtocol(protocol); // Instantiate protocol handler try { Class&lt;?&gt; clazz = Class.forName(protocolHandlerClassName); this.protocolHandler = (ProtocolHandler) clazz.newInstance(); } catch (Exception e) { log.error(sm.getString( \"coyoteConnector.protocolHandlerInstantiationFailed\"), e); } } org.apache.catalina.connector.Connector#setProtocol()123456789101112131415161718192021222324252627/** * Set the Coyote protocol which will be used by the connector. * * @param protocol The Coyote protocol name */ public void setProtocol(String protocol) { if (AprLifecycleListener.isAprAvailable()) { if (\"HTTP/1.1\".equals(protocol)) { setProtocolHandlerClassName(\"org.apache.coyote.http11.Http11AprProtocol\"); } else if (\"AJP/1.3\".equals(protocol)) { setProtocolHandlerClassName(\"org.apache.coyote.ajp.AjpAprProtocol\"); } else if (protocol != null) { setProtocolHandlerClassName(protocol); } else { setProtocolHandlerClassName(\"org.apache.coyote.http11.Http11AprProtocol\"); } } else { // 1 if (\"HTTP/1.1\".equals(protocol)) { setProtocolHandlerClassName(\"org.apache.coyote.http11.Http11Protocol\"); } else if (\"AJP/1.3\".equals(protocol)) { setProtocolHandlerClassName(\"org.apache.coyote.ajp.AjpProtocol\"); } else if (protocol != null) { setProtocolHandlerClassName(protocol); } } } AJP方式：通过AJP协议进行通讯，AJP主要用于Apache的HTTP服务器和Servlet Web容器之间通讯，它是Packet_Oriented的，换句话说，它发送给浏览器（其他Web Server）的数据是Packet(s)，得到Servlet容器的响应也是Packet(s)，这里有特殊情况，如果Servlet 容器发送的数据是二进制的，则直接发送给浏览器。此外，AJP还可以重用和Servlet容器之间的Socket连接（Socket Connection），降低创建开销。从setProtocol的代码中，可以看出主要逻辑分为两块，一种情况是使用APR(Apache Portable Runtime)，另外一种是不使用APR的情况。缺省情况下不采用APR库，这样的话，代码会走到标注1的代码分支，这里通过协议的不同，最终初始化不同的类。如果是http1.1协议就采用org.apache.coyote.http11.Http11Protocol，如果是AJP(Apache Jserv Protocol)协议，就采用org.apache.coyote.ajp.AjpProtocol类，下面来看一下Http11Protocol和AjpProtocol的继承关系图如下。通过上图可以看到它们都继承公共的基类org.apache.coyote.AbstractProtocol，而它们自己的init()最终其实都是调用AbstractProtocol#init()，通过查看AbstractProtocol#init()代码，我们可以看到最终是调用org.apache.tomcat.util.net.AbstractEndpoint#init()。org.apache.coyote.AbstractProtocol#init()12345678910111213141516171819202122232425262728293031323334353637383940414243/* * NOTE: There is no maintenance of state or checking for valid transitions * within this class. It is expected that the connector will maintain state * and prevent invalid state transitions. */@Overridepublic void init() throws Exception { if (getLog().isInfoEnabled()) getLog().info(sm.getString(\"abstractProtocolHandler.init\", getName())); if (oname == null) { // Component not pre-registered so register it oname = createObjectName(); if (oname != null) { Registry.getRegistry(null, null).registerComponent(this, oname, null); } } if (this.domain != null) { try { tpOname = new ObjectName(domain + \":\" + \"type=ThreadPool,name=\" + getName()); Registry.getRegistry(null, null).registerComponent(endpoint, tpOname, null); } catch (Exception e) { getLog().error(sm.getString( \"abstractProtocolHandler.mbeanRegistrationFailed\", tpOname, getName()), e); } rgOname=new ObjectName(domain +\":type=GlobalRequestProcessor,name=\" + getName()); Registry.getRegistry(null, null).registerComponent( getHandler().getGlobal(), rgOname, null ); } String endpointName = getName(); endpoint.setName(endpointName.substring(1, endpointName.length()-1)); try { endpoint.init(); } catch (Exception ex) { getLog().error(sm.getString(\"abstractProtocolHandler.initError\", getName()), ex); throw ex; }} org.apache.tomcat.util.net.AbstractEndpoint#init123456 public final void init() throws Exception { if (bindOnInit) { bind(); bindState = BindState.BOUND_ON_INIT; }} 而AbstractEndpoint的实例化操作是在实例化AjpProtocol和Http11Protocol的时候在其构造函数中实例化的，而AjpProtocol和Http11Protocol构造函数中，其实都是初始化org.apache.tomcat.util.net.JIoEndpoint类，只不过根据是http协议还是AJP协议，它们具有不同的连接处理类。org.apache.coyote.ajp.AjpProtocol()12345678public AjpProtocol() { endpoint = new JIoEndpoint(); cHandler = new AjpConnectionHandler(this); ((JIoEndpoint) endpoint).setHandler(cHandler); setSoLinger(Constants.DEFAULT_CONNECTION_LINGER); setSoTimeout(Constants.DEFAULT_CONNECTION_TIMEOUT); setTcpNoDelay(Constants.DEFAULT_TCP_NO_DELAY); } org.apache.coyote.http11.Http11Protocol12345678public Http11Protocol() { endpoint = new JIoEndpoint(); cHandler = new Http11ConnectionHandler(this); ((JIoEndpoint) endpoint).setHandler(cHandler); setSoLinger(Constants.DEFAULT_CONNECTION_LINGER); setSoTimeout(Constants.DEFAULT_CONNECTION_TIMEOUT); setTcpNoDelay(Constants.DEFAULT_TCP_NO_DELAY); } 其中Http11Protocol的连接处理类为org.apache.coyote.http11.Http11Protocol.Http11ConnectionHandler，而连接处理类为org.apache.coyote.ajp.AjpProtocol.AjpConnectionHandler，因此到这里我们基本清楚Connector的初始化流程，总结如下。Connect init采用APR的情况12345678910111213//1 HTTP/1.1协议连接器org.apache.catalina.connector.Connector#init-&gt;org.apache.coyote.http11.Http11AprProtocol#init--&gt;org.apache.tomcat.util.net.AprEndpoint#init(org.apache.coyote.http11.Http11AprProtocol.Http11ConnectionHandler)// 2 AJP/1.3协议连接器org.apache.catalina.connector.Connector#init-&gt;org.apache.coyote.ajp.AjpAprProtocol#init--&gt;org.apache.tomcat.util.net.AprEndpoint#init(org.apache.coyote.ajp.AjpAprProtocol.AjpConnectionHandler) Connector init 不采用APR的情况12345678910111213// 1 HTTP/1.1协议连接器org.apache.catalina.connector.Connector#init-&gt;org.apache.coyote.http11.Http11Protocol#init--&gt;org.apache.tomcat.util.net.JIoEndpoint#init(org.apache.coyote.http11.Http11Protocol.Http11ConnectionHandler)// 2 AJP/1.3协议连接器org.apache.catalina.connector.Connector#init-&gt;org.apache.coyote.ajp.AjpProtocol#init--&gt;org.apache.tomcat.util.net.JIoEndpoint#init(org.apache.coyote.ajp.AjpProtocol.AjpConnectionHandler) 这里需要注意，除JIoEndpoint外，还有NIoEndpoint，对于Tomcat7.0.24的代码，并没有采用NIOEndPoint，NIOEndpoint采用NIO的方式进行Socket的处理。最后，再来看看org.apache.tomcat.util.net.JIoEndpoint#init()的初始化过程，首先来看一下JIoEndpoint的继承关系图如下。通过上图知道JIoEndpoint继承AbstractEndpoint，而通过查看源码可知，JIoEndpoint没有实现自己的init()，它默认采用父类的init()，那么我们就来看看AbstractEndpoint#init()，它的代码如下。org.apache.tomcat.util.net.AbstractEndpoint#init()123456public final void init() throws Exception { if (bindOnInit) { bind(); bindState = BindState.BOUND_ON_INIT; } } 通过查看上面的代码可知，因为bindOnInit默认是true，所以init()调用bind()，而bind()是抽象方法，最终由JIoEndpoint来实现，代码如下。org.apache.tomcat.util.net.JIoEndpoint#bind()1234567891011121314151617181920212223242526272829303132333435363738394041@Overridepublic void bind() throws Exception { // Initialize thread count defaults for acceptor if (acceptorThreadCount == 0) { acceptorThreadCount = 1; } // Initialize maxConnections if (getMaxConnections() == 0) { // User hasn't set a value - use the default setMaxConnections(getMaxThreadsExecutor(true)); } if (serverSocketFactory == null) { if (isSSLEnabled()) { serverSocketFactory = handler.getSslImplementation().getServerSocketFactory(this); } else { serverSocketFactory = new DefaultServerSocketFactory(this); } } if (serverSocket == null) { try { if (getAddress() == null) { serverSocket = serverSocketFactory.createSocket(getPort(), getBacklog()); } else { serverSocket = serverSocketFactory.createSocket(getPort(), getBacklog(), getAddress()); } } catch (BindException orig) { String msg; if (getAddress() == null) msg = orig.getMessage() + \" &lt;null&gt;:\" + getPort(); else msg = orig.getMessage() + \" \" + getAddress().toString() + \":\" + getPort(); BindException be = new BindException(msg); be.initCause(orig); throw be; } }} 通过上面代码可以看出，最终是调用org.apache.tomcat.util.net.ServerSocketFactory#createSocket()创建一个java.net.ServerSocket，并绑定在conf/server.xml中Connector中配置的端口。结论：Connector#init()的时候，无论是AJP还是HTTP最终其实是调用JioEndpoint的初始化，默认情况在初始化的时候就会创建java.net.ServerSocket绑到到配置的端口上。 Connector#start()接着再来分析一下Connector#start，因为Connector符合LifeCycle模板方法生命周期管理的机制，因此它的start最终会调用startInternal()，org.apache.catalina.connector.Connector#startInternal()代码如下。org.apache.catalina.connector. Connector#startInternal()1234567891011121314151617181920212223242526/** * Begin processing requests via this Connector. * * @exception LifecycleException if a fatal startup error occurs */ @Override protected void startInternal() throws LifecycleException { // Validate settings before starting if (getPort() &lt; 0) { throw new LifecycleException(sm.getString( \"coyoteConnector.invalidPort\", Integer.valueOf(getPort()))); } setState(LifecycleState.STARTING); try { protocolHandler.start(); } catch (Exception e) { String errPrefix = \"\"; if(this.service != null) { errPrefix += \"service.getName(): \\\"\" + this.service.getName() + \"\\\"; \"; } throw new LifecycleException (errPrefix + \" \" + sm.getString (\"coyoteConnector.protocolHandlerStartFailed\"), e); } mapperListener.start(); } 通过上面的代码，可以清晰的看到最终调用protocolHandler#start()，而根据Connector#init()流程的分析，这里会分是否采用APR，默认是不采用APR的，这里会根据不同的协议（AJP，HTTP）来调用对应的org.apache.coyote.ProtocolHandler#start()。 其中AJP会采用org.apache.coyote.ajp.AjpProtocol，HTTP协议采用org.apache.coyote.http11.Http11Protocol，而无论是AjpProtocol还是Http11Protocol都会调用JIoEndpoint的方法，那么接下来我们就来看看JioEndpoint#start()，JioEndpoint没有实现start()，调用它父类的方法。它的代码如下。org.apache.tomcat.util.net.AbstractEndpoint#start()1234567public final void start() throws Exception { if (bindState == BindState.UNBOUND) { bind(); bindState = BindState.BOUND_ON_START; } startInternal(); } startInternal()在JioEndpoint中实现。org.apache.tomcat.util.net.JioEndpoint#startInternal()12345678910111213141516171819@Overridepublic void startInternal() throws Exception { if (!running) { running = true; paused = false; // Create worker collection if (getExecutor() == null) { createExecutor(); } initializeConnectionLatch(); startAcceptorThreads(); // Start async timeout thread Thread timeoutThread = new Thread(new AsyncTimeout(), getName() + \"-AsyncTimeout\"); timeoutThread.setPriority(threadPriority); timeoutThread.setDaemon(true); timeoutThread.start(); }} 从上面的代码可以看出，启动Acceptor线程和AsyncTimeout线程，首先来看看Acceptor线程，我们再来看看startAcceptorThreads()，代码如下。org.apache.tomcat.util.net.AbstractEndpoint#startAcceptorThreads()12345678910111213protected final void startAcceptorThreads() { int count = getAcceptorThreadCount(); acceptors = new Acceptor[count]; for (int i = 0; i &lt; count; i++) { acceptors[i] = createAcceptor(); String threadName = getName() + \"-Acceptor-\" + i; acceptors[i].setThreadName(threadName); Thread t = new Thread(acceptors[i], threadName); t.setPriority(getAcceptorThreadPriority()); t.setDaemon(getDaemon()); t.start(); } } 通过上面的代码，可以看出其实是通过org.apache.tomcat.util.net.AbstractEndpoint.Acceptor这个Runable接口的实现类来启动线程，接下来就来看看Acceptor#run()，通过查看run()，它里面其实就是调用java.net.ServerSocket#accept()来接受一个Socket连接。org.apache.tomcat.util.net.JioEndpoint#Acceptor()1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465protected class Acceptor extends AbstractEndpoint.Acceptor { @Override public void run() { int errorDelay = 0; // Loop until we receive a shutdown command while (running) { // Loop if endpoint is paused while (paused &amp;&amp; running) { state = AcceptorState.PAUSED; try { Thread.sleep(50); } catch (InterruptedException e) { // Ignore } } if (!running) { break; } state = AcceptorState.RUNNING; try { //if we have reached max connections, wait countUpOrAwaitConnection(); Socket socket = null; try { // Accept the next incoming connection from the server // socket socket = serverSocketFactory.acceptSocket(serverSocket); } catch (IOException ioe) { countDownConnection(); // Introduce delay if necessary errorDelay = handleExceptionWithDelay(errorDelay); // re-throw throw ioe; } // Successful accept, reset the error delay errorDelay = 0; // Configure the socket if (running &amp;&amp; !paused &amp;&amp; setSocketOptions(socket)) { // Hand this socket off to an appropriate processor if (!processSocket(socket)) { countDownConnection(); // Close socket right away closeSocket(socket); } } else { countDownConnection(); // Close socket right away closeSocket(socket); } } catch (IOException x) { if (running) { log.error(sm.getString(\"endpoint.accept.fail\"), x); } } catch (NullPointerException npe) { if (running) { log.error(sm.getString(\"endpoint.accept.fail\"), npe); } } catch (Throwable t) { ExceptionUtils.handleThrowable(t); log.error(sm.getString(\"endpoint.accept.fail\"), t); } } state = AcceptorState.ENDED; } } 启动完Acceptor线程以后，接着就会启动AsyncTimeout线程，而这里面需要注意的时候，无论是Acceptor还是AsyncTimeout线程，它们都是Daemon线程，而设置为Daemon的原因，会在下篇Tomcat的关闭中进行说明。 StandardEngine#start()从本文上面的分析中，得知StandardEngine继承ContainerBase，而StandardEngine#startInternal()钩子方法也仅仅是调用父类ContainerBase#startInternal()，那接下来分析一下ContainerBase#startInternal()，代码如下。org.apache.catalina.core.ContainerBase#startInternal()12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849/** * Start this component and implement the requirements * of {@link org.apache.catalina.util.LifecycleBase#startInternal()}. * * @exception LifecycleException if this component detects a fatal error * that prevents this component from being used */ @Override protected synchronized void startInternal() throws LifecycleException { // Start our subordinate components, if any if ((loader != null) &amp;&amp; (loader instanceof Lifecycle)) ((Lifecycle) loader).start(); logger = null; getLogger(); if ((manager != null) &amp;&amp; (manager instanceof Lifecycle)) ((Lifecycle) manager).start(); if ((cluster != null) &amp;&amp; (cluster instanceof Lifecycle)) ((Lifecycle) cluster).start(); Realm realm = getRealmInternal(); if ((realm != null) &amp;&amp; (realm instanceof Lifecycle)) ((Lifecycle) realm).start(); if ((resources != null) &amp;&amp; (resources instanceof Lifecycle)) ((Lifecycle) resources).start(); // Start our child containers, if any Container children[] = findChildren(); List&lt;Future&lt;Void&gt;&gt; results = new ArrayList&lt;Future&lt;Void&gt;&gt;(); for (int i = 0; i &lt; children.length; i++) { results.add(startStopExecutor.submit(new StartChild(children[i]))); } boolean fail = false; for (Future&lt;Void&gt; result : results) { try { result.get(); } catch (Exception e) { log.error(sm.getString(\"containerBase.threadedStartFailed\"), e); fail = true; } } if (fail) { throw new LifecycleException( sm.getString(\"containerBase.threadedStartFailed\")); } // Start the Valves in our pipeline (including the basic), if any if (pipeline instanceof Lifecycle) ((Lifecycle) pipeline).start(); setState(LifecycleState.STARTING); // Start our thread threadStart(); } 可以看到通过startStopExecutor异步的对子容器进行启动，然后设置状态为LifecycleState.STARTING的状态。而startStopExecutor是在容器的initInternal()中进行初始化好的。org.apache.catalina.core.ContainerBase#initInternal()123456789101112@Override protected void initInternal() throws LifecycleException { BlockingQueue&lt;Runnable&gt; startStopQueue = new LinkedBlockingQueue&lt;Runnable&gt;(); startStopExecutor = new ThreadPoolExecutor( getStartStopThreadsInternal(), getStartStopThreadsInternal(), 10, TimeUnit.SECONDS, startStopQueue, new StartStopThreadFactory(getName() + \"-startStop-\")); startStopExecutor.allowCoreThreadTimeOut(true); super.initInternal(); } 接下来我们就来看看StartChild，StardChild的代码如下。org.apache.catalina.core.ContainerBase.StartChild12345678910111213private static class StartChild implements Callable&lt;Void&gt; { private Container child; public StartChild(Container child) { this.child = child; } @Override public Void call() throws LifecycleException { child.start(); return null; } } 通过上面的代码，可以看到StartChild实现Callable接口，实现这个接口的类可以将其放到对应的executor中执行，StartChild在运行的时候就会调用到子容器的start()，而此时的父容器是StandardEngine，子容器就是StandardHost，接下来就来看看StandardHost的启动过程。通过前面对于init()流程的分析，知道StandardHost不是在StandardEngine#init的时候初始化，因此在执行StandardHost#start()的时候，要首先进行init()的调用，init()调用在LifecycleBase#start()里。具体的代码如下。org.apache.catalina.util.LifecycleBase#start()12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849/** * {@inheritDoc} */ @Override public final synchronized void start() throws LifecycleException { if (LifecycleState.STARTING_PREP.equals(state) || LifecycleState.STARTING.equals(state) || LifecycleState.STARTED.equals(state)) { if (log.isDebugEnabled()) { Exception e = new LifecycleException(); log.debug(sm.getString(\"lifecycleBase.alreadyStarted\", toString()), e); } else if (log.isInfoEnabled()) { log.info(sm.getString(\"lifecycleBase.alreadyStarted\", toString())); } return; } //因为此时的StandardHost还没有初始化，因此会走到这一步代码 if (state.equals(LifecycleState.NEW)) { init(); } else if (state.equals(LifecycleState.FAILED)){ stop(); } else if (!state.equals(LifecycleState.INITIALIZED) &amp;&amp; !state.equals(LifecycleState.STOPPED)) { invalidTransition(Lifecycle.BEFORE_START_EVENT); } setStateInternal(LifecycleState.STARTING_PREP, null, false); try { startInternal(); } catch (Throwable t) { ExceptionUtils.handleThrowable(t); setStateInternal(LifecycleState.FAILED, null, false); throw new LifecycleException( sm.getString(\"lifecycleBase.startFail\",toString()), t); } if (state.equals(LifecycleState.FAILED) || state.equals(LifecycleState.MUST_STOP)) { stop(); } else { // Shouldn't be necessary but acts as a check that sub-classes are // doing what they are supposed to. if (!state.equals(LifecycleState.STARTING)) { invalidTransition(Lifecycle.AFTER_START_EVENT); } setStateInternal(LifecycleState.STARTED, null, false); } } 对于StandardHost的初始化，是在start()的时候进行的。那接下来看一下StandardHost#init()，通过查看代码，StandardHost本身没有实现initInternal()的钩子方法，也就意味着最终初始化会调用ContainerBase#initInternal()，而通过上文的描述，已经清楚ContainerBase#initInternal()主要是初始化一个startStopExecutor，这个线程池主要是为异步的初始化子容器来用的。知道StandardEngine初始化的时候，也是初始化一个线程池，而StandardHost也初始化一个线程池，它们的不同点在与创建线程的工厂方法不同，在采用缺省配置的情况下，StandardEngine的线程池中的线程是以Catalina-startStop的形式命名的，而StandardHost是以localhost-startStop的方式进行命名的。StandardHost#start()调用init()初始化完StandardHost以后，会调用钩子的startInternal()，而startInternal()又是调用ContainerBased#startInternal()，而ContainerBase#startInternal()最终又会去启动子容器的，对于StandardHost来说，子容器就是StandardContext。 因此分析到这里可以得出如下结论。对于StandardEngine，StandardHost的启动，父容器在init()的时候创建一个启动和停止子容器的线程池，然后父容器启动的时候首先通过异步的方式将子容器的启动通过org.apache.catalina.core.ContainerBase.StartChild提交到父容器中对应的线程池中进行启动，而子容器启动的时候首先会初始化，然后再启动。（子容器的初始化时执行init()，这里子容器调用star()，未初始化，先执行init()）另外这里还需要注意一点就是，StandEngine#start()的时候，最终调用ContainerBase#startInternal()（StandEngine没有实现start()，调用LifecycleBase#start()，start()里调用startInternal()，这个方法被ContainerBase覆写），而ContainerBase#startInternal()的最后，调用threadStart()，我们来看看它的代码如下。org.apache.catalina.core.ContainerBase#threadStart()123456789101112131415/** * Start the background thread that will periodically check for * session timeouts. */ protected void threadStart() { if (thread != null) return; if (backgroundProcessorDelay &lt;= 0) return; threadDone = false; String threadName = \"ContainerBackgroundProcessor[\" + toString() + \"]\"; thread = new Thread(new ContainerBackgroundProcessor(), threadName); thread.setDaemon(true); thread.start(); } 上面的代码，首先会判断backgroundProcessorDelay是否小于0，而这个值默认情况下是-1，也就意味这后面的代码不会运行，而对于StandardEngine来说，它将backgroundProcessorDelay的值在构造函数中赋值为10，这样的话，当StandardEngine启动的时候，就会启动名称为ContainerBackgroundProcessor[StandardEngine[Catalina]]的线程。经过上面的分析，我们已经清楚StandardEngine启动的过程，但是我们还有一个地方需要进一步的分析。因为上面的分析仅仅只是分析容器通过conf/server.xml配置文件的配置结构进行的启动，而都知道CATALINA-HOME/webapps/中的应用也是需要启动的，那么webapps目录的应用又是如何启动的呢？下面来分析一下，通过Tomcat总体结构的描述，已经知道，webapps目录下面的应用其实是属于Context的，而Context对应Tomcat中的StandardContext类，因此就知道应该对谁下手，知道目标以后，还是采用之前的那种方式，打印调用栈，这里还是通过打印调用栈的方式进行，在org.apache.catalina.core.StandardContext#initInternal()中增加打印调用栈的方法，具体代码如下。org.apache.catalina.core.StandardContext#initInternal()1234567891011121314151617181920212223242526272829protected void initInternal() throws LifecycleException { super.initInternal(); Throwable ex = new Throwable(); StackTraceElement[] stackElements = ex.getStackTrace(); if (stackElements != null) { for (int i = stackElements.length - 1; i &gt;= 0; i--) { System.out.print(stackElements[i].getClassName() + \"\\t\"); System.out.print(stackElements[i].getMethodName() + \"\\t\"); System.out.print(stackElements[i].getFileName() + \"\\t\"); System.out.println(stackElements[i].getLineNumber()); } } if (processTlds) { this.addLifecycleListener(new TldConfig()); } // Register the naming resources if (namingResources != null) { namingResources.init(); } // Send j2ee.object.created notification if (this.getObjectName() != null) { Notification notification = new Notification(\"j2ee.object.created\", this.getObjectName(), sequenceNumber.getAndIncrement()); broadcaster.sendNotification(notification); }} 运行代码，可以看到控制台有如下的输出。12345678910111213java.util.concurrent.ThreadPoolExecutor$Worker run ThreadPoolExecutor.java 918java.util.concurrent.ThreadPoolExecutor$Worker runTask ThreadPoolExecutor.java 895java.util.concurrent.FutureTask run FutureTask.java 138java.util.concurrent.FutureTask$Sync innerRun FutureTask.java 303java.util.concurrent.Executors$RunnableAdapter call Executors.java 439org.apache.catalina.startup.HostConfig$DeployDirectory run HostConfig.java 1671org.apache.catalina.startup.HostConfig deployDirectory HostConfig.java 1113org.apache.catalina.core.StandardHost addChild StandardHost.java 622org.apache.catalina.core.ContainerBase addChild ContainerBase.java 877org.apache.catalina.core.ContainerBase addChildInternal ContainerBase.java 901org.apache.catalina.util.LifecycleBase start LifecycleBase.java 139org.apache.catalina.util.LifecycleBase init LifecycleBase.java 102org.apache.catalina.core.StandardContext initInternal StandardContext.java 6449 通过查看控制台的输出，可以看到有一个org.apache.catalina.startup.HostConfig$DeployDirectory类，于是乎找到这个类去看看呗。打开一看它是一个Runable接口的实现类。12345678910111213141516private static class DeployDirectory implements Runnable { private HostConfig config; private ContextName cn; private File dir; public DeployDirectory(HostConfig config, ContextName cn, File dir) { this.config = config; this.cn = cn; this.dir = dir; } @Override public void run() { config.deployDirectory(cn, dir); } } 因此推断它也是放到某个线程池中进行异步运行的，最终通过IntellIJ IDEA提供的类调用栈分析工具（ctrl+alt+h）得到DeployDirectory构造器方法的调用栈如下图所示通过上图可以清楚的看到，最终的调用方是org.apache.catalina.startup.HostConfig#lifecycleEvent()，到这里就知道Context的启动是通过某个组件的生命周期事件的监听器来启动的，而HostConfig到底是谁的监听器呢？通过名称应该可以猜测出它是StandardHost的监听器，那么它到底监听哪个事件呢？查看下org.apache.catalina.startup.HostConfig#lifecycleEvent()的代码如下。org.apache.catalina.startup.HostConfig#lifecycleEvent()1234567891011121314151617181920212223242526272829/** * Process the START event for an associated Host. * * @param event The lifecycle event that has occurred */ @Override public void lifecycleEvent(LifecycleEvent event) { // Identify the host we are associated with try { host = (Host) event.getLifecycle(); if (host instanceof StandardHost) { setCopyXML(((StandardHost) host).isCopyXML()); setDeployXML(((StandardHost) host).isDeployXML()); setUnpackWARs(((StandardHost) host).isUnpackWARs()); } } catch (ClassCastException e) { log.error(sm.getString(\"hostConfig.cce\", event.getLifecycle()), e); return; } // Process the event that has occurred if (event.getType().equals(Lifecycle.PERIODIC_EVENT)) { check(); } else if (event.getType().equals(Lifecycle.START_EVENT)) { start(); } else if (event.getType().equals(Lifecycle.STOP_EVENT)) { stop(); } } 通过上面的代码，可以看出监听的事件是Lifecycle.START_EVENT，而通过查看org.apache.catalina.LifecycleState的代码STARTING(true,Lifecycle.START_EVENT)就可以得知，此时生命周期状态应该是LifecycleState.STARTING，到这里应该已经猜到，HostConfig是在StandardHost#start()的时候通过监听器调用，为验证的猜测，debug一下代码，可以在HostConfig#start()中打个断点，运行以后得到如下内存结构。通过上面的分析清楚webapps目录中context的启动，总结如下。webapps目录中应用的启动在StandardHost#start()的时候，通过Lifecycle.START_EVENT这个事件的监听器HostConfig进行进一步的启动。综合上面的文章所述，最后再来一下总结，知道Java程序启动以后，最终会以进程的形式存在，而Java进程中又会有很多条线程存在，因此最后就来看看Tomcat启动以后，到底启动哪些线程，通过这些可以反过来验证对源代码的理解是否正确。接下来启动Tomcat，然后运行jstack -l &lt;pid&gt;来看看，jstack的输入如下所示。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081Full thread dump Java HotSpot(TM) 64-Bit Server VM (20.51-b01-457 mixed mode):\"ajp-bio-8009-AsyncTimeout\" daemon prio=5 tid=7f8738afe000 nid=0x115ad6000 waiting on condition [115ad5000] java.lang.Thread.State: TIMED_WAITING (sleeping) at java.lang.Thread.sleep(Native Method) at org.apache.tomcat.util.net.JIoEndpoint$AsyncTimeout.run(JIoEndpoint.java:148) at java.lang.Thread.run(Thread.java:680) Locked ownable synchronizers: - None\"ajp-bio-8009-Acceptor-0\" daemon prio=5 tid=7f8738b05800 nid=0x1159d3000 runnable [1159d2000] java.lang.Thread.State: RUNNABLE at java.net.PlainSocketImpl.socketAccept(Native Method) at java.net.PlainSocketImpl.accept(PlainSocketImpl.java:439) - locked &lt;7f46a8710&gt; (a java.net.SocksSocketImpl) at java.net.ServerSocket.implAccept(ServerSocket.java:468) at java.net.ServerSocket.accept(ServerSocket.java:436) at org.apache.tomcat.util.net.DefaultServerSocketFactory.acceptSocket(DefaultServerSocketFactory.java:60) at org.apache.tomcat.util.net.JIoEndpoint$Acceptor.run(JIoEndpoint.java:216) at java.lang.Thread.run(Thread.java:680) Locked ownable synchronizers: - None\"http-bio-8080-AsyncTimeout\" daemon prio=5 tid=7f8735acb800 nid=0x1158d0000 waiting on condition [1158cf000] java.lang.Thread.State: TIMED_WAITING (sleeping) at java.lang.Thread.sleep(Native Method) at org.apache.tomcat.util.net.JIoEndpoint$AsyncTimeout.run(JIoEndpoint.java:148) at java.lang.Thread.run(Thread.java:680) Locked ownable synchronizers: - None\"http-bio-8080-Acceptor-0\" daemon prio=5 tid=7f8735acd000 nid=0x1157cd000 runnable [1157cc000] java.lang.Thread.State: RUNNABLE at java.net.PlainSocketImpl.socketAccept(Native Method) at java.net.PlainSocketImpl.accept(PlainSocketImpl.java:439) - locked &lt;7f46a8690&gt; (a java.net.SocksSocketImpl) at java.net.ServerSocket.implAccept(ServerSocket.java:468) at java.net.ServerSocket.accept(ServerSocket.java:436) at org.apache.tomcat.util.net.DefaultServerSocketFactory.acceptSocket(DefaultServerSocketFactory.java:60) at org.apache.tomcat.util.net.JIoEndpoint$Acceptor.run(JIoEndpoint.java:216) at java.lang.Thread.run(Thread.java:680) Locked ownable synchronizers: - None\"ContainerBackgroundProcessor[StandardEngine[Catalina]]\" daemon prio=5 tid=7f8732850800 nid=0x111203000 waiting on condition [111202000] java.lang.Thread.State: TIMED_WAITING (sleeping) at java.lang.Thread.sleep(Native Method) at org.apache.catalina.core.ContainerBase$ContainerBackgroundProcessor.run(ContainerBase.java:1508) at java.lang.Thread.run(Thread.java:680) Locked ownable synchronizers: - None\"main\" prio=5 tid=7f8735000800 nid=0x10843e000 runnable [10843c000] java.lang.Thread.State: RUNNABLE at java.net.PlainSocketImpl.socketAccept(Native Method) at java.net.PlainSocketImpl.accept(PlainSocketImpl.java:439) - locked &lt;7f32ea7c8&gt; (a java.net.SocksSocketImpl) at java.net.ServerSocket.implAccept(ServerSocket.java:468) at java.net.ServerSocket.accept(ServerSocket.java:436) at org.apache.catalina.core.StandardServer.await(StandardServer.java:452) at org.apache.catalina.startup.Catalina.await(Catalina.java:779) at org.apache.catalina.startup.Catalina.start(Catalina.java:725) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25) at java.lang.reflect.Method.invoke(Method.java:597) at org.apache.catalina.startup.Bootstrap.start(Bootstrap.java:322) at org.apache.catalina.startup.Bootstrap.main(Bootstrap.java:456) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25) at java.lang.reflect.Method.invoke(Method.java:597) at com.intellij.rt.execution.application.AppMain.main(AppMain.java:120) 从上图中可以清楚的看到，有6条线程，其中ajp-bio-8009-AsyncTimeout和ajp-bio-8009-Acceptor-0是在Ajp的Connector启动的时候启动的，http-bio-8080-AsyncTimeout和http-bio-8080-Acceptor-0是http的Connector启动的时候启动的，ContainerBackgroundProcessor[StandardEngine[Catalina]]是在StandardEngine启动的时候启动的，而main()线程就是主线程。这里还需要注意一点就是除main线程以外，其它的线程都是Dameon线程，相关的内容在下篇Tomcat的关闭再来详细说明。","link":"/Tomcat-2/"},{"title":"metric","text":"1 介绍 Gauges Meters Histograms Timers 2 源码包分析 metrics-annotation metrics-benchmarks metrics-collectd metrics-core CachedGauge.java Clock.java Counter.java Reservoir.java Histogram.java MetricName.java MetricRegistry.java Snapshot.java InstrumentedExecutors.java InstrumentedThreadFactory.java InstrumentedExecutorService.java InstrumentedScheduledExecutorService.java metrics-healthchecks HealthCheck.java HealthCheckRegistry.java SharedHealthCheckRegistries.java ThreadDeadlockHealthCheck.java metrics-httpclient HttpClientMetricNameStrategies.java HttpClientMetricNameStrategy.java InstrumentedHttpClientConnectionManager.java InstrumentedHttpRequestExecutor.java InstrumentedHttpClients.java metrics-jvm BufferPoolMetricSet.java CachedThreadStatesGaugeSet.java ClassLoadingGaugeSet.java FileDescriptorRatioGauge.java GarbageCollectorMetricSet.java MemoryUsageGaugeSet.java ThreadDeadlockDetector.java ThreadDump.java ThreadStatesGaugeSet.java metrics-servlet AbstractInstrumentedFilter.java InstrumentedFilter.java InstrumentedFilterContextListener.java metrics-servlets AdminServlet.java CpuProfileServlet.java HealthCheckServlet.java 1 介绍Metrics Registries类似一个metrics容器，维护一个Map，可以是一个服务一个实例。支持五种metric类型：Gauges、Counters、Meters、Histograms和Timers。git:https://github.com/dropwizard/metrics GaugesGauges是一个最简单的计量，一般用来统计瞬时状态的数据信息，比如系统中处于pending状态的job MetersMeters用来度量某个时间段的平均处理次数（request per second），每1、5、15分钟的TPS。比如一个service的请求数，通过metrics.meter()实例化一个Meter之后，然后通过 meter.mark()方法就能将本次请求记录下来。统计结果有总的请求数，平均每秒的请求数，以及最近的1、5、15分钟的平均TPS。 HistogramsHistograms主要使用来统计数据的分布情况，最大值、最小值、平均值、中位数，百分比（75%、90%、95%、98%、99%和99.9%）。例如，需要统计某个页面的请求响应时间分布情况，可以使用该种类型的Metrics进行统计。 TimersTimers主要是用来统计某一块代码段的执行时间以及其分布情况，具体是基于Histograms和Meters来实现的。 2 源码包分析metrics-annotationCounted，Gauge，Metered，Metric，Timed注解的方式设置name，tags metrics-benchmarksCounter标准 metrics-collectdCollectd - 收集服务客服端打开InetSocketAddress，通过DatagramChannel发送字节数据。 metrics-core核心类包 CachedGauge.javagauge缓存抽象类12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485package io.dropwizard.metrics;import java.util.Objects;import java.util.concurrent.TimeUnit;import java.util.concurrent.atomic.AtomicLong;/** * A {@link Gauge} implementation which caches its value for a period of time. * gauge 的 缓存 * @param &lt;T&gt; the type of the gauge's value */public abstract class CachedGauge&lt;T&gt; implements Gauge&lt;T&gt; { private final Clock clock; private final AtomicLong reloadAt; private final long timeoutNS; private volatile T value; /** * Creates a new cached gauge with the given timeout period. * * @param timeout the timeout * @param timeoutUnit the unit of {@code timeout} */ protected CachedGauge(long timeout, TimeUnit timeoutUnit) { this(Clock.defaultClock(), timeout, timeoutUnit); } /** * Creates a new cached gauge with the given clock and timeout period. * * @param clock the clock used to calculate the timeout * @param timeout the timeout * @param timeoutUnit the unit of {@code timeout} */ protected CachedGauge(Clock clock, long timeout, TimeUnit timeoutUnit) { this.clock = clock; this.reloadAt = new AtomicLong(0); this.timeoutNS = timeoutUnit.toNanos(timeout); } /** * Loads the value and returns it. * * 读取缓存数据 * * @return the new value */ protected abstract T loadValue(); @Override public T getValue() { if (shouldLoad()) { //从缓存获取数据 this.value = loadValue(); } return value; } /** * * */ private boolean shouldLoad() { for (; ; ) { //系统时间 final long time = clock.getTick(); //缓存时间 final long current = reloadAt.get(); //缓存时间 &gt; 系统时间 ，获取缓存 if (current &gt; time) { return false; } //更新缓存数据，重新设置缓存超时时间 if (reloadAt.compareAndSet(current, time + timeoutNS)) { return true; } } } @Override public String toString() { return String.valueOf(this.getValue()); }} Clock.java抽象的时间类123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172package io.dropwizard.metrics;import java.lang.management.ManagementFactory;import java.lang.management.ThreadMXBean;/** * An abstraction for how time passes. It is passed to {@link Timer} to track timing. * * 抽象的时间类 * */public abstract class Clock { /** * Returns the current time tick. * * @return time tick in nanoseconds */ public abstract long getTick(); /** * Returns the current time in milliseconds. * * @return time in milliseconds */ public long getTime() { return System.currentTimeMillis(); } @Override public String toString() { return Long.toString(this.getTime()); } private static final Clock DEFAULT = new UserTimeClock(); /** * The default clock to use. * * @return the default {@link Clock} instance * * @see Clock.UserTimeClock */ public static Clock defaultClock() { return DEFAULT; } /** * A clock implementation which returns the current time in epoch nanoseconds. * 系统时间 * */ public static class UserTimeClock extends Clock { @Override public long getTick() { return System.nanoTime(); } } /** * A clock implementation which returns the current thread's CPU time. * 返回当前CPU时间 * */ public static class CpuTimeClock extends Clock { private static final ThreadMXBean THREAD_MX_BEAN = ManagementFactory.getThreadMXBean(); @Override public long getTick() { return THREAD_MX_BEAN.getCurrentThreadCpuTime(); } }} Counter.java计数抽象类1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162package io.dropwizard.metrics;/** * An incrementing and decrementing counter metric. */public class Counter implements Metric, Counting { /** * 原子自增 */ private final LongAdder count; public Counter() { this.count = LongAdderFactory.create(); } /** * Increment the counter by one. */ public void inc() { inc(1); } /** * Increment the counter by {@code n}. * * @param n the amount by which the counter will be increased */ public void inc(long n) { count.add(n); } /** * Decrement the counter by one. */ public void dec() { dec(1); } /** * Decrement the counter by {@code n}. * * @param n the amount by which the counter will be decreased */ public void dec(long n) { count.add(-n); } /** * Returns the counter's current value. * * @return the counter's current value */ @Override public long getCount() { return count.sum(); } @Override public String toString() { return String.valueOf(this.count); }} Reservoir.java统计存储层的数据流，数据流处理1234567891011121314151617181920212223242526272829package io.dropwizard.metrics;/** * A statistically representative reservoir of a data stream. * 统计代表储层数据流 * */public interface Reservoir { /** * Returns the number of values recorded. * * @return the number of values recorded */ int size(); /** * Adds a new recorded value to the reservoir. * * @param value a new recorded value */ void update(long value); /** * Returns a snapshot of the reservoir's values. * * @return a snapshot of the reservoir's values */ Snapshot getSnapshot();} Histogram.java直方图实现：快照，Counting接口12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182package io.dropwizard.metrics;import java.io.ByteArrayOutputStream;import java.io.UnsupportedEncodingException;import java.nio.charset.Charset;import java.nio.charset.StandardCharsets;/** * A metric which calculates the distribution of a value. * * 计算分布式数据的值 * * @see &lt;a href=\"http://www.johndcook.com/standard_deviation.html\"&gt;Accurately computing running * variance&lt;/a&gt; */public class Histogram implements Metric, Sampling, Counting { /** * 数据流 */ private final Reservoir reservoir; private final LongAdder count; /** * Creates a new {@link Histogram} with the given reservoir. * * @param reservoir the reservoir to create a histogram from */ public Histogram(Reservoir reservoir) { this.reservoir = reservoir; this.count = LongAdderFactory.create(); } /** * Adds a recorded value. * * @param value the length of the value */ public void update(int value) { update((long) value); } /** * Adds a recorded value. * * @param value the length of the value */ public void update(long value) { count.increment(); reservoir.update(value); } /** * Returns the number of values recorded. * * @return the number of values recorded */ @Override public long getCount() { return count.sum(); } /** * 从数据流中获取快照 * @return */ @Override public Snapshot getSnapshot() { return reservoir.getSnapshot(); } @Override public String toString() { final ByteArrayOutputStream out = new ByteArrayOutputStream(); this.getSnapshot().dump(out); try { return out.toString(StandardCharsets.UTF_8.name()); } catch (UnsupportedEncodingException e) { return super.toString(); } }} MetricName.java设置metric的名字，tag123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301package io.dropwizard.metrics;import java.util.Collections;import java.util.HashMap;import java.util.Map;import java.util.Set;import java.util.TreeSet;/** * A metric name with the ability to include semantic tags. * 度量的名字，可能包含的标签 * * * This replaces the previous style where metric names where strictly * dot-separated strings. * * @author udoprog */public class MetricName implements Comparable&lt;MetricName&gt; { public static final String SEPARATOR = \".\"; public static final Map&lt;String, String&gt; EMPTY_TAGS = Collections.unmodifiableMap(new HashMap&lt;String, String&gt;()); public static final MetricName EMPTY = new MetricName(); private final String key; private final Map&lt;String, String&gt; tags; public MetricName() { this.key = null; this.tags = EMPTY_TAGS; } public MetricName(String key) { this.key = key; this.tags = EMPTY_TAGS; } public MetricName(String key, Map&lt;String, String&gt; tags) { this.key = key; this.tags = checkTags(tags); } private Map&lt;String, String&gt; checkTags(Map&lt;String, String&gt; tags) { if (tags == null || tags.isEmpty()) { return EMPTY_TAGS; } return Collections.unmodifiableMap(tags); } public String getKey() { return key; } public Map&lt;String, String&gt; getTags() { return tags; } /** * 重新构建metric的name * Build the MetricName that is this with another path appended to it. * * The new MetricName inherits the tags of this one. * * @param p The extra path element to add to the new metric. * @return A new metric name relative to the original by the path specified * in p. */ public MetricName resolve(String p) { final String next; if (p != null &amp;&amp; !p.isEmpty()) { if (key != null &amp;&amp; !key.isEmpty()) { next = key + SEPARATOR + p; } else { next = p; } } else { next = this.key; } return new MetricName(next, tags); } /** * Add tags to a metric name and return the newly created MetricName. * * @param add Tags to add. * @return A newly created metric name with the specified tags associated with it. */ public MetricName tagged(Map&lt;String, String&gt; add) { final Map&lt;String, String&gt; tags = new HashMap&lt;String, String&gt;(add); tags.putAll(this.tags); return new MetricName(key, tags); } /** * Same as {@link #tagged(Map)}, but takes a variadic list * of arguments. * * @see #tagged(Map) * @param pairs An even list of strings acting as key-value pairs. * @return A newly created metric name with the specified tags associated * with it. */ public MetricName tagged(String... pairs) { if (pairs == null) { return this; } if (pairs.length % 2 != 0) { throw new IllegalArgumentException(\"Argument count must be even\"); } final Map&lt;String, String&gt; add = new HashMap&lt;String, String&gt;(); for (int i = 0; i &lt; pairs.length; i += 2) { add.put(pairs[i], pairs[i+1]); } return tagged(add); } /** * Join the specified set of metric names. * * @param parts Multiple metric names to join using the separator. * @return A newly created metric name which has the name of the specified * parts and includes all tags of all child metric names. **/ public static MetricName join(MetricName... parts) { final StringBuilder nameBuilder = new StringBuilder(); final Map&lt;String, String&gt; tags = new HashMap&lt;String, String&gt;(); boolean first = true; for (MetricName part : parts) { final String name = part.getKey(); if (name != null &amp;&amp; !name.isEmpty()) { if (first) { first = false; } else { nameBuilder.append(SEPARATOR); } nameBuilder.append(name); } if (!part.getTags().isEmpty()) tags.putAll(part.getTags()); } return new MetricName(nameBuilder.toString(), tags); } /** * Build a new metric name using the specific path components. * * @param parts Path of the new metric name. * @return A newly created metric name with the specified path. **/ public static MetricName build(String... parts) { if (parts == null || parts.length == 0) return MetricName.EMPTY; if (parts.length == 1) return new MetricName(parts[0], EMPTY_TAGS); return new MetricName(buildName(parts), EMPTY_TAGS); } private static String buildName(String... names) { final StringBuilder builder = new StringBuilder(); boolean first = true; for (String name : names) { if (name == null || name.isEmpty()) continue; if (first) { first = false; } else { builder.append(SEPARATOR); } builder.append(name); } return builder.toString(); } @Override public String toString() { if (tags.isEmpty()) { return key; //return key + \"{}\"; } return key + tags; } @Override public int hashCode() { final int prime = 31; int result = 1; result = prime * result + ((key == null) ? 0 : key.hashCode()); result = prime * result + ((tags == null) ? 0 : tags.hashCode()); return result; } @Override public boolean equals(Object obj) { if (this == obj) return true; if (obj == null) return false; if (getClass() != obj.getClass()) return false; MetricName other = (MetricName) obj; if (key == null) { if (other.key != null) return false; } else if (!key.equals(other.key)) return false; if (!tags.equals(other.tags)) return false; return true; } @Override public int compareTo(MetricName o) { if (o == null) return -1; int c = compareName(key, o.getKey()); if (c != 0) return c; return compareTags(tags, o.getTags()); } private int compareName(String left, String right) { if (left == null &amp;&amp; right == null) return 0; if (left == null) return 1; if (right == null) return -1; return left.compareTo(right); } private int compareTags(Map&lt;String, String&gt; left, Map&lt;String, String&gt; right) { if (left == null &amp;&amp; right == null) return 0; if (left == null) return 1; if (right == null) return -1; final Iterable&lt;String&gt; keys = uniqueSortedKeys(left, right); for (final String key : keys) { final String a = left.get(key); final String b = right.get(key); if (a == null &amp;&amp; b == null) continue; if (a == null) return -1; if (b == null) return 1; int c = a.compareTo(b); if (c != 0) return c; } return 0; } private Iterable&lt;String&gt; uniqueSortedKeys(Map&lt;String, String&gt; left, Map&lt;String, String&gt; right) { final Set&lt;String&gt; set = new TreeSet&lt;String&gt;(left.keySet()); set.addAll(right.keySet()); return set; }} MetricRegistry.java注册MetricRegistry，构建简单metric类型对象，创建和获取counter,histogram,meter,timer监测的数据。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553package io.dropwizard.metrics;import io.dropwizard.metrics.Counter;import io.dropwizard.metrics.ExponentiallyDecayingReservoir;import io.dropwizard.metrics.Gauge;import io.dropwizard.metrics.Histogram;import io.dropwizard.metrics.Meter;import io.dropwizard.metrics.Metric;import io.dropwizard.metrics.MetricFilter;import io.dropwizard.metrics.MetricRegistry;import io.dropwizard.metrics.MetricRegistryListener;import io.dropwizard.metrics.MetricSet;import io.dropwizard.metrics.Timer;import java.util.*;import java.util.concurrent.ConcurrentHashMap;import java.util.concurrent.ConcurrentMap;import java.util.concurrent.CopyOnWriteArrayList;/** * A registry of metric instances. * * 监测实例：新增监测对象，监测分类 * */public class MetricRegistry implements MetricSet { /** * @see #name(String, String...) * 名字 */ public static MetricName name(Class&lt;?&gt; klass, String... names) { return name(klass.getName(), names); } /** * Shorthand method for backwards compatibility in creating metric names. * * Uses {@link MetricName#build(String...)} for its * heavy lifting. * * @see MetricName#build(String...) * @param name The first element of the name * @param names The remaining elements of the name * @return A metric name matching the specified components. */ public static MetricName name(String name, String... names) { final int length; if (names == null) { length = 0; } else { length = names.length; } final String[] parts = new String[length + 1]; parts[0] = name; for (int i = 0; i &lt; length; i++) { parts[i+1] = names[i]; } return MetricName.build(parts); } //监测tag名字，监测实现类 private final ConcurrentMap&lt;MetricName, Metric&gt; metrics; //监听对象列表 private final List&lt;MetricRegistryListener&gt; listeners; /** * Creates a new {@link MetricRegistry}. */ public MetricRegistry() { this(new ConcurrentHashMap&lt;MetricName, Metric&gt;()); } /** * Creates a {@link MetricRegistry} with a custom {@link ConcurrentMap} implementation for use * inside the registry. Call as the super-constructor to create a {@link MetricRegistry} with * space- or time-bounded metric lifecycles, for example. */ protected MetricRegistry(ConcurrentMap&lt;MetricName, Metric&gt; metricsMap) { this.metrics = metricsMap; this.listeners = new CopyOnWriteArrayList&lt;MetricRegistryListener&gt;(); } /** * @see #register(MetricName, Metric) */ @SuppressWarnings(\"unchecked\") public &lt;T extends Metric&gt; T register(String name, T metric) throws IllegalArgumentException { return register(MetricName.build(name), metric); } /** * Given a {@link Metric}, registers it under the given name. * 注册 * * @param name the name of the metric * @param metric the metric * @param &lt;T&gt; the type of the metric * @return {@code metric} * @throws IllegalArgumentException if the name is already registered */ @SuppressWarnings(\"unchecked\") public &lt;T extends Metric&gt; T register(MetricName name, T metric) throws IllegalArgumentException { //注册metric列表 if (metric instanceof MetricSet) { registerAll(name, (MetricSet) metric); } else { //存在metric final Metric existing = metrics.putIfAbsent(name, metric); if (existing == null) { onMetricAdded(name, metric); } else { throw new IllegalArgumentException(\"A metric named \" + name + \" already exists\"); } } return metric; } /** * Given a metric set, registers them. * * @param metrics a set of metrics * @throws IllegalArgumentException if any of the names are already registered */ public void registerAll(MetricSet metrics) throws IllegalArgumentException { registerAll(null, metrics); } /** * @see #counter(MetricName) */ public Counter counter(String name) { return counter(MetricName.build(name)); } /** * Return the {@link Counter} registered under this name; or create and register * a new {@link Counter} if none is registered. * * @param name the name of the metric * @return a new or pre-existing {@link Counter} */ public Counter counter(MetricName name) { return getOrAdd(name, MetricBuilder.COUNTERS); } /** * @see #histogram(MetricName) */ public Histogram histogram(String name) { return histogram(MetricName.build(name)); } /** * Return the {@link Histogram} registered under this name; or create and register * a new {@link Histogram} if none is registered. * * @param name the name of the metric * @return a new or pre-existing {@link Histogram} */ public Histogram histogram(MetricName name) { return getOrAdd(name, MetricBuilder.HISTOGRAMS); } /** * @see #meter(MetricName) */ public Meter meter(String name) { return meter(MetricName.build(name)); } /** * Return the {@link Meter} registered under this name; or create and register * a new {@link Meter} if none is registered. * * @param name the name of the metric * @return a new or pre-existing {@link Meter} */ public Meter meter(MetricName name) { return getOrAdd(name, MetricBuilder.METERS); } /** * @see #timer(MetricName) */ public Timer timer(String name) { return timer(MetricName.build(name)); } /** * Return the {@link Timer} registered under this name; or create and register * a new {@link Timer} if none is registered. * * @param name the name of the metric * @return a new or pre-existing {@link Timer} */ public Timer timer(MetricName name) { return getOrAdd(name, MetricBuilder.TIMERS); } /** * Removes the metric with the given name. * * @param name the name of the metric * @return whether or not the metric was removed */ public boolean remove(MetricName name) { final Metric metric = metrics.remove(name); if (metric != null) { onMetricRemoved(name, metric); return true; } return false; } /** * Removes all metrics which match the given filter. * * @param filter a filter * @return whether or not a metric was removed */ public boolean removeMatching(MetricFilter filter) { boolean removed = false; for (Map.Entry&lt;MetricName, Metric&gt; entry : metrics.entrySet()) { if (filter.matches(entry.getKey(), entry.getValue())) { removed |= remove(entry.getKey()); } } return removed; } /** * Adds a {@link MetricRegistryListener} to a collection of listeners that will be notified on * metric creation. Listeners will be notified in the order in which they are added. * &lt;p/&gt; * &lt;b&gt;N.B.:&lt;/b&gt; The listener will be notified of all existing metrics when it first registers. * * @param listener the listener that will be notified */ public void addListener(MetricRegistryListener listener) { listeners.add(listener); for (Map.Entry&lt;MetricName, Metric&gt; entry : metrics.entrySet()) { notifyListenerOfAddedMetric(listener, entry.getValue(), entry.getKey()); } } /** * Removes a {@link MetricRegistryListener} from this registry's collection of listeners. * * @param listener the listener that will be removed */ public void removeListener(MetricRegistryListener listener) { listeners.remove(listener); } /** * Returns a set of the names of all the metrics in the registry. * * @return the names of all the metrics */ public SortedSet&lt;MetricName&gt; getNames() { return Collections.unmodifiableSortedSet(new TreeSet&lt;MetricName&gt;(metrics.keySet())); } /** * Returns a map of all the gauges in the registry and their names. * * @return all the gauges in the registry */ public SortedMap&lt;MetricName, Gauge&gt; getGauges() { return getGauges(MetricFilter.ALL); } /** * Returns a map of all the gauges in the registry and their names which match the given filter. * * @param filter the metric filter to match * @return all the gauges in the registry */ public SortedMap&lt;MetricName, Gauge&gt; getGauges(MetricFilter filter) { return getMetrics(Gauge.class, filter); } /** * Returns a map of all the counters in the registry and their names. * * @return all the counters in the registry */ public SortedMap&lt;MetricName, Counter&gt; getCounters() { return getCounters(MetricFilter.ALL); } /** * Returns a map of all the counters in the registry and their names which match the given * filter. * * @param filter the metric filter to match * @return all the counters in the registry */ public SortedMap&lt;MetricName, Counter&gt; getCounters(MetricFilter filter) { return getMetrics(Counter.class, filter); } /** * Returns a map of all the histograms in the registry and their names. * * @return all the histograms in the registry */ public SortedMap&lt;MetricName, Histogram&gt; getHistograms() { return getHistograms(MetricFilter.ALL); } /** * Returns a map of all the histograms in the registry and their names which match the given * filter. * * @param filter the metric filter to match * @return all the histograms in the registry */ public SortedMap&lt;MetricName, Histogram&gt; getHistograms(MetricFilter filter) { return getMetrics(Histogram.class, filter); } /** * Returns a map of all the meters in the registry and their names. * * @return all the meters in the registry */ public SortedMap&lt;MetricName, Meter&gt; getMeters() { return getMeters(MetricFilter.ALL); } /** * Returns a map of all the meters in the registry and their names which match the given filter. * * @param filter the metric filter to match * @return all the meters in the registry */ public SortedMap&lt;MetricName, Meter&gt; getMeters(MetricFilter filter) { return getMetrics(Meter.class, filter); } /** * Returns a map of all the timers in the registry and their names. * * @return all the timers in the registry */ public SortedMap&lt;MetricName, Timer&gt; getTimers() { return getTimers(MetricFilter.ALL); } /** * Returns a map of all the timers in the registry and their names which match the given filter. * * @param filter the metric filter to match * @return all the timers in the registry */ public SortedMap&lt;MetricName, Timer&gt; getTimers(MetricFilter filter) { return getMetrics(Timer.class, filter); } /** * 获取metric，如果没有metric，则新增 * @param name * @param builder * @param &lt;T&gt; * @return */ @SuppressWarnings(\"unchecked\") private &lt;T extends Metric&gt; T getOrAdd(MetricName name, MetricBuilder&lt;T&gt; builder) { final Metric metric = metrics.get(name); if (builder.isInstance(metric)) { return (T) metric; } else if (metric == null) { try { return register(name, builder.newMetric()); } catch (IllegalArgumentException e) { final Metric added = metrics.get(name); if (builder.isInstance(added)) { return (T) added; } } } throw new IllegalArgumentException(name + \" is already used for a different type of metric\"); } @SuppressWarnings(\"unchecked\") private &lt;T extends Metric&gt; SortedMap&lt;MetricName, T&gt; getMetrics(Class&lt;T&gt; klass, MetricFilter filter) { final TreeMap&lt;MetricName, T&gt; timers = new TreeMap&lt;MetricName, T&gt;(); for (Map.Entry&lt;MetricName, Metric&gt; entry : metrics.entrySet()) { if (klass.isInstance(entry.getValue()) &amp;&amp; filter.matches(entry.getKey(), entry.getValue())) { timers.put(entry.getKey(), (T) entry.getValue()); } } return Collections.unmodifiableSortedMap(timers); } /** * 新增metric * @param name * @param metric */ private void onMetricAdded(MetricName name, Metric metric) { for (MetricRegistryListener listener : listeners) { notifyListenerOfAddedMetric(listener, metric, name); } } /** * 根据类型新增metric * @param listener * @param metric * @param name */ private void notifyListenerOfAddedMetric(MetricRegistryListener listener, Metric metric, MetricName name) { if (metric instanceof Gauge) { listener.onGaugeAdded(name, (Gauge&lt;?&gt;) metric); } else if (metric instanceof Counter) { listener.onCounterAdded(name, (Counter) metric); } else if (metric instanceof Histogram) { listener.onHistogramAdded(name, (Histogram) metric); } else if (metric instanceof Meter) { listener.onMeterAdded(name, (Meter) metric); } else if (metric instanceof Timer) { listener.onTimerAdded(name, (Timer) metric); } else { throw new IllegalArgumentException(\"Unknown metric type: \" + metric.getClass()); } } /** * 删除 * @param name * @param metric */ private void onMetricRemoved(MetricName name, Metric metric) { for (MetricRegistryListener listener : listeners) { notifyListenerOfRemovedMetric(name, metric, listener); } } private void notifyListenerOfRemovedMetric(MetricName name, Metric metric, MetricRegistryListener listener) { if (metric instanceof Gauge) { listener.onGaugeRemoved(name); } else if (metric instanceof Counter) { listener.onCounterRemoved(name); } else if (metric instanceof Histogram) { listener.onHistogramRemoved(name); } else if (metric instanceof Meter) { listener.onMeterRemoved(name); } else if (metric instanceof Timer) { listener.onTimerRemoved(name); } else { throw new IllegalArgumentException(\"Unknown metric type: \" + metric.getClass()); } } /** * 注册metric列表 * @param prefix * @param metrics * @throws IllegalArgumentException */ private void registerAll(MetricName prefix, MetricSet metrics) throws IllegalArgumentException { if (prefix == null) prefix = MetricName.EMPTY; for (Map.Entry&lt;MetricName, Metric&gt; entry : metrics.getMetrics().entrySet()) { if (entry.getValue() instanceof MetricSet) { registerAll(MetricName.join(prefix, entry.getKey()), (MetricSet) entry.getValue()); } else { register(MetricName.join(prefix, entry.getKey()), entry.getValue()); } } } /** * 返回metricsMap，一个不能修改的map * @return */ @Override public Map&lt;MetricName, Metric&gt; getMetrics() { return Collections.unmodifiableMap(metrics); } /** * A quick and easy way of capturing the notion of default metrics. * 简单快速自定义接口 * 实现不同metric类型 * */ private interface MetricBuilder&lt;T extends Metric&gt; { //counters MetricBuilder&lt;Counter&gt; COUNTERS = new MetricBuilder&lt;Counter&gt;() { @Override public Counter newMetric() { return new Counter(); } @Override public boolean isInstance(Metric metric) { return Counter.class.isInstance(metric); } }; //histograms MetricBuilder&lt;Histogram&gt; HISTOGRAMS = new MetricBuilder&lt;Histogram&gt;() { @Override public Histogram newMetric() { return new Histogram(new ExponentiallyDecayingReservoir()); } @Override public boolean isInstance(Metric metric) { return Histogram.class.isInstance(metric); } }; //meters MetricBuilder&lt;Meter&gt; METERS = new MetricBuilder&lt;Meter&gt;() { @Override public Meter newMetric() { return new Meter(); } @Override public boolean isInstance(Metric metric) { return Meter.class.isInstance(metric); } }; //timers MetricBuilder&lt;Timer&gt; TIMERS = new MetricBuilder&lt;Timer&gt;() { @Override public Timer newMetric() { return new Timer(); } @Override public boolean isInstance(Metric metric) { return Timer.class.isInstance(metric); } }; T newMetric(); boolean isInstance(Metric metric); }} Snapshot.java输出数据到流中123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124package io.dropwizard.metrics;import java.io.OutputStream;/** * A statistical snapshot of a {@link Snapshot}. * * 统计快照 * */public abstract class Snapshot { /** * Returns the value at the given quantile. * * @param quantile a given quantile, in {@code [0..1]} * @return the value in the distribution at {@code quantile} */ public abstract double getValue(double quantile); /** * Returns the entire set of values in the snapshot. * * @return the entire set of values */ public abstract long[] getValues(); /** * Returns the number of values in the snapshot. * * @return the number of values */ public abstract int size(); /** * Returns the median value in the distribution. * * @return the median value */ public double getMedian() { return getValue(0.5); } /** * Returns the value at the 75th percentile in the distribution. * * @return the value at the 75th percentile */ public double get75thPercentile() { return getValue(0.75); } /** * Returns the value at the 95th percentile in the distribution. * * @return the value at the 95th percentile */ public double get95thPercentile() { return getValue(0.95); } /** * Returns the value at the 98th percentile in the distribution. * * @return the value at the 98th percentile */ public double get98thPercentile() { return getValue(0.98); } /** * Returns the value at the 99th percentile in the distribution. * * @return the value at the 99th percentile */ public double get99thPercentile() { return getValue(0.99); } /** * Returns the value at the 99.9th percentile in the distribution. * * @return the value at the 99.9th percentile */ public double get999thPercentile() { return getValue(0.999); } /** * Returns the highest value in the snapshot. * * @return the highest value */ public abstract long getMax(); /** * Returns the arithmetic mean of the values in the snapshot. * * @return the arithmetic mean */ public abstract double getMean(); /** * Returns the lowest value in the snapshot. * * @return the lowest value */ public abstract long getMin(); /** * Returns the standard deviation of the values in the snapshot. * * @return the standard value */ public abstract double getStdDev(); /** * Writes the values of the snapshot to the given stream. * * @param output an output stream */ public abstract void dump(OutputStream output);} InstrumentedExecutors.java调用：InstrumentedExecutorService，InstrumentedScheduledExecutorService123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565package io.dropwizard.metrics;import java.util.concurrent.ExecutorService;import java.util.concurrent.Executors;import java.util.concurrent.ThreadFactory;import java.util.concurrent.ThreadPoolExecutor;/** * Factory and utility methods for {@link InstrumentedExecutorService}, * {@link InstrumentedScheduledExecutorService}, and {@link InstrumentedThreadFactory} * classes defined in this package. This class supports the following kinds of methods: * &lt;p&gt; * &lt;ul&gt; * &lt;li&gt; Methods that create and return an {@link InstrumentedExecutorService} * set up with commonly useful configuration settings. * &lt;li&gt; Methods that create and return a {@link InstrumentedScheduledExecutorService} * set up with commonly useful configuration settings. * &lt;li&gt; Methods that create and return a \"wrapped\" ExecutorService, that * disables reconfiguration by making implementation-specific methods * inaccessible. * &lt;li&gt; Methods that create and return a {@link InstrumentedThreadFactory} * that sets newly created threads to a known state. * &lt;/ul&gt; * &lt;/p&gt; * * @see java.util.concurrent.Executors *///线程执行服务//创建线程池执行：newFixedThreadPool，newSingleThreadExecutor，newCachedThreadPool，newScheduledThreadPoolpublic final class InstrumentedExecutors { /** * Creates an instrumented thread pool that reuses a fixed number of threads * operating off a shared unbounded queue. At any point, at most * {@code nThreads} threads will be active processing tasks. * If additional tasks are submitted when all threads are active, * they will wait in the queue until a thread is available. * If any thread terminates due to a failure during execution * prior to shutdown, a new one will take its place if needed to * execute subsequent tasks. The threads in the pool will exist * until it is explicitly {@link ExecutorService#shutdown shutdown}. * * @param nThreads the number of threads in the pool * 创建线程池 * @param registry the {@link MetricRegistry} that will contain the metrics. * @param name the (metrics) name for this executor service, see {@link MetricRegistry#name(String, String...)}. * @return the newly created thread pool * @throws IllegalArgumentException if {@code nThreads &lt;= 0} * @see Executors#newFixedThreadPool(int) */ public static InstrumentedExecutorService newFixedThreadPool(int nThreads, MetricRegistry registry, String name) { return new InstrumentedExecutorService(Executors.newFixedThreadPool(nThreads), registry, name); } /** * Creates an instrumented thread pool that reuses a fixed number of threads * operating off a shared unbounded queue. At any point, at most * {@code nThreads} threads will be active processing tasks. * If additional tasks are submitted when all threads are active, * they will wait in the queue until a thread is available. * If any thread terminates due to a failure during execution * prior to shutdown, a new one will take its place if needed to * execute subsequent tasks. The threads in the pool will exist * until it is explicitly {@link java.util.concurrent.ExecutorService#shutdown shutdown}. * * @param nThreads the number of threads in the pool * @param registry the {@link MetricRegistry} that will contain the metrics. * @return the newly created thread pool * @throws IllegalArgumentException if {@code nThreads &lt;= 0} * @see Executors#newFixedThreadPool(int) */ public static InstrumentedExecutorService newFixedThreadPool(int nThreads, MetricRegistry registry) { return new InstrumentedExecutorService(Executors.newFixedThreadPool(nThreads), registry); } /** * Creates an instrumented thread pool that reuses a fixed number of threads * operating off a shared unbounded queue, using the provided * ThreadFactory to create new threads when needed. At any point, * at most {@code nThreads} threads will be active processing * tasks. If additional tasks are submitted when all threads are * active, they will wait in the queue until a thread is * available. If any thread terminates due to a failure during * execution prior to shutdown, a new one will take its place if * needed to execute subsequent tasks. The threads in the pool will * exist until it is explicitly {@link ExecutorService#shutdown shutdown}. * * @param nThreads the number of threads in the pool * @param threadFactory the factory to use when creating new threads * @param registry the {@link MetricRegistry} that will contain the metrics. * @param name the (metrics) name for this executor service, see {@link MetricRegistry#name(String, String...)}. * @return the newly created thread pool * @throws NullPointerException if threadFactory is null * @throws IllegalArgumentException if {@code nThreads &lt;= 0} * @see Executors#newFixedThreadPool(int, ThreadFactory) */ public static InstrumentedExecutorService newFixedThreadPool(int nThreads, ThreadFactory threadFactory, MetricRegistry registry, String name) { return new InstrumentedExecutorService(Executors.newFixedThreadPool(nThreads, threadFactory), registry, name); } /** * Creates a thread pool that reuses a fixed number of threads * operating off a shared unbounded queue, using the provided * ThreadFactory to create new threads when needed. At any point, * at most {@code nThreads} threads will be active processing * tasks. If additional tasks are submitted when all threads are * active, they will wait in the queue until a thread is * available. If any thread terminates due to a failure during * execution prior to shutdown, a new one will take its place if * needed to execute subsequent tasks. The threads in the pool will * exist until it is explicitly {@link ExecutorService#shutdown * shutdown}. * * @param nThreads the number of threads in the pool * @param threadFactory the factory to use when creating new threads * @param registry the {@link MetricRegistry} that will contain the metrics. * @return the newly created thread pool * @throws NullPointerException if threadFactory is null * @throws IllegalArgumentException if {@code nThreads &lt;= 0} * @see Executors#newFixedThreadPool(int, ThreadFactory) */ public static InstrumentedExecutorService newFixedThreadPool(int nThreads, ThreadFactory threadFactory, MetricRegistry registry) { return new InstrumentedExecutorService(Executors.newFixedThreadPool(nThreads, threadFactory), registry); } /** * Creates an InstrumentedExecutor that uses a single worker thread operating * off an unbounded queue. (Note however that if this single * thread terminates due to a failure during execution prior to * shutdown, a new one will take its place if needed to execute * subsequent tasks.) Tasks are guaranteed to execute * sequentially, and no more than one task will be active at any * given time. Unlike the otherwise equivalent * {@code newFixedThreadPool(1)} the returned executor is * guaranteed not to be reconfigurable to use additional threads. * * @param registry the {@link MetricRegistry} that will contain the metrics. * @param name the (metrics) name for this executor service, see {@link MetricRegistry#name(String, String...)}. * @return the newly created single-threaded Executor * @see Executors#newSingleThreadExecutor() */ public static InstrumentedExecutorService newSingleThreadExecutor(MetricRegistry registry, String name) { //单线程 - uses a single worker thread operating return new InstrumentedExecutorService(Executors.newSingleThreadExecutor(), registry, name); } /** * Creates an Executor that uses a single worker thread operating * off an unbounded queue. (Note however that if this single * thread terminates due to a failure during execution prior to * shutdown, a new one will take its place if needed to execute * subsequent tasks.) Tasks are guaranteed to execute * sequentially, and no more than one task will be active at any * given time. Unlike the otherwise equivalent * {@code newFixedThreadPool(1)} the returned executor is * guaranteed not to be reconfigurable to use additional threads. * * @param registry the {@link MetricRegistry} that will contain the metrics. * @return the newly created single-threaded Executor * @see Executors#newSingleThreadExecutor() */ public static InstrumentedExecutorService newSingleThreadExecutor(MetricRegistry registry) { return new InstrumentedExecutorService(Executors.newSingleThreadExecutor(), registry); } /** * Creates an InstrumentedExecutor that uses a single worker thread operating * off an unbounded queue, and uses the provided ThreadFactory to * create a new thread when needed. Unlike the otherwise * equivalent {@code newFixedThreadPool(1, threadFactory)} the * returned executor is guaranteed not to be reconfigurable to use * additional threads. * * @param threadFactory the factory to use when creating new threads * @param registry the {@link MetricRegistry} that will contain the metrics. * @param name the (metrics) name for this executor service, see {@link MetricRegistry#name(String, String...)}. * @return the newly created single-threaded Executor * @throws NullPointerException if threadFactory is null * @see Executors#newSingleThreadExecutor(ThreadFactory) */ public static InstrumentedExecutorService newSingleThreadExecutor(ThreadFactory threadFactory, MetricRegistry registry, String name) { return new InstrumentedExecutorService(Executors.newSingleThreadExecutor(threadFactory), registry, name); } /** * Creates an InstrumentedExecutor that uses a single worker thread operating * off an unbounded queue, and uses the provided ThreadFactory to * create a new thread when needed. Unlike the otherwise * equivalent {@code newFixedThreadPool(1, threadFactory)} the * returned executor is guaranteed not to be reconfigurable to use * additional threads. * * @param threadFactory the factory to use when creating new threads * @param registry the {@link MetricRegistry} that will contain the metrics. * @return the newly created single-threaded Executor * @throws NullPointerException if threadFactory is null * @see Executors#newSingleThreadExecutor(ThreadFactory) */ public static InstrumentedExecutorService newSingleThreadExecutor(ThreadFactory threadFactory, MetricRegistry registry) { return new InstrumentedExecutorService(Executors.newSingleThreadExecutor(threadFactory), registry); } /** * Creates an instrumented thread pool that creates new threads as needed, but * will reuse previously constructed threads when they are * available. These pools will typically improve the performance * of programs that execute many short-lived asynchronous tasks. * Calls to {@code execute} will reuse previously constructed * threads if available. If no existing thread is available, a new * thread will be created and added to the pool. Threads that have * not been used for sixty seconds are terminated and removed from * the cache. Thus, a pool that remains idle for long enough will * not consume any resources. Note that pools with similar * properties but different details (for example, timeout parameters) * may be created using {@link ThreadPoolExecutor} constructors. * * @param registry the {@link MetricRegistry} that will contain the metrics. * @param name the (metrics) name for this executor service, see {@link MetricRegistry#name(String, String...)}. * @return the newly created thread pool * @see Executors#newCachedThreadPool() */ public static InstrumentedExecutorService newCachedThreadPool(MetricRegistry registry, String name) { return new InstrumentedExecutorService(Executors.newCachedThreadPool(), registry, name); } /** * Creates an instrumented thread pool that creates new threads as needed, but * will reuse previously constructed threads when they are * available. These pools will typically improve the performance * of programs that execute many short-lived asynchronous tasks. * Calls to {@code execute} will reuse previously constructed * threads if available. If no existing thread is available, a new * thread will be created and added to the pool. Threads that have * not been used for sixty seconds are terminated and removed from * the cache. Thus, a pool that remains idle for long enough will * not consume any resources. Note that pools with similar * properties but different details (for example, timeout parameters) * may be created using {@link ThreadPoolExecutor} constructors. * * @param registry the {@link MetricRegistry} that will contain the metrics. * @return the newly created thread pool * @see Executors#newCachedThreadPool() */ public static InstrumentedExecutorService newCachedThreadPool(MetricRegistry registry) { return new InstrumentedExecutorService(Executors.newCachedThreadPool(), registry); } /** * Creates an instrumented thread pool that creates new threads as needed, but * will reuse previously constructed threads when they are * available, and uses the provided * ThreadFactory to create new threads when needed. * * @param threadFactory the factory to use when creating new threads * @param registry the {@link MetricRegistry} that will contain the metrics. * @param name the (metrics) name for this executor service, see {@link MetricRegistry#name(String, String...)}. * @return the newly created thread pool * @throws NullPointerException if threadFactory is null * @see Executors#newCachedThreadPool(ThreadFactory) */ public static InstrumentedExecutorService newCachedThreadPool(ThreadFactory threadFactory, MetricRegistry registry, String name) { return new InstrumentedExecutorService(Executors.newCachedThreadPool(threadFactory), registry, name); } /** * Creates an instrumented thread pool that creates new threads as needed, but * will reuse previously constructed threads when they are * available, and uses the provided * ThreadFactory to create new threads when needed. * * @param threadFactory the factory to use when creating new threads * @param registry the {@link MetricRegistry} that will contain the metrics. * @return the newly created thread pool * @throws NullPointerException if threadFactory is null * @see Executors#newCachedThreadPool(ThreadFactory) */ public static InstrumentedExecutorService newCachedThreadPool(ThreadFactory threadFactory, MetricRegistry registry) { return new InstrumentedExecutorService(Executors.newCachedThreadPool(threadFactory), registry); } /** * Creates a single-threaded instrumented executor that can schedule commands * to run after a given delay, or to execute periodically. * (Note however that if this single * thread terminates due to a failure during execution prior to * shutdown, a new one will take its place if needed to execute * subsequent tasks.) Tasks are guaranteed to execute * sequentially, and no more than one task will be active at any * given time. Unlike the otherwise equivalent * {@code newScheduledThreadPool(1)} the returned executor is * guaranteed not to be reconfigurable to use additional threads. * * @param registry the {@link MetricRegistry} that will contain the metrics. * @param name the (metrics) name for this executor service, see {@link MetricRegistry#name(String, String...)}. * @return the newly created scheduled executor * @see Executors#newSingleThreadScheduledExecutor() */ public static InstrumentedScheduledExecutorService newSingleThreadScheduledExecutor(MetricRegistry registry, String name) { return new InstrumentedScheduledExecutorService(Executors.newSingleThreadScheduledExecutor(), registry, name); } /** * Creates a single-threaded instrumented executor that can schedule commands * to run after a given delay, or to execute periodically. * (Note however that if this single * thread terminates due to a failure during execution prior to * shutdown, a new one will take its place if needed to execute * subsequent tasks.) Tasks are guaranteed to execute * sequentially, and no more than one task will be active at any * given time. Unlike the otherwise equivalent * {@code newScheduledThreadPool(1)} the returned executor is * guaranteed not to be reconfigurable to use additional threads. * * @param registry the {@link MetricRegistry} that will contain the metrics. * @return the newly created scheduled executor * @see Executors#newSingleThreadScheduledExecutor() */ public static InstrumentedScheduledExecutorService newSingleThreadScheduledExecutor(MetricRegistry registry) { return new InstrumentedScheduledExecutorService(Executors.newSingleThreadScheduledExecutor(), registry); } /** * Creates a single-threaded instrumented executor that can schedule commands * to run after a given delay, or to execute periodically. (Note * however that if this single thread terminates due to a failure * during execution prior to shutdown, a new one will take its * place if needed to execute subsequent tasks.) Tasks are * guaranteed to execute sequentially, and no more than one task * will be active at any given time. Unlike the otherwise * equivalent {@code newScheduledThreadPool(1, threadFactory)} * the returned executor is guaranteed not to be reconfigurable to * use additional threads. * * @param threadFactory the factory to use when creating new threads * @param registry the {@link MetricRegistry} that will contain the metrics. * @param name the (metrics) name for this executor service, see {@link MetricRegistry#name(String, String...)}. * @return a newly created scheduled executor * @throws NullPointerException if threadFactory is null * @see Executors#newSingleThreadExecutor(ThreadFactory) */ public static InstrumentedScheduledExecutorService newSingleThreadScheduledExecutor(ThreadFactory threadFactory, MetricRegistry registry, String name) { return new InstrumentedScheduledExecutorService(Executors.newSingleThreadScheduledExecutor(threadFactory), registry, name); } /** * Creates a single-threaded instrumented executor that can schedule commands * to run after a given delay, or to execute periodically. (Note * however that if this single thread terminates due to a failure * during execution prior to shutdown, a new one will take its * place if needed to execute subsequent tasks.) Tasks are * guaranteed to execute sequentially, and no more than one task * will be active at any given time. Unlike the otherwise * equivalent {@code newScheduledThreadPool(1, threadFactory)} * the returned executor is guaranteed not to be reconfigurable to * use additional threads. * * @param threadFactory the factory to use when creating new threads * @param registry the {@link MetricRegistry} that will contain the metrics. * @return a newly created scheduled executor * @throws NullPointerException if threadFactory is null * @see Executors#newSingleThreadExecutor(ThreadFactory) */ public static InstrumentedScheduledExecutorService newSingleThreadScheduledExecutor(ThreadFactory threadFactory, MetricRegistry registry) { return new InstrumentedScheduledExecutorService(Executors.newSingleThreadScheduledExecutor(threadFactory), registry); } /** * Creates an instrumented thread pool that can schedule commands to run after a * given delay, or to execute periodically. * * @param corePoolSize the number of threads to keep in the pool, * even if they are idle * @param registry the {@link MetricRegistry} that will contain the metrics. * @param name the (metrics) name for this executor service, see {@link MetricRegistry#name(String, String...)}. * @return a newly created scheduled thread pool * @throws IllegalArgumentException if {@code corePoolSize &lt; 0} * @see Executors#newScheduledThreadPool(int) */ public static InstrumentedScheduledExecutorService newScheduledThreadPool(int corePoolSize, MetricRegistry registry, String name) { return new InstrumentedScheduledExecutorService(Executors.newScheduledThreadPool(corePoolSize), registry, name); } /** * Creates an instrumented thread pool that can schedule commands to run after a * given delay, or to execute periodically. * * @param corePoolSize the number of threads to keep in the pool, * even if they are idle * @param registry the {@link MetricRegistry} that will contain the metrics. * @return a newly created scheduled thread pool * @throws IllegalArgumentException if {@code corePoolSize &lt; 0} * @see Executors#newScheduledThreadPool(int) */ public static InstrumentedScheduledExecutorService newScheduledThreadPool(int corePoolSize, MetricRegistry registry) { return new InstrumentedScheduledExecutorService(Executors.newScheduledThreadPool(corePoolSize), registry); } /** * Creates an instrumented thread pool that can schedule commands to run after a * given delay, or to execute periodically. * * @param corePoolSize the number of threads to keep in the pool, * even if they are idle * @param threadFactory the factory to use when the executor * creates a new thread * @param registry the {@link MetricRegistry} that will contain the metrics. * @param name the (metrics) name for this executor service, see {@link MetricRegistry#name(String, String...)}. * @return a newly created scheduled thread pool * @throws IllegalArgumentException if {@code corePoolSize &lt; 0} * @throws NullPointerException if threadFactory is null * @see Executors#newScheduledThreadPool(int, ThreadFactory) */ public static InstrumentedScheduledExecutorService newScheduledThreadPool(int corePoolSize, ThreadFactory threadFactory, MetricRegistry registry, String name) { return new InstrumentedScheduledExecutorService(Executors.newScheduledThreadPool(corePoolSize, threadFactory), registry, name); } /** * Creates an instrumented thread pool that can schedule commands to run after a * given delay, or to execute periodically. * * @param corePoolSize the number of threads to keep in the pool, even if they are idle * @param threadFactory the factory to use when the executor creates a new thread * @param registry the {@link MetricRegistry} that will contain the metrics. * @return a newly created scheduled thread pool * @throws IllegalArgumentException if {@code corePoolSize &lt; 0} * @throws NullPointerException if threadFactory is null * @see Executors#newScheduledThreadPool(int, ThreadFactory) */ public static InstrumentedScheduledExecutorService newScheduledThreadPool(int corePoolSize, ThreadFactory threadFactory, MetricRegistry registry) { return new InstrumentedScheduledExecutorService(Executors.newScheduledThreadPool(corePoolSize, threadFactory), registry); } /** * Returns an instrumented default thread factory used to create new threads. * This factory creates all new threads used by an Executor in the * same {@link ThreadGroup}. If there is a {@link * java.lang.SecurityManager}, it uses the group of {@link * System#getSecurityManager}, else the group of the thread * invoking this {@code defaultThreadFactory} method. Each new * thread is created as a non-daemon thread with priority set to * the smaller of {@code Thread.NORM_PRIORITY} and the maximum * priority permitted in the thread group. New threads have names * accessible via {@link Thread#getName} of * &lt;em&gt;pool-N-thread-M&lt;/em&gt;, where &lt;em&gt;N&lt;/em&gt; is the sequence * number of this factory, and &lt;em&gt;M&lt;/em&gt; is the sequence number * of the thread created by this factory. * * @param registry the {@link MetricRegistry} that will contain the metrics. * @param name the (metrics) name for this executor service, see {@link MetricRegistry#name(String, String...)}. * @return a thread factory * @see Executors#defaultThreadFactory() */ public static InstrumentedThreadFactory defaultThreadFactory(MetricRegistry registry, String name) { return new InstrumentedThreadFactory(Executors.defaultThreadFactory(), registry, name); } /** * Returns an instrumented default thread factory used to create new threads. * This factory creates all new threads used by an Executor in the * same {@link ThreadGroup}. If there is a {@link * java.lang.SecurityManager}, it uses the group of {@link * System#getSecurityManager}, else the group of the thread * invoking this {@code defaultThreadFactory} method. Each new * thread is created as a non-daemon thread with priority set to * the smaller of {@code Thread.NORM_PRIORITY} and the maximum * priority permitted in the thread group. New threads have names * accessible via {@link Thread#getName} of * &lt;em&gt;pool-N-thread-M&lt;/em&gt;, where &lt;em&gt;N&lt;/em&gt; is the sequence * number of this factory, and &lt;em&gt;M&lt;/em&gt; is the sequence number * of the thread created by this factory. * * @param registry the {@link MetricRegistry} that will contain the metrics. * @return a thread factory * @see Executors#defaultThreadFactory() */ public static InstrumentedThreadFactory defaultThreadFactory(MetricRegistry registry) { return new InstrumentedThreadFactory(Executors.defaultThreadFactory(), registry); } /** * Returns an instrumented thread factory used to create new threads that * have the same permissions as the current thread. * &lt;p&gt; * This factory creates threads with the same settings as {@link * Executors#defaultThreadFactory}, additionally setting the * AccessControlContext and contextClassLoader of new threads to * be the same as the thread invoking this * {@code privilegedThreadFactory} method. A new * {@code privilegedThreadFactory} can be created within an * {@link java.security.AccessController#doPrivileged AccessController.doPrivileged} * action setting the current thread's access control context to * create threads with the selected permission settings holding * within that action. * &lt;/p&gt; * &lt;p&gt;Note that while tasks running within such threads will have * the same access control and class loader settings as the * current thread, they need not have the same {@link * java.lang.ThreadLocal} or {@link * java.lang.InheritableThreadLocal} values. If necessary, * particular values of thread locals can be set or reset before * any task runs in {@link ThreadPoolExecutor} subclasses using * {@link ThreadPoolExecutor#beforeExecute(Thread, Runnable)}. * Also, if it is necessary to initialize worker threads to have * the same InheritableThreadLocal settings as some other * designated thread, you can create a custom ThreadFactory in * which that thread waits for and services requests to create * others that will inherit its values. * * @param registry the {@link MetricRegistry} that will contain the metrics. * @param name the (metrics) name for this executor service, see {@link MetricRegistry#name(String, String...)}. * @return a thread factory * @throws java.security.AccessControlException if the current access control * context does not have permission to both get and set context * class loader * @see Executors#privilegedThreadFactory() */ public static InstrumentedThreadFactory privilegedThreadFactory(MetricRegistry registry, String name) { return new InstrumentedThreadFactory(Executors.privilegedThreadFactory(), registry, name); } /** * Returns an instrumented thread factory used to create new threads that * have the same permissions as the current thread. * &lt;p&gt; * This factory creates threads with the same settings as {@link * Executors#defaultThreadFactory}, additionally setting the * AccessControlContext and contextClassLoader of new threads to * be the same as the thread invoking this * {@code privilegedThreadFactory} method. A new * {@code privilegedThreadFactory} can be created within an * {@link java.security.AccessController#doPrivileged AccessController.doPrivileged} * action setting the current thread's access control context to * create threads with the selected permission settings holding * within that action. * &lt;/p&gt; * &lt;p&gt;Note that while tasks running within such threads will have * the same access control and class loader settings as the * current thread, they need not have the same {@link * java.lang.ThreadLocal} or {@link * java.lang.InheritableThreadLocal} values. If necessary, * particular values of thread locals can be set or reset before * any task runs in {@link ThreadPoolExecutor} subclasses using * {@link ThreadPoolExecutor#beforeExecute(Thread, Runnable)}. * Also, if it is necessary to initialize worker threads to have * the same InheritableThreadLocal settings as some other * designated thread, you can create a custom ThreadFactory in * which that thread waits for and services requests to create * others that will inherit its values. * * @param registry the {@link MetricRegistry} that will contain the metrics. * @return a thread factory * @throws java.security.AccessControlException if the current access control * context does not have permission to both get and set context * class loader * @see Executors#privilegedThreadFactory() */ public static InstrumentedThreadFactory privilegedThreadFactory(MetricRegistry registry) { return new InstrumentedThreadFactory(Executors.privilegedThreadFactory(), registry); } /** * Cannot instantiate. */ private InstrumentedExecutors() { }} InstrumentedThreadFactory.java123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687package io.dropwizard.metrics;import java.util.concurrent.ThreadFactory;import java.util.concurrent.atomic.AtomicLong;/** * A {@link ThreadFactory} that monitors the number of threads created, running and terminated. * &lt;p/&gt; * It will register the metrics using the given (or auto-generated) name as classifier, e.g: * \"your-thread-delegate.created\", \"your-thread-delegate.running\", etc. *///包装ThreadFactorypublic class InstrumentedThreadFactory implements ThreadFactory { private static final AtomicLong nameCounter = new AtomicLong(); private final ThreadFactory delegate; /** * 记录创建时数据 */ private final Meter created; /** * 记录运行时数据 */ private final Counter running; /** * 记录中断时数据 */ private final Meter terminated; /** * Wraps a {@link ThreadFactory}, uses a default auto-generated name. * * @param delegate {@link ThreadFactory} to wrap. * @param registry {@link MetricRegistry} that will contain the metrics. */ public InstrumentedThreadFactory(ThreadFactory delegate, MetricRegistry registry) { this(delegate, registry, \"instrumented-thread-delegate-\" + nameCounter.incrementAndGet()); } /** * Wraps a {@link ThreadFactory} with an explicit name. * * @param delegate {@link ThreadFactory} to wrap. * @param registry {@link MetricRegistry} that will contain the metrics. * @param name name for this delegate. */ public InstrumentedThreadFactory(ThreadFactory delegate, MetricRegistry registry, String name) { this.delegate = delegate; this.created = registry.meter(MetricRegistry.name(name, \"created\")); this.running = registry.counter(MetricRegistry.name(name, \"running\")); this.terminated = registry.meter(MetricRegistry.name(name, \"terminated\")); } /** * {@inheritDoc} * 新建线程 * */ @Override public Thread newThread(Runnable runnable) { Runnable wrappedRunnable = new InstrumentedRunnable(runnable); Thread thread = delegate.newThread(wrappedRunnable); created.mark(); return thread; } //包装runnable private class InstrumentedRunnable implements Runnable { private final Runnable task; InstrumentedRunnable(Runnable task) { this.task = task; } @Override public void run() { running.inc(); try { task.run(); } finally { running.dec(); terminated.mark(); } } }} InstrumentedExecutorService.java123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261package io.dropwizard.metrics;import java.util.ArrayList;import java.util.Collection;import java.util.List;import java.util.concurrent.*;import java.util.concurrent.atomic.AtomicLong;/** * An {@link ExecutorService} that monitors the number of tasks submitted, running, * completed and also keeps a {@link Timer} for the task duration. * &lt;p/&gt; * It will register the metrics using the given (or auto-generated) name as classifier, e.g: * \"your-executor-service.submitted\", \"your-executor-service.running\", etc. *///包装executorService，写入监控对象public class InstrumentedExecutorService implements ExecutorService { //计数 private static final AtomicLong nameCounter = new AtomicLong(); private final ExecutorService delegate; //检测类型的对象 /** * 任务执行次数 */ private final Meter submitted; private final Counter running; private final Meter completed; private final Timer duration; private final Meter rejected; /** * Wraps an {@link ExecutorService} uses an auto-generated default name. * * @param delegate {@link ExecutorService} to wrap. * @param registry {@link MetricRegistry} that will contain the metrics. */ public InstrumentedExecutorService(ExecutorService delegate, MetricRegistry registry) { this(delegate, registry, \"instrumented-delegate-\" + nameCounter.incrementAndGet()); } /** * Wraps an {@link ExecutorService} with an explicit name. * * @param delegate {@link ExecutorService} to wrap. * @param registry {@link MetricRegistry} that will contain the metrics. * @param name name for this executor service. */ public InstrumentedExecutorService(ExecutorService delegate, MetricRegistry registry, String name) { this.delegate = delegate; this.submitted = registry.meter(MetricRegistry.name(name, \"submitted\")); this.running = registry.counter(MetricRegistry.name(name, \"running\")); this.completed = registry.meter(MetricRegistry.name(name, \"completed\")); this.duration = registry.timer(MetricRegistry.name(name, \"duration\")); this.rejected = registry.meter(MetricRegistry.name(name, \"rejected\")); } /** * {@inheritDoc} */ @Override public void execute(Runnable runnable) { submitted.mark(); try { //执行包装任务 delegate.execute(new InstrumentedRunnable(runnable)); } catch (RejectedExecutionException e) { rejected.mark(); throw e; } } /** * {@inheritDoc} */ @Override public Future&lt;?&gt; submit(Runnable runnable) { submitted.mark(); try { return delegate.submit(new InstrumentedRunnable(runnable)); } catch (RejectedExecutionException e) { rejected.mark(); throw e; } } /** * {@inheritDoc} */ @Override public &lt;T&gt; Future&lt;T&gt; submit(Runnable runnable, T result) { submitted.mark(); try { return delegate.submit(new InstrumentedRunnable(runnable), result); } catch (RejectedExecutionException e) { rejected.mark(); throw e; } } /** * {@inheritDoc} */ @Override public &lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task) { submitted.mark(); try { return delegate.submit(new InstrumentedCallable&lt;T&gt;(task)); } catch (RejectedExecutionException e) { rejected.mark(); throw e; } } /** * {@inheritDoc} * 执行所有任务 */ @Override public &lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks) throws InterruptedException { submitted.mark(tasks.size()); Collection&lt;? extends Callable&lt;T&gt;&gt; instrumented = instrument(tasks); try { return delegate.invokeAll(instrumented); } catch (RejectedExecutionException e) { rejected.mark(); throw e; } } /** * {@inheritDoc} */ @Override public &lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, long timeout, TimeUnit unit) throws InterruptedException { submitted.mark(tasks.size()); Collection&lt;? extends Callable&lt;T&gt;&gt; instrumented = instrument(tasks); try { return delegate.invokeAll(instrumented, timeout, unit); } catch (RejectedExecutionException e) { rejected.mark(); throw e; } } /** * {@inheritDoc} */ @Override public &lt;T&gt; T invokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks) throws ExecutionException, InterruptedException { submitted.mark(tasks.size()); Collection&lt;? extends Callable&lt;T&gt;&gt; instrumented = instrument(tasks); try { return delegate.invokeAny(instrumented); } catch (RejectedExecutionException e) { rejected.mark(); throw e; } } /** * {@inheritDoc} */ @Override public &lt;T&gt; T invokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, long timeout, TimeUnit unit) throws ExecutionException, InterruptedException, TimeoutException { submitted.mark(tasks.size()); //包装后的callable的列表 Collection&lt;? extends Callable&lt;T&gt;&gt; instrumented = instrument(tasks); try { return delegate.invokeAny(instrumented, timeout, unit); } catch (RejectedExecutionException e) { rejected.mark(); throw e; } } /** * 包装任务callable列表 * @param tasks * @param &lt;T&gt; * @return */ private &lt;T&gt; Collection&lt;? extends Callable&lt;T&gt;&gt; instrument(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks) { //好习惯。默认初始化大小 final List&lt;InstrumentedCallable&lt;T&gt;&gt; instrumented = new ArrayList&lt;InstrumentedCallable&lt;T&gt;&gt;(tasks.size()); for (Callable&lt;T&gt; task : tasks) { instrumented.add(new InstrumentedCallable&lt;T&gt;(task)); } return instrumented; } @Override public void shutdown() { delegate.shutdown(); } @Override public List&lt;Runnable&gt; shutdownNow() { return delegate.shutdownNow(); } @Override public boolean isShutdown() { return delegate.isShutdown(); } @Override public boolean isTerminated() { return delegate.isTerminated(); } @Override public boolean awaitTermination(long l, TimeUnit timeUnit) throws InterruptedException { return delegate.awaitTermination(l, timeUnit); } //runnble private class InstrumentedRunnable implements Runnable { private final Runnable task; InstrumentedRunnable(Runnable task) { this.task = task; } @Override public void run() { running.inc(); final Timer.Context context = duration.time(); try { task.run(); } finally { context.stop(); running.dec(); completed.mark(); } } } //覆写callable方法 //加入检测 private class InstrumentedCallable&lt;T&gt; implements Callable&lt;T&gt; { private final Callable&lt;T&gt; callable; InstrumentedCallable(Callable&lt;T&gt; callable) { this.callable = callable; } @Override public T call() throws Exception { running.inc(); final Timer.Context context = duration.time(); try { return callable.call(); } finally { context.stop(); running.dec(); completed.mark(); } } }} InstrumentedScheduledExecutorService.java包装ScheduledExecutorService类，嵌入监控对象123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295package io.dropwizard.metrics;import java.util.ArrayList;import java.util.Collection;import java.util.List;import java.util.concurrent.*;import java.util.concurrent.atomic.AtomicLong;/** * An {@link ScheduledExecutorService} that monitors the number of tasks submitted, running, * completed and also keeps a {@link Timer} for the task duration. * &lt;p/&gt; * It will register the metrics using the given (or auto-generated) name as classifier, e.g: * \"your-executor-service.submitted\", \"your-executor-service.running\", etc. */public class InstrumentedScheduledExecutorService implements ScheduledExecutorService { private static final AtomicLong nameCounter = new AtomicLong(); private final ScheduledExecutorService delegate; private final Meter submitted; private final Counter running; private final Meter completed; private final Timer duration; //1次 private final Meter scheduledOnce; //重复 private final Meter scheduledRepetitively; private final Counter scheduledOverrun; private final Histogram percentOfPeriod; /** * Wraps an {@link ScheduledExecutorService} uses an auto-generated default name. * * @param delegate {@link ScheduledExecutorService} to wrap. * @param registry {@link MetricRegistry} that will contain the metrics. */ public InstrumentedScheduledExecutorService(ScheduledExecutorService delegate, MetricRegistry registry) { this(delegate, registry, \"instrumented-scheduled-executor-service-\" + nameCounter.incrementAndGet()); } /** * Wraps an {@link ScheduledExecutorService} with an explicit name. * * @param delegate {@link ScheduledExecutorService} to wrap. * @param registry {@link MetricRegistry} that will contain the metrics. * @param name name for this executor service. */ public InstrumentedScheduledExecutorService(ScheduledExecutorService delegate, MetricRegistry registry, String name) { this.delegate = delegate; this.submitted = registry.meter(MetricRegistry.name(name, \"submitted\")); this.running = registry.counter(MetricRegistry.name(name, \"running\")); this.completed = registry.meter(MetricRegistry.name(name, \"completed\")); this.duration = registry.timer(MetricRegistry.name(name, \"duration\")); this.scheduledOnce = registry.meter(MetricRegistry.name(name, \"scheduled.once\")); this.scheduledRepetitively = registry.meter(MetricRegistry.name(name, \"scheduled.repetitively\")); this.scheduledOverrun = registry.counter(MetricRegistry.name(name, \"scheduled.overrun\")); this.percentOfPeriod = registry.histogram(MetricRegistry.name(name, \"scheduled.percent-of-period\")); } /** * {@inheritDoc} */ @Override public ScheduledFuture&lt;?&gt; schedule(Runnable command, long delay, TimeUnit unit) { scheduledOnce.mark(); return delegate.schedule(new InstrumentedRunnable(command), delay, unit); } /** * {@inheritDoc} */ @Override public &lt;V&gt; ScheduledFuture&lt;V&gt; schedule(Callable&lt;V&gt; callable, long delay, TimeUnit unit) { scheduledOnce.mark(); return delegate.schedule(new InstrumentedCallable&lt;V&gt;(callable), delay, unit); } /** * {@inheritDoc} */ @Override public ScheduledFuture&lt;?&gt; scheduleAtFixedRate(Runnable command, long initialDelay, long period, TimeUnit unit) { scheduledRepetitively.mark(); return delegate.scheduleAtFixedRate(new InstrumentedPeriodicRunnable(command, period, unit), initialDelay, period, unit); } /** * {@inheritDoc} */ @Override public ScheduledFuture&lt;?&gt; scheduleWithFixedDelay(Runnable command, long initialDelay, long delay, TimeUnit unit) { scheduledRepetitively.mark(); return delegate.scheduleAtFixedRate(new InstrumentedRunnable(command), initialDelay, delay, unit); } /** * {@inheritDoc} */ @Override public void shutdown() { delegate.shutdown(); } /** * {@inheritDoc} */ @Override public List&lt;Runnable&gt; shutdownNow() { return delegate.shutdownNow(); } /** * {@inheritDoc} */ @Override public boolean isShutdown() { return delegate.isShutdown(); } /** * {@inheritDoc} */ @Override public boolean isTerminated() { return delegate.isTerminated(); } /** * {@inheritDoc} */ @Override public boolean awaitTermination(long timeout, TimeUnit unit) throws InterruptedException { return delegate.awaitTermination(timeout, unit); } /** * {@inheritDoc} */ @Override public &lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task) { submitted.mark(); return delegate.submit(new InstrumentedCallable&lt;T&gt;(task)); } /** * {@inheritDoc} */ @Override public &lt;T&gt; Future&lt;T&gt; submit(Runnable task, T result) { submitted.mark(); return delegate.submit(new InstrumentedRunnable(task), result); } /** * {@inheritDoc} */ @Override public Future&lt;?&gt; submit(Runnable task) { submitted.mark(); return delegate.submit(new InstrumentedRunnable(task)); } /** * {@inheritDoc} */ @Override public &lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks) throws InterruptedException { submitted.mark(tasks.size()); Collection&lt;? extends Callable&lt;T&gt;&gt; instrumented = instrument(tasks); return delegate.invokeAll(instrumented); } /** * {@inheritDoc} */ @Override public &lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, long timeout, TimeUnit unit) throws InterruptedException { submitted.mark(tasks.size()); Collection&lt;? extends Callable&lt;T&gt;&gt; instrumented = instrument(tasks); return delegate.invokeAll(instrumented, timeout, unit); } /** * {@inheritDoc} */ @Override public &lt;T&gt; T invokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks) throws InterruptedException, ExecutionException { submitted.mark(tasks.size()); Collection&lt;? extends Callable&lt;T&gt;&gt; instrumented = instrument(tasks); return delegate.invokeAny(instrumented); } /** * {@inheritDoc} */ @Override public &lt;T&gt; T invokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException { submitted.mark(tasks.size()); Collection&lt;? extends Callable&lt;T&gt;&gt; instrumented = instrument(tasks); return delegate.invokeAny(instrumented, timeout, unit); } private &lt;T&gt; Collection&lt;? extends Callable&lt;T&gt;&gt; instrument(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks) { final List&lt;InstrumentedCallable&lt;T&gt;&gt; instrumented = new ArrayList&lt;InstrumentedCallable&lt;T&gt;&gt;(tasks.size()); for (Callable&lt;T&gt; task : tasks) { instrumented.add(new InstrumentedCallable(task)); } return instrumented; } /** * {@inheritDoc} */ @Override public void execute(Runnable command) { submitted.mark(); delegate.execute(new InstrumentedRunnable(command)); } //-----------------内部类 private class InstrumentedRunnable implements Runnable { private final Runnable command; InstrumentedRunnable(Runnable command) { this.command = command; } @Override public void run() { running.inc(); final Timer.Context context = duration.time(); try { command.run(); } finally { context.stop(); running.dec(); completed.mark(); } } } private class InstrumentedPeriodicRunnable implements Runnable { private final Runnable command; private final long periodInNanos; InstrumentedPeriodicRunnable(Runnable command, long period, TimeUnit unit) { this.command = command; this.periodInNanos = unit.toNanos(period); } @Override public void run() { running.inc(); final Timer.Context context = duration.time(); try { command.run(); } finally { final long elapsed = context.stop(); running.dec(); completed.mark(); if (elapsed &gt; periodInNanos) { scheduledOverrun.inc(); } percentOfPeriod.update((100L * elapsed) / periodInNanos); } } } private class InstrumentedCallable&lt;T&gt; implements Callable&lt;T&gt; { private final Callable&lt;T&gt; task; InstrumentedCallable(Callable&lt;T&gt; task) { this.task = task; } @Override public T call() throws Exception { running.inc(); final Timer.Context context = duration.time(); try { return task.call(); } finally { context.stop(); running.dec(); completed.mark(); } } }} metrics-healthchecksHealthCheck.java健康监测抽象类123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187package io.dropwizard.metrics.health;/** * A health check for a component of your application. * * 应用健康监测抽象类 */public abstract class HealthCheck { /** * The result of a {@link HealthCheck} being run. It can be healthy (with an optional message) * or unhealthy (with either an error message or a thrown exception). * * 检测结果类：健康，非健康 * */ public static class Result { private static final Result HEALTHY = new Result(true, null, null); private static final int PRIME = 31; /** * Returns a healthy {@link Result} with no additional message. * * @return a healthy {@link Result} with no additional message */ public static Result healthy() { return HEALTHY; } /** * Returns a healthy {@link Result} with an additional message. * * @param message an informative message * @return a healthy {@link Result} with an additional message */ public static Result healthy(String message) { return new Result(true, message, null); } /** * Returns a healthy {@link Result} with a formatted message. * &lt;p/&gt; * Message formatting follows the same rules as {@link String#format(String, Object...)}. * * @param message a message format * @param args the arguments apply to the message format * @return a healthy {@link Result} with an additional message * @see String#format(String, Object...) */ public static Result healthy(String message, Object... args) { return healthy(String.format(message, args)); } /** * Returns an unhealthy {@link Result} with the given message. * * @param message an informative message describing how the health check failed * @return an unhealthy {@link Result} with the given message */ public static Result unhealthy(String message) { return new Result(false, message, null); } /** * Returns an unhealthy {@link Result} with a formatted message. * &lt;p/&gt; * Message formatting follows the same rules as {@link String#format(String, Object...)}. * * @param message a message format * @param args the arguments apply to the message format * @return an unhealthy {@link Result} with an additional message * @see String#format(String, Object...) */ public static Result unhealthy(String message, Object... args) { return unhealthy(String.format(message, args)); } /** * Returns an unhealthy {@link Result} with the given error. * * @param error an exception thrown during the health check * @return an unhealthy {@link Result} with the given error */ public static Result unhealthy(Throwable error) { return new Result(false, error.getMessage(), error); } //是否健康 private final boolean healthy; //内容 private final String message; private final Throwable error; protected Result(boolean isHealthy, String message, Throwable error) { this.healthy = isHealthy; this.message = message; this.error = error; } /** * Returns {@code true} if the result indicates the component is healthy; {@code false} * otherwise. * * @return {@code true} if the result indicates the component is healthy */ public boolean isHealthy() { return healthy; } /** * Returns any additional message for the result, or {@code null} if the result has no * message. * * @return any additional message for the result, or {@code null} */ public String getMessage() { return message; } /** * Returns any exception for the result, or {@code null} if the result has no exception. * * @return any exception for the result, or {@code null} */ public Throwable getError() { return error; } @Override public boolean equals(Object o) { if (this == o) { return true; } if (o == null || getClass() != o.getClass()) { return false; } final Result result = (Result) o; return healthy == result.healthy &amp;&amp; !(error != null ? !error.equals(result.error) : result.error != null) &amp;&amp; !(message != null ? !message.equals(result.message) : result.message != null); } @Override public int hashCode() { int result = (healthy ? 1 : 0); result = PRIME * result + (message != null ? message.hashCode() : 0); result = PRIME * result + (error != null ? error.hashCode() : 0); return result; } @Override public String toString() { final StringBuilder builder = new StringBuilder(\"Result{isHealthy=\"); builder.append(healthy); if (message != null) { builder.append(\", message=\").append(message); } if (error != null) { builder.append(\", error=\").append(error); } builder.append('}'); return builder.toString(); } } /** * Perform a check of the application component. * * 检测health * * @return if the component is healthy, a healthy {@link Result}; otherwise, an unhealthy {@link * Result} with a descriptive error message or exception * @throws Exception if there is an unhandled error during the health check; this will result in * a failed health check */ protected abstract Result check() throws Exception; /** * Executes the health check, catching and handling any exceptions raised by {@link #check()}. * 线程执行 health check * * @return if the component is healthy, a healthy {@link Result}; otherwise, an unhealthy {@link * Result} with a descriptive error message or exception */ public Result execute() { try { return check(); } catch (Exception e) { return Result.unhealthy(e); } }} HealthCheckRegistry.javahealthCheck的注册类123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132package io.dropwizard.metrics.health;import static io.dropwizard.metrics.health.HealthCheck.Result;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import java.util.*;import java.util.concurrent.*;/** * A registry for health checks. * * healthCheck的注册类 * 把HealthCheck注册到Map中 * */public class HealthCheckRegistry { private static final Logger LOGGER = LoggerFactory.getLogger(HealthCheckRegistry.class); //health 的map private final ConcurrentMap&lt;String, HealthCheck&gt; healthChecks; /** * Creates a new {@link HealthCheckRegistry}. */ public HealthCheckRegistry() { this.healthChecks = new ConcurrentHashMap&lt;String, HealthCheck&gt;(); } /** * Registers an application {@link HealthCheck}. * 存储到map * * @param name the name of the health check * @param healthCheck the {@link HealthCheck} instance */ public void register(String name, HealthCheck healthCheck) { healthChecks.putIfAbsent(name, healthCheck); } /** * Unregisters the application {@link HealthCheck} with the given name. * * @param name the name of the {@link HealthCheck} instance */ public void unregister(String name) { healthChecks.remove(name); } /** * Returns a set of the names of all registered health checks. * * 返回注册healthCheck的name * 且是不可修改的set * * @return the names of all registered health checks */ public SortedSet&lt;String&gt; getNames() { return Collections.unmodifiableSortedSet(new TreeSet&lt;String&gt;(healthChecks.keySet())); } /** * Runs the health check with the given name. * 根据名字执行healthCheck 检测 * * @param name the health check's name * @return the result of the health check * @throws NoSuchElementException if there is no health check with the given name */ public HealthCheck.Result runHealthCheck(String name) throws NoSuchElementException { final HealthCheck healthCheck = healthChecks.get(name); if (healthCheck == null) { throw new NoSuchElementException(\"No health check named \" + name + \" exists\"); } return healthCheck.execute(); } /** * Runs the registered health checks and returns a map of the results. * * 运行health 检测 ，返回执行结果 * 返回不可修改的map * * @return a map of the health check results */ public SortedMap&lt;String, HealthCheck.Result&gt; runHealthChecks() { final SortedMap&lt;String, HealthCheck.Result&gt; results = new TreeMap&lt;String, HealthCheck.Result&gt;(); //检测结果 for (Map.Entry&lt;String, HealthCheck&gt; entry : healthChecks.entrySet()) { //执行任务 final Result result = entry.getValue().execute(); results.put(entry.getKey(), result); } //返回不可修改的执行结果 return Collections.unmodifiableSortedMap(results); } /** * * 线程池执行健康监测 * 阻塞（Callable）的返回执行结果 * * Runs the registered health checks in parallel and returns a map of the results. * @param executor object to launch and track health checks progress * @return a map of the health check results */ public SortedMap&lt;String, HealthCheck.Result&gt; runHealthChecks(ExecutorService executor) { final Map&lt;String, Future&lt;HealthCheck.Result&gt;&gt; futures = new HashMap&lt;String, Future&lt;Result&gt;&gt;(); for (final Map.Entry&lt;String, HealthCheck&gt; entry : healthChecks.entrySet()) { //线程池中执行任务 futures.put(entry.getKey(), executor.submit(new Callable&lt;Result&gt;() { @Override public Result call() throws Exception { return entry.getValue().execute(); } })); } final SortedMap&lt;String, HealthCheck.Result&gt; results = new TreeMap&lt;String, HealthCheck.Result&gt;(); for (Map.Entry&lt;String, Future&lt;Result&gt;&gt; entry : futures.entrySet()) { try { results.put(entry.getKey(), entry.getValue().get()); } catch (Exception e) { LOGGER.warn(\"Error executing health check {}\", entry.getKey(), e); results.put(entry.getKey(), HealthCheck.Result.unhealthy(e)); } } return Collections.unmodifiableSortedMap(results); }} SharedHealthCheckRegistries.javaHealthCheckRegistry的全局Map1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859package io.dropwizard.metrics.health;import java.util.Set;import java.util.concurrent.ConcurrentHashMap;import java.util.concurrent.ConcurrentMap;/** * A map of shared, named health registries. * HealthCheckRegistry的全局Map * */public class SharedHealthCheckRegistries { /** * 全局 */ private static final ConcurrentMap&lt;String, HealthCheckRegistry&gt; REGISTRIES = new ConcurrentHashMap&lt;String, HealthCheckRegistry&gt;(); private SharedHealthCheckRegistries() { /* singleton */ } public static void clear() { REGISTRIES.clear(); } public static Set&lt;String&gt; names() { return REGISTRIES.keySet(); } public static void remove(String key) { REGISTRIES.remove(key); } /** * 根据名字新增HealthCheckRegistry对象 * @param name * @param registry * @return */ public static HealthCheckRegistry add(String name, HealthCheckRegistry registry) { return REGISTRIES.putIfAbsent(name, registry); } /** * 从缓存中获取HealthCheckRegistry对象，如果不存在，则新增HealthCheckRegistry对象 * @param name * @return */ public static HealthCheckRegistry getOrCreate(String name) { final HealthCheckRegistry existing = REGISTRIES.get(name); if (existing == null) { final HealthCheckRegistry created = new HealthCheckRegistry(); final HealthCheckRegistry raced = add(name, created); if (raced == null) { return created; } return raced; } return existing; }} ThreadDeadlockHealthCheck.java健康线程死锁检测1234567891011121314151617181920212223242526272829303132333435363738394041package io.dropwizard.metrics.health.jvm;import io.dropwizard.metrics.jvm.ThreadDeadlockDetector;import io.dropwizard.metrics.health.HealthCheck;import java.util.Set;/** * A health check which returns healthy if no threads are deadlocked. * 健康线程死锁检测 * */public class ThreadDeadlockHealthCheck extends HealthCheck { private final ThreadDeadlockDetector detector; /** * Creates a new health check. */ public ThreadDeadlockHealthCheck() { this(new ThreadDeadlockDetector()); } /** * Creates a new health check with the given detector. * * @param detector a thread deadlock detector */ public ThreadDeadlockHealthCheck(ThreadDeadlockDetector detector) { this.detector = detector; } @Override protected Result check() throws Exception { final Set&lt;String&gt; threads = detector.getDeadlockedThreads(); if (threads.isEmpty()) { return Result.healthy(); } return Result.unhealthy(threads.toString()); }} metrics-httpclientHttpClientMetricNameStrategies.java创建HttpClientMetricNameStrategy对象12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182package io.dropwizard.metrics.httpclient;import static io.dropwizard.metrics.MetricRegistry.name;import org.apache.http.HttpRequest;import org.apache.http.client.HttpClient;import org.apache.http.client.methods.HttpRequestWrapper;import org.apache.http.client.methods.HttpUriRequest;import org.apache.http.client.utils.URIBuilder;import io.dropwizard.metrics.MetricName;import java.net.URI;import java.net.URISyntaxException;/** * httpclient名字策略组成 * 创建HttpClientMetricNameStrategy对象 */public class HttpClientMetricNameStrategies { /** * method */ public static final HttpClientMetricNameStrategy METHOD_ONLY = new HttpClientMetricNameStrategy() { @Override public MetricName getNameFor(String name, HttpRequest request) { return name(HttpClient.class, name, methodNameString(request)); } }; /** * host_and_method */ public static final HttpClientMetricNameStrategy HOST_AND_METHOD = new HttpClientMetricNameStrategy() { @Override public MetricName getNameFor(String name, HttpRequest request) { return name(HttpClient.class, name, requestURI(request).getHost(), methodNameString(request)); } }; /** * queryless_url_and_method */ public static final HttpClientMetricNameStrategy QUERYLESS_URL_AND_METHOD = new HttpClientMetricNameStrategy() { @Override public MetricName getNameFor(String name, HttpRequest request) { try { final URIBuilder url = new URIBuilder(requestURI(request)); return name(HttpClient.class, name, url.removeQuery().build().toString(), methodNameString(request)); } catch (URISyntaxException e) { throw new IllegalArgumentException(e); } } }; private static String methodNameString(HttpRequest request) { return request.getRequestLine().getMethod().toLowerCase() + \"-requests\"; } private static URI requestURI(HttpRequest request) { if (request instanceof HttpRequestWrapper) return requestURI(((HttpRequestWrapper) request).getOriginal()); return (request instanceof HttpUriRequest) ? ((HttpUriRequest) request).getURI() : URI.create(request.getRequestLine().getUri()); }} HttpClientMetricNameStrategy.java接口：创建httpclient的MetricName1234567891011121314151617181920212223package io.dropwizard.metrics.httpclient;import static io.dropwizard.metrics.MetricRegistry.name;import org.apache.http.HttpRequest;import org.apache.http.client.HttpClient;import io.dropwizard.metrics.MetricName;/** * 监测，名字策略 */public interface HttpClientMetricNameStrategy { MetricName getNameFor(String name, HttpRequest request); //name + exception组成名字 default MetricName getNameFor(String name, Exception exception) { return name(HttpClient.class, name, exception.getClass().getSimpleName()); }} InstrumentedHttpClientConnectionManager.java监控http 连接工具，继承http 连接池创建Gauge的4种连接监控注册对象：available-connections，leased-connections,max-connections，pending-connections123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150package io.dropwizard.metrics.httpclient;import static io.dropwizard.metrics.MetricRegistry.name;import org.apache.http.config.Registry;import org.apache.http.config.RegistryBuilder;import org.apache.http.conn.*;import org.apache.http.conn.routing.HttpRoute;import org.apache.http.conn.socket.ConnectionSocketFactory;import org.apache.http.conn.socket.PlainConnectionSocketFactory;import org.apache.http.conn.ssl.SSLConnectionSocketFactory;import org.apache.http.impl.conn.PoolingHttpClientConnectionManager;import org.apache.http.impl.conn.SystemDefaultDnsResolver;import io.dropwizard.metrics.Gauge;import io.dropwizard.metrics.MetricRegistry;import java.util.concurrent.TimeUnit;/** * A {@link HttpClientConnectionManager} which monitors the number of open connections. * 监控http 连接工具，继承http 连接池 * 创建Gauge的4种连接监控注册对象：available-connections，leased-connections,max-connections，pending-connections */public class InstrumentedHttpClientConnectionManager extends PoolingHttpClientConnectionManager { /** * 获取http默认策略 * @return */ protected static Registry&lt;ConnectionSocketFactory&gt; getDefaultRegistry() { return RegistryBuilder.&lt;ConnectionSocketFactory&gt;create() .register(\"http\", PlainConnectionSocketFactory.getSocketFactory()) .register(\"https\", SSLConnectionSocketFactory.getSocketFactory()) .build(); } /** * 监测注册对象 */ private final MetricRegistry metricsRegistry; private final String name; /** * 构造方法 * @param metricRegistry */ public InstrumentedHttpClientConnectionManager(MetricRegistry metricRegistry) { this(metricRegistry, getDefaultRegistry()); } /** * 构造方法 * @param metricsRegistry * @param socketFactoryRegistry */ public InstrumentedHttpClientConnectionManager(MetricRegistry metricsRegistry, Registry&lt;ConnectionSocketFactory&gt; socketFactoryRegistry) { this(metricsRegistry, socketFactoryRegistry, -1, TimeUnit.MILLISECONDS); } /** * 构造方法 * @param metricsRegistry * @param socketFactoryRegistry * @param connTTL * @param connTTLTimeUnit */ public InstrumentedHttpClientConnectionManager(MetricRegistry metricsRegistry, Registry&lt;ConnectionSocketFactory&gt; socketFactoryRegistry, long connTTL, TimeUnit connTTLTimeUnit) { this(metricsRegistry, socketFactoryRegistry, null, null, SystemDefaultDnsResolver.INSTANCE, connTTL, connTTLTimeUnit, null); } /** * 构造方法，注册http，4种连接监控注册对象：available-connections，leased-connections,max-connections，pending-connections * @param metricsRegistry * @param socketFactoryRegistry * @param connFactory * @param schemePortResolver * @param dnsResolver * @param connTTL * @param connTTLTimeUnit * @param name */ public InstrumentedHttpClientConnectionManager(MetricRegistry metricsRegistry, Registry&lt;ConnectionSocketFactory&gt; socketFactoryRegistry, HttpConnectionFactory&lt;HttpRoute,ManagedHttpClientConnection&gt; connFactory, SchemePortResolver schemePortResolver, DnsResolver dnsResolver, long connTTL, TimeUnit connTTLTimeUnit, String name) { //调用http里的方法 super(socketFactoryRegistry, connFactory, schemePortResolver, dnsResolver, connTTL, connTTLTimeUnit); //监测注册对象 this.metricsRegistry = metricsRegistry; this.name = name; //可以获得连接 metricsRegistry.register(name(HttpClientConnectionManager.class, name, \"available-connections\"), new Gauge&lt;Integer&gt;() { @Override public Integer getValue() { // this acquires a lock on the connection pool; remove if contention sucks return getTotalStats().getAvailable(); } }); //专线 metricsRegistry.register(name(HttpClientConnectionManager.class, name, \"leased-connections\"), new Gauge&lt;Integer&gt;() { @Override public Integer getValue() { // this acquires a lock on the connection pool; remove if contention sucks return getTotalStats().getLeased(); } }); //最大连接 metricsRegistry.register(name(HttpClientConnectionManager.class, name, \"max-connections\"), new Gauge&lt;Integer&gt;() { @Override public Integer getValue() { // this acquires a lock on the connection pool; remove if contention sucks return getTotalStats().getMax(); } }); //待定 metricsRegistry.register(name(HttpClientConnectionManager.class, name, \"pending-connections\"), new Gauge&lt;Integer&gt;() { @Override public Integer getValue() { // this acquires a lock on the connection pool; remove if contention sucks return getTotalStats().getPending(); } }); } /** * 删除所有连接 */ @Override public void shutdown() { super.shutdown(); metricsRegistry.remove(name(HttpClientConnectionManager.class, name, \"available-connections\")); metricsRegistry.remove(name(HttpClientConnectionManager.class, name, \"leased-connections\")); metricsRegistry.remove(name(HttpClientConnectionManager.class, name, \"max-connections\")); metricsRegistry.remove(name(HttpClientConnectionManager.class, name, \"pending-connections\")); }} InstrumentedHttpRequestExecutor.javahttpRequest执行类123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596package io.dropwizard.metrics.httpclient;import org.apache.http.HttpClientConnection;import org.apache.http.HttpException;import org.apache.http.HttpRequest;import org.apache.http.HttpResponse;import org.apache.http.protocol.HttpContext;import org.apache.http.protocol.HttpRequestExecutor;import io.dropwizard.metrics.Meter;import io.dropwizard.metrics.MetricRegistry;import io.dropwizard.metrics.Timer;import java.io.IOException;/** * * httpRequest执行类 * */public class InstrumentedHttpRequestExecutor extends HttpRequestExecutor { /** * 监测注册对象 */ private final MetricRegistry registry; /** * 监测名字策略 */ private final HttpClientMetricNameStrategy metricNameStrategy; private final String name; public InstrumentedHttpRequestExecutor(MetricRegistry registry, HttpClientMetricNameStrategy metricNameStrategy) { this(registry, metricNameStrategy, null); } public InstrumentedHttpRequestExecutor(MetricRegistry registry, HttpClientMetricNameStrategy metricNameStrategy, String name) { this(registry, metricNameStrategy, name, HttpRequestExecutor.DEFAULT_WAIT_FOR_CONTINUE); } public InstrumentedHttpRequestExecutor(MetricRegistry registry, HttpClientMetricNameStrategy metricNameStrategy, String name, int waitForContinue) { super(waitForContinue); this.registry = registry; this.name = name; this.metricNameStrategy = metricNameStrategy; } /** * 覆写父类的方法，新增：timer对象。 * 对执行方法进行时间监控。 * @param request * @param conn * @param context * @return * @throws HttpException * @throws IOException */ @Override public HttpResponse execute(HttpRequest request, HttpClientConnection conn, HttpContext context) throws HttpException, IOException { //时间上下文 final Timer.Context timerContext = timer(request).time(); try { //调用httpclient的执行请求 return super.execute(request, conn, context); } catch (HttpException | IOException e) { meter(e).mark(); throw e; } finally { //时间停止 timerContext.stop(); } } /** * 注册execute执行时间 * @param request * @return */ private Timer timer(HttpRequest request) { return registry.timer(metricNameStrategy.getNameFor(name, request)); } /** * 统计异常处理次数 * @param e * @return */ private Meter meter(Exception e) { return registry.meter(metricNameStrategy.getNameFor(name, e)); }} InstrumentedHttpClients.javahttpClient监测工具，创建监测的HttpClientBuilder对象1234567891011121314151617181920212223242526272829303132333435363738394041424344454647package io.dropwizard.metrics.httpclient;import static io.dropwizard.metrics.httpclient.HttpClientMetricNameStrategies.METHOD_ONLY;import org.apache.http.impl.client.CloseableHttpClient;import org.apache.http.impl.client.HttpClientBuilder;import io.dropwizard.metrics.MetricRegistry;/** * httpClient监测工具 * 创建监测的HttpClientBuilder对象 */public class InstrumentedHttpClients { private InstrumentedHttpClients() { super(); } public static CloseableHttpClient createDefault(MetricRegistry metricRegistry) { return createDefault(metricRegistry, METHOD_ONLY); } public static CloseableHttpClient createDefault(MetricRegistry metricRegistry, HttpClientMetricNameStrategy metricNameStrategy) { return custom(metricRegistry, metricNameStrategy).build(); } public static HttpClientBuilder custom(MetricRegistry metricRegistry) { return custom(metricRegistry, METHOD_ONLY); } /** * 继承HttpRequestExecutor的监测工具类：InstrumentedHttpRequestExecutor * 继承PoolingHttpClientConnectionManager的连接池工具类，InstrumentedHttpClientConnectionManager * 创建HttpClientBuilder对象 * * @param metricRegistry * @param metricNameStrategy * @return */ public static HttpClientBuilder custom(MetricRegistry metricRegistry, HttpClientMetricNameStrategy metricNameStrategy) { return HttpClientBuilder.create() .setRequestExecutor(new InstrumentedHttpRequestExecutor(metricRegistry, metricNameStrategy)) .setConnectionManager(new InstrumentedHttpClientConnectionManager(metricRegistry)); }} metrics-jvmBufferPoolMetricSet.java通过：MBeanServer，JVM指标统计，映射内存图12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364package io.dropwizard.metrics.jvm;import static io.dropwizard.metrics.MetricRegistry.name;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import io.dropwizard.metrics.JmxAttributeGauge;import io.dropwizard.metrics.Metric;import io.dropwizard.metrics.MetricName;import io.dropwizard.metrics.MetricSet;import javax.management.JMException;import javax.management.MBeanServer;import javax.management.ObjectName;import java.util.Collections;import java.util.HashMap;import java.util.Map;/** * A set of gauges for the count, usage, and capacity of the JVM's direct and mapped buffer pools. * 通过：MBeanServer，JVM指标统计，映射内存图 * * &lt;p&gt; * These JMX objects are only available on Java 7 and above. */public class BufferPoolMetricSet implements MetricSet { private static final Logger LOGGER = LoggerFactory.getLogger(BufferPoolMetricSet.class); private static final String[] ATTRIBUTES = {\"Count\", \"MemoryUsed\", \"TotalCapacity\"}; private static final String[] NAMES = {\"count\", \"used\", \"capacity\"}; private static final String[] POOLS = {\"direct\", \"mapped\"}; private final MBeanServer mBeanServer; public BufferPoolMetricSet(MBeanServer mBeanServer) { this.mBeanServer = mBeanServer; } /** * 通过MBeanServer获取JVM缓存池数据，设置gauges，存入不可变的Map * @return */ @Override public Map&lt;MetricName, Metric&gt; getMetrics() { final Map&lt;MetricName, Metric&gt; gauges = new HashMap&lt;MetricName, Metric&gt;(); for (String pool : POOLS) { for (int i = 0; i &lt; ATTRIBUTES.length; i++) { final String attribute = ATTRIBUTES[i]; final String name = NAMES[i]; try { final ObjectName on = new ObjectName(\"java.nio:type=BufferPool,name=\" + pool); mBeanServer.getMBeanInfo(on); gauges.put(name(pool, name), new JmxAttributeGauge(mBeanServer, on, attribute)); } catch (JMException ignored) { LOGGER.debug(\"Unable to load buffer pool MBeans, possibly running on Java 6\"); } } } return Collections.unmodifiableMap(gauges); }} CachedThreadStatesGaugeSet.java使用ThreadMXBean创建指定时间内的缓存信息，存入gauges中1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162package io.dropwizard.metrics.jvm;import java.lang.management.ManagementFactory;import java.lang.management.ThreadInfo;import java.lang.management.ThreadMXBean;import java.util.concurrent.TimeUnit;import io.dropwizard.metrics.CachedGauge;/** * A variation of ThreadStatesGaugeSet that caches the ThreadInfo[] objects for * a given interval. * 使用ThreadMXBean创建指定时间内的缓存信息，存入gauges中 * */public class CachedThreadStatesGaugeSet extends ThreadStatesGaugeSet { //缓存 private final CachedGauge&lt;ThreadInfo[]&gt; threadInfo; /** * 使用ThreadMXBean创建指定时间内的缓存信息，存入gauges中 * * Creates a new set of gauges using the given MXBean and detector. * Caches the information for the given interval and time unit. * * @param threadMXBean a thread MXBean * @param deadlockDetector a deadlock detector * @param interval cache interval * @param unit cache interval time unit */ public CachedThreadStatesGaugeSet(final ThreadMXBean threadMXBean, ThreadDeadlockDetector deadlockDetector, long interval, TimeUnit unit) { super(threadMXBean, deadlockDetector); //所有线程信息对象 threadInfo = new CachedGauge&lt;ThreadInfo[]&gt;(interval, unit) { @Override protected ThreadInfo[] loadValue() { return CachedThreadStatesGaugeSet.super.getThreadInfo(); } }; } /** * Creates a new set of gauges using the default MXBeans. * Caches the information for the given interval and time unit. * @param interval cache interval * @param unit cache interval time unit */ public CachedThreadStatesGaugeSet(long interval, TimeUnit unit) { this(ManagementFactory.getThreadMXBean(), new ThreadDeadlockDetector(), interval, unit); } /** * 获取线程信息数组 * @return */ @Override ThreadInfo[] getThreadInfo() { return threadInfo.getValue(); }} ClassLoadingGaugeSet.javaJVM classloader 使用率，class load 数目和 unload 数目1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556package io.dropwizard.metrics.jvm;import io.dropwizard.metrics.Gauge;import io.dropwizard.metrics.Metric;import io.dropwizard.metrics.MetricName;import io.dropwizard.metrics.MetricSet;import java.lang.management.ClassLoadingMXBean;import java.lang.management.ManagementFactory;import java.util.HashMap;import java.util.Map;/** * A set of gauges for JVM classloader usage. * * JVM classloader 使用率 * class load 数目和 unload 数目 * */public class ClassLoadingGaugeSet implements MetricSet { private final ClassLoadingMXBean mxBean; public ClassLoadingGaugeSet() { this(ManagementFactory.getClassLoadingMXBean()); } public ClassLoadingGaugeSet(ClassLoadingMXBean mxBean) { this.mxBean = mxBean; } /** * class load 数目和 unload 数目 * @return */ @Override public Map&lt;MetricName, Metric&gt; getMetrics() { final Map&lt;MetricName, Metric&gt; gauges = new HashMap&lt;MetricName, Metric&gt;(); gauges.put(MetricName.build(\"loaded\"), new Gauge&lt;Long&gt;() { @Override public Long getValue() { return mxBean.getTotalLoadedClassCount(); } }); gauges.put(MetricName.build(\"unloaded\"), new Gauge&lt;Long&gt;() { @Override public Long getValue() { return mxBean.getUnloadedClassCount(); } }); return gauges; }} FileDescriptorRatioGauge.java通过OperatingSystemMXBean，文件描述使用比率1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253package io.dropwizard.metrics.jvm;import io.dropwizard.metrics.RatioGauge;import java.lang.management.ManagementFactory;import java.lang.management.OperatingSystemMXBean;import java.lang.reflect.InvocationTargetException;import java.lang.reflect.Method;/** * A gauge for the ratio of used to total file descriptors. * 通过OperatingSystemMXBean，文件描述使用比率 * */public class FileDescriptorRatioGauge extends RatioGauge { private final OperatingSystemMXBean os; /** * Creates a new gauge using the platform OS bean. */ public FileDescriptorRatioGauge() { this(ManagementFactory.getOperatingSystemMXBean()); } /** * Creates a new gauge using the given OS bean. * * @param os an {@link OperatingSystemMXBean} */ public FileDescriptorRatioGauge(OperatingSystemMXBean os) { this.os = os; } @Override protected Ratio getRatio() { try { //打开文件数目，最大文件数目 return Ratio.of(invoke(\"getOpenFileDescriptorCount\"), invoke(\"getMaxFileDescriptorCount\")); } catch (NoSuchMethodException e) { return Ratio.of(Double.NaN, Double.NaN); } catch (IllegalAccessException e) { return Ratio.of(Double.NaN, Double.NaN); } catch (InvocationTargetException e) { return Ratio.of(Double.NaN, Double.NaN); } } private long invoke(String name) throws NoSuchMethodException, IllegalAccessException, InvocationTargetException { final Method method = os.getClass().getDeclaredMethod(name); method.setAccessible(true); return (Long) method.invoke(os); }} GarbageCollectorMetricSet.java通过GarbageCollectorMXBean实现运行时垃圾收集:收集数目,收集时间1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465package io.dropwizard.metrics.jvm;import static io.dropwizard.metrics.MetricRegistry.name;import io.dropwizard.metrics.Gauge;import io.dropwizard.metrics.Metric;import io.dropwizard.metrics.MetricName;import io.dropwizard.metrics.MetricSet;import java.lang.management.GarbageCollectorMXBean;import java.lang.management.ManagementFactory;import java.util.*;import java.util.regex.Pattern;/** * A set of gauges for the counts and elapsed times of garbage collections. * * 通过GarbageCollectorMXBean实现运行时垃圾收集:收集数目,收集时间 * */public class GarbageCollectorMetricSet implements MetricSet { //空格 private static final Pattern WHITESPACE = Pattern.compile(\"[\\\\s]+\"); private final List&lt;GarbageCollectorMXBean&gt; garbageCollectors; /** * Creates a new set of gauges for all discoverable garbage collectors. */ public GarbageCollectorMetricSet() { this(ManagementFactory.getGarbageCollectorMXBeans()); } /** * Creates a new set of gauges for the given collection of garbage collectors. * * @param garbageCollectors the garbage collectors */ public GarbageCollectorMetricSet(Collection&lt;GarbageCollectorMXBean&gt; garbageCollectors) { this.garbageCollectors = new ArrayList&lt;GarbageCollectorMXBean&gt;(garbageCollectors); } @Override public Map&lt;MetricName, Metric&gt; getMetrics() { final Map&lt;MetricName, Metric&gt; gauges = new HashMap&lt;MetricName, Metric&gt;(); for (final GarbageCollectorMXBean gc : garbageCollectors) { final String name = WHITESPACE.matcher(gc.getName()).replaceAll(\"-\"); //收集数目 gauges.put(name(name, \"count\"), new Gauge&lt;Long&gt;() { @Override public Long getValue() { return gc.getCollectionCount(); } }); //收集时间 gauges.put(name(name, \"time\"), new Gauge&lt;Long&gt;() { @Override public Long getValue() { return gc.getCollectionTime(); } }); } return Collections.unmodifiableMap(gauges); }} MemoryUsageGaugeSet.java通过MemoryMXBean实现JVM 内存使用，堆状态，GC特殊内存池包括：堆内存，非堆内存，内存池获取监测的数据：总初始化数目，总被使用数目，最大数目，堆初始化，堆使用，堆最大值，非堆内存-初始化，非堆内存-使用，内存池数据的获取，使用比率，最大使用，初始化123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233package io.dropwizard.metrics.jvm;import static io.dropwizard.metrics.MetricRegistry.name;import io.dropwizard.metrics.Gauge;import io.dropwizard.metrics.Metric;import io.dropwizard.metrics.MetricName;import io.dropwizard.metrics.MetricSet;import io.dropwizard.metrics.RatioGauge;import java.lang.management.ManagementFactory;import java.lang.management.MemoryMXBean;import java.lang.management.MemoryPoolMXBean;import java.lang.management.MemoryUsage;import java.util.ArrayList;import java.util.Collection;import java.util.Collections;import java.util.HashMap;import java.util.List;import java.util.Map;import java.util.regex.Pattern;/** * A set of gauges for JVM memory usage, including stats on heap vs. non-heap memory, plus * GC-specific memory pools. * * 通过MemoryMXBean实现JVM 内存使用，堆状态，GC特殊内存池 * * 包括：堆内存，非堆内存，内存池 * * 获取监测的数据：总初始化数目，总被使用数目，最大数目，堆初始化，堆使用，堆最大值，非堆内存-初始化，非堆内存-使用 * 内存池数据的获取，使用比率，最大使用，初始化 * */public class MemoryUsageGaugeSet implements MetricSet { private static final Pattern WHITESPACE = Pattern.compile(\"[\\\\s]+\"); /** * 内存MXbean */ private final MemoryMXBean mxBean; /** * 内存池MXBean对象 */ private final List&lt;MemoryPoolMXBean&gt; memoryPools; public MemoryUsageGaugeSet() { this(ManagementFactory.getMemoryMXBean(), ManagementFactory.getMemoryPoolMXBeans()); } public MemoryUsageGaugeSet(MemoryMXBean mxBean, Collection&lt;MemoryPoolMXBean&gt; memoryPools) { this.mxBean = mxBean; this.memoryPools = new ArrayList&lt;MemoryPoolMXBean&gt;(memoryPools); } @Override public Map&lt;MetricName, Metric&gt; getMetrics() { final Map&lt;MetricName, Metric&gt; gauges = new HashMap&lt;MetricName, Metric&gt;(); //总初始化数目： gauges.put(MetricName.build(\"total.init\"), new Gauge&lt;Long&gt;() { @Override public Long getValue() { return mxBean.getHeapMemoryUsage().getInit() + mxBean.getNonHeapMemoryUsage().getInit(); } }); //总被使用数目： gauges.put(MetricName.build(\"total.used\"), new Gauge&lt;Long&gt;() { @Override public Long getValue() { return mxBean.getHeapMemoryUsage().getUsed() + mxBean.getNonHeapMemoryUsage().getUsed(); } }); //最大数目 gauges.put(MetricName.build(\"total.max\"), new Gauge&lt;Long&gt;() { @Override public Long getValue() { return mxBean.getHeapMemoryUsage().getMax() + mxBean.getNonHeapMemoryUsage().getMax(); } }); gauges.put(MetricName.build(\"total.committed\"), new Gauge&lt;Long&gt;() { @Override public Long getValue() { return mxBean.getHeapMemoryUsage().getCommitted() + mxBean.getNonHeapMemoryUsage().getCommitted(); } }); //堆初始化 gauges.put(MetricName.build(\"heap.init\"), new Gauge&lt;Long&gt;() { @Override public Long getValue() { return mxBean.getHeapMemoryUsage().getInit(); } }); //堆使用 gauges.put(MetricName.build(\"heap.used\"), new Gauge&lt;Long&gt;() { @Override public Long getValue() { return mxBean.getHeapMemoryUsage().getUsed(); } }); //最大值 gauges.put(MetricName.build(\"heap.max\"), new Gauge&lt;Long&gt;() { @Override public Long getValue() { return mxBean.getHeapMemoryUsage().getMax(); } }); gauges.put(MetricName.build(\"heap.committed\"), new Gauge&lt;Long&gt;() { @Override public Long getValue() { return mxBean.getHeapMemoryUsage().getCommitted(); } }); //堆使用 gauges.put(MetricName.build(\"heap.usage\"), new RatioGauge() { @Override protected Ratio getRatio() { final MemoryUsage usage = mxBean.getHeapMemoryUsage(); return Ratio.of(usage.getUsed(), usage.getMax()); } }); //非堆内存-初始化 gauges.put(MetricName.build(\"non-heap.init\"), new Gauge&lt;Long&gt;() { @Override public Long getValue() { return mxBean.getNonHeapMemoryUsage().getInit(); } }); //非堆内存-使用 gauges.put(MetricName.build(\"non-heap.used\"), new Gauge&lt;Long&gt;() { @Override public Long getValue() { return mxBean.getNonHeapMemoryUsage().getUsed(); } }); // gauges.put(MetricName.build(\"non-heap.max\"), new Gauge&lt;Long&gt;() { @Override public Long getValue() { return mxBean.getNonHeapMemoryUsage().getMax(); } }); gauges.put(MetricName.build(\"non-heap.committed\"), new Gauge&lt;Long&gt;() { @Override public Long getValue() { return mxBean.getNonHeapMemoryUsage().getCommitted(); } }); gauges.put(MetricName.build(\"non-heap.usage\"), new RatioGauge() { @Override protected Ratio getRatio() { final MemoryUsage usage = mxBean.getNonHeapMemoryUsage(); return Ratio.of(usage.getUsed(), usage.getMax()); } }); //内存池数据的获取，使用比率，最大使用，初始化 for (final MemoryPoolMXBean pool : memoryPools) { final MetricName poolName = name(\"pools\", WHITESPACE.matcher(pool.getName()).replaceAll(\"-\")); //使用比率 gauges.put(poolName.resolve(\"usage\"), new RatioGauge() { @Override protected Ratio getRatio() { MemoryUsage usage = pool.getUsage(); return Ratio.of(usage.getUsed(), usage.getMax() == -1 ? usage.getCommitted() : usage.getMax()); } }); //内存池最大使用 gauges.put(poolName.resolve(\"max\"),new Gauge&lt;Long&gt;() { @Override public Long getValue() { return pool.getUsage().getMax(); } }); //使用 gauges.put(poolName.resolve(\"used\"),new Gauge&lt;Long&gt;() { @Override public Long getValue() { return pool.getUsage().getUsed(); } }); //提交 gauges.put(poolName.resolve(\"committed\"),new Gauge&lt;Long&gt;() { @Override public Long getValue() { return pool.getUsage().getCommitted(); } }); // Only register GC usage metrics if the memory pool supports usage statistics. if (pool.getCollectionUsage() != null) { gauges.put(poolName.resolve(\"used-after-gc\"),new Gauge&lt;Long&gt;() { @Override public Long getValue() { return pool.getCollectionUsage().getUsed(); } }); } //初始化 gauges.put(poolName.resolve(\"init\"),new Gauge&lt;Long&gt;() { @Override public Long getValue() { return pool.getUsage().getInit(); } }); } return Collections.unmodifiableMap(gauges); }} ThreadDeadlockDetector.java通过ThreadMXBean，检测线程死锁123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172package io.dropwizard.metrics.jvm;import java.lang.management.ManagementFactory;import java.lang.management.ThreadInfo;import java.lang.management.ThreadMXBean;import java.util.Collections;import java.util.HashSet;import java.util.Set;/** * A utility class for detecting deadlocked threads. * * 通过ThreadMXBean，检测线程死锁 */public class ThreadDeadlockDetector { private static final int MAX_STACK_TRACE_DEPTH = 100; private final ThreadMXBean threads; /** * Creates a new detector. */ public ThreadDeadlockDetector() { this(ManagementFactory.getThreadMXBean()); } /** * Creates a new detector using the given {@link ThreadMXBean}. * * @param threads a {@link ThreadMXBean} */ public ThreadDeadlockDetector(ThreadMXBean threads) { this.threads = threads; } /** * Returns a set of diagnostic stack traces for any deadlocked threads. If no threads are * deadlocked, returns an empty set. * * 返回线程死锁信息 * * @return stack traces for deadlocked threads or an empty set */ public Set&lt;String&gt; getDeadlockedThreads() { //死锁线程id final long[] ids = threads.findDeadlockedThreads(); if (ids != null) { final Set&lt;String&gt; deadlocks = new HashSet&lt;String&gt;(); //死锁线程信息 for (ThreadInfo info : threads.getThreadInfo(ids, MAX_STACK_TRACE_DEPTH)) { final StringBuilder stackTrace = new StringBuilder(); //线程堆栈信息 for (StackTraceElement element : info.getStackTrace()) { stackTrace.append(\"\\t at \") .append(element.toString()) .append(String.format(\"%n\")); } deadlocks.add( String.format(\"%s locked on %s (owned by %s):%n%s\", info.getThreadName(), info.getLockName(), info.getLockOwnerName(), stackTrace.toString() ) ); } return Collections.unmodifiableSet(deadlocks); } return Collections.emptySet(); }} ThreadDump.java通过ThreadMXBean，获取线程快照123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105package io.dropwizard.metrics.jvm;import java.io.OutputStream;import java.io.OutputStreamWriter;import java.io.PrintWriter;import java.lang.management.LockInfo;import java.lang.management.MonitorInfo;import java.lang.management.ThreadInfo;import java.lang.management.ThreadMXBean;import java.nio.charset.Charset;/** * A convenience class for getting a thread dump. * * 通过ThreadMXBean，获取线程快照 * */public class ThreadDump { private static final Charset UTF_8 = Charset.forName(\"UTF-8\"); private final ThreadMXBean threadMXBean; public ThreadDump(ThreadMXBean threadMXBean) { this.threadMXBean = threadMXBean; } /** * Dumps all of the threads' current information to an output stream. * * @param out an output stream */ public void dump(OutputStream out) { //Returns the thread info for all live threads with stack trace final ThreadInfo[] threads = this.threadMXBean.dumpAllThreads(true, true); final PrintWriter writer = new PrintWriter(new OutputStreamWriter(out, UTF_8)); //线程信息 for (int ti = threads.length - 1; ti &gt;= 0; ti--) { final ThreadInfo t = threads[ti]; writer.printf(\"\\\"%s\\\" id=%d state=%s\", t.getThreadName(), t.getThreadId(), t.getThreadState()); //锁信息 //锁状态：sync,block，wait final LockInfo lock = t.getLockInfo(); //非锁 if (lock != null &amp;&amp; t.getThreadState() != Thread.State.BLOCKED) { writer.printf(\"%n - waiting on &lt;0x%08x&gt; (a %s)\", lock.getIdentityHashCode(), lock.getClassName()); writer.printf(\"%n - locked &lt;0x%08x&gt; (a %s)\", lock.getIdentityHashCode(), lock.getClassName()); } else if (lock != null &amp;&amp; t.getThreadState() == Thread.State.BLOCKED) {//锁 writer.printf(\"%n - waiting to lock &lt;0x%08x&gt; (a %s)\", lock.getIdentityHashCode(), lock.getClassName()); } if (t.isSuspended()) { writer.print(\" (suspended)\"); } if (t.isInNative()) { writer.print(\" (running in native)\"); } writer.println(); if (t.getLockOwnerName() != null) { writer.printf(\" owned by %s id=%d%n\", t.getLockOwnerName(), t.getLockOwnerId()); } //线程堆栈信息 final StackTraceElement[] elements = t.getStackTrace(); //锁监控信息 final MonitorInfo[] monitors = t.getLockedMonitors(); for (int i = 0; i &lt; elements.length; i++) { final StackTraceElement element = elements[i]; writer.printf(\" at %s%n\", element); //监控 for (int j = 1; j &lt; monitors.length; j++) { final MonitorInfo monitor = monitors[j]; if (monitor.getLockedStackDepth() == i) { writer.printf(\" - locked %s%n\", monitor); } } } writer.println(); //sync的lock final LockInfo[] locks = t.getLockedSynchronizers(); if (locks.length &gt; 0) { writer.printf(\" Locked synchronizers: count = %d%n\", locks.length); for (LockInfo l : locks) { writer.printf(\" - %s%n\", l); } writer.println(); } } writer.println(); writer.flush(); }} ThreadStatesGaugeSet.java通过ThreadMXBean，ThreadDeadlockDetector检测状态、死锁123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129package io.dropwizard.metrics.jvm;import static io.dropwizard.metrics.MetricRegistry.name;import io.dropwizard.metrics.Gauge;import io.dropwizard.metrics.Metric;import io.dropwizard.metrics.MetricName;import io.dropwizard.metrics.MetricSet;import java.lang.management.ManagementFactory;import java.lang.management.ThreadInfo;import java.lang.management.ThreadMXBean;import java.util.Collections;import java.util.HashMap;import java.util.Map;import java.util.Set;/** * A set of gauges for the number of threads in their various states and deadlock detection. * * 通过ThreadMXBean，ThreadDeadlockDetector检测状态、死锁 * * */public class ThreadStatesGaugeSet implements MetricSet { // do not compute stack traces. private final static int STACK_TRACE_DEPTH = 0; private final ThreadMXBean threads; private final ThreadDeadlockDetector deadlockDetector; /** * Creates a new set of gauges using the default MXBeans. */ public ThreadStatesGaugeSet() { this(ManagementFactory.getThreadMXBean(), new ThreadDeadlockDetector()); } /** * Creates a new set of gauges using the given MXBean and detector. * * @param threads a thread MXBean * @param deadlockDetector a deadlock detector */ public ThreadStatesGaugeSet(ThreadMXBean threads, ThreadDeadlockDetector deadlockDetector) { this.threads = threads; this.deadlockDetector = deadlockDetector; } /** * 获取监控线程的数据：线程的数目，守护线程的数目，死锁线程的数目，死锁线程 */ @Override public Map&lt;MetricName, Metric&gt; getMetrics() { final Map&lt;MetricName, Metric&gt; gauges = new HashMap&lt;MetricName, Metric&gt;(); //线程状态的数目 for (final Thread.State state : Thread.State.values()) { gauges.put(name(state.toString().toLowerCase(), \"count\"), new Gauge&lt;Integer&gt;() { @Override public Integer getValue() { return getThreadCount(state); } }); } //所有线程的数目 gauges.put(MetricName.build(\"count\"), new Gauge&lt;Integer&gt;() { @Override public Integer getValue() { return threads.getThreadCount(); } }); //守护线程的数目 gauges.put(MetricName.build(\"daemon.count\"), new Gauge&lt;Integer&gt;() { @Override public Integer getValue() { return threads.getDaemonThreadCount(); } }); //死锁线程的数目 gauges.put(MetricName.build(\"deadlock.count\"), new Gauge&lt;Integer&gt;() { @Override public Integer getValue() { return deadlockDetector.getDeadlockedThreads().size(); } }); //死锁线程 gauges.put(MetricName.build(\"deadlocks\"), new Gauge&lt;Set&lt;String&gt;&gt;() { @Override public Set&lt;String&gt; getValue() { return deadlockDetector.getDeadlockedThreads(); } }); return Collections.unmodifiableMap(gauges); } /** * 线程数目 * @param state * @return */ private int getThreadCount(Thread.State state) { //所有线程 final ThreadInfo[] allThreads = getThreadInfo(); int count = 0; for (ThreadInfo info : allThreads) { if (info != null &amp;&amp; info.getThreadState() == state) { count++; } } return count; } /** * 获取所有线程信息对象 * @return */ ThreadInfo[] getThreadInfo() { return threads.getThreadInfo(threads.getAllThreadIds(), STACK_TRACE_DEPTH); }} metrics-servletAbstractInstrumentedFilter.java实现Filter覆写：init，destroy，doFilter，嵌入监控对象。实现AsyncListener,覆写方法，嵌入监控对象123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288package io.dropwizard.metrics.servlet;import static io.dropwizard.metrics.MetricRegistry.name;import io.dropwizard.metrics.Counter;import io.dropwizard.metrics.Meter;import io.dropwizard.metrics.MetricRegistry;import io.dropwizard.metrics.Timer;import javax.servlet.*;import javax.servlet.http.HttpServletResponse;import javax.servlet.http.HttpServletResponseWrapper;import java.io.IOException;import java.util.Map;import java.util.Map.Entry;import java.util.concurrent.ConcurrentHashMap;import java.util.concurrent.ConcurrentMap;/** * {@link Filter} implementation which captures request information and a breakdown of the response * codes being returned. * &lt;p&gt; * 拦截请求，返回计数信息 * * 实现Filter覆写：init，destroy，doFilter，嵌入监控对象 * 实现AsyncListener,覆写方法，嵌入监控对象 * */public abstract class AbstractInstrumentedFilter implements Filter { static final String METRIC_PREFIX = \"name-prefix\"; private final String otherMetricName; //状态码 private final Map&lt;Integer, String&gt; meterNamesByStatusCode; //注册属性 private final String registryAttribute; // initialized after call of init method //状态码的meter private ConcurrentMap&lt;Integer, Meter&gt; metersByStatusCode; private Meter otherMeter; //超时 private Meter timeoutsMeter; //错误 private Meter errorsMeter; //有效请求 private Counter activeRequests; // private Timer requestTimer; /** * Creates a new instance of the filter. * * @param registryAttribute the attribute used to look up the metrics registry in the * servlet context * @param meterNamesByStatusCode A map, keyed by status code, of meter names that we are * interested in. * @param otherMetricName The name used for the catch-all meter. 其他metric名字 */ protected AbstractInstrumentedFilter(String registryAttribute, Map&lt;Integer, String&gt; meterNamesByStatusCode, String otherMetricName) { this.registryAttribute = registryAttribute; this.meterNamesByStatusCode = meterNamesByStatusCode; this.otherMetricName = otherMetricName; } /** * 初始化 * * @param filterConfig * @throws ServletException */ @Override public void init(FilterConfig filterConfig) throws ServletException { // final MetricRegistry metricsRegistry = getMetricsFactory(filterConfig); String metricName = filterConfig.getInitParameter(METRIC_PREFIX); //重新赋值metricName if (metricName == null || metricName.isEmpty()) { metricName = getClass().getName(); } //状态码 this.metersByStatusCode = new ConcurrentHashMap&lt;Integer, Meter&gt;(meterNamesByStatusCode .size()); //初始化状态的meter for (Entry&lt;Integer, String&gt; entry : meterNamesByStatusCode.entrySet()) { metersByStatusCode.put(entry.getKey(), metricsRegistry.meter(name(metricName, entry.getValue()))); } //-----初始化meter this.otherMeter = metricsRegistry.meter(name(metricName, otherMetricName)); this.timeoutsMeter = metricsRegistry.meter(name(metricName, \"timeouts\")); this.errorsMeter = metricsRegistry.meter(name(metricName, \"errors\")); this.activeRequests = metricsRegistry.counter(name(metricName, \"activeRequests\")); this.requestTimer = metricsRegistry.timer(name(metricName, \"requests\")); } /** * 获取MetricRegistry对象 * * @param filterConfig * @return */ private MetricRegistry getMetricsFactory(FilterConfig filterConfig) { final MetricRegistry metricsRegistry; final Object o = filterConfig.getServletContext().getAttribute(this.registryAttribute); if (o instanceof MetricRegistry) { metricsRegistry = (MetricRegistry) o; } else { metricsRegistry = new MetricRegistry(); } return metricsRegistry; } /** * 销毁 */ @Override public void destroy() { } @Override public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException { final StatusExposingServletResponse wrappedResponse = new StatusExposingServletResponse((HttpServletResponse) response); //+1 activeRequests.inc(); //计时 final Timer.Context context = requestTimer.time(); //错误：true，正确：false boolean error = false; try { chain.doFilter(request, wrappedResponse); } catch (IOException e) { error = true; throw e; } catch (ServletException e) { error = true; throw e; } catch (RuntimeException e) { error = true; throw e; } finally { //非错误，请求是sync if (!error &amp;&amp; request.isAsyncStarted()) { //执行sync listener request.getAsyncContext().addListener(new AsyncResultListener(context)); } else {//非，sync //时间停止 context.stop(); activeRequests.dec(); //错误 if (error) { //Meters用来度量某个时间段的平均处理次数 errorsMeter.mark(); } else { markMeterForStatusCode(wrappedResponse.getStatus()); } } } } /** * 根据status code 获取对应的meter * @param status */ private void markMeterForStatusCode(int status) { final Meter metric = metersByStatusCode.get(status); if (metric != null) { metric.mark(); } else { otherMeter.mark(); } } //status wrapp response private static class StatusExposingServletResponse extends HttpServletResponseWrapper { // The Servlet spec says: calling setStatus is optional, if no status is set, the default is 200. private int httpStatus = 200; public StatusExposingServletResponse(HttpServletResponse response) { super(response); } @Override public void sendError(int sc) throws IOException { httpStatus = sc; super.sendError(sc); } @Override public void sendError(int sc, String msg) throws IOException { httpStatus = sc; super.sendError(sc, msg); } @Override public void setStatus(int sc) { httpStatus = sc; super.setStatus(sc); } @Override public void setStatus(int sc, String sm) { httpStatus = sc; super.setStatus(sc, sm); } public int getStatus() { return httpStatus; } } /** * * Servlet 3.0 为异步处理提供了一个监听器，使用 AsyncListener 接口表示。它可以监控如下四种事件： 异步线程开始时，调用 AsyncListener 的 onStartAsync(AsyncEvent event) 方法； 异步线程出错时，调用 AsyncListener 的 onError(AsyncEvent event) 方法； 异步线程执行超时，则调用 AsyncListener 的 onTimeout(AsyncEvent event) 方法； 异步执行完毕时，调用 AsyncListener 的 onComplete(AsyncEvent event) 方法； 要注册一个 AsyncListener，只需将准备好的 AsyncListener 对象传递给 AsyncContext 对象的 addListener() 方法即可 * * */ private class AsyncResultListener implements AsyncListener { private Timer.Context context; //非异常：false。异常：true private boolean done = false; public AsyncResultListener(Timer.Context context) { this.context = context; } @Override public void onComplete(AsyncEvent event) throws IOException { //正常流程 if (!done) { HttpServletResponse suppliedResponse = (HttpServletResponse) event.getSuppliedResponse(); //时间停止 context.stop(); //请求-1 activeRequests.dec(); markMeterForStatusCode(suppliedResponse.getStatus()); } } @Override public void onTimeout(AsyncEvent event) throws IOException { context.stop(); activeRequests.dec(); //timeout meter timeoutsMeter.mark(); done = true; } @Override public void onError(AsyncEvent event) throws IOException { context.stop(); activeRequests.dec(); //errors errorsMeter.mark(); done = true; } @Override public void onStartAsync(AsyncEvent event) throws IOException { } }} InstrumentedFilter.java继承AbstractInstrumentedFilter，状态码前缀1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950package io.dropwizard.metrics.servlet;import java.util.HashMap;import java.util.Map;/** * Implementation of the {@link AbstractInstrumentedFilter} which provides a default set of response codes * to capture information about. &lt;p&gt;Use it in your servlet.xml like this:&lt;/p&gt; * &lt;pre&gt;{@code * &lt;filter&gt; * &lt;filter-name&gt;instrumentedFilter&lt;/filter-name&gt; * &lt;filter-class&gt;io.dropwizard.metrics.servlet.InstrumentedFilter&lt;/filter-class&gt; * &lt;/filter&gt; * &lt;filter-mapping&gt; * &lt;filter-name&gt;instrumentedFilter&lt;/filter-name&gt; * &lt;url-pattern&gt;/*&lt;/url-pattern&gt; * &lt;/filter-mapping&gt; * }&lt;/pre&gt; */public class InstrumentedFilter extends AbstractInstrumentedFilter { //注册属性 = InstrumentedFilter.registry public static final String REGISTRY_ATTRIBUTE = InstrumentedFilter.class.getName() + \".registry\"; //状态码-前缀 private static final String NAME_PREFIX = \"responseCodes.\"; private static final int OK = 200; private static final int CREATED = 201; private static final int NO_CONTENT = 204; private static final int BAD_REQUEST = 400; private static final int NOT_FOUND = 404; private static final int SERVER_ERROR = 500; /** * Creates a new instance of the filter. */ public InstrumentedFilter() { super(REGISTRY_ATTRIBUTE, createMeterNamesByStatusCode(), NAME_PREFIX + \"other\"); } //状态码 - 名字 private static Map&lt;Integer, String&gt; createMeterNamesByStatusCode() { final Map&lt;Integer, String&gt; meterNamesByStatusCode = new HashMap&lt;Integer, String&gt;(6); meterNamesByStatusCode.put(OK, NAME_PREFIX + \"ok\"); meterNamesByStatusCode.put(CREATED, NAME_PREFIX + \"created\"); meterNamesByStatusCode.put(NO_CONTENT, NAME_PREFIX + \"noContent\"); meterNamesByStatusCode.put(BAD_REQUEST, NAME_PREFIX + \"badRequest\"); meterNamesByStatusCode.put(NOT_FOUND, NAME_PREFIX + \"notFound\"); meterNamesByStatusCode.put(SERVER_ERROR, NAME_PREFIX + \"serverError\"); return meterNamesByStatusCode; }} InstrumentedFilterContextListener.java实现ServletContextListener监听器，嵌入监控对象123456789101112131415161718192021222324252627282930313233343536package io.dropwizard.metrics.servlet;import io.dropwizard.metrics.MetricRegistry;import javax.servlet.ServletContextEvent;import javax.servlet.ServletContextListener;/** * A listener implementation which injects a {@link MetricRegistry} instance into the servlet * context. Implement {@link #getMetricRegistry()} to return the {@link MetricRegistry} for your * application. * * 实现ServletContextListener监听器，嵌入监控对象 * */public abstract class InstrumentedFilterContextListener implements ServletContextListener { /** * @return the {@link MetricRegistry} to inject into the servlet context. * * 获取注册的metric * */ protected abstract MetricRegistry getMetricRegistry(); @Override public void contextInitialized(ServletContextEvent sce) { //设request值attribute：metric //arrribute属性 - 值 sce.getServletContext().setAttribute(InstrumentedFilter.REGISTRY_ATTRIBUTE, getMetricRegistry()); } @Override public void contextDestroyed(ServletContextEvent sce) { }} metrics-servletsAdminServlet.java123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142package io.dropwizard.metrics.servlets;import javax.servlet.ServletConfig;import javax.servlet.ServletException;import javax.servlet.http.HttpServlet;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;import java.io.IOException;import java.io.PrintWriter;import java.text.MessageFormat;/** * 不同类型的servlet监测 */public class AdminServlet extends HttpServlet { public static final String DEFAULT_HEALTHCHECK_URI = \"/healthcheck\"; public static final String DEFAULT_METRICS_URI = \"/metrics\"; public static final String DEFAULT_PING_URI = \"/ping\"; public static final String DEFAULT_THREADS_URI = \"/threads\"; public static final String DEFAULT_CPU_PROFILE_URI = \"/pprof\"; public static final String METRICS_URI_PARAM_KEY = \"metrics-uri\"; public static final String PING_URI_PARAM_KEY = \"ping-uri\"; public static final String THREADS_URI_PARAM_KEY = \"threads-uri\"; public static final String HEALTHCHECK_URI_PARAM_KEY = \"healthcheck-uri\"; public static final String SERVICE_NAME_PARAM_KEY= \"service-name\"; public static final String CPU_PROFILE_URI_PARAM_KEY = \"cpu-profile-uri\"; private static final String TEMPLATE = String.format( \"&lt;!DOCTYPE HTML PUBLIC \\\"-//W3C//DTD HTML 4.01 Transitional//EN\\\"%n\" + \" \\\"http://www.w3.org/TR/html4/loose.dtd\\\"&gt;%n\" + \"&lt;html&gt;%n\" + \"&lt;head&gt;%n\" + \" &lt;title&gt;Metrics{10}&lt;/title&gt;%n\" + \"&lt;/head&gt;%n\" + \"&lt;body&gt;%n\" + \" &lt;h1&gt;Operational Menu{10}&lt;/h1&gt;%n\" + \" &lt;ul&gt;%n\" + \" &lt;li&gt;&lt;a href=\\\"{0}{1}?pretty=true\\\"&gt;Metrics&lt;/a&gt;&lt;/li&gt;%n\" + \" &lt;li&gt;&lt;a href=\\\"{2}{3}\\\"&gt;Ping&lt;/a&gt;&lt;/li&gt;%n\" + \" &lt;li&gt;&lt;a href=\\\"{4}{5}\\\"&gt;Threads&lt;/a&gt;&lt;/li&gt;%n\" + \" &lt;li&gt;&lt;a href=\\\"{6}{7}?pretty=true\\\"&gt;Healthcheck&lt;/a&gt;&lt;/li&gt;%n\" + \" &lt;li&gt;&lt;a href=\\\"{8}{9}\\\"&gt;CPU Profile&lt;/a&gt;&lt;/li&gt;%n\" + \" &lt;li&gt;&lt;a href=\\\"{8}{9}?state=blocked\\\"&gt;CPU Contention&lt;/a&gt;&lt;/li&gt;%n\" + \" &lt;/ul&gt;%n\" + \"&lt;/body&gt;%n\" + \"&lt;/html&gt;\" ); private static final String CONTENT_TYPE = \"text/html\"; private static final long serialVersionUID = -2850794040708785318L; private transient HealthCheckServlet healthCheckServlet; private transient MetricsServlet metricsServlet; private transient PingServlet pingServlet; private transient ThreadDumpServlet threadDumpServlet; private transient CpuProfileServlet cpuProfileServlet; private transient String metricsUri; private transient String pingUri; private transient String threadsUri; private transient String healthcheckUri; private transient String cpuprofileUri; private transient String serviceName; /** * 初始化不同的servlet数据 * @param config * @throws ServletException */ @Override public void init(ServletConfig config) throws ServletException { super.init(config); this.healthCheckServlet = new HealthCheckServlet(); healthCheckServlet.init(config); this.metricsServlet = new MetricsServlet(); metricsServlet.init(config); this.pingServlet = new PingServlet(); pingServlet.init(config); this.threadDumpServlet = new ThreadDumpServlet(); threadDumpServlet.init(config); this.cpuProfileServlet = new CpuProfileServlet(); cpuProfileServlet.init(config); this.metricsUri = getParam(config.getInitParameter(METRICS_URI_PARAM_KEY), DEFAULT_METRICS_URI); this.pingUri = getParam(config.getInitParameter(PING_URI_PARAM_KEY), DEFAULT_PING_URI); this.threadsUri = getParam(config.getInitParameter(THREADS_URI_PARAM_KEY), DEFAULT_THREADS_URI); this.healthcheckUri = getParam(config.getInitParameter(HEALTHCHECK_URI_PARAM_KEY), DEFAULT_HEALTHCHECK_URI); this.cpuprofileUri = getParam(config.getInitParameter(CPU_PROFILE_URI_PARAM_KEY), DEFAULT_CPU_PROFILE_URI); this.serviceName = getParam(config.getInitParameter(SERVICE_NAME_PARAM_KEY), null); } @Override protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException { final String path = req.getContextPath() + req.getServletPath(); resp.setStatus(HttpServletResponse.SC_OK); resp.setHeader(\"Cache-Control\", \"must-revalidate,no-cache,no-store\"); resp.setContentType(CONTENT_TYPE); final PrintWriter writer = resp.getWriter(); try { writer.println(MessageFormat.format(TEMPLATE, path, metricsUri, path, pingUri, path, threadsUri, path, healthcheckUri, path, cpuprofileUri, serviceName == null ? \"\" : \" (\" + serviceName + \")\")); } finally { writer.close(); } } /** * * 执行不同metric的servlet的service * */ @Override protected void service(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException { final String uri = req.getPathInfo(); if (uri == null || uri.equals(\"/\")) { super.service(req, resp); } else if (uri.equals(healthcheckUri)) { healthCheckServlet.service(req, resp); } else if (uri.startsWith(metricsUri)) { metricsServlet.service(req, resp); } else if (uri.equals(pingUri)) { pingServlet.service(req, resp); } else if (uri.equals(threadsUri)) { threadDumpServlet.service(req, resp); } else if (uri.equals(cpuprofileUri)) { cpuProfileServlet.service(req, resp); } else { resp.sendError(HttpServletResponse.SC_NOT_FOUND); } } private static String getParam(String initParam, String defaultValue) { return initParam == null ? defaultValue : initParam; }} CpuProfileServlet.javacpu概况的servlet，快照时候需要加锁12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788package io.dropwizard.metrics.servlets;import java.io.IOException;import java.io.OutputStream;import java.util.concurrent.locks.Lock;import java.util.concurrent.locks.ReentrantLock;import javax.servlet.ServletException;import javax.servlet.http.HttpServlet;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;import org.joda.time.Duration;import com.papertrail.profiler.CpuProfile;/** * An HTTP servlets which outputs a &lt;a href=\"https://github.com/gperftools/gperftools\"&gt;pprof&lt;/a&gt; parseable response. * * cpu 概况 */public class CpuProfileServlet extends HttpServlet { private static final long serialVersionUID = -668666696530287501L; private static final String CONTENT_TYPE = \"pprof/raw\"; private static final String CACHE_CONTROL = \"Cache-Control\"; private static final String NO_CACHE = \"must-revalidate,no-cache,no-store\"; /** * 处理线程安全 */ private final Lock lock = new ReentrantLock(); @Override protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException { //持续 int duration = 10; if (req.getParameter(\"duration\") != null) { try { duration = Integer.parseInt(req.getParameter(\"duration\")); } catch (NumberFormatException e) { duration = 10; } } //频率 int frequency = 100; if (req.getParameter(\"frequency\") != null) { try { frequency = Integer.parseInt(req.getParameter(\"frequency\")); } catch (NumberFormatException e) { frequency = 100; } } //线程状态 final Thread.State state; if (\"blocked\".equalsIgnoreCase(req.getParameter(\"state\"))) { state = Thread.State.BLOCKED; } else { state = Thread.State.RUNNABLE; } resp.setStatus(HttpServletResponse.SC_OK); resp.setHeader(CACHE_CONTROL, NO_CACHE); resp.setContentType(CONTENT_TYPE); final OutputStream output = resp.getOutputStream(); try { doProfile(output, duration, frequency, state); } finally { output.close(); } } //获取cpu快照 protected void doProfile(OutputStream out, int duration, int frequency, Thread.State state) throws IOException { if (lock.tryLock()) { try { //单进程的获取cpu信息 CpuProfile profile = CpuProfile.record(Duration.standardSeconds(duration), frequency, state); if (profile == null) { throw new RuntimeException(\"could not create CpuProfile\"); } profile.writeGoogleProfile(out); return; } finally { lock.unlock(); } } throw new RuntimeException(\"Only one profile request may be active at a time\"); }} HealthCheckServlet.java健康监测，通过对象或者线程服务123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170package io.dropwizard.metrics.servlets;import com.fasterxml.jackson.databind.ObjectMapper;import com.fasterxml.jackson.databind.ObjectWriter;import io.dropwizard.metrics.json.HealthCheckModule;import io.dropwizard.metrics.health.HealthCheck;import io.dropwizard.metrics.health.HealthCheckRegistry;import javax.servlet.*;import javax.servlet.http.HttpServlet;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;import java.io.IOException;import java.io.OutputStream;import java.util.Map;import java.util.SortedMap;import java.util.concurrent.ExecutorService;/** * 健康监测，通过对象或者线程服务 */public class HealthCheckServlet extends HttpServlet { /** * 自定义此servlet监听器 */ public static abstract class ContextListener implements ServletContextListener { /** * @return the {@link HealthCheckRegistry} to inject into the servlet context. * * 获取对象 * */ protected abstract HealthCheckRegistry getHealthCheckRegistry(); /** * @return the {@link ExecutorService} to inject into the servlet context, or {@code null} * if the health checks should be run in the servlet worker thread. * * */ protected ExecutorService getExecutorService() { // don't use a thread pool by default return null; } @Override public void contextInitialized(ServletContextEvent event) { final ServletContext context = event.getServletContext(); context.setAttribute(HEALTH_CHECK_REGISTRY, getHealthCheckRegistry()); context.setAttribute(HEALTH_CHECK_EXECUTOR, getExecutorService()); } @Override public void contextDestroyed(ServletContextEvent event) { // no-op } } //////////////////////////////////////////////////////////////////////////////// public static final String HEALTH_CHECK_REGISTRY = HealthCheckServlet.class.getCanonicalName() + \".registry\"; public static final String HEALTH_CHECK_EXECUTOR = HealthCheckServlet.class.getCanonicalName() + \".executor\"; private static final long serialVersionUID = -8432996484889177321L; private static final String CONTENT_TYPE = \"application/json\"; /** * 健康监测注册对象 */ private transient HealthCheckRegistry registry; /** * 线程执行服务 */ private transient ExecutorService executorService; private transient ObjectMapper mapper; public HealthCheckServlet() { } public HealthCheckServlet(HealthCheckRegistry registry) { this.registry = registry; } @Override public void init(ServletConfig config) throws ServletException { super.init(config); //初始化 HealthCheckRegistry 对象 if (null == registry) { final Object registryAttr = config.getServletContext().getAttribute(HEALTH_CHECK_REGISTRY); //初始化注册对象 if (registryAttr instanceof HealthCheckRegistry) { this.registry = (HealthCheckRegistry) registryAttr; } else { throw new ServletException(\"Couldn't find a HealthCheckRegistry instance.\"); } } //初始化线程池 final Object executorAttr = config.getServletContext().getAttribute(HEALTH_CHECK_EXECUTOR); if (executorAttr instanceof ExecutorService) { this.executorService = (ExecutorService) executorAttr; } //json对象 this.mapper = new ObjectMapper().registerModule(new HealthCheckModule()); } @Override protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException { //检测 health 返回结果 final SortedMap&lt;String, HealthCheck.Result&gt; results = runHealthChecks(); resp.setContentType(CONTENT_TYPE); resp.setHeader(\"Cache-Control\", \"must-revalidate,no-cache,no-store\"); //检测结果 if (results.isEmpty()) { resp.setStatus(HttpServletResponse.SC_NOT_IMPLEMENTED); } else { //是否健康 if (isAllHealthy(results)) { resp.setStatus(HttpServletResponse.SC_OK); } else {//错误 resp.setStatus(HttpServletResponse.SC_INTERNAL_SERVER_ERROR); } } final OutputStream output = resp.getOutputStream(); try { getWriter(req).writeValue(output, results); } finally { output.close(); } } private ObjectWriter getWriter(HttpServletRequest request) { final boolean prettyPrint = Boolean.parseBoolean(request.getParameter(\"pretty\")); if (prettyPrint) { return mapper.writerWithDefaultPrettyPrinter(); } return mapper.writer(); } /** * 运行健康监测 * @return */ private SortedMap&lt;String, HealthCheck.Result&gt; runHealthChecks() { if (executorService == null) { return registry.runHealthChecks(); } return registry.runHealthChecks(executorService); } /** * 检测当前结果是否健康 * @param results * @return */ private static boolean isAllHealthy(Map&lt;String, HealthCheck.Result&gt; results) { for (HealthCheck.Result result : results.values()) { if (!result.isHealthy()) { return false; } } return true; }}","link":"/metric/"},{"title":"Tomcat（七）设计模式总结","text":"1 前言 2 外观模式 3 观察者模式 4 责任链模式 5 模版方法模式 6 命令模式 1 前言分析一下Tomcat中所涉及到设计模式，本文我们将主要来分析外观模式，观察者模式，责任链模式，模板方法模式,命令模式。在开始本文之前，先说明一下对于设计模式的一点看法。曾经经常看到网上有人讨论设计模式，也偶尔会遇到有人非要严格按照GOF设计模式的类图以及其中的角色去套用别人的设计，只要类图不一样，或者角色多了或者少了就会觉得怎么和官方定义的模式不一样，我个人认为这是对设计模式的误解。设计模式其实不仅仅存在软件行业，各行各业其实都有模式，它是所在行业对一些通用问题解决方案的总结和抽象，是一种对常见问题的抽象的解决方案，不是一种具体的实现，所以我觉得在讨论设计模式的时候，千万别一个劲的套用GOF设计模式中的类图以及其中所涉及到的角色，而是要理解设计模式的思维，理解设计模式的使用场景，在代码层面上有无数种实现，无需照搬(或者copy)代码。 2 外观模式在Tomcat中对于Request，Response，StandardSession，ApplicationContext，StandardWrapper都采用外观模式，它的类图如下。通过上图，可以看到RequestFacade包装了Request，它们都实现了HttpServletRequest，当传递Request对象给应用的时候，其实是返回了RequestFacade对象，而RequestFacade内部可以根据是否自定义了安全管理器来进行相应的操作。对于Response，StandardSession等处理是类似的，这里就不写了。 3 观察者模式Tomcat中需要对很多组件进行生命周期管理，为此Tomcat抽象了统一的生命周期管理骨架，通过这个骨架将所有需要进行生命周期管理的类都纳入进来管理，而这里的骨架的类图如下。通过上图可以看出Tomcat抽象了一个LifecycleSupport的类，而所有需要生命周期管理的组件通过LifecycleSupport类通知对某个生命周期事件感兴趣的观察者，而所有的观察者都需要实现LifecycleListener。关注一下EventObject对象，它里面定义了一个事件源对象，所谓事件源就是事件发生的地方，而在Tomcat的设计中，事件源就是实现了LifeCycle接口的各个需要管理生命周期的组件，这里LifecycleSupport和LifeCycleBase之间是双向的关联，LifeCycleSupport关联LifeCycle对象就是为了实现事件源的传递，这样在LifeCycleSupport触发事件的时候，可以通过事件源构建EventObject。这样以来LifecycleListener就可以通过事件对象获取到事件源，从而做一些与事件源相关的操作。 4 责任链模式Tomcat中请求的处理流程其实就是采用了责任链模式，关于Tomcat请求处理，可以参考下Tomcat请求处理流程，Tomcat中责任链模式的实现的类图如下图所示:从上图中，可以看到每一个容器都会有一个Pipeline，而一个Pipeline又会具有多个Valve阀门，其中StandardEngine对应的阀门是StandardEngineValve，StandardHost对应的阀门是StandardHostValve，StandardContext对应的阀门是StandardContextValve，StandardWrapper对应的阀门是StandardWrapperValve。这里每一Pipeline就好比一个管道，而每一Valve就相当于一个阀门，一个管道可以有多个阀门，而对于阀门来说有两种，一种阀门在处理完自己的事情以后，只需要将工作委托给下一个和自己在同一管道的阀门即可，第二种阀门是负责衔接各个管道的，它负责将请求传递给下个管道的第一个阀门处理，而这种阀门叫Basic阀门，它是每个管道中最后一个阀门，上面的Standard*Valve都属于第二种阀门。可以形象的通过下图来描述上面的过程。通过上图，可以很清楚的了解到Tomcat的请求处理流程。当用户请求服务器的时候，Connector会接受请求，从Socket连接中根据http协议解析出对应的数据，构造Request和Response对象，然后传递给后面的容器处理，顶层容器是StandardEngine，StandardEngine处理请求其实是通过容器的Pipeline进行的，而Pipeline其实最终是通过管道上的各个阀门进行的，当请求到达StandardEngineValve的时候，此阀门会将请求转发给对应StandardHost的Pipeline的第一个阀门处理，然后以此最终到达StandardHostValve阀门，它又会将请求转发给StandardContext的Pipeline的第一个阀门，这样以此类推，最后到达StandardWrapperValve，此阀门会根据Request来构建对应的Servlet，并将请求转发给对应的HttpServlet处理。从这里我们可以看出其实Tomcat核心处理流程就是通过责任链一步步的组装起来的。 5 模版方法模式Tomcat中关于生命周期管理的地方很好应用了模板方法模式，在一个组件的生命周期中都会涉及到init()初始化，start()启动，stop()停止，destory()销毁，而对于每一个生命周期阶段其实都有固定一些事情要做，比如判断前置状态，设置后置状态，以及通知状态变更事件的监听者等，而这些工作其实是可以固化的，所以Tomcat中就将每个生命周期阶段公共的部分固化，然后通过initInternal，startInternal，stopInternal，destoryInternal这几个钩子方法开放给子类去实现具体的逻辑。Tomcat中关于模板方法模式的实现如下图所示。 6 命令模式命令模式在Tomcat中主要是应用在对请求的处理过程中，Tomcat的实现中，根据它支持两种协议AJP和Http，而在具体的IO实现中，又分为Java同步阻赛IO，Java同步非祖塞IO，以及采用APRApache Portable Runtime支持库，因此Tomcat统一了org.apache.coyote.Processor接口，根据协议和IO实现的不同通过不同的Process子类去实现，Connector作为客户端每次只需要根据具体的协议和IO实现创建对应的Process执行即可。下面来看一下命令模式在Tomcat中实现的相关类图。通过上图可以清楚的看到，Tomcat首先根据协议的不同将Processor分为了Ajp和Http两组，然后又根据具体的IO实现方式的不同，将每一组都会实现同步祖塞IO，同步非祖塞IO，以及APR的Processor。再来看一个类图，就可以更加清楚的看到Tomcat中是如何利用命令模式来根据不同的协议以及IO实现方式来处理请求的。看一下Tomcat中关于ProtocolHandler的类图。通过上图可以看到针对每一种协议和IO实现方式的组合，都会有相应的协议处理类，而每个协议处理类都会有一个Handler，而每一个Handler在运行的时候就会创建出对应的Processor，比如AjpProtocol.AjpConnectionHandler创建AjpProcessor处理器，其它的类似。通过上面的描述，可以看出Tomcat接受请求的处理流程如下。Connector通过对应的Endpint监听Socket连接，当对应的端口有连接进来的时候，对应的Endpoint就会通过对应的Handler类处理，而Handler处理的时候，又会创建对应的Processor处理，而对应的Processor命令对象会解析Socket流的数据，然后生成Request和Response对象，最终通过上面说的责任链模式一步步的通过各个容器。","link":"/Tomcat-7/"},{"title":"VIM 命令","text":"1 移动光标 命令 说明 h,j,k,l 上，下，左，右 ctrl-e 移动页面 ctrl-f 上翻一页 ctrl-b 下翻一页 ctrl-u 上翻半页 ctrl-d 下翻半页 w 跳到下一个字首，按标点或单词分割 W 跳到下一个字首，长跳，如end-of-line被认为是一个字 e 跳到下一个字尾 E 跳到下一个字尾，长跳 b 跳到上一个字 B 跳到上一个字，长跳 0 跳至行首，不管有无缩进，就是跳到第0个字符 ^ 跳至行首的第一个字符 $ 跳至行尾 gg 跳至文首 G 调至文尾 5gg/5G 调至第5行 gd 跳至当前光标所在的变量的声明处 fx 在当前行中找x字符，找到了就跳转至 ; 重复上一个f命令，而不用重复的输入fx * 查找光标所在处的单词，向下查找 # 查找光标所在处的单词，向上查找 2 删除复制 命令 说明 dd 删除光标所在行 dw 删除一个字(word) d/D 删除到行末x，删除当前字符X，删除前一个字符yy，复制一行yw，复制一个字y/D p 粘贴粘贴板的内容到当前行的下面 P 粘贴粘贴板的内容到当前行的上面 3 插入模式 命令 说明 i 从当前光标处进入插入模式 I 进入插入模式，并置光标于行首 a 追加模式，置光标于当前光标之后 A 追加模式，置光标于行末 o 在当前行之下新加一行，并进入插入模式 O 在当前行之上新加一行，并进入插入模式 Esc 退出插入模式 4 编辑 命令 说明 J 将下一行和当前行连接为一行 cc 删除当前行并进入编辑模式 cw 删除当前字，并进入编辑模式 c$ 擦除从当前位置至行末的内容，并进入编辑模式 s 删除当前字符并进入编辑模式 S 删除光标所在行并进入编辑模式 xp 交换当前字符和下一个字符 u 撤销 ctrl+r 重做 ~ 切换大小写，当前字符 &gt;&gt; 将当前行右移一个单位 &lt;&lt; 将当前行左移一个单位(一个tab符) == 自动缩进当前行 5 查找替换 命令 说明 /pattern 向后搜索字符串pattern ?pattern 向前搜索字符串pattern \\c 忽略大小写 \\C 大小写敏感 n 下一个匹配(如果是/搜索，则是向下的下一个，?搜索则是向上的下一个) N 上一个匹配(同上) :%s/old/new/g 搜索整个文件，将所有的old替换为new :%s/old/new/gc 搜索整个文件，将所有的old替换为new，每次都要你确认是否替换 6 退出编辑器 命令 说明 :w 将缓冲区写入文件，即保存修改 :wq 保存修改并退出 :x 保存修改并退出 :q 退出，如果对缓冲区进行过修改，则会提示 :q! 强制退出，放弃修改 7 多文件编辑 命令 说明 vim file1.. 同时打开多个文件 :args 显示当前编辑文件 :next 切换到下个文件 :prev 切换到前个文件 :next! 不保存当前编辑文件并切换到下个文件 :prev! 不保存当前编辑文件并切换到上个文件 :wnext 保存当前编辑文件并切换到下个文件 :wprev 保存当前编辑文件并切换到上个文件 :first 定位首文件 :last 定位尾文件 ctrl+^ 快速在最近打开的两个文件间切换 :split[sp] 把当前文件水平分割 :split file 把当前窗口水平分割， file :vsplit[vsp] file 把当前窗口垂直分割， file :new file 同split file :close 关闭当前窗口 :only 只显示当前窗口， 关闭所有其他的窗口 :all 打开所有的窗口 :vertical all 打开所有的窗口， 垂直打开 :qall 对所有窗口执行：q操作 :qall! 对所有窗口执行：q!操作 :wall 对所有窗口执行：w操作 :wqall 对所有窗口执行：wq操作 ctrl-w h 跳转到左边的窗口 ctrl-w j 跳转到下面的窗口 ctrl-w k 跳转到上面的窗口 ctrl-w l 跳转到右边的窗口 ctrl-w t 跳转到最顶上的窗口 ctrl-w b 跳转到最底下的窗口 8 多标签编辑 命令 说明 :tabedit file 在新标签中打开文件file :tab split file 在新标签中打开文件file :tabp 切换到前一个标签 :tabn 切换到后一个标签 :tabc 关闭当前标签 :tabo 关闭其他标签 gt 到下一个tab gT 到上一个tab 0gt 跳到第一个tab 5gt 跳到第五个tab 9 执行shell命令 在命令模式下输入:sh，可以运行相当于在字符模式下，到输入结束想回到vim编辑器中用exit，ctrl+D返回vim编辑器 可以!command，运行结束后自动回到vim编辑器中 用Ctrl+Z回到shell，用fg返回编辑 :!make直接在当前目录下运行make指令 10 VIM启动项 命令 说明 -o[n] 以水平分屏的方式打开多个文件 -O[n] 以垂直分屏的方式打开多个文件 11 自动排版在粘贴了一些代码之后，vim变得比较乱，只要执行gg=G就能搞定。 12 如何在vim中编译程序 在vim中可以完成make，而且可以将编译的结果也显示在vim里，先执行:copen命令，将结果输出的窗口打开，然后执行:make。 编译后的结果就显示在copen打开的小窗口里了，而且用鼠标双击错误信息，就会跳转到发生错误的行。 13 buffer操作buffer状态命令 | 说明———|———-- | 非活动的缓冲区a | 当前被激活缓冲区h | 隐藏的缓冲区% | 当前的缓冲区# | 交换缓冲区= | 只读缓冲区+ | 已经更改的缓冲区 14 VIM 操作目录14.1 打开目录 命令 说明 vim . vim a-path/ 14.2 以下操作在操作目录时生效p,P,t,u,U,x,v,o,r,s命令 | 说明———|———-c | 使当前打开的目录成为当前目录d | 创建目录% | 创建文件D | 删除文件/目录- | 转到上层目录gb | 转到上一个bookmarked directoryi | 改变目录文件列表方式^l | 刷新当前打开的目录mf | 标记文件mu | unmark all marked filesmz | Compress/decompress marked filesgh | 显示/不显示隐藏文件(dot-files)^h | 编辑隐藏文件列表a | 转换显示模式，all - hide - unhideqf | diplay infomation about fileqb | list the bookmarked directories and directory traversal historygi | Display information on filemd | 将标记的文件(mf标记文件)使用diff模式me | 编辑标记的文件，只显示一个，其余放入buffer中 14.3 复制，移动文件 命令 说明 mt 移动到的目录 mf 标记要移动的文件 mc 移动/复制 R 移动文件 14.4 打开当前编辑文件的目录 命令 说明 :Explore :Hexplore :Nexplore :Pexplore :Sexplore :Texplore :Vexplore","link":"/VIM-Command/"},{"title":"变位词(编程珠玑)","text":"1 问题 2 解决思路 2.1 sign程序 2.2 sort程序 2.3 squash程序 3 程序代码 C++代码 Java代码 1 问题给定一本英语单词词典，请找出所有的变位词集。所谓的变位词是指，组成各个单词的字母完全相同，只是字母排列的顺序不同。例如，“pots”,”stop”和“tops”互为变位词，因为每个单词都可以通过改变其他单词中字母的顺序来得到。 2 解决思路编程珠玑的变位词程序要按照三个步骤来执行，其中前一个步骤程序的输出作为下一个步骤程序的输入： 程序标识单词。 程序排序标识后的文件。 程序将这些单词压缩为每个变位词类一行的形式。 单词的字典的处理过程：由以上可看出需要三个程序的处理。 2.1 sign程序假设输入单词的长度不超过100，对每个输入的单词依照字母进行排序，将结果输入这个单词所对应的“签名”。 2.2 sort程序程序排序后的输出的“签名”，对其输出的结果排序，如上图。 2.3 squash程序将同一个变位词类中的各个单词放到同一行中。 3 程序代码C++代码完整例子：先按照字符排序，比较是否是同一个字符串，输出字符串12345678910111213141516171819202122232425262728293031323334353637383940414243444546#include&lt;iostream&gt;#include&lt;cstring&gt;#include&lt;algorithm&gt;using namespace std;//最简洁的换位词void main(){ char s1[1000]=\"stop\",s2[1000]=\"opst\"; int len1,len2; //字符的长度 len1=strlen(s1); len2=strlen(s2); cout&lt;&lt;\"排序前\"&lt;&lt;endl; cout&lt;&lt;\"s1---------------------------\"&lt;&lt;endl; for(int i=0;i&lt;len1;i++){ cout&lt;&lt;s1[i]; } cout&lt;&lt;\"-----------------------------\"&lt;&lt;endl; cout&lt;&lt;\"s2---------------------------\"&lt;&lt;endl; for(int i=0;i&lt;len2;i++){ cout&lt;&lt;s2[i]; } cout&lt;&lt;\"-----------------------------\"&lt;&lt;endl; //对给定区间所有元素进行排序 //有一个数组int a[100]，要对从a[0]到a[99]的元素进行排序，只要写sort(a,a+100)就行了，默认的排序方式是升序 //按ASCII值大小排序 sort(s1,s1+len1); sort(s2,s2+len2); cout&lt;&lt;\"排序后\"&lt;&lt;endl; cout&lt;&lt;\"s1---------------------------\"&lt;&lt;endl; for(int i=0;i&lt;len1;i++){ cout&lt;&lt;s1[i]; } cout&lt;&lt;\"-----------------------------\"&lt;&lt;endl; cout&lt;&lt;\"s2---------------------------\"&lt;&lt;endl; for(int i=0;i&lt;len2;i++){ cout&lt;&lt;s2[i]; } cout&lt;&lt;\"-----------------------------\"&lt;&lt;endl; //两个字符串自左向右逐个字符相比（按ASCII值大小相比较） if(strcmp(s1,s2)==0){ cout&lt;&lt;\"Yes\"&lt;&lt;endl; }else{ cout&lt;&lt;\"No\"&lt;&lt;endl; }} 字符排序：1234567891011121314151617181920212223242526272829303132#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;string.h&gt;#include &lt;algorithm&gt;using namespace std;#define WORDMAX 100//由小到大排序int charcomp(const void *x , const void *y){ return *(char *)x - *(char *)y;}int main(){ char word[WORDMAX], sig[WORDMAX]; while (scanf(\"%s\", word) != EOF) { strcpy(sig, word); //1 待排序数组首地址 //2 数组中待排序元素数量 //3 各元素的占用空间大小 //4 指向函数的指针，用于确定排序的顺序（排序规则） //qsort(sig, strlen(sig), sizeof(char), charcomp); //另一种排序 sort(sig,sig+strlen(sig)); printf(\"%s %s\\n\", sig, word); } return 0;} Java代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687package 换位词;import java.util.ArrayList;import java.util.List;import java.util.Map;import java.util.Set;import java.util.TreeMap;public class WordManipulation { private Map&lt;String, List&lt;String&gt;&gt; result; private String[] wordInput; public WordManipulation(String[] word) { this.wordInput = word; } /** * string sort to find a lable like (mississippi,i4m1p2s4) 字符按照每个字母标识数量 * * @param word * The string to be sorted * @return the string sorted */ private String sort(String word) { // 按照字符（ASCII排序） // &lt;字符，相同字符数目&gt; Map&lt;Character, Integer&gt; map = new TreeMap&lt;Character, Integer&gt;(); for (int i = 0; i &lt; word.length(); i++) { char temp = word.charAt(i); if (map.get(temp) == null) { map.put(temp, 1); } else { int value = map.get(temp); map.put(temp, ++value); } } return map.toString(); } /** * squash the same label into a ArrayList 计算字符串是否是同一个，然后添加到同一个list中 * * @param map */ private void squash(Map&lt;String, String&gt; map) { result = new TreeMap&lt;String, List&lt;String&gt;&gt;(); Set&lt;Map.Entry&lt;String, String&gt;&gt; entrySet = map.entrySet(); for (Map.Entry&lt;String, String&gt; entry : entrySet) { // 单词名字 String strKey = entry.getKey(); // 经过sort排序过后的字符相同数字 String strValue = entry.getValue(); System.out.println(strKey + \" ----&gt; \" + strValue); List&lt;String&gt; resultList; if (result.get(strValue) == null) { resultList = new ArrayList&lt;String&gt;(); } else { resultList = result.get(strValue); } resultList.add(strKey); result.put(strValue, resultList); } } /** * calculate the anagram */ public void doCalculate() { Map&lt;String, String&gt; temp = new TreeMap&lt;String, String&gt;(); for (int i = 0; i &lt; this.wordInput.length; i++) { temp.put(this.wordInput[i], sort(this.wordInput[i])); } squash(temp); print(); } private void print() { System.out.println(result.values()); } public static void main(String[] args) { String[] a = { \"stop\", \"pots\", \"snap\", \"naps\" }; WordManipulation wm = new WordManipulation(a); wm.doCalculate(); }}","link":"/Variant/"}],"tags":[{"name":"JDK6 源码","slug":"JDK6-源码","link":"/tags/JDK6-源码/"},{"name":"Java","slug":"Java","link":"/tags/Java/"},{"name":"计算机基础","slug":"计算机基础","link":"/tags/计算机基础/"},{"name":"算法","slug":"算法","link":"/tags/算法/"},{"name":"动态规划算法","slug":"动态规划算法","link":"/tags/动态规划算法/"},{"name":"手机游戏","slug":"手机游戏","link":"/tags/手机游戏/"},{"name":"最优路径算法","slug":"最优路径算法","link":"/tags/最优路径算法/"},{"name":"Spring","slug":"Spring","link":"/tags/Spring/"},{"name":"贪心算法","slug":"贪心算法","link":"/tags/贪心算法/"},{"name":"回溯算法","slug":"回溯算法","link":"/tags/回溯算法/"},{"name":"分支限界算法","slug":"分支限界算法","link":"/tags/分支限界算法/"},{"name":"编程珠玑","slug":"编程珠玑","link":"/tags/编程珠玑/"},{"name":"Centos","slug":"Centos","link":"/tags/Centos/"},{"name":"Linux","slug":"Linux","link":"/tags/Linux/"},{"name":"分治算法","slug":"分治算法","link":"/tags/分治算法/"},{"name":"并发","slug":"并发","link":"/tags/并发/"},{"name":"一致性哈希算法","slug":"一致性哈希算法","link":"/tags/一致性哈希算法/"},{"name":"源码","slug":"源码","link":"/tags/源码/"},{"name":"开源项目","slug":"开源项目","link":"/tags/开源项目/"},{"name":"分词算法","slug":"分词算法","link":"/tags/分词算法/"},{"name":"Effect Java","slug":"Effect-Java","link":"/tags/Effect-Java/"},{"name":"书","slug":"书","link":"/tags/书/"},{"name":"设计模式","slug":"设计模式","link":"/tags/设计模式/"},{"name":"散列表","slug":"散列表","link":"/tags/散列表/"},{"name":"数据结构","slug":"数据结构","link":"/tags/数据结构/"},{"name":"华为","slug":"华为","link":"/tags/华为/"},{"name":"面试","slug":"面试","link":"/tags/面试/"},{"name":"JVM","slug":"JVM","link":"/tags/JVM/"},{"name":"日语","slug":"日语","link":"/tags/日语/"},{"name":"倒排索引","slug":"倒排索引","link":"/tags/倒排索引/"},{"name":"多线程","slug":"多线程","link":"/tags/多线程/"},{"name":"JDK7 源码","slug":"JDK7-源码","link":"/tags/JDK7-源码/"},{"name":"JMM","slug":"JMM","link":"/tags/JMM/"},{"name":"JDK8 源码","slug":"JDK8-源码","link":"/tags/JDK8-源码/"},{"name":"工具","slug":"工具","link":"/tags/工具/"},{"name":"内存泄漏","slug":"内存泄漏","link":"/tags/内存泄漏/"},{"name":"MySQL","slug":"MySQL","link":"/tags/MySQL/"},{"name":"MyBatis","slug":"MyBatis","link":"/tags/MyBatis/"},{"name":"MongoDB","slug":"MongoDB","link":"/tags/MongoDB/"},{"name":"数据库","slug":"数据库","link":"/tags/数据库/"},{"name":"推荐","slug":"推荐","link":"/tags/推荐/"},{"name":"机器学习","slug":"机器学习","link":"/tags/机器学习/"},{"name":"Android","slug":"Android","link":"/tags/Android/"},{"name":"分治法","slug":"分治法","link":"/tags/分治法/"},{"name":"动态规划","slug":"动态规划","link":"/tags/动态规划/"},{"name":"Think In Java","slug":"Think-In-Java","link":"/tags/Think-In-Java/"},{"name":"跳表","slug":"跳表","link":"/tags/跳表/"},{"name":"Mongodb","slug":"Mongodb","link":"/tags/Mongodb/"},{"name":"Redis","slug":"Redis","link":"/tags/Redis/"},{"name":"数学","slug":"数学","link":"/tags/数学/"},{"name":"线程安全","slug":"线程安全","link":"/tags/线程安全/"},{"name":"Tomcat","slug":"Tomcat","link":"/tags/Tomcat/"},{"name":"排序算法","slug":"排序算法","link":"/tags/排序算法/"},{"name":"Ubuntu","slug":"Ubuntu","link":"/tags/Ubuntu/"}],"categories":[{"name":"JDK6 源码","slug":"JDK6-源码","link":"/categories/JDK6-源码/"},{"name":"Java","slug":"Java","link":"/categories/Java/"},{"name":"计算机基础","slug":"计算机基础","link":"/categories/计算机基础/"},{"name":"算法","slug":"算法","link":"/categories/算法/"},{"name":"Spring","slug":"Spring","link":"/categories/Spring/"},{"name":"Linux","slug":"Linux","link":"/categories/Linux/"},{"name":"并发","slug":"并发","link":"/categories/并发/"},{"name":"开源项目","slug":"开源项目","link":"/categories/开源项目/"},{"name":"书","slug":"书","link":"/categories/书/"},{"name":"设计模式","slug":"设计模式","link":"/categories/设计模式/"},{"name":"数据结构","slug":"数据结构","link":"/categories/数据结构/"},{"name":"面试","slug":"面试","link":"/categories/面试/"},{"name":"JVM","slug":"JVM","link":"/categories/JVM/"},{"name":"日语","slug":"日语","link":"/categories/日语/"},{"name":"多线程","slug":"多线程","link":"/categories/多线程/"},{"name":"JDK7 源码","slug":"JDK7-源码","link":"/categories/JDK7-源码/"},{"name":"JMM","slug":"JMM","link":"/categories/JMM/"},{"name":"JDK8 源码","slug":"JDK8-源码","link":"/categories/JDK8-源码/"},{"name":"MySQL","slug":"MySQL","link":"/categories/MySQL/"},{"name":"MyBatis","slug":"MyBatis","link":"/categories/MyBatis/"},{"name":"数据库","slug":"数据库","link":"/categories/数据库/"},{"name":"机器学习","slug":"机器学习","link":"/categories/机器学习/"},{"name":"Android","slug":"Android","link":"/categories/Android/"},{"name":"Redis","slug":"Redis","link":"/categories/Redis/"},{"name":"数学","slug":"数学","link":"/categories/数学/"},{"name":"Tomcat","slug":"Tomcat","link":"/categories/Tomcat/"}]}